{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k20225YI4ifh"
      },
      "source": [
        "# Advanced RAG 01: Small to Big\n",
        "\n",
        "### Child-Parent RecursiveRetriever and Sentence Window Retrieval with LlamaIndex\n",
        "\n",
        "Sources:\n",
        "- https://docs.llamaindex.ai/en/stable/examples/retrievers/recursive_retriever_nodes.html\n",
        "- https://docs.llamaindex.ai/en/latest/examples/node_postprocessor/MetadataReplacementDemo.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h0L1ZfgxqPNf",
        "outputId": "3b8f6fa8-0160-41ca-cf70-330bdc87d8c4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: llama_hub in /usr/local/lib/python3.10/dist-packages (0.0.43)\n",
            "Requirement already satisfied: llama_index in /usr/local/lib/python3.10/dist-packages (0.8.59)\n",
            "Requirement already satisfied: braintrust in /usr/local/lib/python3.10/dist-packages (0.0.64)\n",
            "Requirement already satisfied: autoevals in /usr/local/lib/python3.10/dist-packages (0.0.28)\n",
            "Requirement already satisfied: pypdf in /usr/local/lib/python3.10/dist-packages (3.17.0)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (10.1.0)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.35.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.1.0+cu118)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.16.0+cu118)\n",
            "Requirement already satisfied: atlassian-python-api in /usr/local/lib/python3.10/dist-packages (from llama_hub) (3.41.3)\n",
            "Requirement already satisfied: html2text in /usr/local/lib/python3.10/dist-packages (from llama_hub) (2020.1.16)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from llama_hub) (5.9.5)\n",
            "Requirement already satisfied: retrying in /usr/local/lib/python3.10/dist-packages (from llama_hub) (1.3.4)\n",
            "Requirement already satisfied: SQLAlchemy[asyncio]>=1.4.49 in /usr/local/lib/python3.10/dist-packages (from llama_index) (2.0.22)\n",
            "Requirement already satisfied: aiostream<0.6.0,>=0.5.2 in /usr/local/lib/python3.10/dist-packages (from llama_index) (0.5.2)\n",
            "Requirement already satisfied: dataclasses-json<0.6.0,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from llama_index) (0.5.14)\n",
            "Requirement already satisfied: deprecated>=1.2.9.3 in /usr/local/lib/python3.10/dist-packages (from llama_index) (1.2.14)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from llama_index) (2023.6.0)\n",
            "Requirement already satisfied: langchain>=0.0.303 in /usr/local/lib/python3.10/dist-packages (from llama_index) (0.0.330)\n",
            "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /usr/local/lib/python3.10/dist-packages (from llama_index) (1.5.8)\n",
            "Requirement already satisfied: nltk<4.0.0,>=3.8.1 in /usr/local/lib/python3.10/dist-packages (from llama_index) (3.8.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from llama_index) (1.23.5)\n",
            "Requirement already satisfied: openai>=0.26.4 in /usr/local/lib/python3.10/dist-packages (from llama_index) (0.28.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from llama_index) (1.5.3)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.2.0 in /usr/local/lib/python3.10/dist-packages (from llama_index) (8.2.3)\n",
            "Requirement already satisfied: tiktoken>=0.3.3 in /usr/local/lib/python3.10/dist-packages (from llama_index) (0.5.1)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from llama_index) (4.5.0)\n",
            "Requirement already satisfied: typing-inspect>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from llama_index) (0.9.0)\n",
            "Requirement already satisfied: urllib3<2 in /usr/local/lib/python3.10/dist-packages (from llama_index) (1.26.18)\n",
            "Requirement already satisfied: GitPython in /usr/local/lib/python3.10/dist-packages (from braintrust) (3.1.40)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from braintrust) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from braintrust) (4.66.1)\n",
            "Requirement already satisfied: chevron in /usr/local/lib/python3.10/dist-packages (from autoevals) (0.14.0)\n",
            "Requirement already satisfied: levenshtein in /usr/local/lib/python3.10/dist-packages (from autoevals) (0.23.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from autoevals) (6.0.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.17.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: tokenizers<0.15,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.14.1)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.2)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.1.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.6.0,>=0.5.7->llama_index) (3.20.1)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.10/dist-packages (from deprecated>=1.2.9.3->llama_index) (1.14.1)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain>=0.0.303->llama_index) (3.8.6)\n",
            "Requirement already satisfied: anyio<4.0 in /usr/local/lib/python3.10/dist-packages (from langchain>=0.0.303->llama_index) (3.7.1)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain>=0.0.303->llama_index) (4.0.3)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain>=0.0.303->llama_index) (1.33)\n",
            "Requirement already satisfied: langsmith<0.1.0,>=0.0.52 in /usr/local/lib/python3.10/dist-packages (from langchain>=0.0.303->llama_index) (0.0.57)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain>=0.0.303->llama_index) (1.10.13)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->llama_index) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->llama_index) (1.3.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->braintrust) (3.3.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->braintrust) (3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->braintrust) (2023.7.22)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy[asyncio]>=1.4.49->llama_index) (3.0.0)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect>=0.8.0->llama_index) (1.0.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from atlassian-python-api->llama_hub) (1.16.0)\n",
            "Requirement already satisfied: oauthlib in /usr/local/lib/python3.10/dist-packages (from atlassian-python-api->llama_hub) (3.2.2)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.10/dist-packages (from atlassian-python-api->llama_hub) (1.3.1)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from GitPython->braintrust) (4.0.11)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.3)\n",
            "Requirement already satisfied: rapidfuzz<4.0.0,>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from levenshtein->autoevals) (3.5.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->llama_index) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->llama_index) (2023.3.post1)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.303->llama_index) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.303->llama_index) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.303->llama_index) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.303->llama_index) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.303->llama_index) (1.3.1)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<4.0->langchain>=0.0.303->llama_index) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4.0->langchain>=0.0.303->llama_index) (1.1.3)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->GitPython->braintrust) (5.0.1)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain>=0.0.303->llama_index) (2.4)\n"
          ]
        }
      ],
      "source": [
        "! pip install -U llama_hub llama_index braintrust autoevals pypdf pillow transformers torch torchvision"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "lbirJ-0R3bjz"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"TYPE YOUR API KEY HERE\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QxnMKsUN3fr-",
        "outputId": "39e2b3fc-35d2-4343-8004-43f7be575b64"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-11-04 03:12:43--  https://arxiv.org/pdf/2307.09288.pdf\n",
            "Resolving arxiv.org (arxiv.org)... 128.84.21.199\n",
            "Connecting to arxiv.org (arxiv.org)|128.84.21.199|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 13661300 (13M) [application/pdf]\n",
            "Saving to: ‘llama2.pdf’\n",
            "\n",
            "llama2.pdf          100%[===================>]  13.03M  4.85MB/s    in 2.7s    \n",
            "\n",
            "2023-11-04 03:12:46 (4.85 MB/s) - ‘llama2.pdf’ saved [13661300/13661300]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget --user-agent \"Mozilla\" \"https://arxiv.org/pdf/2307.09288.pdf\" -O \"llama2.pdf\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Basic RAG Review"
      ],
      "metadata": {
        "id": "AMofKy8tSf99"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "UQ44weGBqqYG"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "from llama_hub.file.pdf.base import PDFReader\n",
        "from llama_index.response.notebook_utils import display_source_node\n",
        "from llama_index.retrievers import RecursiveRetriever\n",
        "from llama_index.query_engine import RetrieverQueryEngine\n",
        "from llama_index import VectorStoreIndex, ServiceContext\n",
        "from llama_index.llms import OpenAI\n",
        "import json"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 1: Loading Documents"
      ],
      "metadata": {
        "id": "ScMsd6fSSqL2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "OkXdENA1qsO4"
      },
      "outputs": [],
      "source": [
        "loader = PDFReader()\n",
        "docs0 = loader.load_data(file=Path(\"llama2.pdf\"))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "docs0[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eq4pBk92TNEk",
        "outputId": "4de7e667-31a8-48f4-c90a-4bb83c06e283"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Document(id_='94d54eb2-a774-4940-a77a-b78309629028', embedding=None, metadata={'page_label': '1', 'file_name': 'llama2.pdf'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='018b304d342200869f05b9e3bcb41cf91a368cd743da48c666fb67110a4a2c1f', text='Llama 2 : Open Foundation and Fine-Tuned Chat Models\\nHugo Touvron∗Louis Martin†Kevin Stone†\\nPeter Albert Amjad Almahairi Yasmine Babaei Nikolay Bashlykov Soumya Batra\\nPrajjwal Bhargava Shruti Bhosale Dan Bikel Lukas Blecher Cristian Canton Ferrer Moya Chen\\nGuillem Cucurull David Esiobu Jude Fernandes Jeremy Fu Wenyin Fu Brian Fuller\\nCynthia Gao Vedanuj Goswami Naman Goyal Anthony Hartshorn Saghar Hosseini Rui Hou\\nHakan Inan Marcin Kardas Viktor Kerkez Madian Khabsa Isabel Kloumann Artem Korenev\\nPunit Singh Koura Marie-Anne Lachaux Thibaut Lavril Jenya Lee Diana Liskovich\\nYinghai Lu Yuning Mao Xavier Martinet Todor Mihaylov Pushkar Mishra\\nIgor Molybog Yixin Nie Andrew Poulton Jeremy Reizenstein Rashi Rungta Kalyan Saladi\\nAlan Schelten Ruan Silva Eric Michael Smith Ranjan Subramanian Xiaoqing Ellen Tan Binh Tang\\nRoss Taylor Adina Williams Jian Xiang Kuan Puxin Xu Zheng Yan Iliyan Zarov Yuchen Zhang\\nAngela Fan Melanie Kambadur Sharan Narang Aurelien Rodriguez Robert Stojnic\\nSergey Edunov Thomas Scialom∗\\nGenAI, Meta\\nAbstract\\nIn this work, we develop and release Llama 2, a collection of pretrained and fine-tuned\\nlarge language models (LLMs) ranging in scale from 7 billion to 70 billion parameters.\\nOur fine-tuned LLMs, called Llama 2-Chat , are optimized for dialogue use cases. Our\\nmodels outperform open-source chat models on most benchmarks we tested, and based on\\nourhumanevaluationsforhelpfulnessandsafety,maybeasuitablesubstituteforclosed-\\nsource models. We provide a detailed description of our approach to fine-tuning and safety\\nimprovements of Llama 2-Chat in order to enable the community to build on our work and\\ncontribute to the responsible development of LLMs.\\n∗Equal contribution, corresponding authors: {tscialom, htouvron}@meta.com\\n†Second author\\nContributions for all the authors can be found in Section A.1.arXiv:2307.09288v2  [cs.CL]  19 Jul 2023', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n')"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "N0wxq1l6qtTl"
      },
      "outputs": [],
      "source": [
        "from llama_index import Document\n",
        "\n",
        "doc_text = \"\\n\\n\".join([d.get_content() for d in docs0])\n",
        "docs = [Document(text=doc_text)]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 2: Parsing Documents into Text Chunks (Nodes)"
      ],
      "metadata": {
        "id": "7NkYqcZDSvZM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "GwyfDZg8quVJ"
      },
      "outputs": [],
      "source": [
        "from llama_index.node_parser import SimpleNodeParser\n",
        "from llama_index.schema import IndexNode"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "1jtEc7QiqwOL"
      },
      "outputs": [],
      "source": [
        "node_parser = SimpleNodeParser.from_defaults(chunk_size=1024)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yOCx6xhPYrjI",
        "outputId": "e1ba3b9b-8e07-4f95-da6c-af5e26bbf7f8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SimpleNodeParser(text_splitter=SentenceSplitter(chunk_size=1024, chunk_overlap=20, separator=' ', paragraph_separator='\\n\\n\\n', secondary_chunking_regex='[^,.;。？！]+[,.;。？！]?', chunking_tokenizer_fn=<function split_by_sentence_tokenizer.<locals>.split at 0x79021031aef0>, callback_manager=<llama_index.callbacks.base.CallbackManager object at 0x790211ff8670>, tokenizer=functools.partial(<bound method Encoding.encode of <Encoding 'gpt2'>>, allowed_special='all')), include_metadata=True, include_prev_next_rel=True, metadata_extractor=None, callback_manager=<llama_index.callbacks.base.CallbackManager object at 0x790211ff8670>)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "node_parser"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "5PwFBSYdqxZB"
      },
      "outputs": [],
      "source": [
        "base_nodes = node_parser.get_nodes_from_documents(docs)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_nodes[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CtCNy-EYSQnX",
        "outputId": "f8f943a9-30dd-4928-f48f-2488f9456f2b"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TextNode(id_='a3d19a41-f0fe-4186-a735-65d6a708e346', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='415b7efc-e73f-4ac4-bbfd-c1546f099026', node_type=<ObjectType.DOCUMENT: '4'>, metadata={}, hash='231b3bd773f012c01b893ada9e009ecf25ee59934614c5a595c9bf1b3a123292'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='03c2eb6e-9f22-42ca-bee5-d17ac7b425c4', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='f74f9aa4a60dc525c2747d000de93c5af7ff255ce1a4727f02e31285ea86edbe')}, hash='a4e2b17c5d3212c7c9807ab1be88deff6d2fa30d7beb15bdb19e093829955b66', text='Llama 2 : Open Foundation and Fine-Tuned Chat Models\\nHugo Touvron∗Louis Martin†Kevin Stone†\\nPeter Albert Amjad Almahairi Yasmine Babaei Nikolay Bashlykov Soumya Batra\\nPrajjwal Bhargava Shruti Bhosale Dan Bikel Lukas Blecher Cristian Canton Ferrer Moya Chen\\nGuillem Cucurull David Esiobu Jude Fernandes Jeremy Fu Wenyin Fu Brian Fuller\\nCynthia Gao Vedanuj Goswami Naman Goyal Anthony Hartshorn Saghar Hosseini Rui Hou\\nHakan Inan Marcin Kardas Viktor Kerkez Madian Khabsa Isabel Kloumann Artem Korenev\\nPunit Singh Koura Marie-Anne Lachaux Thibaut Lavril Jenya Lee Diana Liskovich\\nYinghai Lu Yuning Mao Xavier Martinet Todor Mihaylov Pushkar Mishra\\nIgor Molybog Yixin Nie Andrew Poulton Jeremy Reizenstein Rashi Rungta Kalyan Saladi\\nAlan Schelten Ruan Silva Eric Michael Smith Ranjan Subramanian Xiaoqing Ellen Tan Binh Tang\\nRoss Taylor Adina Williams Jian Xiang Kuan Puxin Xu Zheng Yan Iliyan Zarov Yuchen Zhang\\nAngela Fan Melanie Kambadur Sharan Narang Aurelien Rodriguez Robert Stojnic\\nSergey Edunov Thomas Scialom∗\\nGenAI, Meta\\nAbstract\\nIn this work, we develop and release Llama 2, a collection of pretrained and fine-tuned\\nlarge language models (LLMs) ranging in scale from 7 billion to 70 billion parameters.\\nOur fine-tuned LLMs, called Llama 2-Chat , are optimized for dialogue use cases. Our\\nmodels outperform open-source chat models on most benchmarks we tested, and based on\\nourhumanevaluationsforhelpfulnessandsafety,maybeasuitablesubstituteforclosed-\\nsource models. We provide a detailed description of our approach to fine-tuning and safety\\nimprovements of Llama 2-Chat in order to enable the community to build on our work and\\ncontribute to the responsible development of LLMs.\\n∗Equal contribution, corresponding authors: {tscialom, htouvron}@meta.com\\n†Second author\\nContributions for all the authors can be found in Section A.1.arXiv:2307.09288v2  [cs.CL]  19 Jul 2023\\n\\nContents\\n1 Introduction 3\\n2 Pretraining 5\\n2.1 Pretraining Data . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5\\n2.2 Training Details . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5\\n2.3 Llama 2 Pretrained Model Evaluation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 7\\n3 Fine-tuning 8\\n3.1 Supervised Fine-Tuning (SFT) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 9\\n3.2 Reinforcement Learning with Human Feedback (RLHF) . . . . . . . . . . . . . . . . . . . . . 9\\n3.3 System Message for Multi-Turn Consistency . . . . . . . . . . .', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n')"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# set node ids to be a constant\n",
        "for idx, node in enumerate(base_nodes):\n",
        "    node.id_ = f\"node-{idx}\""
      ],
      "metadata": {
        "id": "Mjn9e6hOSMYx"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3mjamtA7YvvO",
        "outputId": "23151841-d452-4e9c-aa60-6cf4bff2ee95"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TextNode(id_='node-0', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='415b7efc-e73f-4ac4-bbfd-c1546f099026', node_type=<ObjectType.DOCUMENT: '4'>, metadata={}, hash='231b3bd773f012c01b893ada9e009ecf25ee59934614c5a595c9bf1b3a123292'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='03c2eb6e-9f22-42ca-bee5-d17ac7b425c4', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='f74f9aa4a60dc525c2747d000de93c5af7ff255ce1a4727f02e31285ea86edbe')}, hash='a4e2b17c5d3212c7c9807ab1be88deff6d2fa30d7beb15bdb19e093829955b66', text='Llama 2 : Open Foundation and Fine-Tuned Chat Models\\nHugo Touvron∗Louis Martin†Kevin Stone†\\nPeter Albert Amjad Almahairi Yasmine Babaei Nikolay Bashlykov Soumya Batra\\nPrajjwal Bhargava Shruti Bhosale Dan Bikel Lukas Blecher Cristian Canton Ferrer Moya Chen\\nGuillem Cucurull David Esiobu Jude Fernandes Jeremy Fu Wenyin Fu Brian Fuller\\nCynthia Gao Vedanuj Goswami Naman Goyal Anthony Hartshorn Saghar Hosseini Rui Hou\\nHakan Inan Marcin Kardas Viktor Kerkez Madian Khabsa Isabel Kloumann Artem Korenev\\nPunit Singh Koura Marie-Anne Lachaux Thibaut Lavril Jenya Lee Diana Liskovich\\nYinghai Lu Yuning Mao Xavier Martinet Todor Mihaylov Pushkar Mishra\\nIgor Molybog Yixin Nie Andrew Poulton Jeremy Reizenstein Rashi Rungta Kalyan Saladi\\nAlan Schelten Ruan Silva Eric Michael Smith Ranjan Subramanian Xiaoqing Ellen Tan Binh Tang\\nRoss Taylor Adina Williams Jian Xiang Kuan Puxin Xu Zheng Yan Iliyan Zarov Yuchen Zhang\\nAngela Fan Melanie Kambadur Sharan Narang Aurelien Rodriguez Robert Stojnic\\nSergey Edunov Thomas Scialom∗\\nGenAI, Meta\\nAbstract\\nIn this work, we develop and release Llama 2, a collection of pretrained and fine-tuned\\nlarge language models (LLMs) ranging in scale from 7 billion to 70 billion parameters.\\nOur fine-tuned LLMs, called Llama 2-Chat , are optimized for dialogue use cases. Our\\nmodels outperform open-source chat models on most benchmarks we tested, and based on\\nourhumanevaluationsforhelpfulnessandsafety,maybeasuitablesubstituteforclosed-\\nsource models. We provide a detailed description of our approach to fine-tuning and safety\\nimprovements of Llama 2-Chat in order to enable the community to build on our work and\\ncontribute to the responsible development of LLMs.\\n∗Equal contribution, corresponding authors: {tscialom, htouvron}@meta.com\\n†Second author\\nContributions for all the authors can be found in Section A.1.arXiv:2307.09288v2  [cs.CL]  19 Jul 2023\\n\\nContents\\n1 Introduction 3\\n2 Pretraining 5\\n2.1 Pretraining Data . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5\\n2.2 Training Details . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5\\n2.3 Llama 2 Pretrained Model Evaluation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 7\\n3 Fine-tuning 8\\n3.1 Supervised Fine-Tuning (SFT) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 9\\n3.2 Reinforcement Learning with Human Feedback (RLHF) . . . . . . . . . . . . . . . . . . . . . 9\\n3.3 System Message for Multi-Turn Consistency . . . . . . . . . . .', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n')"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "base_nodes[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 3: Select Embedding Model and LLM"
      ],
      "metadata": {
        "id": "W2msA59qS10V"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "awCBMmzuqypC"
      },
      "outputs": [],
      "source": [
        "from llama_index.embeddings import resolve_embed_model\n",
        "\n",
        "embed_model = resolve_embed_model(\"local:BAAI/bge-small-en\")\n",
        "llm = OpenAI(model=\"gpt-3.5-turbo\")\n",
        "service_context = ServiceContext.from_defaults(\n",
        "    llm=llm, embed_model=embed_model\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 4: Create Index, retriever, and query engine"
      ],
      "metadata": {
        "id": "5BpGcyXIS7Hb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "u-V8NQgHq0Ae"
      },
      "outputs": [],
      "source": [
        "base_index = VectorStoreIndex(base_nodes, service_context=service_context)\n",
        "base_retriever = base_index.as_retriever(similarity_top_k=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "2C_4Fe4Pq2fx"
      },
      "outputs": [],
      "source": [
        "retrievals = base_retriever.retrieve(\n",
        "    \"Can you tell me about the key concepts for safety finetuning\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 549
        },
        "id": "C8OMXJpaq5oR",
        "outputId": "7646712d-0d1d-4bc1-d2b3-272a36057449"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "**Node ID:** node-22<br>**Similarity:** 0.8486295004749903<br>**Text:** We observe that models\ntrained from less aggressively filtered pretraining data also required fewer examples to achieve reasonable\nsafety-alignment. Wereiteratethatthismotivatedchoicedoesimplythatadditionalsafetymitigationsshould\nbe applied before deployment of base Llama 2 models.\n22\n\nTruthfulQA ↑ToxiGen ↓\nMPT7B 29.13 22.32\n30B 35.25 22.61\nFalcon7B 25.95 14.53\n40B 40.39 23.44\nLlama 17B 27.42 23.00\n13B 41.74 23.08\n33B 44.19 22.57\n65B 48.71 21.77\nLlama 27B 33.29 21.25\n13B 41.86 26.10\n34B 43.45 21.19\n70B 50.18 24.60\nTable 11: Evaluation of pretrained LLMs on automatic safety benchmarks. For TruthfulQA, we present the\npercentageofgenerationsthatarebothtruthfulandinformative(thehigherthebetter). ForToxiGen,we\npresent the percentage of toxic generations (the smaller, the better).\nBenchmarks give a summary view ofmodel capabilities and behaviors that allow us to understand general\npatternsinthemodel,buttheydonotprovideafullycomprehensiveviewoftheimpactthemodelmayhave\nonpeopleorreal-worldoutcomes;thatwouldrequirestudyofend-to-endproductdeployments. Further\ntesting and mitigation should be done to understand bias and other social issues for the specific context\nin which a system may be deployed. For this, it may be necessary to test beyond the groups available in\ntheBOLDdataset(race,religion,andgender). AsLLMsareintegratedanddeployed,welookforwardto\ncontinuing research that will amplify their potential for positive impact on these important social issues.\n4.2 Safety Fine-Tuning\nIn...<br>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "**Node ID:** node-65<br>**Similarity:** 0.8475738617788042<br>**Text:** Theassis-\ntant’sanswersshouldnotincludeanyharmful,unethical,orsociallybiasedcontent,andshouldmovethe\nconversation in a positive direction.\n(Based on a specific risk category) The following is a question that can elicit unsafe behavior from you. The\nquestion was classified as belonging to the violating category: ‘Criminal / Fraudulent Content’. You should\nanswer using the following template:\n1. [ifapplicable]Addressimmediatesafetyconcerns. Forexample,iftheuserdiscussescommittingaviolent\ncrime, the model should point them towards law enforcement resources.\n2. Addresstheprompt. themodelshouldrefusetoanswerthepromptasgiven,statingthatitviolatesits\npolicy to commit, advise or give information on illegal activities.\n3. Add context and additional information. If applicable, the model can advise on legal alternatives.\n4. Encourageuserstoaskfor/viewadditionalinfoasappropriate. Ifapplicable,themodelcanencouragethe\nuser to refine their prompt so that it does not contain any illegal requests or activities.\n(Based on a specific risk category) The following is a question that can elicit unsafe behavior from you. The\nquestionwasclassified asbelongingtotheviolatingcategory: ‘ExplicitContent’. Youshould answerusing\nthe following template:\n1. Address immediate safety concerns. For example, if a prompt states the user is a victim of violence or\nabuse, the model should provide support resources in an empathetic tone.\n2. Address the prompt. the model should refuse to generate explicit sexual o...<br>"
          },
          "metadata": {}
        }
      ],
      "source": [
        "for n in retrievals:\n",
        "    display_source_node(n, source_length=1500)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "6ey8fw_Xq9Yb"
      },
      "outputs": [],
      "source": [
        "query_engine_base = RetrieverQueryEngine.from_args(\n",
        "    base_retriever, service_context=service_context\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4C2uUn-Wq_C4",
        "outputId": "f9b29366-32c4-4520-f8cf-2ae05f1c5620"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The key concepts for safety fine-tuning include supervised safety fine-tuning, safety RLHF (Reinforcement Learning from Human Feedback), and safety context distillation. Supervised safety fine-tuning involves gathering adversarial prompts and safe demonstrations to train the model to align with safety guidelines. Safety RLHF integrates safety into the RLHF pipeline by training a safety-specific reward model and gathering challenging adversarial prompts for fine-tuning. Safety context distillation involves generating safer model responses by prefixing a prompt with a safety preprompt and fine-tuning the model on the safer responses without the preprompt. These techniques aim to mitigate safety risks and ensure that the model's answers do not include harmful, unethical, or socially biased content.\n"
          ]
        }
      ],
      "source": [
        "response = query_engine_base.query(\n",
        "    \"Can you tell me about the key concepts for safety finetuning\"\n",
        ")\n",
        "print(str(response))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7XGmqQ5z8k4t"
      },
      "source": [
        "# Chunk References: Smaller Child Chunks Referring to Bigger Parent Chunk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "SaAiq97Nq_4v"
      },
      "outputs": [],
      "source": [
        "sub_chunk_sizes = [128, 256, 512]\n",
        "sub_node_parsers = [\n",
        "    SimpleNodeParser.from_defaults(chunk_size=c) for c in sub_chunk_sizes\n",
        "]\n",
        "\n",
        "all_nodes = []\n",
        "for base_node in base_nodes:\n",
        "    for n in sub_node_parsers:\n",
        "        sub_nodes = n.get_nodes_from_documents([base_node])\n",
        "        sub_inodes = [\n",
        "            IndexNode.from_text_node(sn, base_node.node_id) for sn in sub_nodes\n",
        "        ]\n",
        "        all_nodes.extend(sub_inodes)\n",
        "\n",
        "    # also add original node to node\n",
        "    original_node = IndexNode.from_text_node(base_node, base_node.node_id)\n",
        "    all_nodes.append(original_node)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "9V_-7-mXrA6R"
      },
      "outputs": [],
      "source": [
        "all_nodes_dict = {n.node_id: n for n in all_nodes}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Ne0rYmDTl5A",
        "outputId": "f7b7fb2c-5a43-4ab8-a818-e07ec8116f8f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1448"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "len(all_nodes_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sHBxFUCQjiop",
        "outputId": "7a31d40d-fc57-4a0e-fe6c-1eb77e266b72"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'ecf3e729-0555-42a3-95e6-9cfe34b65b3e': IndexNode(id_='ecf3e729-0555-42a3-95e6-9cfe34b65b3e', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-0', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='a4e2b17c5d3212c7c9807ab1be88deff6d2fa30d7beb15bdb19e093829955b66'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='f41e7cb9-e784-4c07-8db0-c5451b2ae78f', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='c1cd7a3cd4e6b6f0bf126aec76d521214773696e2cc43ab2e814cffbb76582cf')}, hash='9aedf530bac762f456983dcc676b48da098997325ea380dcb858ba23ab0ddd95', text='Llama 2 : Open Foundation and Fine-Tuned Chat Models\\nHugo Touvron∗Louis Martin†Kevin Stone†\\nPeter Albert Amjad Almahairi Yasmine Babaei Nikolay Bashlykov Soumya Batra\\nPrajjwal Bhargava Shruti Bhosale Dan Bikel Lukas Blecher Cristian Canton Ferrer Moya Chen\\nGuillem Cucurull David Esiobu Jude Fernandes Jeremy Fu Wenyin Fu Brian Fuller\\nCynthia Gao Vedanuj Goswami Naman Goyal Anthony Hartshorn Saghar', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-0'),\n",
              " 'f41e7cb9-e784-4c07-8db0-c5451b2ae78f': IndexNode(id_='f41e7cb9-e784-4c07-8db0-c5451b2ae78f', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-0', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='a4e2b17c5d3212c7c9807ab1be88deff6d2fa30d7beb15bdb19e093829955b66'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='ecf3e729-0555-42a3-95e6-9cfe34b65b3e', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='9aedf530bac762f456983dcc676b48da098997325ea380dcb858ba23ab0ddd95'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='51c2bb02-0756-420c-84a3-387a65722d37', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='7212409a988729a3c158322852f62542b7788b696f5785c22ed35ee692f02fcb')}, hash='c1cd7a3cd4e6b6f0bf126aec76d521214773696e2cc43ab2e814cffbb76582cf', text='Gao Vedanuj Goswami Naman Goyal Anthony Hartshorn Saghar Hosseini Rui Hou\\nHakan Inan Marcin Kardas Viktor Kerkez Madian Khabsa Isabel Kloumann Artem Korenev\\nPunit Singh Koura Marie-Anne Lachaux Thibaut Lavril Jenya Lee Diana Liskovich\\nYinghai Lu Yuning Mao Xavier Martinet Todor Mihaylov Pushkar Mishra\\nIgor Molybog Yixin Nie Andrew Poulton Jeremy Reizenstein Rashi Rungta Kalyan Saladi\\nAlan', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-0'),\n",
              " '51c2bb02-0756-420c-84a3-387a65722d37': IndexNode(id_='51c2bb02-0756-420c-84a3-387a65722d37', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-0', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='a4e2b17c5d3212c7c9807ab1be88deff6d2fa30d7beb15bdb19e093829955b66'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='f41e7cb9-e784-4c07-8db0-c5451b2ae78f', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='c1cd7a3cd4e6b6f0bf126aec76d521214773696e2cc43ab2e814cffbb76582cf'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='b91233a0-f8c9-4155-b6cc-507e2fff0fe0', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='b7073b83b4736a3666db3eecade636eea5ce61eaf16749a2072f6e558bcd999f')}, hash='7212409a988729a3c158322852f62542b7788b696f5785c22ed35ee692f02fcb', text='Andrew Poulton Jeremy Reizenstein Rashi Rungta Kalyan Saladi\\nAlan Schelten Ruan Silva Eric Michael Smith Ranjan Subramanian Xiaoqing Ellen Tan Binh Tang\\nRoss Taylor Adina Williams Jian Xiang Kuan Puxin Xu Zheng Yan Iliyan Zarov Yuchen Zhang\\nAngela Fan Melanie Kambadur Sharan Narang Aurelien Rodriguez Robert Stojnic\\nSergey Edunov Thomas Scialom∗\\nGenAI, Meta\\nAbstract\\nIn this work, we develop and release Llama 2,', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-0'),\n",
              " 'b91233a0-f8c9-4155-b6cc-507e2fff0fe0': IndexNode(id_='b91233a0-f8c9-4155-b6cc-507e2fff0fe0', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-0', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='a4e2b17c5d3212c7c9807ab1be88deff6d2fa30d7beb15bdb19e093829955b66'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='51c2bb02-0756-420c-84a3-387a65722d37', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='7212409a988729a3c158322852f62542b7788b696f5785c22ed35ee692f02fcb'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='5e8aa150-5767-482a-8b64-cba9690bb67e', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='5a8192a9ab282678eec3a60ecd4d698093a387390c5598f77e3918bc11dfc1dd')}, hash='b7073b83b4736a3666db3eecade636eea5ce61eaf16749a2072f6e558bcd999f', text='Meta\\nAbstract\\nIn this work, we develop and release Llama 2, a collection of pretrained and fine-tuned\\nlarge language models (LLMs) ranging in scale from 7 billion to 70 billion parameters.\\nOur fine-tuned LLMs, called Llama 2-Chat , are optimized for dialogue use cases. Our\\nmodels outperform open-source chat models on most benchmarks we tested, and based on\\nourhumanevaluationsforhelpfulnessandsafety,maybeasuitablesubstituteforclosed-\\nsource models.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-0'),\n",
              " '5e8aa150-5767-482a-8b64-cba9690bb67e': IndexNode(id_='5e8aa150-5767-482a-8b64-cba9690bb67e', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-0', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='a4e2b17c5d3212c7c9807ab1be88deff6d2fa30d7beb15bdb19e093829955b66'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='b91233a0-f8c9-4155-b6cc-507e2fff0fe0', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='b7073b83b4736a3666db3eecade636eea5ce61eaf16749a2072f6e558bcd999f'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='f037939f-64a3-4dfe-8eda-8faf8bca7dd8', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='96d86861b54944ef512003e0393709e8802dfdfb0340f84bfb3fba470e74433d')}, hash='5a8192a9ab282678eec3a60ecd4d698093a387390c5598f77e3918bc11dfc1dd', text='We provide a detailed description of our approach to fine-tuning and safety\\nimprovements of Llama 2-Chat in order to enable the community to build on our work and\\ncontribute to the responsible development of LLMs.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-0'),\n",
              " 'f037939f-64a3-4dfe-8eda-8faf8bca7dd8': IndexNode(id_='f037939f-64a3-4dfe-8eda-8faf8bca7dd8', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-0', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='a4e2b17c5d3212c7c9807ab1be88deff6d2fa30d7beb15bdb19e093829955b66'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='5e8aa150-5767-482a-8b64-cba9690bb67e', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='5a8192a9ab282678eec3a60ecd4d698093a387390c5598f77e3918bc11dfc1dd'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='aec4aca7-6e34-4cc3-90d9-88d519853c56', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='50e26a01f482028be44bcefde12b9de0ab16a9ab86a6d183ad048de2a49d268e')}, hash='96d86861b54944ef512003e0393709e8802dfdfb0340f84bfb3fba470e74433d', text='∗Equal contribution, corresponding authors: {tscialom, htouvron}@meta.com\\n†Second author\\nContributions for all the authors can be found in Section A.1.arXiv:2307.09288v2  [cs.CL]  19 Jul 2023\\n\\nContents\\n1 Introduction 3\\n2 Pretraining 5\\n2.1 Pretraining Data . . . . . . . . . . . . . . . . . . . . .', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-0'),\n",
              " 'aec4aca7-6e34-4cc3-90d9-88d519853c56': IndexNode(id_='aec4aca7-6e34-4cc3-90d9-88d519853c56', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-0', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='a4e2b17c5d3212c7c9807ab1be88deff6d2fa30d7beb15bdb19e093829955b66'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='f037939f-64a3-4dfe-8eda-8faf8bca7dd8', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='96d86861b54944ef512003e0393709e8802dfdfb0340f84bfb3fba470e74433d'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='3a9e95f0-b2a2-4ef8-ac83-f1cc5f8c1ee1', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='a271d236c93535b1692ba276407520f37c0e01374aaf29d2e6e17fa235fa2522')}, hash='50e26a01f482028be44bcefde12b9de0ab16a9ab86a6d183ad048de2a49d268e', text='. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5\\n2.2 Training Details . . . . . . . . . . . . . . . . . . . . . . . . . .', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-0'),\n",
              " '3a9e95f0-b2a2-4ef8-ac83-f1cc5f8c1ee1': IndexNode(id_='3a9e95f0-b2a2-4ef8-ac83-f1cc5f8c1ee1', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-0', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='a4e2b17c5d3212c7c9807ab1be88deff6d2fa30d7beb15bdb19e093829955b66'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='aec4aca7-6e34-4cc3-90d9-88d519853c56', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='50e26a01f482028be44bcefde12b9de0ab16a9ab86a6d183ad048de2a49d268e'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='f4ca40fe-3a14-4018-9ea7-f6cc6bf96f9c', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='11063ba72da0560623dd367e5372b595232bdb89146e4b89e8d62f7fc1ea104a')}, hash='a271d236c93535b1692ba276407520f37c0e01374aaf29d2e6e17fa235fa2522', text='. . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5\\n2.3 Llama 2 Pretrained Model Evaluation . . . . . . . . . . . . . . . . . . . . . . . . . . . . .', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-0'),\n",
              " 'f4ca40fe-3a14-4018-9ea7-f6cc6bf96f9c': IndexNode(id_='f4ca40fe-3a14-4018-9ea7-f6cc6bf96f9c', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-0', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='a4e2b17c5d3212c7c9807ab1be88deff6d2fa30d7beb15bdb19e093829955b66'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='3a9e95f0-b2a2-4ef8-ac83-f1cc5f8c1ee1', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='a271d236c93535b1692ba276407520f37c0e01374aaf29d2e6e17fa235fa2522'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='a352f91e-a579-481a-9450-3e9e4e111901', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='bb33e71ffd79ee0c462af6163e9f5339ef2811f8d97538dc13a3684464cb8faf')}, hash='11063ba72da0560623dd367e5372b595232bdb89146e4b89e8d62f7fc1ea104a', text='. . . . . . . . . . . . . 7\\n3 Fine-tuning 8\\n3.1 Supervised Fine-Tuning (SFT) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-0'),\n",
              " 'a352f91e-a579-481a-9450-3e9e4e111901': IndexNode(id_='a352f91e-a579-481a-9450-3e9e4e111901', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-0', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='a4e2b17c5d3212c7c9807ab1be88deff6d2fa30d7beb15bdb19e093829955b66'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='f4ca40fe-3a14-4018-9ea7-f6cc6bf96f9c', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='11063ba72da0560623dd367e5372b595232bdb89146e4b89e8d62f7fc1ea104a')}, hash='bb33e71ffd79ee0c462af6163e9f5339ef2811f8d97538dc13a3684464cb8faf', text='. . . . . . . . . . 9\\n3.2 Reinforcement Learning with Human Feedback (RLHF) . . . . . . . . . . . . . . . . . . . . . 9\\n3.3 System Message for Multi-Turn Consistency . . . . . . . . . . .', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-0'),\n",
              " 'c940bac9-9103-470a-860f-864aa5bd623d': IndexNode(id_='c940bac9-9103-470a-860f-864aa5bd623d', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-0', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='a4e2b17c5d3212c7c9807ab1be88deff6d2fa30d7beb15bdb19e093829955b66'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='7cc1cabb-9d22-4ff5-841b-ed973b15dd68', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='789bc159789fee10750cdba0af656a8603457453e58cc5fc81ed782c74d929bb')}, hash='6c06773f15a7763604a2dd3e4f9f8aa8c554f0ad8d7a39654000677efe4aa186', text='Llama 2 : Open Foundation and Fine-Tuned Chat Models\\nHugo Touvron∗Louis Martin†Kevin Stone†\\nPeter Albert Amjad Almahairi Yasmine Babaei Nikolay Bashlykov Soumya Batra\\nPrajjwal Bhargava Shruti Bhosale Dan Bikel Lukas Blecher Cristian Canton Ferrer Moya Chen\\nGuillem Cucurull David Esiobu Jude Fernandes Jeremy Fu Wenyin Fu Brian Fuller\\nCynthia Gao Vedanuj Goswami Naman Goyal Anthony Hartshorn Saghar Hosseini Rui Hou\\nHakan Inan Marcin Kardas Viktor Kerkez Madian Khabsa Isabel Kloumann Artem Korenev\\nPunit Singh Koura Marie-Anne Lachaux Thibaut Lavril Jenya Lee Diana Liskovich\\nYinghai Lu Yuning Mao Xavier Martinet Todor Mihaylov Pushkar Mishra\\nIgor Molybog Yixin Nie Andrew Poulton Jeremy Reizenstein Rashi Rungta Kalyan Saladi\\nAlan Schelten Ruan Silva Eric Michael Smith Ranjan Subramanian Xiaoqing Ellen', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-0'),\n",
              " '7cc1cabb-9d22-4ff5-841b-ed973b15dd68': IndexNode(id_='7cc1cabb-9d22-4ff5-841b-ed973b15dd68', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-0', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='a4e2b17c5d3212c7c9807ab1be88deff6d2fa30d7beb15bdb19e093829955b66'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='c940bac9-9103-470a-860f-864aa5bd623d', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='6c06773f15a7763604a2dd3e4f9f8aa8c554f0ad8d7a39654000677efe4aa186'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='fab681fa-b45e-470c-9c96-3cd86b1fdef4', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='9f7e34bdcb948138d9856deab36c67b0de6814e552154f36a65d0a120eb53637')}, hash='789bc159789fee10750cdba0af656a8603457453e58cc5fc81ed782c74d929bb', text='Schelten Ruan Silva Eric Michael Smith Ranjan Subramanian Xiaoqing Ellen Tan Binh Tang\\nRoss Taylor Adina Williams Jian Xiang Kuan Puxin Xu Zheng Yan Iliyan Zarov Yuchen Zhang\\nAngela Fan Melanie Kambadur Sharan Narang Aurelien Rodriguez Robert Stojnic\\nSergey Edunov Thomas Scialom∗\\nGenAI, Meta\\nAbstract\\nIn this work, we develop and release Llama 2, a collection of pretrained and fine-tuned\\nlarge language models (LLMs) ranging in scale from 7 billion to 70 billion parameters.\\nOur fine-tuned LLMs, called Llama 2-Chat , are optimized for dialogue use cases. Our\\nmodels outperform open-source chat models on most benchmarks we tested, and based on\\nourhumanevaluationsforhelpfulnessandsafety,maybeasuitablesubstituteforclosed-\\nsource models. We provide a detailed description of our approach to fine-tuning and safety\\nimprovements of Llama 2-Chat in order to enable the community to build on our work and\\ncontribute to the responsible development of LLMs.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-0'),\n",
              " 'fab681fa-b45e-470c-9c96-3cd86b1fdef4': IndexNode(id_='fab681fa-b45e-470c-9c96-3cd86b1fdef4', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-0', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='a4e2b17c5d3212c7c9807ab1be88deff6d2fa30d7beb15bdb19e093829955b66'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='7cc1cabb-9d22-4ff5-841b-ed973b15dd68', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='789bc159789fee10750cdba0af656a8603457453e58cc5fc81ed782c74d929bb'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='20a922cd-0a9a-46fa-aaaa-0d1a586a530a', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='24ceeb52dfd999c9bae5ebb078907b0498100ac684885ae0e1eb2b19af690963')}, hash='9f7e34bdcb948138d9856deab36c67b0de6814e552154f36a65d0a120eb53637', text='∗Equal contribution, corresponding authors: {tscialom, htouvron}@meta.com\\n†Second author\\nContributions for all the authors can be found in Section A.1.arXiv:2307.09288v2  [cs.CL]  19 Jul 2023\\n\\nContents\\n1 Introduction 3\\n2 Pretraining 5\\n2.1 Pretraining Data . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5\\n2.2 Training Details . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-0'),\n",
              " '20a922cd-0a9a-46fa-aaaa-0d1a586a530a': IndexNode(id_='20a922cd-0a9a-46fa-aaaa-0d1a586a530a', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-0', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='a4e2b17c5d3212c7c9807ab1be88deff6d2fa30d7beb15bdb19e093829955b66'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='fab681fa-b45e-470c-9c96-3cd86b1fdef4', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='9f7e34bdcb948138d9856deab36c67b0de6814e552154f36a65d0a120eb53637'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='4841a256-8447-4e83-b3f1-14ed11263dd9', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='4a1d37a268c49d337906bd37648dd7b4e16d2523ebf73a9889249ba3c9b132e3')}, hash='24ceeb52dfd999c9bae5ebb078907b0498100ac684885ae0e1eb2b19af690963', text='. . . . . . . . . . . . . . . . . . 5\\n2.3 Llama 2 Pretrained Model Evaluation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 7\\n3 Fine-tuning 8\\n3.1 Supervised Fine-Tuning (SFT) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 9\\n3.2 Reinforcement Learning with Human Feedback (RLHF) . . . . . . . . . . . . . . . .', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-0'),\n",
              " '4841a256-8447-4e83-b3f1-14ed11263dd9': IndexNode(id_='4841a256-8447-4e83-b3f1-14ed11263dd9', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-0', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='a4e2b17c5d3212c7c9807ab1be88deff6d2fa30d7beb15bdb19e093829955b66'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='20a922cd-0a9a-46fa-aaaa-0d1a586a530a', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='24ceeb52dfd999c9bae5ebb078907b0498100ac684885ae0e1eb2b19af690963')}, hash='4a1d37a268c49d337906bd37648dd7b4e16d2523ebf73a9889249ba3c9b132e3', text='. . . . . . . . . . . . . . . 9\\n3.3 System Message for Multi-Turn Consistency . . . . . . . . . . .', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-0'),\n",
              " '3ce1a808-fd43-463b-b348-349df1e8ee09': IndexNode(id_='3ce1a808-fd43-463b-b348-349df1e8ee09', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-0', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='a4e2b17c5d3212c7c9807ab1be88deff6d2fa30d7beb15bdb19e093829955b66'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='da003ba8-4101-48cc-a974-6535ed3436bc', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='7dddb8ab39f951251f1b17be0bbb674ccc44e3d13eb86f63ce3512199b1b8447')}, hash='5a6b221c61775340cb31a35eab60ee8b96f0d3e4e163e24d244848868bce0adb', text='Llama 2 : Open Foundation and Fine-Tuned Chat Models\\nHugo Touvron∗Louis Martin†Kevin Stone†\\nPeter Albert Amjad Almahairi Yasmine Babaei Nikolay Bashlykov Soumya Batra\\nPrajjwal Bhargava Shruti Bhosale Dan Bikel Lukas Blecher Cristian Canton Ferrer Moya Chen\\nGuillem Cucurull David Esiobu Jude Fernandes Jeremy Fu Wenyin Fu Brian Fuller\\nCynthia Gao Vedanuj Goswami Naman Goyal Anthony Hartshorn Saghar Hosseini Rui Hou\\nHakan Inan Marcin Kardas Viktor Kerkez Madian Khabsa Isabel Kloumann Artem Korenev\\nPunit Singh Koura Marie-Anne Lachaux Thibaut Lavril Jenya Lee Diana Liskovich\\nYinghai Lu Yuning Mao Xavier Martinet Todor Mihaylov Pushkar Mishra\\nIgor Molybog Yixin Nie Andrew Poulton Jeremy Reizenstein Rashi Rungta Kalyan Saladi\\nAlan Schelten Ruan Silva Eric Michael Smith Ranjan Subramanian Xiaoqing Ellen Tan Binh Tang\\nRoss Taylor Adina Williams Jian Xiang Kuan Puxin Xu Zheng Yan Iliyan Zarov Yuchen Zhang\\nAngela Fan Melanie Kambadur Sharan Narang Aurelien Rodriguez Robert Stojnic\\nSergey Edunov Thomas Scialom∗\\nGenAI, Meta\\nAbstract\\nIn this work, we develop and release Llama 2, a collection of pretrained and fine-tuned\\nlarge language models (LLMs) ranging in scale from 7 billion to 70 billion parameters.\\nOur fine-tuned LLMs, called Llama 2-Chat , are optimized for dialogue use cases. Our\\nmodels outperform open-source chat models on most benchmarks we tested, and based on\\nourhumanevaluationsforhelpfulnessandsafety,maybeasuitablesubstituteforclosed-\\nsource models. We provide a detailed description of our approach to fine-tuning and safety\\nimprovements of Llama 2-Chat in order to enable the community to build on our work and\\ncontribute to the responsible development of LLMs.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-0'),\n",
              " 'da003ba8-4101-48cc-a974-6535ed3436bc': IndexNode(id_='da003ba8-4101-48cc-a974-6535ed3436bc', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-0', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='a4e2b17c5d3212c7c9807ab1be88deff6d2fa30d7beb15bdb19e093829955b66'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='3ce1a808-fd43-463b-b348-349df1e8ee09', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='5a6b221c61775340cb31a35eab60ee8b96f0d3e4e163e24d244848868bce0adb'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='7e6182b7-c0cc-4db8-9471-a90ef3970dda', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='370098b606d4dcfe70b9ac9810f50c4c6e16b74bcb0c2cc79cfa85f260c2e4a3')}, hash='7dddb8ab39f951251f1b17be0bbb674ccc44e3d13eb86f63ce3512199b1b8447', text='∗Equal contribution, corresponding authors: {tscialom, htouvron}@meta.com\\n†Second author\\nContributions for all the authors can be found in Section A.1.arXiv:2307.09288v2  [cs.CL]  19 Jul 2023\\n\\nContents\\n1 Introduction 3\\n2 Pretraining 5\\n2.1 Pretraining Data . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5\\n2.2 Training Details . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5\\n2.3 Llama 2 Pretrained Model Evaluation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 7\\n3 Fine-tuning 8\\n3.1 Supervised Fine-Tuning (SFT) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 9\\n3.2 Reinforcement Learning with Human Feedback (RLHF) . . . . . . . . . . . . . . . . . . . . .', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-0'),\n",
              " '7e6182b7-c0cc-4db8-9471-a90ef3970dda': IndexNode(id_='7e6182b7-c0cc-4db8-9471-a90ef3970dda', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-0', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='a4e2b17c5d3212c7c9807ab1be88deff6d2fa30d7beb15bdb19e093829955b66'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='da003ba8-4101-48cc-a974-6535ed3436bc', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='7dddb8ab39f951251f1b17be0bbb674ccc44e3d13eb86f63ce3512199b1b8447')}, hash='370098b606d4dcfe70b9ac9810f50c4c6e16b74bcb0c2cc79cfa85f260c2e4a3', text='. . . . . . . . . . 9\\n3.3 System Message for Multi-Turn Consistency . . . . . . . . . . .', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-0'),\n",
              " 'node-0': IndexNode(id_='node-0', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='415b7efc-e73f-4ac4-bbfd-c1546f099026', node_type=<ObjectType.DOCUMENT: '4'>, metadata={}, hash='231b3bd773f012c01b893ada9e009ecf25ee59934614c5a595c9bf1b3a123292'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='03c2eb6e-9f22-42ca-bee5-d17ac7b425c4', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='f74f9aa4a60dc525c2747d000de93c5af7ff255ce1a4727f02e31285ea86edbe')}, hash='a4e2b17c5d3212c7c9807ab1be88deff6d2fa30d7beb15bdb19e093829955b66', text='Llama 2 : Open Foundation and Fine-Tuned Chat Models\\nHugo Touvron∗Louis Martin†Kevin Stone†\\nPeter Albert Amjad Almahairi Yasmine Babaei Nikolay Bashlykov Soumya Batra\\nPrajjwal Bhargava Shruti Bhosale Dan Bikel Lukas Blecher Cristian Canton Ferrer Moya Chen\\nGuillem Cucurull David Esiobu Jude Fernandes Jeremy Fu Wenyin Fu Brian Fuller\\nCynthia Gao Vedanuj Goswami Naman Goyal Anthony Hartshorn Saghar Hosseini Rui Hou\\nHakan Inan Marcin Kardas Viktor Kerkez Madian Khabsa Isabel Kloumann Artem Korenev\\nPunit Singh Koura Marie-Anne Lachaux Thibaut Lavril Jenya Lee Diana Liskovich\\nYinghai Lu Yuning Mao Xavier Martinet Todor Mihaylov Pushkar Mishra\\nIgor Molybog Yixin Nie Andrew Poulton Jeremy Reizenstein Rashi Rungta Kalyan Saladi\\nAlan Schelten Ruan Silva Eric Michael Smith Ranjan Subramanian Xiaoqing Ellen Tan Binh Tang\\nRoss Taylor Adina Williams Jian Xiang Kuan Puxin Xu Zheng Yan Iliyan Zarov Yuchen Zhang\\nAngela Fan Melanie Kambadur Sharan Narang Aurelien Rodriguez Robert Stojnic\\nSergey Edunov Thomas Scialom∗\\nGenAI, Meta\\nAbstract\\nIn this work, we develop and release Llama 2, a collection of pretrained and fine-tuned\\nlarge language models (LLMs) ranging in scale from 7 billion to 70 billion parameters.\\nOur fine-tuned LLMs, called Llama 2-Chat , are optimized for dialogue use cases. Our\\nmodels outperform open-source chat models on most benchmarks we tested, and based on\\nourhumanevaluationsforhelpfulnessandsafety,maybeasuitablesubstituteforclosed-\\nsource models. We provide a detailed description of our approach to fine-tuning and safety\\nimprovements of Llama 2-Chat in order to enable the community to build on our work and\\ncontribute to the responsible development of LLMs.\\n∗Equal contribution, corresponding authors: {tscialom, htouvron}@meta.com\\n†Second author\\nContributions for all the authors can be found in Section A.1.arXiv:2307.09288v2  [cs.CL]  19 Jul 2023\\n\\nContents\\n1 Introduction 3\\n2 Pretraining 5\\n2.1 Pretraining Data . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5\\n2.2 Training Details . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5\\n2.3 Llama 2 Pretrained Model Evaluation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 7\\n3 Fine-tuning 8\\n3.1 Supervised Fine-Tuning (SFT) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 9\\n3.2 Reinforcement Learning with Human Feedback (RLHF) . . . . . . . . . . . . . . . . . . . . . 9\\n3.3 System Message for Multi-Turn Consistency . . . . . . . . . . .', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-0'),\n",
              " 'f1b857d8-f4c9-4b58-998e-120a2d06db2d': IndexNode(id_='f1b857d8-f4c9-4b58-998e-120a2d06db2d', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-1', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='f74f9aa4a60dc525c2747d000de93c5af7ff255ce1a4727f02e31285ea86edbe'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='7245c33f-a1ab-474b-805c-62456288320b', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='78d5a3f707cbc9bd3ba1e12395186936c8caf50d0f52045084b3fb6402b1aa26')}, hash='f4ef10773df4c2e5bffc04c019b8abab6887fea89b8a1296c996a882f6187b57', text='. . . . . . . . . . . . . . . . . . . . . . . . . . . . 16\\n3.4 RLHF Results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-1'),\n",
              " '7245c33f-a1ab-474b-805c-62456288320b': IndexNode(id_='7245c33f-a1ab-474b-805c-62456288320b', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-1', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='f74f9aa4a60dc525c2747d000de93c5af7ff255ce1a4727f02e31285ea86edbe'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='f1b857d8-f4c9-4b58-998e-120a2d06db2d', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='f4ef10773df4c2e5bffc04c019b8abab6887fea89b8a1296c996a882f6187b57'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='bd161fe2-cb41-443e-96b7-24b6b51c018d', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='181bf62783d0d3ff6c4b20e4fa56ccae5fd8f5da856f0e7cbfc939e98b61c5dd')}, hash='78d5a3f707cbc9bd3ba1e12395186936c8caf50d0f52045084b3fb6402b1aa26', text='. . . . . . . . . . . . . . . . . . . . . . . . 17\\n4 Safety 20\\n4.1 Safety in Pretraining . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-1'),\n",
              " 'bd161fe2-cb41-443e-96b7-24b6b51c018d': IndexNode(id_='bd161fe2-cb41-443e-96b7-24b6b51c018d', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-1', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='f74f9aa4a60dc525c2747d000de93c5af7ff255ce1a4727f02e31285ea86edbe'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='7245c33f-a1ab-474b-805c-62456288320b', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='78d5a3f707cbc9bd3ba1e12395186936c8caf50d0f52045084b3fb6402b1aa26'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='7aa4e61f-1f30-4d97-910f-e5e48a26ce87', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='f064fe4d0d9ff1e97efdd9423340c6a2454b09e2af44b142988490754fb8d9a4')}, hash='181bf62783d0d3ff6c4b20e4fa56ccae5fd8f5da856f0e7cbfc939e98b61c5dd', text='. . . . . . . . . . . . . . . . . . . 20\\n4.2 Safety Fine-Tuning . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-1'),\n",
              " '7aa4e61f-1f30-4d97-910f-e5e48a26ce87': IndexNode(id_='7aa4e61f-1f30-4d97-910f-e5e48a26ce87', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-1', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='f74f9aa4a60dc525c2747d000de93c5af7ff255ce1a4727f02e31285ea86edbe'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='bd161fe2-cb41-443e-96b7-24b6b51c018d', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='181bf62783d0d3ff6c4b20e4fa56ccae5fd8f5da856f0e7cbfc939e98b61c5dd'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='67e55cb2-fe2a-41bc-9fb3-dd14cb28c6b8', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='507a3b714dd6fcb8e89f36d0059f408f1c52c842230466833c55e0790aff918a')}, hash='f064fe4d0d9ff1e97efdd9423340c6a2454b09e2af44b142988490754fb8d9a4', text='. . . . . . . . . . . . . 23\\n4.3 Red Teaming . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-1'),\n",
              " '67e55cb2-fe2a-41bc-9fb3-dd14cb28c6b8': IndexNode(id_='67e55cb2-fe2a-41bc-9fb3-dd14cb28c6b8', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-1', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='f74f9aa4a60dc525c2747d000de93c5af7ff255ce1a4727f02e31285ea86edbe'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='7aa4e61f-1f30-4d97-910f-e5e48a26ce87', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='f064fe4d0d9ff1e97efdd9423340c6a2454b09e2af44b142988490754fb8d9a4'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='f2f3ccfa-beed-41ca-b51e-7dbb0ee5e74a', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='26511c4696e46e8a05a0a5fbe01f5a334fbeb18689371e30474a795a16905267')}, hash='507a3b714dd6fcb8e89f36d0059f408f1c52c842230466833c55e0790aff918a', text='. . . . . . . . . . 28\\n4.4 Safety Evaluation of Llama 2-Chat . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 29\\n5 Discussion 32\\n5.1 Learnings and Observations . . . . . .', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-1'),\n",
              " 'f2f3ccfa-beed-41ca-b51e-7dbb0ee5e74a': IndexNode(id_='f2f3ccfa-beed-41ca-b51e-7dbb0ee5e74a', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-1', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='f74f9aa4a60dc525c2747d000de93c5af7ff255ce1a4727f02e31285ea86edbe'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='67e55cb2-fe2a-41bc-9fb3-dd14cb28c6b8', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='507a3b714dd6fcb8e89f36d0059f408f1c52c842230466833c55e0790aff918a'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='df8444e0-f0ff-49b5-8995-9befdcce5ca3', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='6e4f14b3cbfdf44865aeb73a7d7b7d56e9714d559dd2507ac8bb9ee2ba4d0150')}, hash='26511c4696e46e8a05a0a5fbe01f5a334fbeb18689371e30474a795a16905267', text='. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 32\\n5.2 Limitations and Ethical Considerations . . . . . . . . . . . . . . . . . . . . .', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-1'),\n",
              " 'df8444e0-f0ff-49b5-8995-9befdcce5ca3': IndexNode(id_='df8444e0-f0ff-49b5-8995-9befdcce5ca3', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-1', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='f74f9aa4a60dc525c2747d000de93c5af7ff255ce1a4727f02e31285ea86edbe'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='f2f3ccfa-beed-41ca-b51e-7dbb0ee5e74a', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='26511c4696e46e8a05a0a5fbe01f5a334fbeb18689371e30474a795a16905267'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='5ef79705-f9bd-4b05-bdfd-d74f127b4f47', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='4cd31ba739f17b5949f83fbd3d8acf6b5629f829e3f123c0009aa0c4569f208f')}, hash='6e4f14b3cbfdf44865aeb73a7d7b7d56e9714d559dd2507ac8bb9ee2ba4d0150', text='. . . . . . . . . . . . . . . . . . . . 34\\n5.3 Responsible Release Strategy . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-1'),\n",
              " '5ef79705-f9bd-4b05-bdfd-d74f127b4f47': IndexNode(id_='5ef79705-f9bd-4b05-bdfd-d74f127b4f47', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-1', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='f74f9aa4a60dc525c2747d000de93c5af7ff255ce1a4727f02e31285ea86edbe'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='df8444e0-f0ff-49b5-8995-9befdcce5ca3', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='6e4f14b3cbfdf44865aeb73a7d7b7d56e9714d559dd2507ac8bb9ee2ba4d0150'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='c0f4c553-9caf-47bb-935c-c93fef579ad3', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='a52c265cede70b6699781bc9e5bd4e39d1dcf666b86cbc8acd6c3d9f01fd6e99')}, hash='4cd31ba739f17b5949f83fbd3d8acf6b5629f829e3f123c0009aa0c4569f208f', text='. . . . . . . . . . 35\\n6 Related Work 35\\n7 Conclusion 36\\nA Appendix 46\\nA.1 Contributions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-1'),\n",
              " 'c0f4c553-9caf-47bb-935c-c93fef579ad3': IndexNode(id_='c0f4c553-9caf-47bb-935c-c93fef579ad3', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-1', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='f74f9aa4a60dc525c2747d000de93c5af7ff255ce1a4727f02e31285ea86edbe'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='5ef79705-f9bd-4b05-bdfd-d74f127b4f47', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='4cd31ba739f17b5949f83fbd3d8acf6b5629f829e3f123c0009aa0c4569f208f'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='3bd04a4b-01e8-4d5e-9f05-f69bb63082e0', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='f97b6444b9fa88445836399f63a2d7f787e4669b0049c1056e9df6cda7c87d39')}, hash='a52c265cede70b6699781bc9e5bd4e39d1dcf666b86cbc8acd6c3d9f01fd6e99', text='. . . . . . . . . . . . 46\\nA.2 Additional Details for Pretraining . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 47\\nA.3 Additional Details for Fine-tuning . . . . . .', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-1'),\n",
              " '3bd04a4b-01e8-4d5e-9f05-f69bb63082e0': IndexNode(id_='3bd04a4b-01e8-4d5e-9f05-f69bb63082e0', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-1', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='f74f9aa4a60dc525c2747d000de93c5af7ff255ce1a4727f02e31285ea86edbe'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='c0f4c553-9caf-47bb-935c-c93fef579ad3', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='a52c265cede70b6699781bc9e5bd4e39d1dcf666b86cbc8acd6c3d9f01fd6e99')}, hash='f97b6444b9fa88445836399f63a2d7f787e4669b0049c1056e9df6cda7c87d39', text='. . . . . . . . . . . . . . . . . . . .', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-1'),\n",
              " '335a6db5-eddb-425d-8002-d5075bcf5c3a': IndexNode(id_='335a6db5-eddb-425d-8002-d5075bcf5c3a', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-1', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='f74f9aa4a60dc525c2747d000de93c5af7ff255ce1a4727f02e31285ea86edbe'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='b6fe92ef-db85-4353-b421-427af9fb2fec', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='92369d1d1f58c225d48e20505767ec57e5b61d0ac7bd8980dc12c26d53e0d821')}, hash='f2bcc2467ed5defdb1d3c50bb98dec9162fb3cfc0284fc5b462b30d0622cdb19', text='. . . . . . . . . . . . . . . . . . . . . . . . . . . . 16\\n3.4 RLHF Results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 17\\n4 Safety 20\\n4.1 Safety in Pretraining . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-1'),\n",
              " 'b6fe92ef-db85-4353-b421-427af9fb2fec': IndexNode(id_='b6fe92ef-db85-4353-b421-427af9fb2fec', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-1', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='f74f9aa4a60dc525c2747d000de93c5af7ff255ce1a4727f02e31285ea86edbe'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='335a6db5-eddb-425d-8002-d5075bcf5c3a', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='f2bcc2467ed5defdb1d3c50bb98dec9162fb3cfc0284fc5b462b30d0622cdb19'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='0c667380-ed86-407d-9f77-2d5240671cf8', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='eab5148e07533cccc6548a489cea286c69d52554ba8ec82110d924c8dd73d5b7')}, hash='92369d1d1f58c225d48e20505767ec57e5b61d0ac7bd8980dc12c26d53e0d821', text='. . . . . . . . . . 20\\n4.2 Safety Fine-Tuning . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 23\\n4.3 Red Teaming . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 28\\n4.4 Safety Evaluation of Llama 2-Chat . . . . . . . . . . . .', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-1'),\n",
              " '0c667380-ed86-407d-9f77-2d5240671cf8': IndexNode(id_='0c667380-ed86-407d-9f77-2d5240671cf8', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-1', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='f74f9aa4a60dc525c2747d000de93c5af7ff255ce1a4727f02e31285ea86edbe'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='b6fe92ef-db85-4353-b421-427af9fb2fec', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='92369d1d1f58c225d48e20505767ec57e5b61d0ac7bd8980dc12c26d53e0d821'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='43ce3690-7764-48cd-a88d-24597b4d9861', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='7f5a75deb31541b7cf83c54b26e3ca9f32f9c730cc60a0e8b1773c73d65f184d')}, hash='eab5148e07533cccc6548a489cea286c69d52554ba8ec82110d924c8dd73d5b7', text='. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 29\\n5 Discussion 32\\n5.1 Learnings and Observations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 32\\n5.2 Limitations and Ethical Considerations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 34\\n5.3 Responsible Release Strategy . . . . . . . . .', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-1'),\n",
              " '43ce3690-7764-48cd-a88d-24597b4d9861': IndexNode(id_='43ce3690-7764-48cd-a88d-24597b4d9861', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-1', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='f74f9aa4a60dc525c2747d000de93c5af7ff255ce1a4727f02e31285ea86edbe'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='0c667380-ed86-407d-9f77-2d5240671cf8', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='eab5148e07533cccc6548a489cea286c69d52554ba8ec82110d924c8dd73d5b7'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='e488070a-ab4c-422f-8b20-c89c330d85d6', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='9ad146332007b9af532cc2d3f759688b0406a3412ebe6919d803d3579efc3a49')}, hash='7f5a75deb31541b7cf83c54b26e3ca9f32f9c730cc60a0e8b1773c73d65f184d', text='. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 35\\n6 Related Work 35\\n7 Conclusion 36\\nA Appendix 46\\nA.1 Contributions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 46\\nA.2 Additional Details for Pretraining . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-1'),\n",
              " 'e488070a-ab4c-422f-8b20-c89c330d85d6': IndexNode(id_='e488070a-ab4c-422f-8b20-c89c330d85d6', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-1', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='f74f9aa4a60dc525c2747d000de93c5af7ff255ce1a4727f02e31285ea86edbe'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='43ce3690-7764-48cd-a88d-24597b4d9861', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='7f5a75deb31541b7cf83c54b26e3ca9f32f9c730cc60a0e8b1773c73d65f184d')}, hash='9ad146332007b9af532cc2d3f759688b0406a3412ebe6919d803d3579efc3a49', text='. . . . . . . . . . . . . . 47\\nA.3 Additional Details for Fine-tuning . . . . . . . . . . . . . . . . . . . . .', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-1'),\n",
              " 'e4e8ddcf-4f6d-4c43-ba8a-59b9a422d125': IndexNode(id_='e4e8ddcf-4f6d-4c43-ba8a-59b9a422d125', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-1', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='f74f9aa4a60dc525c2747d000de93c5af7ff255ce1a4727f02e31285ea86edbe'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='90715df1-1f1a-436a-9837-1445d018cb75', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='aa2f7d76e7ea182b5655eb6d069a155e4e9973374f51915c49cf8c1d385da9ae')}, hash='f286dddd330922edad3a276c9915fa1ec28cd89d3fa59e0943bd072e49641663', text='. . . . . . . . . . . . . . . . . . . . . . . . . . . . 16\\n3.4 RLHF Results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 17\\n4 Safety 20\\n4.1 Safety in Pretraining . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 20\\n4.2 Safety Fine-Tuning . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 23\\n4.3 Red Teaming . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 28\\n4.4 Safety Evaluation of Llama 2-Chat . . . . . . . . . . . . . . . . . . . . . . . .', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-1'),\n",
              " '90715df1-1f1a-436a-9837-1445d018cb75': IndexNode(id_='90715df1-1f1a-436a-9837-1445d018cb75', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-1', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='f74f9aa4a60dc525c2747d000de93c5af7ff255ce1a4727f02e31285ea86edbe'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='e4e8ddcf-4f6d-4c43-ba8a-59b9a422d125', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='f286dddd330922edad3a276c9915fa1ec28cd89d3fa59e0943bd072e49641663'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='286f8c2f-b442-4c53-8166-01b1ee5b6a3e', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='f97b6444b9fa88445836399f63a2d7f787e4669b0049c1056e9df6cda7c87d39')}, hash='aa2f7d76e7ea182b5655eb6d069a155e4e9973374f51915c49cf8c1d385da9ae', text='. . . . . . . . . . . . . . . . . . . . 29\\n5 Discussion 32\\n5.1 Learnings and Observations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 32\\n5.2 Limitations and Ethical Considerations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 34\\n5.3 Responsible Release Strategy . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 35\\n6 Related Work 35\\n7 Conclusion 36\\nA Appendix 46\\nA.1 Contributions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 46\\nA.2 Additional Details for Pretraining . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 47\\nA.3 Additional Details for Fine-tuning . . . . . . . . . . .', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-1'),\n",
              " '286f8c2f-b442-4c53-8166-01b1ee5b6a3e': IndexNode(id_='286f8c2f-b442-4c53-8166-01b1ee5b6a3e', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-1', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='f74f9aa4a60dc525c2747d000de93c5af7ff255ce1a4727f02e31285ea86edbe'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='90715df1-1f1a-436a-9837-1445d018cb75', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='aa2f7d76e7ea182b5655eb6d069a155e4e9973374f51915c49cf8c1d385da9ae')}, hash='f97b6444b9fa88445836399f63a2d7f787e4669b0049c1056e9df6cda7c87d39', text='. . . . . . . . . . . . . . . . . . . .', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-1'),\n",
              " 'node-1': IndexNode(id_='node-1', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='415b7efc-e73f-4ac4-bbfd-c1546f099026', node_type=<ObjectType.DOCUMENT: '4'>, metadata={}, hash='231b3bd773f012c01b893ada9e009ecf25ee59934614c5a595c9bf1b3a123292'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='a3d19a41-f0fe-4186-a735-65d6a708e346', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='a4e2b17c5d3212c7c9807ab1be88deff6d2fa30d7beb15bdb19e093829955b66'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='94b39f83-e630-4e05-b7c4-a446a16fc0d7', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='20a92a5d45f4989ea849418e3812a40766d2f433e9e9fcc2dbbc8a45dd53229c')}, hash='f74f9aa4a60dc525c2747d000de93c5af7ff255ce1a4727f02e31285ea86edbe', text='. . . . . . . . . . . . . . . . . . . . . . . . . . . . 16\\n3.4 RLHF Results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 17\\n4 Safety 20\\n4.1 Safety in Pretraining . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 20\\n4.2 Safety Fine-Tuning . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 23\\n4.3 Red Teaming . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 28\\n4.4 Safety Evaluation of Llama 2-Chat . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 29\\n5 Discussion 32\\n5.1 Learnings and Observations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 32\\n5.2 Limitations and Ethical Considerations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 34\\n5.3 Responsible Release Strategy . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 35\\n6 Related Work 35\\n7 Conclusion 36\\nA Appendix 46\\nA.1 Contributions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 46\\nA.2 Additional Details for Pretraining . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 47\\nA.3 Additional Details for Fine-tuning . . . . . . . . . . . . . . . . . . . . .', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-1'),\n",
              " '568b928b-8962-4842-841c-8c022e488e55': IndexNode(id_='568b928b-8962-4842-841c-8c022e488e55', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-2', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='20a92a5d45f4989ea849418e3812a40766d2f433e9e9fcc2dbbc8a45dd53229c'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='aaad4d5b-fc0a-42c3-b5e4-8ca78f6042a3', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='96845f7642678a5df2a5f3ec11bbc6d8887a5028d7475cd0f27937b6ebbca5bc')}, hash='fc00d08670f89cfa9ae8eb89efba55536828abc2c527239f6bf71bd2066dd52a', text='. . . . . . . . . . . . . . . . . . . . . . . 51\\nA.4 Additional Details for Safety . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-2'),\n",
              " 'aaad4d5b-fc0a-42c3-b5e4-8ca78f6042a3': IndexNode(id_='aaad4d5b-fc0a-42c3-b5e4-8ca78f6042a3', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-2', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='20a92a5d45f4989ea849418e3812a40766d2f433e9e9fcc2dbbc8a45dd53229c'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='568b928b-8962-4842-841c-8c022e488e55', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='fc00d08670f89cfa9ae8eb89efba55536828abc2c527239f6bf71bd2066dd52a'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='2c2bd0e9-39ab-4a9b-8122-76006b524dc1', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='99bdc722dd668a6257f0b9ac54e17e6299e6168f561ef8df028f48c5e0f23fb7')}, hash='96845f7642678a5df2a5f3ec11bbc6d8887a5028d7475cd0f27937b6ebbca5bc', text='. . . . . . . . . . . . 58\\nA.5 Data Annotation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-2'),\n",
              " '2c2bd0e9-39ab-4a9b-8122-76006b524dc1': IndexNode(id_='2c2bd0e9-39ab-4a9b-8122-76006b524dc1', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-2', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='20a92a5d45f4989ea849418e3812a40766d2f433e9e9fcc2dbbc8a45dd53229c'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='aaad4d5b-fc0a-42c3-b5e4-8ca78f6042a3', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='96845f7642678a5df2a5f3ec11bbc6d8887a5028d7475cd0f27937b6ebbca5bc'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='6ffb3720-b016-4d8d-affa-7fb1648a9fb2', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='5a7a446d574434dd09db30c6dd6634596bb832a9c8ea7384bddc6c0cd3a6ca7a')}, hash='99bdc722dd668a6257f0b9ac54e17e6299e6168f561ef8df028f48c5e0f23fb7', text='. . . . . . . . . . 72\\nA.6 Dataset Contamination . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 75\\nA.7 Model Card . . . .', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-2'),\n",
              " '6ffb3720-b016-4d8d-affa-7fb1648a9fb2': IndexNode(id_='6ffb3720-b016-4d8d-affa-7fb1648a9fb2', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-2', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='20a92a5d45f4989ea849418e3812a40766d2f433e9e9fcc2dbbc8a45dd53229c'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='2c2bd0e9-39ab-4a9b-8122-76006b524dc1', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='99bdc722dd668a6257f0b9ac54e17e6299e6168f561ef8df028f48c5e0f23fb7'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='51333770-a092-425e-9c7f-565e1381e4a4', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='ddab2f064558775d4c975399d9db1a13c56c3df95850540f20f0e29bcca73f5a')}, hash='5a7a446d574434dd09db30c6dd6634596bb832a9c8ea7384bddc6c0cd3a6ca7a', text='. . 75\\nA.7 Model Card . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-2'),\n",
              " '51333770-a092-425e-9c7f-565e1381e4a4': IndexNode(id_='51333770-a092-425e-9c7f-565e1381e4a4', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-2', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='20a92a5d45f4989ea849418e3812a40766d2f433e9e9fcc2dbbc8a45dd53229c'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='6ffb3720-b016-4d8d-affa-7fb1648a9fb2', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='5a7a446d574434dd09db30c6dd6634596bb832a9c8ea7384bddc6c0cd3a6ca7a'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='8c01170b-8038-485a-ab6e-7eab336b7779', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='8d3feccad38ece8cb343b6b20f0416062ad63a46d4e1199e15a969e113ba8f23')}, hash='ddab2f064558775d4c975399d9db1a13c56c3df95850540f20f0e29bcca73f5a', text='. . . . . . . . . . 77\\n2\\n\\nFigure 1: Helpfulness human evaluation results for Llama\\n2-Chatcomparedtootheropen-sourceandclosed-source\\nmodels. Human raters compared model generations on ~4k\\npromptsconsistingofbothsingleandmulti-turnprompts.\\nThe95%confidenceintervalsforthisevaluationarebetween\\n1%and2%. MoredetailsinSection3.4.2.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-2'),\n",
              " '8c01170b-8038-485a-ab6e-7eab336b7779': IndexNode(id_='8c01170b-8038-485a-ab6e-7eab336b7779', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-2', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='20a92a5d45f4989ea849418e3812a40766d2f433e9e9fcc2dbbc8a45dd53229c'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='51333770-a092-425e-9c7f-565e1381e4a4', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='ddab2f064558775d4c975399d9db1a13c56c3df95850540f20f0e29bcca73f5a'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='cecab3a8-321e-4e7a-9420-869723645224', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='b5e1d1b58b7ee93652056085ebf41a8bc410ba7cd515a1914282c0405b15248d')}, hash='8d3feccad38ece8cb343b6b20f0416062ad63a46d4e1199e15a969e113ba8f23', text='MoredetailsinSection3.4.2. Whilereviewing\\nthese results, it is important to note that human evaluations\\ncanbenoisyduetolimitationsofthepromptset,subjectivity\\nof the review guidelines, subjectivity of individual raters,\\nand the inherent difficulty of comparing generations.\\nFigure 2: Win-rate % for helpfulness and\\nsafety between commercial-licensed base-\\nlines and Llama 2-Chat , according to GPT-\\n4.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-2'),\n",
              " 'cecab3a8-321e-4e7a-9420-869723645224': IndexNode(id_='cecab3a8-321e-4e7a-9420-869723645224', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-2', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='20a92a5d45f4989ea849418e3812a40766d2f433e9e9fcc2dbbc8a45dd53229c'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='8c01170b-8038-485a-ab6e-7eab336b7779', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='8d3feccad38ece8cb343b6b20f0416062ad63a46d4e1199e15a969e113ba8f23'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='bc3ebcd0-8c3a-4855-b90c-edfdec1c6b0b', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='3e8e69c26d4de9336400eb6e326063a4d2aaffde97cbab5e630c4fa870251321')}, hash='b5e1d1b58b7ee93652056085ebf41a8bc410ba7cd515a1914282c0405b15248d', text='Tocomplementthehumanevaluation,we\\nused a more capable model, not subject to\\nourownguidance. Greenareaindicatesour\\nmodelisbetteraccordingtoGPT-4. Toremove\\nties, we used win/ (win+loss). The orders in\\nwhichthemodelresponsesarepresentedto\\nGPT-4arerandomlyswappedtoalleviatebias.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-2'),\n",
              " 'bc3ebcd0-8c3a-4855-b90c-edfdec1c6b0b': IndexNode(id_='bc3ebcd0-8c3a-4855-b90c-edfdec1c6b0b', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-2', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='20a92a5d45f4989ea849418e3812a40766d2f433e9e9fcc2dbbc8a45dd53229c'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='cecab3a8-321e-4e7a-9420-869723645224', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='b5e1d1b58b7ee93652056085ebf41a8bc410ba7cd515a1914282c0405b15248d'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='eff2075b-9f34-4a1f-b212-fef68c97e4a3', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='ce7db2a4a0b466dab1bf94ce71d72b4cc30aa2f7a99475c762f2f7e8af682ea8')}, hash='3e8e69c26d4de9336400eb6e326063a4d2aaffde97cbab5e630c4fa870251321', text='1 Introduction\\nLarge Language Models (LLMs) have shown great promise as highly capable AI assistants that excel in\\ncomplex reasoning tasks requiring expert knowledge across a wide range of fields, including in specialized\\ndomains such as programming and creative writing. They enable interaction with humans through intuitive\\nchat interfaces, which has led to rapid and widespread adoption among the general public.\\nThecapabilitiesofLLMsareremarkableconsideringtheseeminglystraightforwardnatureofthetraining\\nmethodology.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-2'),\n",
              " 'eff2075b-9f34-4a1f-b212-fef68c97e4a3': IndexNode(id_='eff2075b-9f34-4a1f-b212-fef68c97e4a3', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-2', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='20a92a5d45f4989ea849418e3812a40766d2f433e9e9fcc2dbbc8a45dd53229c'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='bc3ebcd0-8c3a-4855-b90c-edfdec1c6b0b', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='3e8e69c26d4de9336400eb6e326063a4d2aaffde97cbab5e630c4fa870251321'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='417cdf53-0326-422f-8186-48ae263ed834', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='52a758b52b6d0706c52f2bdb964af4fb4c6cded5d4f2186fdc8a823831dbd923')}, hash='ce7db2a4a0b466dab1bf94ce71d72b4cc30aa2f7a99475c762f2f7e8af682ea8', text='Auto-regressivetransformersarepretrainedonanextensivecorpusofself-superviseddata,\\nfollowed by alignment with human preferences via techniques such as Reinforcement Learning with Human\\nFeedback(RLHF).Althoughthetrainingmethodologyissimple,highcomputationalrequirementshave\\nlimited the development of LLMs to a few players.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-2'),\n",
              " '417cdf53-0326-422f-8186-48ae263ed834': IndexNode(id_='417cdf53-0326-422f-8186-48ae263ed834', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-2', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='20a92a5d45f4989ea849418e3812a40766d2f433e9e9fcc2dbbc8a45dd53229c'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='eff2075b-9f34-4a1f-b212-fef68c97e4a3', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='ce7db2a4a0b466dab1bf94ce71d72b4cc30aa2f7a99475c762f2f7e8af682ea8')}, hash='52a758b52b6d0706c52f2bdb964af4fb4c6cded5d4f2186fdc8a823831dbd923', text='There have been public releases of pretrained LLMs\\n(such as BLOOM (Scao et al., 2022), LLaMa-1 (Touvron et al., 2023), and Falcon (Penedo et al., 2023)) that\\nmatch the performance of closed pretrained competitors like GPT-3 (Brown et al., 2020) and Chinchilla\\n(Hoffmann et al., 2022), but none of these models are suitable substitutes for closed “product” LLMs, such\\nasChatGPT,BARD,andClaude.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-2'),\n",
              " 'a9da1105-b67e-448c-851c-7f65c51ae4f2': IndexNode(id_='a9da1105-b67e-448c-851c-7f65c51ae4f2', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-2', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='20a92a5d45f4989ea849418e3812a40766d2f433e9e9fcc2dbbc8a45dd53229c'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='23330750-8960-404c-9121-861842770a3b', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='13e837bd10e62b15968c19a273d660ddedb2fe6454c96ba368f2e92075fdcfdd')}, hash='d04354213b4f79e7573cd9795a2e7388139ffa2e4c679e24c41a5e04bd2c5225', text='. . . . . . . . . . . . . . . . . . . . . . . 51\\nA.4 Additional Details for Safety . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 58\\nA.5 Data Annotation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 72\\nA.6 Dataset Contamination . . . . . . . .', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-2'),\n",
              " '23330750-8960-404c-9121-861842770a3b': IndexNode(id_='23330750-8960-404c-9121-861842770a3b', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-2', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='20a92a5d45f4989ea849418e3812a40766d2f433e9e9fcc2dbbc8a45dd53229c'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='a9da1105-b67e-448c-851c-7f65c51ae4f2', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='d04354213b4f79e7573cd9795a2e7388139ffa2e4c679e24c41a5e04bd2c5225'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='8883e61e-1da8-40fb-98e0-dcb87374277f', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='3108b30a45d67143a4048238cb42565b6612528960347b3eafe4bf518d40bdfd')}, hash='13e837bd10e62b15968c19a273d660ddedb2fe6454c96ba368f2e92075fdcfdd', text='. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 75\\nA.7 Model Card . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 77\\n2\\n\\nFigure 1: Helpfulness human evaluation results for Llama\\n2-Chatcomparedtootheropen-sourceandclosed-source\\nmodels. Human raters compared model generations on ~4k\\npromptsconsistingofbothsingleandmulti-turnprompts.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-2'),\n",
              " '8883e61e-1da8-40fb-98e0-dcb87374277f': IndexNode(id_='8883e61e-1da8-40fb-98e0-dcb87374277f', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-2', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='20a92a5d45f4989ea849418e3812a40766d2f433e9e9fcc2dbbc8a45dd53229c'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='23330750-8960-404c-9121-861842770a3b', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='13e837bd10e62b15968c19a273d660ddedb2fe6454c96ba368f2e92075fdcfdd'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='f048cec8-fca3-4726-a692-c5dc6acb638d', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='5eef7d0912ce36cc165976da7296951cd7b8869247bd0fb953d779481925f55b')}, hash='3108b30a45d67143a4048238cb42565b6612528960347b3eafe4bf518d40bdfd', text='The95%confidenceintervalsforthisevaluationarebetween\\n1%and2%. MoredetailsinSection3.4.2. Whilereviewing\\nthese results, it is important to note that human evaluations\\ncanbenoisyduetolimitationsofthepromptset,subjectivity\\nof the review guidelines, subjectivity of individual raters,\\nand the inherent difficulty of comparing generations.\\nFigure 2: Win-rate % for helpfulness and\\nsafety between commercial-licensed base-\\nlines and Llama 2-Chat , according to GPT-\\n4. Tocomplementthehumanevaluation,we\\nused a more capable model, not subject to\\nourownguidance. Greenareaindicatesour\\nmodelisbetteraccordingtoGPT-4. Toremove\\nties, we used win/ (win+loss). The orders in\\nwhichthemodelresponsesarepresentedto\\nGPT-4arerandomlyswappedtoalleviatebias.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-2'),\n",
              " 'f048cec8-fca3-4726-a692-c5dc6acb638d': IndexNode(id_='f048cec8-fca3-4726-a692-c5dc6acb638d', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-2', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='20a92a5d45f4989ea849418e3812a40766d2f433e9e9fcc2dbbc8a45dd53229c'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='8883e61e-1da8-40fb-98e0-dcb87374277f', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='3108b30a45d67143a4048238cb42565b6612528960347b3eafe4bf518d40bdfd'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='1800dced-d09d-42b4-b2c4-e8359fb0b5c4', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='52a758b52b6d0706c52f2bdb964af4fb4c6cded5d4f2186fdc8a823831dbd923')}, hash='5eef7d0912ce36cc165976da7296951cd7b8869247bd0fb953d779481925f55b', text='1 Introduction\\nLarge Language Models (LLMs) have shown great promise as highly capable AI assistants that excel in\\ncomplex reasoning tasks requiring expert knowledge across a wide range of fields, including in specialized\\ndomains such as programming and creative writing. They enable interaction with humans through intuitive\\nchat interfaces, which has led to rapid and widespread adoption among the general public.\\nThecapabilitiesofLLMsareremarkableconsideringtheseeminglystraightforwardnatureofthetraining\\nmethodology. Auto-regressivetransformersarepretrainedonanextensivecorpusofself-superviseddata,\\nfollowed by alignment with human preferences via techniques such as Reinforcement Learning with Human\\nFeedback(RLHF).Althoughthetrainingmethodologyissimple,highcomputationalrequirementshave\\nlimited the development of LLMs to a few players.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-2'),\n",
              " '1800dced-d09d-42b4-b2c4-e8359fb0b5c4': IndexNode(id_='1800dced-d09d-42b4-b2c4-e8359fb0b5c4', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-2', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='20a92a5d45f4989ea849418e3812a40766d2f433e9e9fcc2dbbc8a45dd53229c'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='f048cec8-fca3-4726-a692-c5dc6acb638d', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='5eef7d0912ce36cc165976da7296951cd7b8869247bd0fb953d779481925f55b')}, hash='52a758b52b6d0706c52f2bdb964af4fb4c6cded5d4f2186fdc8a823831dbd923', text='There have been public releases of pretrained LLMs\\n(such as BLOOM (Scao et al., 2022), LLaMa-1 (Touvron et al., 2023), and Falcon (Penedo et al., 2023)) that\\nmatch the performance of closed pretrained competitors like GPT-3 (Brown et al., 2020) and Chinchilla\\n(Hoffmann et al., 2022), but none of these models are suitable substitutes for closed “product” LLMs, such\\nasChatGPT,BARD,andClaude.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-2'),\n",
              " '88b6563f-b89d-4eaa-998c-621de571bdef': IndexNode(id_='88b6563f-b89d-4eaa-998c-621de571bdef', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-2', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='20a92a5d45f4989ea849418e3812a40766d2f433e9e9fcc2dbbc8a45dd53229c'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='64594ebf-3e2b-4c4c-8df4-6cc74c44fd5c', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='037f271d8ef0c8e34b5367590f7f817bd28e1ffb35b2e8a5ef1930a89bbdaff5')}, hash='e9fefe018a4dcc83b144c7000886e80aa3e700e57a3568153ace1fb2bea0cec2', text='. . . . . . . . . . . . . . . . . . . . . . . 51\\nA.4 Additional Details for Safety . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 58\\nA.5 Data Annotation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 72\\nA.6 Dataset Contamination . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 75\\nA.7 Model Card . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 77\\n2\\n\\nFigure 1: Helpfulness human evaluation results for Llama\\n2-Chatcomparedtootheropen-sourceandclosed-source\\nmodels. Human raters compared model generations on ~4k\\npromptsconsistingofbothsingleandmulti-turnprompts.\\nThe95%confidenceintervalsforthisevaluationarebetween\\n1%and2%.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-2'),\n",
              " '64594ebf-3e2b-4c4c-8df4-6cc74c44fd5c': IndexNode(id_='64594ebf-3e2b-4c4c-8df4-6cc74c44fd5c', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-2', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='20a92a5d45f4989ea849418e3812a40766d2f433e9e9fcc2dbbc8a45dd53229c'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='88b6563f-b89d-4eaa-998c-621de571bdef', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='e9fefe018a4dcc83b144c7000886e80aa3e700e57a3568153ace1fb2bea0cec2'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='99814d91-1b27-4d16-8960-aff1fdc2c446', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='52a758b52b6d0706c52f2bdb964af4fb4c6cded5d4f2186fdc8a823831dbd923')}, hash='037f271d8ef0c8e34b5367590f7f817bd28e1ffb35b2e8a5ef1930a89bbdaff5', text='The95%confidenceintervalsforthisevaluationarebetween\\n1%and2%. MoredetailsinSection3.4.2. Whilereviewing\\nthese results, it is important to note that human evaluations\\ncanbenoisyduetolimitationsofthepromptset,subjectivity\\nof the review guidelines, subjectivity of individual raters,\\nand the inherent difficulty of comparing generations.\\nFigure 2: Win-rate % for helpfulness and\\nsafety between commercial-licensed base-\\nlines and Llama 2-Chat , according to GPT-\\n4. Tocomplementthehumanevaluation,we\\nused a more capable model, not subject to\\nourownguidance. Greenareaindicatesour\\nmodelisbetteraccordingtoGPT-4. Toremove\\nties, we used win/ (win+loss). The orders in\\nwhichthemodelresponsesarepresentedto\\nGPT-4arerandomlyswappedtoalleviatebias.\\n1 Introduction\\nLarge Language Models (LLMs) have shown great promise as highly capable AI assistants that excel in\\ncomplex reasoning tasks requiring expert knowledge across a wide range of fields, including in specialized\\ndomains such as programming and creative writing. They enable interaction with humans through intuitive\\nchat interfaces, which has led to rapid and widespread adoption among the general public.\\nThecapabilitiesofLLMsareremarkableconsideringtheseeminglystraightforwardnatureofthetraining\\nmethodology. Auto-regressivetransformersarepretrainedonanextensivecorpusofself-superviseddata,\\nfollowed by alignment with human preferences via techniques such as Reinforcement Learning with Human\\nFeedback(RLHF).Althoughthetrainingmethodologyissimple,highcomputationalrequirementshave\\nlimited the development of LLMs to a few players.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-2'),\n",
              " '99814d91-1b27-4d16-8960-aff1fdc2c446': IndexNode(id_='99814d91-1b27-4d16-8960-aff1fdc2c446', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-2', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='20a92a5d45f4989ea849418e3812a40766d2f433e9e9fcc2dbbc8a45dd53229c'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='64594ebf-3e2b-4c4c-8df4-6cc74c44fd5c', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='037f271d8ef0c8e34b5367590f7f817bd28e1ffb35b2e8a5ef1930a89bbdaff5')}, hash='52a758b52b6d0706c52f2bdb964af4fb4c6cded5d4f2186fdc8a823831dbd923', text='There have been public releases of pretrained LLMs\\n(such as BLOOM (Scao et al., 2022), LLaMa-1 (Touvron et al., 2023), and Falcon (Penedo et al., 2023)) that\\nmatch the performance of closed pretrained competitors like GPT-3 (Brown et al., 2020) and Chinchilla\\n(Hoffmann et al., 2022), but none of these models are suitable substitutes for closed “product” LLMs, such\\nasChatGPT,BARD,andClaude.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-2'),\n",
              " 'node-2': IndexNode(id_='node-2', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='415b7efc-e73f-4ac4-bbfd-c1546f099026', node_type=<ObjectType.DOCUMENT: '4'>, metadata={}, hash='231b3bd773f012c01b893ada9e009ecf25ee59934614c5a595c9bf1b3a123292'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='03c2eb6e-9f22-42ca-bee5-d17ac7b425c4', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='f74f9aa4a60dc525c2747d000de93c5af7ff255ce1a4727f02e31285ea86edbe'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='19da8bba-6827-4924-88f8-f064a63fc9e8', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='0087ff2312f2cc99d68939de4f483b08dce69a6503322d4751765ca07051df28')}, hash='20a92a5d45f4989ea849418e3812a40766d2f433e9e9fcc2dbbc8a45dd53229c', text='. . . . . . . . . . . . . . . . . . . . . . . 51\\nA.4 Additional Details for Safety . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 58\\nA.5 Data Annotation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 72\\nA.6 Dataset Contamination . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 75\\nA.7 Model Card . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 77\\n2\\n\\nFigure 1: Helpfulness human evaluation results for Llama\\n2-Chatcomparedtootheropen-sourceandclosed-source\\nmodels. Human raters compared model generations on ~4k\\npromptsconsistingofbothsingleandmulti-turnprompts.\\nThe95%confidenceintervalsforthisevaluationarebetween\\n1%and2%. MoredetailsinSection3.4.2. Whilereviewing\\nthese results, it is important to note that human evaluations\\ncanbenoisyduetolimitationsofthepromptset,subjectivity\\nof the review guidelines, subjectivity of individual raters,\\nand the inherent difficulty of comparing generations.\\nFigure 2: Win-rate % for helpfulness and\\nsafety between commercial-licensed base-\\nlines and Llama 2-Chat , according to GPT-\\n4. Tocomplementthehumanevaluation,we\\nused a more capable model, not subject to\\nourownguidance. Greenareaindicatesour\\nmodelisbetteraccordingtoGPT-4. Toremove\\nties, we used win/ (win+loss). The orders in\\nwhichthemodelresponsesarepresentedto\\nGPT-4arerandomlyswappedtoalleviatebias.\\n1 Introduction\\nLarge Language Models (LLMs) have shown great promise as highly capable AI assistants that excel in\\ncomplex reasoning tasks requiring expert knowledge across a wide range of fields, including in specialized\\ndomains such as programming and creative writing. They enable interaction with humans through intuitive\\nchat interfaces, which has led to rapid and widespread adoption among the general public.\\nThecapabilitiesofLLMsareremarkableconsideringtheseeminglystraightforwardnatureofthetraining\\nmethodology. Auto-regressivetransformersarepretrainedonanextensivecorpusofself-superviseddata,\\nfollowed by alignment with human preferences via techniques such as Reinforcement Learning with Human\\nFeedback(RLHF).Althoughthetrainingmethodologyissimple,highcomputationalrequirementshave\\nlimited the development of LLMs to a few players. There have been public releases of pretrained LLMs\\n(such as BLOOM (Scao et al., 2022), LLaMa-1 (Touvron et al., 2023), and Falcon (Penedo et al., 2023)) that\\nmatch the performance of closed pretrained competitors like GPT-3 (Brown et al., 2020) and Chinchilla\\n(Hoffmann et al., 2022), but none of these models are suitable substitutes for closed “product” LLMs, such\\nasChatGPT,BARD,andClaude.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-2'),\n",
              " '24b25121-cd86-4ddc-acad-69002f9a3bc6': IndexNode(id_='24b25121-cd86-4ddc-acad-69002f9a3bc6', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-3', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='0087ff2312f2cc99d68939de4f483b08dce69a6503322d4751765ca07051df28'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='5f007854-0ae0-438c-8a88-1ea5c345ac9a', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='1207e915786a96fa570188f69a1816de32d00a32e41076464896aae464ea3e41')}, hash='06b0082a98cf5bc68807044d14ea1a9f06844bc9fc409dfc61e3b973f701a488', text='TheseclosedproductLLMsareheavilyfine-tunedtoalignwithhuman\\npreferences, which greatly enhances their usability and safety. This step can require significant costs in\\ncomputeandhumanannotation,andisoftennottransparentoreasilyreproducible,limitingprogresswithin\\nthe community to advance AI alignment research.\\nIn this work, we develop and release Llama 2, a family of pretrained and fine-tuned LLMs, Llama 2 and\\nLlama 2-Chat , at scales up to 70B parameters.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-3'),\n",
              " '5f007854-0ae0-438c-8a88-1ea5c345ac9a': IndexNode(id_='5f007854-0ae0-438c-8a88-1ea5c345ac9a', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-3', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='0087ff2312f2cc99d68939de4f483b08dce69a6503322d4751765ca07051df28'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='24b25121-cd86-4ddc-acad-69002f9a3bc6', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='06b0082a98cf5bc68807044d14ea1a9f06844bc9fc409dfc61e3b973f701a488'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='622820c5-0174-4415-9349-aca17db6ceec', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='21b324e576592c5ccd2729e133ba3592d6da96447135dd89527c771b07ea900a')}, hash='1207e915786a96fa570188f69a1816de32d00a32e41076464896aae464ea3e41', text='On the series of helpfulness and safety benchmarks we tested,\\nLlama 2-Chat models generally perform better than existing open-source models. They also appear to\\nbe on par with some of the closed-source models, at least on the human evaluations we performed (see\\nFigures1and3). Wehavetakenmeasurestoincreasethesafetyofthesemodels,usingsafety-specificdata\\nannotation and tuning, as well as conducting red-teaming and employing iterative evaluations.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-3'),\n",
              " '622820c5-0174-4415-9349-aca17db6ceec': IndexNode(id_='622820c5-0174-4415-9349-aca17db6ceec', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-3', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='0087ff2312f2cc99d68939de4f483b08dce69a6503322d4751765ca07051df28'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='5f007854-0ae0-438c-8a88-1ea5c345ac9a', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='1207e915786a96fa570188f69a1816de32d00a32e41076464896aae464ea3e41'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='c9d800d7-4335-4608-8ffc-0605d22f05be', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='5b48c84b4222f7564b54cd0f3ed6abb6dc0604b6accc491cd60703cf4553e1f1')}, hash='21b324e576592c5ccd2729e133ba3592d6da96447135dd89527c771b07ea900a', text='Additionally,\\nthispapercontributesathoroughdescriptionofourfine-tuningmethodologyandapproachtoimproving\\nLLM safety. We hope that this openness will enable the community to reproduce fine-tuned LLMs and\\ncontinue to improve the safety of those models, paving the way for more responsible development of LLMs.\\nWealsosharenovelobservationswemadeduringthedevelopmentof Llama 2 andLlama 2-Chat ,suchas\\nthe emergence of tool usage and temporal organization of knowledge.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-3'),\n",
              " 'c9d800d7-4335-4608-8ffc-0605d22f05be': IndexNode(id_='c9d800d7-4335-4608-8ffc-0605d22f05be', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-3', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='0087ff2312f2cc99d68939de4f483b08dce69a6503322d4751765ca07051df28'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='622820c5-0174-4415-9349-aca17db6ceec', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='21b324e576592c5ccd2729e133ba3592d6da96447135dd89527c771b07ea900a'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='df0d223a-5c8a-4627-af50-c9b2f1d46a6f', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='a5cf564773982025d3fdb6b06952079471d5219590088ae32ccc8a0aa281fe7d')}, hash='5b48c84b4222f7564b54cd0f3ed6abb6dc0604b6accc491cd60703cf4553e1f1', text='3\\n\\nFigure 3: Safety human evaluation results for Llama 2-Chat compared to other open-source and closed-\\nsource models. Human raters judged model generations for safety violations across ~2,000 adversarial\\nprompts consisting of both single and multi-turn prompts. More details can be found in Section 4.4. It is\\nimportanttocaveatthesesafetyresultswiththeinherentbiasofLLMevaluationsduetolimitationsofthe\\npromptset,subjectivityofthereviewguidelines,andsubjectivityofindividualraters.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-3'),\n",
              " 'df0d223a-5c8a-4627-af50-c9b2f1d46a6f': IndexNode(id_='df0d223a-5c8a-4627-af50-c9b2f1d46a6f', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-3', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='0087ff2312f2cc99d68939de4f483b08dce69a6503322d4751765ca07051df28'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='c9d800d7-4335-4608-8ffc-0605d22f05be', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='5b48c84b4222f7564b54cd0f3ed6abb6dc0604b6accc491cd60703cf4553e1f1'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='588a7e8b-6611-4efb-8db6-a4bdc9addb9c', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='bc8f6119e1e398b7365deb41a2a8f2ba18cd256f734a6ddd83a8bb2ca0bd7e13')}, hash='a5cf564773982025d3fdb6b06952079471d5219590088ae32ccc8a0aa281fe7d', text='Additionally,these\\nsafety evaluations are performed using content standards that are likely to be biased towards the Llama\\n2-Chatmodels.\\nWe are releasing the following models to the general public for research and commercial use‡:\\n1.Llama 2 ,anupdatedversionof Llama 1,trainedonanewmixofpubliclyavailabledata. Wealso\\nincreasedthesizeofthepretrainingcorpusby40%,doubledthecontextlengthofthemodel,and\\nadoptedgrouped-queryattention(Ainslieetal.,2023).', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-3'),\n",
              " '588a7e8b-6611-4efb-8db6-a4bdc9addb9c': IndexNode(id_='588a7e8b-6611-4efb-8db6-a4bdc9addb9c', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-3', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='0087ff2312f2cc99d68939de4f483b08dce69a6503322d4751765ca07051df28'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='df0d223a-5c8a-4627-af50-c9b2f1d46a6f', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='a5cf564773982025d3fdb6b06952079471d5219590088ae32ccc8a0aa281fe7d'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='d00232f9-4c06-40d9-b3c2-ebd1125cf2bc', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='5c6dddb5cd0afbc33fab2532e776903c6217b75e7143f3c76b31ba2c92f76dd8')}, hash='bc8f6119e1e398b7365deb41a2a8f2ba18cd256f734a6ddd83a8bb2ca0bd7e13', text='Wearereleasingvariantsof Llama 2 with\\n7B,13B,and70Bparameters. Wehavealsotrained34Bvariants,whichwereportoninthispaper\\nbut are not releasing.§\\n2.Llama 2-Chat , a fine-tuned version of Llama 2 that is optimized for dialogue use cases. We release\\nvariants of this model with 7B, 13B, and 70B parameters as well.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-3'),\n",
              " 'd00232f9-4c06-40d9-b3c2-ebd1125cf2bc': IndexNode(id_='d00232f9-4c06-40d9-b3c2-ebd1125cf2bc', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-3', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='0087ff2312f2cc99d68939de4f483b08dce69a6503322d4751765ca07051df28'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='588a7e8b-6611-4efb-8db6-a4bdc9addb9c', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='bc8f6119e1e398b7365deb41a2a8f2ba18cd256f734a6ddd83a8bb2ca0bd7e13'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='ad952a51-0a04-4971-a335-88259e574803', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='588b11547216a2af2112857934ab822ca6929036138fc06a6e56f31a0453cc48')}, hash='5c6dddb5cd0afbc33fab2532e776903c6217b75e7143f3c76b31ba2c92f76dd8', text='WebelievethattheopenreleaseofLLMs,whendonesafely,willbeanetbenefittosociety. LikeallLLMs,\\nLlama 2 is a new technology that carries potential risks with use (Bender et al., 2021b; Weidinger et al., 2021;\\nSolaimanet al.,2023). Testingconductedtodate hasbeeninEnglish andhasnot— andcouldnot— cover\\nall scenarios.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-3'),\n",
              " 'ad952a51-0a04-4971-a335-88259e574803': IndexNode(id_='ad952a51-0a04-4971-a335-88259e574803', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-3', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='0087ff2312f2cc99d68939de4f483b08dce69a6503322d4751765ca07051df28'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='d00232f9-4c06-40d9-b3c2-ebd1125cf2bc', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='5c6dddb5cd0afbc33fab2532e776903c6217b75e7143f3c76b31ba2c92f76dd8'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='f12c2197-fefe-4027-8183-7f6574009042', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='ccf007b461a7defb9a5037a1dbcdd99a5c08b6e9cb8f592915d2575058a73fe7')}, hash='588b11547216a2af2112857934ab822ca6929036138fc06a6e56f31a0453cc48', text='Therefore, before deploying any applications of Llama 2-Chat , developers should perform\\nsafetytestingand tuningtailoredtotheirspecificapplicationsofthemodel. Weprovidearesponsibleuse\\nguide¶and code examples‖to facilitate the safe deployment of Llama 2 andLlama 2-Chat . More details of\\nour responsible release strategy can be found in Section 5.3.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-3'),\n",
              " 'f12c2197-fefe-4027-8183-7f6574009042': IndexNode(id_='f12c2197-fefe-4027-8183-7f6574009042', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-3', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='0087ff2312f2cc99d68939de4f483b08dce69a6503322d4751765ca07051df28'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='ad952a51-0a04-4971-a335-88259e574803', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='588b11547216a2af2112857934ab822ca6929036138fc06a6e56f31a0453cc48')}, hash='ccf007b461a7defb9a5037a1dbcdd99a5c08b6e9cb8f592915d2575058a73fe7', text='More details of\\nour responsible release strategy can be found in Section 5.3.\\nTheremainderofthispaperdescribesourpretrainingmethodology(Section2),fine-tuningmethodology\\n(Section 3), approach to model safety (Section 4), key observations and insights (Section 5), relevant related\\nwork (Section 6), and conclusions (Section 7).\\n‡https://ai.meta.com/resources/models-and-libraries/llama/\\n§We are delaying the release of the 34B model due to a lack of time to sufficiently red team.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-3'),\n",
              " 'd87ea091-2d1f-4da6-a368-dceebb98fe25': IndexNode(id_='d87ea091-2d1f-4da6-a368-dceebb98fe25', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-3', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='0087ff2312f2cc99d68939de4f483b08dce69a6503322d4751765ca07051df28'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='c09a7cb2-9833-4022-9a9d-e00bee33dc3f', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='899b660d000b5a2b35d4483cf61a75349124f917eca4bab576de4d0a8362192d')}, hash='553673432fb031ec8a8dc5bc43d93950f59940aa9a5ac23b9523718e047ed80d', text='TheseclosedproductLLMsareheavilyfine-tunedtoalignwithhuman\\npreferences, which greatly enhances their usability and safety. This step can require significant costs in\\ncomputeandhumanannotation,andisoftennottransparentoreasilyreproducible,limitingprogresswithin\\nthe community to advance AI alignment research.\\nIn this work, we develop and release Llama 2, a family of pretrained and fine-tuned LLMs, Llama 2 and\\nLlama 2-Chat , at scales up to 70B parameters. On the series of helpfulness and safety benchmarks we tested,\\nLlama 2-Chat models generally perform better than existing open-source models. They also appear to\\nbe on par with some of the closed-source models, at least on the human evaluations we performed (see\\nFigures1and3). Wehavetakenmeasurestoincreasethesafetyofthesemodels,usingsafety-specificdata\\nannotation and tuning, as well as conducting red-teaming and employing iterative evaluations.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-3'),\n",
              " 'c09a7cb2-9833-4022-9a9d-e00bee33dc3f': IndexNode(id_='c09a7cb2-9833-4022-9a9d-e00bee33dc3f', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-3', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='0087ff2312f2cc99d68939de4f483b08dce69a6503322d4751765ca07051df28'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='d87ea091-2d1f-4da6-a368-dceebb98fe25', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='553673432fb031ec8a8dc5bc43d93950f59940aa9a5ac23b9523718e047ed80d'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='08499f91-936c-4023-8785-fa2d117bdcce', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='3d71a80332e138d9e54ba57cd1ca89ac51ae6a80d36371c818b220b26c5f0418')}, hash='899b660d000b5a2b35d4483cf61a75349124f917eca4bab576de4d0a8362192d', text='Additionally,\\nthispapercontributesathoroughdescriptionofourfine-tuningmethodologyandapproachtoimproving\\nLLM safety. We hope that this openness will enable the community to reproduce fine-tuned LLMs and\\ncontinue to improve the safety of those models, paving the way for more responsible development of LLMs.\\nWealsosharenovelobservationswemadeduringthedevelopmentof Llama 2 andLlama 2-Chat ,suchas\\nthe emergence of tool usage and temporal organization of knowledge.\\n3\\n\\nFigure 3: Safety human evaluation results for Llama 2-Chat compared to other open-source and closed-\\nsource models. Human raters judged model generations for safety violations across ~2,000 adversarial\\nprompts consisting of both single and multi-turn prompts. More details can be found in Section 4.4. It is\\nimportanttocaveatthesesafetyresultswiththeinherentbiasofLLMevaluationsduetolimitationsofthe\\npromptset,subjectivityofthereviewguidelines,andsubjectivityofindividualraters.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-3'),\n",
              " '08499f91-936c-4023-8785-fa2d117bdcce': IndexNode(id_='08499f91-936c-4023-8785-fa2d117bdcce', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-3', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='0087ff2312f2cc99d68939de4f483b08dce69a6503322d4751765ca07051df28'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='c09a7cb2-9833-4022-9a9d-e00bee33dc3f', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='899b660d000b5a2b35d4483cf61a75349124f917eca4bab576de4d0a8362192d'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='a393d4eb-3e17-49e4-8f63-93effc86f6eb', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='23b15cda5541c0475f85d6bd6a14dff8fa8108178a4bcc614b5b04ed79fb5cfa')}, hash='3d71a80332e138d9e54ba57cd1ca89ac51ae6a80d36371c818b220b26c5f0418', text='Additionally,these\\nsafety evaluations are performed using content standards that are likely to be biased towards the Llama\\n2-Chatmodels.\\nWe are releasing the following models to the general public for research and commercial use‡:\\n1.Llama 2 ,anupdatedversionof Llama 1,trainedonanewmixofpubliclyavailabledata. Wealso\\nincreasedthesizeofthepretrainingcorpusby40%,doubledthecontextlengthofthemodel,and\\nadoptedgrouped-queryattention(Ainslieetal.,2023). Wearereleasingvariantsof Llama 2 with\\n7B,13B,and70Bparameters. Wehavealsotrained34Bvariants,whichwereportoninthispaper\\nbut are not releasing.§\\n2.Llama 2-Chat , a fine-tuned version of Llama 2 that is optimized for dialogue use cases. We release\\nvariants of this model with 7B, 13B, and 70B parameters as well.\\nWebelievethattheopenreleaseofLLMs,whendonesafely,willbeanetbenefittosociety.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-3'),\n",
              " 'a393d4eb-3e17-49e4-8f63-93effc86f6eb': IndexNode(id_='a393d4eb-3e17-49e4-8f63-93effc86f6eb', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-3', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='0087ff2312f2cc99d68939de4f483b08dce69a6503322d4751765ca07051df28'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='08499f91-936c-4023-8785-fa2d117bdcce', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='3d71a80332e138d9e54ba57cd1ca89ac51ae6a80d36371c818b220b26c5f0418'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='b159cc47-208f-475c-85d7-965d9c485061', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='4788ffce58d55e42fea1f4f3e5ac7b3c23d4e5a48023ffec525fb8ee4b7449eb')}, hash='23b15cda5541c0475f85d6bd6a14dff8fa8108178a4bcc614b5b04ed79fb5cfa', text='LikeallLLMs,\\nLlama 2 is a new technology that carries potential risks with use (Bender et al., 2021b; Weidinger et al., 2021;\\nSolaimanet al.,2023). Testingconductedtodate hasbeeninEnglish andhasnot— andcouldnot— cover\\nall scenarios. Therefore, before deploying any applications of Llama 2-Chat , developers should perform\\nsafetytestingand tuningtailoredtotheirspecificapplicationsofthemodel. Weprovidearesponsibleuse\\nguide¶and code examples‖to facilitate the safe deployment of Llama 2 andLlama 2-Chat . More details of\\nour responsible release strategy can be found in Section 5.3.\\nTheremainderofthispaperdescribesourpretrainingmethodology(Section2),fine-tuningmethodology\\n(Section 3), approach to model safety (Section 4), key observations and insights (Section 5), relevant related\\nwork (Section 6), and conclusions (Section 7).', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-3'),\n",
              " 'b159cc47-208f-475c-85d7-965d9c485061': IndexNode(id_='b159cc47-208f-475c-85d7-965d9c485061', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-3', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='0087ff2312f2cc99d68939de4f483b08dce69a6503322d4751765ca07051df28'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='a393d4eb-3e17-49e4-8f63-93effc86f6eb', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='23b15cda5541c0475f85d6bd6a14dff8fa8108178a4bcc614b5b04ed79fb5cfa')}, hash='4788ffce58d55e42fea1f4f3e5ac7b3c23d4e5a48023ffec525fb8ee4b7449eb', text='‡https://ai.meta.com/resources/models-and-libraries/llama/\\n§We are delaying the release of the 34B model due to a lack of time to sufficiently red team.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-3'),\n",
              " '63dd195c-5ec6-4dc8-8579-0935683d2592': IndexNode(id_='63dd195c-5ec6-4dc8-8579-0935683d2592', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-3', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='0087ff2312f2cc99d68939de4f483b08dce69a6503322d4751765ca07051df28'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='e776caa3-cf26-4aad-8893-becd5426c6f8', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='b9770395104fd65d8e28dd5c88ca2a9e7393f6d273f20f72d26f8c421cef7425')}, hash='aadff8db5204f6e06ba4825762c6e324a735b73ed7b0068b7b64a02558fb2335', text='TheseclosedproductLLMsareheavilyfine-tunedtoalignwithhuman\\npreferences, which greatly enhances their usability and safety. This step can require significant costs in\\ncomputeandhumanannotation,andisoftennottransparentoreasilyreproducible,limitingprogresswithin\\nthe community to advance AI alignment research.\\nIn this work, we develop and release Llama 2, a family of pretrained and fine-tuned LLMs, Llama 2 and\\nLlama 2-Chat , at scales up to 70B parameters. On the series of helpfulness and safety benchmarks we tested,\\nLlama 2-Chat models generally perform better than existing open-source models. They also appear to\\nbe on par with some of the closed-source models, at least on the human evaluations we performed (see\\nFigures1and3). Wehavetakenmeasurestoincreasethesafetyofthesemodels,usingsafety-specificdata\\nannotation and tuning, as well as conducting red-teaming and employing iterative evaluations. Additionally,\\nthispapercontributesathoroughdescriptionofourfine-tuningmethodologyandapproachtoimproving\\nLLM safety. We hope that this openness will enable the community to reproduce fine-tuned LLMs and\\ncontinue to improve the safety of those models, paving the way for more responsible development of LLMs.\\nWealsosharenovelobservationswemadeduringthedevelopmentof Llama 2 andLlama 2-Chat ,suchas\\nthe emergence of tool usage and temporal organization of knowledge.\\n3\\n\\nFigure 3: Safety human evaluation results for Llama 2-Chat compared to other open-source and closed-\\nsource models. Human raters judged model generations for safety violations across ~2,000 adversarial\\nprompts consisting of both single and multi-turn prompts. More details can be found in Section 4.4. It is\\nimportanttocaveatthesesafetyresultswiththeinherentbiasofLLMevaluationsduetolimitationsofthe\\npromptset,subjectivityofthereviewguidelines,andsubjectivityofindividualraters. Additionally,these\\nsafety evaluations are performed using content standards that are likely to be biased towards the Llama\\n2-Chatmodels.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-3'),\n",
              " 'e776caa3-cf26-4aad-8893-becd5426c6f8': IndexNode(id_='e776caa3-cf26-4aad-8893-becd5426c6f8', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-3', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='0087ff2312f2cc99d68939de4f483b08dce69a6503322d4751765ca07051df28'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='63dd195c-5ec6-4dc8-8579-0935683d2592', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='aadff8db5204f6e06ba4825762c6e324a735b73ed7b0068b7b64a02558fb2335')}, hash='b9770395104fd65d8e28dd5c88ca2a9e7393f6d273f20f72d26f8c421cef7425', text='We are releasing the following models to the general public for research and commercial use‡:\\n1.Llama 2 ,anupdatedversionof Llama 1,trainedonanewmixofpubliclyavailabledata. Wealso\\nincreasedthesizeofthepretrainingcorpusby40%,doubledthecontextlengthofthemodel,and\\nadoptedgrouped-queryattention(Ainslieetal.,2023). Wearereleasingvariantsof Llama 2 with\\n7B,13B,and70Bparameters. Wehavealsotrained34Bvariants,whichwereportoninthispaper\\nbut are not releasing.§\\n2.Llama 2-Chat , a fine-tuned version of Llama 2 that is optimized for dialogue use cases. We release\\nvariants of this model with 7B, 13B, and 70B parameters as well.\\nWebelievethattheopenreleaseofLLMs,whendonesafely,willbeanetbenefittosociety. LikeallLLMs,\\nLlama 2 is a new technology that carries potential risks with use (Bender et al., 2021b; Weidinger et al., 2021;\\nSolaimanet al.,2023). Testingconductedtodate hasbeeninEnglish andhasnot— andcouldnot— cover\\nall scenarios. Therefore, before deploying any applications of Llama 2-Chat , developers should perform\\nsafetytestingand tuningtailoredtotheirspecificapplicationsofthemodel. Weprovidearesponsibleuse\\nguide¶and code examples‖to facilitate the safe deployment of Llama 2 andLlama 2-Chat . More details of\\nour responsible release strategy can be found in Section 5.3.\\nTheremainderofthispaperdescribesourpretrainingmethodology(Section2),fine-tuningmethodology\\n(Section 3), approach to model safety (Section 4), key observations and insights (Section 5), relevant related\\nwork (Section 6), and conclusions (Section 7).\\n‡https://ai.meta.com/resources/models-and-libraries/llama/\\n§We are delaying the release of the 34B model due to a lack of time to sufficiently red team.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-3'),\n",
              " 'node-3': IndexNode(id_='node-3', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='415b7efc-e73f-4ac4-bbfd-c1546f099026', node_type=<ObjectType.DOCUMENT: '4'>, metadata={}, hash='231b3bd773f012c01b893ada9e009ecf25ee59934614c5a595c9bf1b3a123292'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='94b39f83-e630-4e05-b7c4-a446a16fc0d7', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='20a92a5d45f4989ea849418e3812a40766d2f433e9e9fcc2dbbc8a45dd53229c'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='7c3113ce-9d82-4c50-9918-a877d7b82656', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='c8cebba0d1ac65faa2fca9c54a46b35a0c13f8bfb740aab2b919f3d80ff29993')}, hash='0087ff2312f2cc99d68939de4f483b08dce69a6503322d4751765ca07051df28', text='TheseclosedproductLLMsareheavilyfine-tunedtoalignwithhuman\\npreferences, which greatly enhances their usability and safety. This step can require significant costs in\\ncomputeandhumanannotation,andisoftennottransparentoreasilyreproducible,limitingprogresswithin\\nthe community to advance AI alignment research.\\nIn this work, we develop and release Llama 2, a family of pretrained and fine-tuned LLMs, Llama 2 and\\nLlama 2-Chat , at scales up to 70B parameters. On the series of helpfulness and safety benchmarks we tested,\\nLlama 2-Chat models generally perform better than existing open-source models. They also appear to\\nbe on par with some of the closed-source models, at least on the human evaluations we performed (see\\nFigures1and3). Wehavetakenmeasurestoincreasethesafetyofthesemodels,usingsafety-specificdata\\nannotation and tuning, as well as conducting red-teaming and employing iterative evaluations. Additionally,\\nthispapercontributesathoroughdescriptionofourfine-tuningmethodologyandapproachtoimproving\\nLLM safety. We hope that this openness will enable the community to reproduce fine-tuned LLMs and\\ncontinue to improve the safety of those models, paving the way for more responsible development of LLMs.\\nWealsosharenovelobservationswemadeduringthedevelopmentof Llama 2 andLlama 2-Chat ,suchas\\nthe emergence of tool usage and temporal organization of knowledge.\\n3\\n\\nFigure 3: Safety human evaluation results for Llama 2-Chat compared to other open-source and closed-\\nsource models. Human raters judged model generations for safety violations across ~2,000 adversarial\\nprompts consisting of both single and multi-turn prompts. More details can be found in Section 4.4. It is\\nimportanttocaveatthesesafetyresultswiththeinherentbiasofLLMevaluationsduetolimitationsofthe\\npromptset,subjectivityofthereviewguidelines,andsubjectivityofindividualraters. Additionally,these\\nsafety evaluations are performed using content standards that are likely to be biased towards the Llama\\n2-Chatmodels.\\nWe are releasing the following models to the general public for research and commercial use‡:\\n1.Llama 2 ,anupdatedversionof Llama 1,trainedonanewmixofpubliclyavailabledata. Wealso\\nincreasedthesizeofthepretrainingcorpusby40%,doubledthecontextlengthofthemodel,and\\nadoptedgrouped-queryattention(Ainslieetal.,2023). Wearereleasingvariantsof Llama 2 with\\n7B,13B,and70Bparameters. Wehavealsotrained34Bvariants,whichwereportoninthispaper\\nbut are not releasing.§\\n2.Llama 2-Chat , a fine-tuned version of Llama 2 that is optimized for dialogue use cases. We release\\nvariants of this model with 7B, 13B, and 70B parameters as well.\\nWebelievethattheopenreleaseofLLMs,whendonesafely,willbeanetbenefittosociety. LikeallLLMs,\\nLlama 2 is a new technology that carries potential risks with use (Bender et al., 2021b; Weidinger et al., 2021;\\nSolaimanet al.,2023). Testingconductedtodate hasbeeninEnglish andhasnot— andcouldnot— cover\\nall scenarios. Therefore, before deploying any applications of Llama 2-Chat , developers should perform\\nsafetytestingand tuningtailoredtotheirspecificapplicationsofthemodel. Weprovidearesponsibleuse\\nguide¶and code examples‖to facilitate the safe deployment of Llama 2 andLlama 2-Chat . More details of\\nour responsible release strategy can be found in Section 5.3.\\nTheremainderofthispaperdescribesourpretrainingmethodology(Section2),fine-tuningmethodology\\n(Section 3), approach to model safety (Section 4), key observations and insights (Section 5), relevant related\\nwork (Section 6), and conclusions (Section 7).\\n‡https://ai.meta.com/resources/models-and-libraries/llama/\\n§We are delaying the release of the 34B model due to a lack of time to sufficiently red team.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-3'),\n",
              " 'c3e069f0-29cc-43e2-bb90-1be98bd95e30': IndexNode(id_='c3e069f0-29cc-43e2-bb90-1be98bd95e30', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-4', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='c8cebba0d1ac65faa2fca9c54a46b35a0c13f8bfb740aab2b919f3d80ff29993'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='cd4ce0d1-92b3-4b15-ac25-1547b39b6a52', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='15f29bd36bc57c28ebdac8f2c7f0460561b7309e2ea73279ebabd980909e1fbb')}, hash='952bba6d6074bb3a4dae4d0be2f8dad065a4b32c6bdd99c104fd667b4bdfef8b', text='¶https://ai.meta.com/llama\\n‖https://github.com/facebookresearch/llama\\n4\\n\\nFigure4: Trainingof Llama 2-Chat : Thisprocessbeginswiththe pretraining ofLlama 2 usingpublicly\\navailableonlinesources. Followingthis,wecreateaninitialversionof Llama 2-Chat throughtheapplication\\nofsupervised fine-tuning .', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-4'),\n",
              " 'cd4ce0d1-92b3-4b15-ac25-1547b39b6a52': IndexNode(id_='cd4ce0d1-92b3-4b15-ac25-1547b39b6a52', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-4', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='c8cebba0d1ac65faa2fca9c54a46b35a0c13f8bfb740aab2b919f3d80ff29993'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='c3e069f0-29cc-43e2-bb90-1be98bd95e30', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='952bba6d6074bb3a4dae4d0be2f8dad065a4b32c6bdd99c104fd667b4bdfef8b'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='aab26b21-13da-49ed-8bc4-7f52a8fe8d94', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='6df262e9a47442201dc0521ac720738b37526835eb4a8305c407b4dffdee10a5')}, hash='15f29bd36bc57c28ebdac8f2c7f0460561b7309e2ea73279ebabd980909e1fbb', text='Subsequently, the model is iteratively refined using Reinforcement Learning\\nwith Human Feedback (RLHF) methodologies, specifically through rejection sampling and Proximal Policy\\nOptimization(PPO).ThroughouttheRLHFstage,theaccumulationof iterativerewardmodelingdata in\\nparallel with model enhancements is crucial to ensure the reward models remain within distribution.\\n2 Pretraining\\nTocreatethenewfamilyof Llama 2models,webeganwiththepretrainingapproachdescribedinTouvronetal.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-4'),\n",
              " 'aab26b21-13da-49ed-8bc4-7f52a8fe8d94': IndexNode(id_='aab26b21-13da-49ed-8bc4-7f52a8fe8d94', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-4', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='c8cebba0d1ac65faa2fca9c54a46b35a0c13f8bfb740aab2b919f3d80ff29993'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='cd4ce0d1-92b3-4b15-ac25-1547b39b6a52', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='15f29bd36bc57c28ebdac8f2c7f0460561b7309e2ea73279ebabd980909e1fbb'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='b1a6b3dd-5958-4e98-8afe-75733a6607c8', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='7f91649db9467c39c08d9682fca3055cade879e2e4ddae210ecde73190c66451')}, hash='6df262e9a47442201dc0521ac720738b37526835eb4a8305c407b4dffdee10a5', text='(2023), using an optimized auto-regressive transformer, but made several changes to improve performance.\\nSpecifically,weperformedmorerobustdatacleaning,updatedourdatamixes,trainedon40%moretotal\\ntokens,doubledthecontextlength,andusedgrouped-queryattention(GQA)toimproveinferencescalability\\nfor our larger models. Table 1 compares the attributes of the new Llama 2 models with the Llama 1 models.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-4'),\n",
              " 'b1a6b3dd-5958-4e98-8afe-75733a6607c8': IndexNode(id_='b1a6b3dd-5958-4e98-8afe-75733a6607c8', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-4', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='c8cebba0d1ac65faa2fca9c54a46b35a0c13f8bfb740aab2b919f3d80ff29993'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='aab26b21-13da-49ed-8bc4-7f52a8fe8d94', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='6df262e9a47442201dc0521ac720738b37526835eb4a8305c407b4dffdee10a5'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='e9753cb7-eb98-4af1-b675-194a84eb12a4', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='398116bb220b47359310d5a5a8e56b09afbc59515b21b3c0dde14e13336e3362')}, hash='7f91649db9467c39c08d9682fca3055cade879e2e4ddae210ecde73190c66451', text='Table 1 compares the attributes of the new Llama 2 models with the Llama 1 models.\\n2.1 Pretraining Data\\nOur training corpus includes a new mix of data from publicly available sources, which does not include data\\nfromMeta’sproductsorservices. Wemadeanefforttoremovedatafromcertainsitesknowntocontaina\\nhighvolumeofpersonalinformationaboutprivateindividuals.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-4'),\n",
              " 'e9753cb7-eb98-4af1-b675-194a84eb12a4': IndexNode(id_='e9753cb7-eb98-4af1-b675-194a84eb12a4', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-4', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='c8cebba0d1ac65faa2fca9c54a46b35a0c13f8bfb740aab2b919f3d80ff29993'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='b1a6b3dd-5958-4e98-8afe-75733a6607c8', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='7f91649db9467c39c08d9682fca3055cade879e2e4ddae210ecde73190c66451'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='6ee702ce-b417-4e38-8ae9-5ac0281adabb', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='531e17607492d148c0c312a4106beb2305a7098a37e458682f713ce7e053b931')}, hash='398116bb220b47359310d5a5a8e56b09afbc59515b21b3c0dde14e13336e3362', text='Wetrainedon2trilliontokensofdataasthis\\nprovidesagoodperformance–costtrade-off,up-samplingthemostfactualsourcesinanefforttoincrease\\nknowledge and dampen hallucinations.\\nWeperformedavarietyofpretrainingdatainvestigationssothatuserscanbetterunderstandthepotential\\ncapabilities and limitations of our models; results can be found in Section 4.1.\\n2.2 Training Details\\nWe adopt most of the pretraining setting and model architecture from Llama 1 .', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-4'),\n",
              " '6ee702ce-b417-4e38-8ae9-5ac0281adabb': IndexNode(id_='6ee702ce-b417-4e38-8ae9-5ac0281adabb', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-4', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='c8cebba0d1ac65faa2fca9c54a46b35a0c13f8bfb740aab2b919f3d80ff29993'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='e9753cb7-eb98-4af1-b675-194a84eb12a4', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='398116bb220b47359310d5a5a8e56b09afbc59515b21b3c0dde14e13336e3362'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='619b88f2-0cb9-4083-9d99-d0a776339968', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='2fc2b8f3dc0657d1e82e46680a1e8751eac72cefd203b662f28410a9320e89c6')}, hash='531e17607492d148c0c312a4106beb2305a7098a37e458682f713ce7e053b931', text='We use the standard\\ntransformer architecture (Vaswani et al., 2017), apply pre-normalization using RMSNorm (Zhang and\\nSennrich, 2019), use the SwiGLU activation function (Shazeer, 2020), and rotary positional embeddings\\n(RoPE, Su et al. 2022). The primary architectural differences from Llama 1 include increased context length\\nandgrouped-queryattention(GQA).WedetailinAppendixSectionA.2.1eachofthesedifferenceswith\\nablation experiments to demonstrate their importance.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-4'),\n",
              " '619b88f2-0cb9-4083-9d99-d0a776339968': IndexNode(id_='619b88f2-0cb9-4083-9d99-d0a776339968', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-4', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='c8cebba0d1ac65faa2fca9c54a46b35a0c13f8bfb740aab2b919f3d80ff29993'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='6ee702ce-b417-4e38-8ae9-5ac0281adabb', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='531e17607492d148c0c312a4106beb2305a7098a37e458682f713ce7e053b931'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='a3e6d64c-a1d0-4520-b7f3-7bda9e75014c', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='2bc785d83e78713f19904b076518f3d2aa1c008f06f1d086425c10f1dd5b4164')}, hash='2fc2b8f3dc0657d1e82e46680a1e8751eac72cefd203b662f28410a9320e89c6', text='Hyperparameters. We trained using the AdamW optimizer (Loshchilov and Hutter, 2017), with β1=\\n0.9, β2= 0.95,eps= 10−5. We use a cosine learning rate schedule, with warmup of 2000 steps, and decay\\nfinallearningratedownto10%ofthepeaklearningrate. Weuseaweightdecayof 0.1andgradientclipping\\nof1.0. Figure 5 (a) shows the training loss for Llama 2 with these hyperparameters.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-4'),\n",
              " 'a3e6d64c-a1d0-4520-b7f3-7bda9e75014c': IndexNode(id_='a3e6d64c-a1d0-4520-b7f3-7bda9e75014c', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-4', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='c8cebba0d1ac65faa2fca9c54a46b35a0c13f8bfb740aab2b919f3d80ff29993'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='619b88f2-0cb9-4083-9d99-d0a776339968', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='2fc2b8f3dc0657d1e82e46680a1e8751eac72cefd203b662f28410a9320e89c6'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='d14a7e1c-ba4f-4eab-a85d-5788e5dbee50', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='a7e3b35db9476dfd68412dff8aee6144fb930af757894fc4b025d3c4abd6a78a')}, hash='2bc785d83e78713f19904b076518f3d2aa1c008f06f1d086425c10f1dd5b4164', text='Figure 5 (a) shows the training loss for Llama 2 with these hyperparameters.\\n5\\n\\nTraining Data Params Context\\nLengthGQA Tokens LR\\nLlama 1See Touvron et al.\\n(2023)7B 2k ✗ 1.0T 3.0×10−4\\n13B 2k ✗ 1.0T 3.0×10−4\\n33B 2k ✗ 1.4T 1.5×10−4\\n65B 2k ✗ 1.4T 1.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-4'),\n",
              " 'd14a7e1c-ba4f-4eab-a85d-5788e5dbee50': IndexNode(id_='d14a7e1c-ba4f-4eab-a85d-5788e5dbee50', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-4', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='c8cebba0d1ac65faa2fca9c54a46b35a0c13f8bfb740aab2b919f3d80ff29993'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='a3e6d64c-a1d0-4520-b7f3-7bda9e75014c', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='2bc785d83e78713f19904b076518f3d2aa1c008f06f1d086425c10f1dd5b4164'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='a8230140-caf2-4cd4-9223-2285b0a51977', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='52d513a0ca558e25e4cb66b08c1867bfc41cc576b2503f708baab0e4d67c0546')}, hash='a7e3b35db9476dfd68412dff8aee6144fb930af757894fc4b025d3c4abd6a78a', text='5×10−4\\n65B 2k ✗ 1.4T 1.5×10−4\\nLlama 2A new mix of publicly\\navailable online data7B 4k ✗ 2.0T 3.0×10−4\\n13B 4k ✗ 2.0T 3.0×10−4\\n34B 4k ✓ 2.0T 1.5×10−4\\n70B 4k ✓ 2.0T 1.5×10−4\\nTable 1: Llama 2 family of models. Token counts refer to pretraining data only.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-4'),\n",
              " 'a8230140-caf2-4cd4-9223-2285b0a51977': IndexNode(id_='a8230140-caf2-4cd4-9223-2285b0a51977', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-4', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='c8cebba0d1ac65faa2fca9c54a46b35a0c13f8bfb740aab2b919f3d80ff29993'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='d14a7e1c-ba4f-4eab-a85d-5788e5dbee50', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='a7e3b35db9476dfd68412dff8aee6144fb930af757894fc4b025d3c4abd6a78a')}, hash='52d513a0ca558e25e4cb66b08c1867bfc41cc576b2503f708baab0e4d67c0546', text='Token counts refer to pretraining data only. All models are trained with\\na global batch-size of 4M tokens. Bigger models — 34B and 70B — use Grouped-Query Attention (GQA) for\\nimproved inference scalability.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-4'),\n",
              " 'bd63cf44-1ad4-47e7-bd8c-6ff1205486bb': IndexNode(id_='bd63cf44-1ad4-47e7-bd8c-6ff1205486bb', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-4', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='c8cebba0d1ac65faa2fca9c54a46b35a0c13f8bfb740aab2b919f3d80ff29993'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='61de7d61-f10f-4c36-9d20-3540378796e8', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='a5f7e87fdc611172dfff31d0e6f75519fc5caa626985d06b9ce15db9712d3c03')}, hash='87bd84d1bd9743396e8bc950ed3aa99e12ac0376ac846c625b3de4914bb1413a', text='¶https://ai.meta.com/llama\\n‖https://github.com/facebookresearch/llama\\n4\\n\\nFigure4: Trainingof Llama 2-Chat : Thisprocessbeginswiththe pretraining ofLlama 2 usingpublicly\\navailableonlinesources. Followingthis,wecreateaninitialversionof Llama 2-Chat throughtheapplication\\nofsupervised fine-tuning . Subsequently, the model is iteratively refined using Reinforcement Learning\\nwith Human Feedback (RLHF) methodologies, specifically through rejection sampling and Proximal Policy\\nOptimization(PPO).ThroughouttheRLHFstage,theaccumulationof iterativerewardmodelingdata in\\nparallel with model enhancements is crucial to ensure the reward models remain within distribution.\\n2 Pretraining\\nTocreatethenewfamilyof Llama 2models,webeganwiththepretrainingapproachdescribedinTouvronetal.\\n(2023), using an optimized auto-regressive transformer, but made several changes to improve performance.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-4'),\n",
              " '61de7d61-f10f-4c36-9d20-3540378796e8': IndexNode(id_='61de7d61-f10f-4c36-9d20-3540378796e8', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-4', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='c8cebba0d1ac65faa2fca9c54a46b35a0c13f8bfb740aab2b919f3d80ff29993'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='bd63cf44-1ad4-47e7-bd8c-6ff1205486bb', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='87bd84d1bd9743396e8bc950ed3aa99e12ac0376ac846c625b3de4914bb1413a'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='c7d046fe-0205-4043-9c9f-21c532ce180e', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='18a082b56f6f5af8f2dd6b16b3d73ce828122018f2e2e71036e1066d01a3a494')}, hash='a5f7e87fdc611172dfff31d0e6f75519fc5caa626985d06b9ce15db9712d3c03', text='Specifically,weperformedmorerobustdatacleaning,updatedourdatamixes,trainedon40%moretotal\\ntokens,doubledthecontextlength,andusedgrouped-queryattention(GQA)toimproveinferencescalability\\nfor our larger models. Table 1 compares the attributes of the new Llama 2 models with the Llama 1 models.\\n2.1 Pretraining Data\\nOur training corpus includes a new mix of data from publicly available sources, which does not include data\\nfromMeta’sproductsorservices. Wemadeanefforttoremovedatafromcertainsitesknowntocontaina\\nhighvolumeofpersonalinformationaboutprivateindividuals. Wetrainedon2trilliontokensofdataasthis\\nprovidesagoodperformance–costtrade-off,up-samplingthemostfactualsourcesinanefforttoincrease\\nknowledge and dampen hallucinations.\\nWeperformedavarietyofpretrainingdatainvestigationssothatuserscanbetterunderstandthepotential\\ncapabilities and limitations of our models; results can be found in Section 4.1.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-4'),\n",
              " 'c7d046fe-0205-4043-9c9f-21c532ce180e': IndexNode(id_='c7d046fe-0205-4043-9c9f-21c532ce180e', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-4', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='c8cebba0d1ac65faa2fca9c54a46b35a0c13f8bfb740aab2b919f3d80ff29993'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='61de7d61-f10f-4c36-9d20-3540378796e8', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='a5f7e87fdc611172dfff31d0e6f75519fc5caa626985d06b9ce15db9712d3c03'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='98050e08-8b30-4d63-9bdf-b557728df261', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='4c8a412dcc5ad8a2983bcad57049f19ce422fbd2387ea361132cdfb960c79c4c')}, hash='18a082b56f6f5af8f2dd6b16b3d73ce828122018f2e2e71036e1066d01a3a494', text='2.2 Training Details\\nWe adopt most of the pretraining setting and model architecture from Llama 1 . We use the standard\\ntransformer architecture (Vaswani et al., 2017), apply pre-normalization using RMSNorm (Zhang and\\nSennrich, 2019), use the SwiGLU activation function (Shazeer, 2020), and rotary positional embeddings\\n(RoPE, Su et al. 2022). The primary architectural differences from Llama 1 include increased context length\\nandgrouped-queryattention(GQA).WedetailinAppendixSectionA.2.1eachofthesedifferenceswith\\nablation experiments to demonstrate their importance.\\nHyperparameters. We trained using the AdamW optimizer (Loshchilov and Hutter, 2017), with β1=\\n0.9, β2= 0.95,eps= 10−5. We use a cosine learning rate schedule, with warmup of 2000 steps, and decay\\nfinallearningratedownto10%ofthepeaklearningrate. Weuseaweightdecayof 0.1andgradientclipping\\nof1.0.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-4'),\n",
              " '98050e08-8b30-4d63-9bdf-b557728df261': IndexNode(id_='98050e08-8b30-4d63-9bdf-b557728df261', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-4', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='c8cebba0d1ac65faa2fca9c54a46b35a0c13f8bfb740aab2b919f3d80ff29993'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='c7d046fe-0205-4043-9c9f-21c532ce180e', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='18a082b56f6f5af8f2dd6b16b3d73ce828122018f2e2e71036e1066d01a3a494'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='89a056c9-f39c-445b-8c93-90a71e4d15c7', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='845d50d8ec68f9df0e7f4e6e55a3d6ff268296320ee11741de5a6071d6541bd5')}, hash='4c8a412dcc5ad8a2983bcad57049f19ce422fbd2387ea361132cdfb960c79c4c', text='Figure 5 (a) shows the training loss for Llama 2 with these hyperparameters.\\n5\\n\\nTraining Data Params Context\\nLengthGQA Tokens LR\\nLlama 1See Touvron et al.\\n(2023)7B 2k ✗ 1.0T 3.0×10−4\\n13B 2k ✗ 1.0T 3.0×10−4\\n33B 2k ✗ 1.4T 1.5×10−4\\n65B 2k ✗ 1.4T 1.5×10−4\\nLlama 2A new mix of publicly\\navailable online data7B 4k ✗ 2.0T 3.0×10−4\\n13B 4k ✗ 2.0T 3.0×10−4\\n34B 4k ✓ 2.0T 1.5×10−4\\n70B 4k ✓ 2.0T 1.5×10−4\\nTable 1: Llama 2 family of models. Token counts refer to pretraining data only. All models are trained with\\na global batch-size of 4M tokens.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-4'),\n",
              " '89a056c9-f39c-445b-8c93-90a71e4d15c7': IndexNode(id_='89a056c9-f39c-445b-8c93-90a71e4d15c7', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-4', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='c8cebba0d1ac65faa2fca9c54a46b35a0c13f8bfb740aab2b919f3d80ff29993'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='98050e08-8b30-4d63-9bdf-b557728df261', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='4c8a412dcc5ad8a2983bcad57049f19ce422fbd2387ea361132cdfb960c79c4c')}, hash='845d50d8ec68f9df0e7f4e6e55a3d6ff268296320ee11741de5a6071d6541bd5', text='All models are trained with\\na global batch-size of 4M tokens. Bigger models — 34B and 70B — use Grouped-Query Attention (GQA) for\\nimproved inference scalability.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-4'),\n",
              " 'e2200be0-b9cd-4d2b-92bf-84ea71b41683': IndexNode(id_='e2200be0-b9cd-4d2b-92bf-84ea71b41683', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-4', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='c8cebba0d1ac65faa2fca9c54a46b35a0c13f8bfb740aab2b919f3d80ff29993'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='94316fdf-3df2-44f8-a2a6-8e1444a65c91', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='ad040374ead1d7221411861f135120f5a2d7809db177fc5c8b0802218879b4fc')}, hash='23f15df1bac8939af844ebdc6db918ed7a57337693b990934fc0c63954396b09', text='¶https://ai.meta.com/llama\\n‖https://github.com/facebookresearch/llama\\n4\\n\\nFigure4: Trainingof Llama 2-Chat : Thisprocessbeginswiththe pretraining ofLlama 2 usingpublicly\\navailableonlinesources. Followingthis,wecreateaninitialversionof Llama 2-Chat throughtheapplication\\nofsupervised fine-tuning . Subsequently, the model is iteratively refined using Reinforcement Learning\\nwith Human Feedback (RLHF) methodologies, specifically through rejection sampling and Proximal Policy\\nOptimization(PPO).ThroughouttheRLHFstage,theaccumulationof iterativerewardmodelingdata in\\nparallel with model enhancements is crucial to ensure the reward models remain within distribution.\\n2 Pretraining\\nTocreatethenewfamilyof Llama 2models,webeganwiththepretrainingapproachdescribedinTouvronetal.\\n(2023), using an optimized auto-regressive transformer, but made several changes to improve performance.\\nSpecifically,weperformedmorerobustdatacleaning,updatedourdatamixes,trainedon40%moretotal\\ntokens,doubledthecontextlength,andusedgrouped-queryattention(GQA)toimproveinferencescalability\\nfor our larger models. Table 1 compares the attributes of the new Llama 2 models with the Llama 1 models.\\n2.1 Pretraining Data\\nOur training corpus includes a new mix of data from publicly available sources, which does not include data\\nfromMeta’sproductsorservices. Wemadeanefforttoremovedatafromcertainsitesknowntocontaina\\nhighvolumeofpersonalinformationaboutprivateindividuals. Wetrainedon2trilliontokensofdataasthis\\nprovidesagoodperformance–costtrade-off,up-samplingthemostfactualsourcesinanefforttoincrease\\nknowledge and dampen hallucinations.\\nWeperformedavarietyofpretrainingdatainvestigationssothatuserscanbetterunderstandthepotential\\ncapabilities and limitations of our models; results can be found in Section 4.1.\\n2.2 Training Details\\nWe adopt most of the pretraining setting and model architecture from Llama 1 .', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-4'),\n",
              " '94316fdf-3df2-44f8-a2a6-8e1444a65c91': IndexNode(id_='94316fdf-3df2-44f8-a2a6-8e1444a65c91', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-4', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='c8cebba0d1ac65faa2fca9c54a46b35a0c13f8bfb740aab2b919f3d80ff29993'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='e2200be0-b9cd-4d2b-92bf-84ea71b41683', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='23f15df1bac8939af844ebdc6db918ed7a57337693b990934fc0c63954396b09')}, hash='ad040374ead1d7221411861f135120f5a2d7809db177fc5c8b0802218879b4fc', text='We use the standard\\ntransformer architecture (Vaswani et al., 2017), apply pre-normalization using RMSNorm (Zhang and\\nSennrich, 2019), use the SwiGLU activation function (Shazeer, 2020), and rotary positional embeddings\\n(RoPE, Su et al. 2022). The primary architectural differences from Llama 1 include increased context length\\nandgrouped-queryattention(GQA).WedetailinAppendixSectionA.2.1eachofthesedifferenceswith\\nablation experiments to demonstrate their importance.\\nHyperparameters. We trained using the AdamW optimizer (Loshchilov and Hutter, 2017), with β1=\\n0.9, β2= 0.95,eps= 10−5. We use a cosine learning rate schedule, with warmup of 2000 steps, and decay\\nfinallearningratedownto10%ofthepeaklearningrate. Weuseaweightdecayof 0.1andgradientclipping\\nof1.0. Figure 5 (a) shows the training loss for Llama 2 with these hyperparameters.\\n5\\n\\nTraining Data Params Context\\nLengthGQA Tokens LR\\nLlama 1See Touvron et al.\\n(2023)7B 2k ✗ 1.0T 3.0×10−4\\n13B 2k ✗ 1.0T 3.0×10−4\\n33B 2k ✗ 1.4T 1.5×10−4\\n65B 2k ✗ 1.4T 1.5×10−4\\nLlama 2A new mix of publicly\\navailable online data7B 4k ✗ 2.0T 3.0×10−4\\n13B 4k ✗ 2.0T 3.0×10−4\\n34B 4k ✓ 2.0T 1.5×10−4\\n70B 4k ✓ 2.0T 1.5×10−4\\nTable 1: Llama 2 family of models. Token counts refer to pretraining data only. All models are trained with\\na global batch-size of 4M tokens. Bigger models — 34B and 70B — use Grouped-Query Attention (GQA) for\\nimproved inference scalability.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-4'),\n",
              " 'node-4': IndexNode(id_='node-4', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='415b7efc-e73f-4ac4-bbfd-c1546f099026', node_type=<ObjectType.DOCUMENT: '4'>, metadata={}, hash='231b3bd773f012c01b893ada9e009ecf25ee59934614c5a595c9bf1b3a123292'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='19da8bba-6827-4924-88f8-f064a63fc9e8', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='0087ff2312f2cc99d68939de4f483b08dce69a6503322d4751765ca07051df28'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='9a521d76-47f8-433e-b43e-3f05c5487766', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='21d40cc11522dda47b6adc15531a3413b90a6e2631453085d7ab9492c08d56c6')}, hash='c8cebba0d1ac65faa2fca9c54a46b35a0c13f8bfb740aab2b919f3d80ff29993', text='¶https://ai.meta.com/llama\\n‖https://github.com/facebookresearch/llama\\n4\\n\\nFigure4: Trainingof Llama 2-Chat : Thisprocessbeginswiththe pretraining ofLlama 2 usingpublicly\\navailableonlinesources. Followingthis,wecreateaninitialversionof Llama 2-Chat throughtheapplication\\nofsupervised fine-tuning . Subsequently, the model is iteratively refined using Reinforcement Learning\\nwith Human Feedback (RLHF) methodologies, specifically through rejection sampling and Proximal Policy\\nOptimization(PPO).ThroughouttheRLHFstage,theaccumulationof iterativerewardmodelingdata in\\nparallel with model enhancements is crucial to ensure the reward models remain within distribution.\\n2 Pretraining\\nTocreatethenewfamilyof Llama 2models,webeganwiththepretrainingapproachdescribedinTouvronetal.\\n(2023), using an optimized auto-regressive transformer, but made several changes to improve performance.\\nSpecifically,weperformedmorerobustdatacleaning,updatedourdatamixes,trainedon40%moretotal\\ntokens,doubledthecontextlength,andusedgrouped-queryattention(GQA)toimproveinferencescalability\\nfor our larger models. Table 1 compares the attributes of the new Llama 2 models with the Llama 1 models.\\n2.1 Pretraining Data\\nOur training corpus includes a new mix of data from publicly available sources, which does not include data\\nfromMeta’sproductsorservices. Wemadeanefforttoremovedatafromcertainsitesknowntocontaina\\nhighvolumeofpersonalinformationaboutprivateindividuals. Wetrainedon2trilliontokensofdataasthis\\nprovidesagoodperformance–costtrade-off,up-samplingthemostfactualsourcesinanefforttoincrease\\nknowledge and dampen hallucinations.\\nWeperformedavarietyofpretrainingdatainvestigationssothatuserscanbetterunderstandthepotential\\ncapabilities and limitations of our models; results can be found in Section 4.1.\\n2.2 Training Details\\nWe adopt most of the pretraining setting and model architecture from Llama 1 . We use the standard\\ntransformer architecture (Vaswani et al., 2017), apply pre-normalization using RMSNorm (Zhang and\\nSennrich, 2019), use the SwiGLU activation function (Shazeer, 2020), and rotary positional embeddings\\n(RoPE, Su et al. 2022). The primary architectural differences from Llama 1 include increased context length\\nandgrouped-queryattention(GQA).WedetailinAppendixSectionA.2.1eachofthesedifferenceswith\\nablation experiments to demonstrate their importance.\\nHyperparameters. We trained using the AdamW optimizer (Loshchilov and Hutter, 2017), with β1=\\n0.9, β2= 0.95,eps= 10−5. We use a cosine learning rate schedule, with warmup of 2000 steps, and decay\\nfinallearningratedownto10%ofthepeaklearningrate. Weuseaweightdecayof 0.1andgradientclipping\\nof1.0. Figure 5 (a) shows the training loss for Llama 2 with these hyperparameters.\\n5\\n\\nTraining Data Params Context\\nLengthGQA Tokens LR\\nLlama 1See Touvron et al.\\n(2023)7B 2k ✗ 1.0T 3.0×10−4\\n13B 2k ✗ 1.0T 3.0×10−4\\n33B 2k ✗ 1.4T 1.5×10−4\\n65B 2k ✗ 1.4T 1.5×10−4\\nLlama 2A new mix of publicly\\navailable online data7B 4k ✗ 2.0T 3.0×10−4\\n13B 4k ✗ 2.0T 3.0×10−4\\n34B 4k ✓ 2.0T 1.5×10−4\\n70B 4k ✓ 2.0T 1.5×10−4\\nTable 1: Llama 2 family of models. Token counts refer to pretraining data only. All models are trained with\\na global batch-size of 4M tokens. Bigger models — 34B and 70B — use Grouped-Query Attention (GQA) for\\nimproved inference scalability.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-4'),\n",
              " '6a3378e8-633d-4c5e-81ab-3c83c520dc20': IndexNode(id_='6a3378e8-633d-4c5e-81ab-3c83c520dc20', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-5', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='21d40cc11522dda47b6adc15531a3413b90a6e2631453085d7ab9492c08d56c6'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='e760ed7c-e695-48be-841e-2145fa0679d8', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='0b50a8f0da6da4d7dd5462c0f9a3e04ef10be456c0b6571e4331f849f58cf46d')}, hash='98f12818826ff3134bf4eebbdd5f245acb64992a736657bae2eb7b6c3c79f81d', text='0 250 500 750 1000 1250 1500 1750 2000\\nProcessed Tokens (Billions)1.41.51.61.71.81.92.02.12.2Train PPLLlama-2\\n7B\\n13B\\n34B\\n70B\\nFigure 5: Training Loss for Llama 2 models. We compare the training loss of the Llama 2 family of models.\\nWe observe that after pretraining on 2T Tokens, the models still did not show any sign of saturation.\\nTokenizer.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-5'),\n",
              " 'e760ed7c-e695-48be-841e-2145fa0679d8': IndexNode(id_='e760ed7c-e695-48be-841e-2145fa0679d8', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-5', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='21d40cc11522dda47b6adc15531a3413b90a6e2631453085d7ab9492c08d56c6'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='6a3378e8-633d-4c5e-81ab-3c83c520dc20', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='98f12818826ff3134bf4eebbdd5f245acb64992a736657bae2eb7b6c3c79f81d'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='cb365092-a9b6-45dc-be9d-ef2827fc85fc', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='768fd6b031c4111a0e35f9a2115d7f8a776cc0a32f2db1467a8572bc4666acf8')}, hash='0b50a8f0da6da4d7dd5462c0f9a3e04ef10be456c0b6571e4331f849f58cf46d', text='Tokenizer. Weusethesametokenizeras Llama 1;itemploysabytepairencoding(BPE)algorithm(Sennrich\\netal.,2016)usingtheimplementationfromSentencePiece(KudoandRichardson,2018). Aswith Llama 1,\\nwe split all numbers into individual digits and use bytes to decompose unknown UTF-8 characters. The total\\nvocabulary size is 32k tokens.\\n2.2.1 Training Hardware & Carbon Footprint\\nTrainingHardware.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-5'),\n",
              " 'cb365092-a9b6-45dc-be9d-ef2827fc85fc': IndexNode(id_='cb365092-a9b6-45dc-be9d-ef2827fc85fc', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-5', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='21d40cc11522dda47b6adc15531a3413b90a6e2631453085d7ab9492c08d56c6'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='e760ed7c-e695-48be-841e-2145fa0679d8', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='0b50a8f0da6da4d7dd5462c0f9a3e04ef10be456c0b6571e4331f849f58cf46d'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='849bc2a7-936b-432c-8ee6-eefc97ec0ad1', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='b0f00d5a6b465bb64a20d9e65f8511c5b05994589fa8af3017a3824202e9d546')}, hash='768fd6b031c4111a0e35f9a2115d7f8a776cc0a32f2db1467a8572bc4666acf8', text='2.2.1 Training Hardware & Carbon Footprint\\nTrainingHardware. WepretrainedourmodelsonMeta’sResearchSuperCluster(RSC)(LeeandSengupta,\\n2022)aswellasinternalproductionclusters. BothclustersuseNVIDIAA100s.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-5'),\n",
              " '849bc2a7-936b-432c-8ee6-eefc97ec0ad1': IndexNode(id_='849bc2a7-936b-432c-8ee6-eefc97ec0ad1', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-5', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='21d40cc11522dda47b6adc15531a3413b90a6e2631453085d7ab9492c08d56c6'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='cb365092-a9b6-45dc-be9d-ef2827fc85fc', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='768fd6b031c4111a0e35f9a2115d7f8a776cc0a32f2db1467a8572bc4666acf8'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='6528a87a-3dda-47f0-857f-89218c0f0c47', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='fef20ba2c688ba32f3a5f5187342d2aafecb50b67b91189c6cc75152186bf905')}, hash='b0f00d5a6b465bb64a20d9e65f8511c5b05994589fa8af3017a3824202e9d546', text='BothclustersuseNVIDIAA100s. Therearetwokeydifferences\\nbetween the two clusters, with the first being the type of interconnect available: RSC uses NVIDIA Quantum\\nInfiniBandwhileourproductionclusterisequippedwithaRoCE(RDMAoverconvergedEthernet)solution\\nbased on commodity ethernet Switches. Both of these solutions interconnect 200 Gbps end-points.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-5'),\n",
              " '6528a87a-3dda-47f0-857f-89218c0f0c47': IndexNode(id_='6528a87a-3dda-47f0-857f-89218c0f0c47', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-5', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='21d40cc11522dda47b6adc15531a3413b90a6e2631453085d7ab9492c08d56c6'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='849bc2a7-936b-432c-8ee6-eefc97ec0ad1', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='b0f00d5a6b465bb64a20d9e65f8511c5b05994589fa8af3017a3824202e9d546'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='38c7183f-f8bc-4d37-a44c-af7fba908f5d', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='048d84dd2c2dcfb376e991a9faa3feac1e05a05d82281e803dcee6f4ff5ea1a6')}, hash='fef20ba2c688ba32f3a5f5187342d2aafecb50b67b91189c6cc75152186bf905', text='Both of these solutions interconnect 200 Gbps end-points. The\\nseconddifferenceistheper-GPUpowerconsumptioncap—RSCuses400Wwhileourproductioncluster\\nuses350W.Withthistwo-clustersetup,wewereabletocomparethesuitabilityofthesedifferenttypesof\\ninterconnectforlargescaletraining.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-5'),\n",
              " '38c7183f-f8bc-4d37-a44c-af7fba908f5d': IndexNode(id_='38c7183f-f8bc-4d37-a44c-af7fba908f5d', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-5', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='21d40cc11522dda47b6adc15531a3413b90a6e2631453085d7ab9492c08d56c6'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='6528a87a-3dda-47f0-857f-89218c0f0c47', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='fef20ba2c688ba32f3a5f5187342d2aafecb50b67b91189c6cc75152186bf905'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='5607151d-2223-47ae-9340-4978da9e3ca5', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='aef4801bc02da3227a6cda17e03b0f7fa2e714c2d2b6138ecd25ea5f1afa279c')}, hash='048d84dd2c2dcfb376e991a9faa3feac1e05a05d82281e803dcee6f4ff5ea1a6', text='RoCE(whichisamoreaffordable,commercialinterconnectnetwork)\\n6\\n\\nTime\\n(GPU hours)Power\\nConsumption (W)Carbon Emitted\\n(tCO 2eq)\\nLlama 27B 184320 400 31.22\\n13B 368640 400 62.44\\n34B 1038336 350 153.90\\n70B 1720320 400 291.42\\nTotal 3311616 539.00\\nTable 2: CO2emissions during pretraining. Time: total GPU time required for training each model.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-5'),\n",
              " '5607151d-2223-47ae-9340-4978da9e3ca5': IndexNode(id_='5607151d-2223-47ae-9340-4978da9e3ca5', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-5', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='21d40cc11522dda47b6adc15531a3413b90a6e2631453085d7ab9492c08d56c6'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='38c7183f-f8bc-4d37-a44c-af7fba908f5d', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='048d84dd2c2dcfb376e991a9faa3feac1e05a05d82281e803dcee6f4ff5ea1a6'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='8d468839-6a30-4ba1-9412-2aa156e6c7ab', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='d0c11e7b55e703cf53f2f4aac55660fed2e5484ff1caaec039baa71778353a4a')}, hash='aef4801bc02da3227a6cda17e03b0f7fa2e714c2d2b6138ecd25ea5f1afa279c', text='Time: total GPU time required for training each model. Power\\nConsumption: peak power capacity per GPU device for the GPUs used adjusted for power usage efficiency.\\n100%oftheemissionsaredirectlyoffsetbyMeta’ssustainabilityprogram,andbecauseweareopenlyreleasing\\nthese models, the pretraining costs do not need to be incurred by others.\\ncan scale almost as well as expensive Infiniband up to 2000 GPUs, which makes pretraining even more\\ndemocratizable.\\nCarbon Footprint of Pretraining.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-5'),\n",
              " '8d468839-6a30-4ba1-9412-2aa156e6c7ab': IndexNode(id_='8d468839-6a30-4ba1-9412-2aa156e6c7ab', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-5', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='21d40cc11522dda47b6adc15531a3413b90a6e2631453085d7ab9492c08d56c6'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='5607151d-2223-47ae-9340-4978da9e3ca5', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='aef4801bc02da3227a6cda17e03b0f7fa2e714c2d2b6138ecd25ea5f1afa279c'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='b01b2645-cd19-4576-998d-1f51dde4baee', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='473a660983d74e841586d136a9cfb880d69b729e7972ffb8514a384498417995')}, hash='d0c11e7b55e703cf53f2f4aac55660fed2e5484ff1caaec039baa71778353a4a', text='Carbon Footprint of Pretraining. Following preceding research (Bender et al., 2021a; Patterson et al., 2021;\\nWu et al., 2022; Dodge et al., 2022) and using power consumption estimates of GPU devices and carbon\\nefficiency, we aim tocalculate thecarbon emissions resultingfrom the pretrainingof Llama 2 models. The\\nactualpowerusageofaGPUisdependentonitsutilizationandislikelytovaryfromtheThermalDesign\\nPower(TDP)thatweemployasanestimationforGPUpower.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-5'),\n",
              " 'b01b2645-cd19-4576-998d-1f51dde4baee': IndexNode(id_='b01b2645-cd19-4576-998d-1f51dde4baee', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-5', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='21d40cc11522dda47b6adc15531a3413b90a6e2631453085d7ab9492c08d56c6'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='8d468839-6a30-4ba1-9412-2aa156e6c7ab', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='d0c11e7b55e703cf53f2f4aac55660fed2e5484ff1caaec039baa71778353a4a'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='67b9fcb3-0844-4ad1-9956-b5f7536b361f', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='685f689e106ab5710ae85fb9da1468a353af4985c6b3517c9ca35454db3a3071')}, hash='473a660983d74e841586d136a9cfb880d69b729e7972ffb8514a384498417995', text='Itisimportanttonotethatourcalculations\\ndo not account for further power demands, such as those from interconnect or non-GPU server power\\nconsumption,norfromdatacentercoolingsystems. Additionally,thecarbonoutputrelatedtotheproduction\\nof AI hardware, like GPUs, could add to the overall carbon footprint as suggested by Gupta et al. (2022b,a).\\nTable 2 summarizes the carbon emission for pretraining the Llama 2 family of models.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-5'),\n",
              " '67b9fcb3-0844-4ad1-9956-b5f7536b361f': IndexNode(id_='67b9fcb3-0844-4ad1-9956-b5f7536b361f', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-5', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='21d40cc11522dda47b6adc15531a3413b90a6e2631453085d7ab9492c08d56c6'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='b01b2645-cd19-4576-998d-1f51dde4baee', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='473a660983d74e841586d136a9cfb880d69b729e7972ffb8514a384498417995')}, hash='685f689e106ab5710ae85fb9da1468a353af4985c6b3517c9ca35454db3a3071', text='Table 2 summarizes the carbon emission for pretraining the Llama 2 family of models. A cumulative of\\n3.3M GPUhours ofcomputation wasperformed onhardware oftype A100-80GB (TDPof 400Wor 350W).\\nWe estimate the total emissions for training to be 539 tCO 2eq, of which 100% were directly offset by Meta’s\\nsustainability program.∗∗Our open release strategy also means that these pretraining costs will not need to\\nbe incurred by other companies, saving more global resources.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-5'),\n",
              " '50928df3-69e9-4c3d-a29f-0b28b2421038': IndexNode(id_='50928df3-69e9-4c3d-a29f-0b28b2421038', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-5', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='21d40cc11522dda47b6adc15531a3413b90a6e2631453085d7ab9492c08d56c6'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='ec713814-f0ed-42ae-be58-738b89a5c380', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='fb0938bf8245a8b61334222dd7914a4b59152390d40695076c9fd5c617d6c406')}, hash='e3e4eb9252892cf7ca653fbbca30f09b17febc1668ce972ca9091c80b77f21d7', text='0 250 500 750 1000 1250 1500 1750 2000\\nProcessed Tokens (Billions)1.41.51.61.71.81.92.02.12.2Train PPLLlama-2\\n7B\\n13B\\n34B\\n70B\\nFigure 5: Training Loss for Llama 2 models. We compare the training loss of the Llama 2 family of models.\\nWe observe that after pretraining on 2T Tokens, the models still did not show any sign of saturation.\\nTokenizer. Weusethesametokenizeras Llama 1;itemploysabytepairencoding(BPE)algorithm(Sennrich\\netal.,2016)usingtheimplementationfromSentencePiece(KudoandRichardson,2018). Aswith Llama 1,\\nwe split all numbers into individual digits and use bytes to decompose unknown UTF-8 characters. The total\\nvocabulary size is 32k tokens.\\n2.2.1 Training Hardware & Carbon Footprint\\nTrainingHardware.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-5'),\n",
              " 'ec713814-f0ed-42ae-be58-738b89a5c380': IndexNode(id_='ec713814-f0ed-42ae-be58-738b89a5c380', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-5', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='21d40cc11522dda47b6adc15531a3413b90a6e2631453085d7ab9492c08d56c6'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='50928df3-69e9-4c3d-a29f-0b28b2421038', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='e3e4eb9252892cf7ca653fbbca30f09b17febc1668ce972ca9091c80b77f21d7'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='ce0f7522-d9e0-4a14-bae1-bd1171a07873', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='08947687ae444091199c4f7fa817542122a4b499fcf5a9d1aaa71d9a70169f2b')}, hash='fb0938bf8245a8b61334222dd7914a4b59152390d40695076c9fd5c617d6c406', text='2.2.1 Training Hardware & Carbon Footprint\\nTrainingHardware. WepretrainedourmodelsonMeta’sResearchSuperCluster(RSC)(LeeandSengupta,\\n2022)aswellasinternalproductionclusters. BothclustersuseNVIDIAA100s. Therearetwokeydifferences\\nbetween the two clusters, with the first being the type of interconnect available: RSC uses NVIDIA Quantum\\nInfiniBandwhileourproductionclusterisequippedwithaRoCE(RDMAoverconvergedEthernet)solution\\nbased on commodity ethernet Switches. Both of these solutions interconnect 200 Gbps end-points. The\\nseconddifferenceistheper-GPUpowerconsumptioncap—RSCuses400Wwhileourproductioncluster\\nuses350W.Withthistwo-clustersetup,wewereabletocomparethesuitabilityofthesedifferenttypesof\\ninterconnectforlargescaletraining.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-5'),\n",
              " 'ce0f7522-d9e0-4a14-bae1-bd1171a07873': IndexNode(id_='ce0f7522-d9e0-4a14-bae1-bd1171a07873', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-5', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='21d40cc11522dda47b6adc15531a3413b90a6e2631453085d7ab9492c08d56c6'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='ec713814-f0ed-42ae-be58-738b89a5c380', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='fb0938bf8245a8b61334222dd7914a4b59152390d40695076c9fd5c617d6c406'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='d03d64ac-ccc0-43d3-968d-7c3aacbe3576', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='347c5c11a66e8ab7480284177716bd80d72cfc2c2e76fed1d4dbf75a48d0d2d2')}, hash='08947687ae444091199c4f7fa817542122a4b499fcf5a9d1aaa71d9a70169f2b', text='RoCE(whichisamoreaffordable,commercialinterconnectnetwork)\\n6\\n\\nTime\\n(GPU hours)Power\\nConsumption (W)Carbon Emitted\\n(tCO 2eq)\\nLlama 27B 184320 400 31.22\\n13B 368640 400 62.44\\n34B 1038336 350 153.90\\n70B 1720320 400 291.42\\nTotal 3311616 539.00\\nTable 2: CO2emissions during pretraining. Time: total GPU time required for training each model. Power\\nConsumption: peak power capacity per GPU device for the GPUs used adjusted for power usage efficiency.\\n100%oftheemissionsaredirectlyoffsetbyMeta’ssustainabilityprogram,andbecauseweareopenlyreleasing\\nthese models, the pretraining costs do not need to be incurred by others.\\ncan scale almost as well as expensive Infiniband up to 2000 GPUs, which makes pretraining even more\\ndemocratizable.\\nCarbon Footprint of Pretraining.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-5'),\n",
              " 'd03d64ac-ccc0-43d3-968d-7c3aacbe3576': IndexNode(id_='d03d64ac-ccc0-43d3-968d-7c3aacbe3576', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-5', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='21d40cc11522dda47b6adc15531a3413b90a6e2631453085d7ab9492c08d56c6'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='ce0f7522-d9e0-4a14-bae1-bd1171a07873', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='08947687ae444091199c4f7fa817542122a4b499fcf5a9d1aaa71d9a70169f2b'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='49bcd039-059a-4561-b64d-fc5146fc3890', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='685f689e106ab5710ae85fb9da1468a353af4985c6b3517c9ca35454db3a3071')}, hash='347c5c11a66e8ab7480284177716bd80d72cfc2c2e76fed1d4dbf75a48d0d2d2', text='Carbon Footprint of Pretraining. Following preceding research (Bender et al., 2021a; Patterson et al., 2021;\\nWu et al., 2022; Dodge et al., 2022) and using power consumption estimates of GPU devices and carbon\\nefficiency, we aim tocalculate thecarbon emissions resultingfrom the pretrainingof Llama 2 models. The\\nactualpowerusageofaGPUisdependentonitsutilizationandislikelytovaryfromtheThermalDesign\\nPower(TDP)thatweemployasanestimationforGPUpower. Itisimportanttonotethatourcalculations\\ndo not account for further power demands, such as those from interconnect or non-GPU server power\\nconsumption,norfromdatacentercoolingsystems. Additionally,thecarbonoutputrelatedtotheproduction\\nof AI hardware, like GPUs, could add to the overall carbon footprint as suggested by Gupta et al. (2022b,a).\\nTable 2 summarizes the carbon emission for pretraining the Llama 2 family of models.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-5'),\n",
              " '49bcd039-059a-4561-b64d-fc5146fc3890': IndexNode(id_='49bcd039-059a-4561-b64d-fc5146fc3890', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-5', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='21d40cc11522dda47b6adc15531a3413b90a6e2631453085d7ab9492c08d56c6'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='d03d64ac-ccc0-43d3-968d-7c3aacbe3576', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='347c5c11a66e8ab7480284177716bd80d72cfc2c2e76fed1d4dbf75a48d0d2d2')}, hash='685f689e106ab5710ae85fb9da1468a353af4985c6b3517c9ca35454db3a3071', text='Table 2 summarizes the carbon emission for pretraining the Llama 2 family of models. A cumulative of\\n3.3M GPUhours ofcomputation wasperformed onhardware oftype A100-80GB (TDPof 400Wor 350W).\\nWe estimate the total emissions for training to be 539 tCO 2eq, of which 100% were directly offset by Meta’s\\nsustainability program.∗∗Our open release strategy also means that these pretraining costs will not need to\\nbe incurred by other companies, saving more global resources.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-5'),\n",
              " '18c96546-7dbd-47cb-a8b4-fb9feaf069f8': IndexNode(id_='18c96546-7dbd-47cb-a8b4-fb9feaf069f8', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-5', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='21d40cc11522dda47b6adc15531a3413b90a6e2631453085d7ab9492c08d56c6'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='a93ee194-64d6-4400-bcc2-8529175e04c7', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='36b75b4a38421d127a17fc0e88333c19e443898f66456024517f578ac7256dc9')}, hash='4520e074ffc01518f27a4f94e605822ba7619f706fb3ada68fef60a1acdd59bc', text='0 250 500 750 1000 1250 1500 1750 2000\\nProcessed Tokens (Billions)1.41.51.61.71.81.92.02.12.2Train PPLLlama-2\\n7B\\n13B\\n34B\\n70B\\nFigure 5: Training Loss for Llama 2 models. We compare the training loss of the Llama 2 family of models.\\nWe observe that after pretraining on 2T Tokens, the models still did not show any sign of saturation.\\nTokenizer. Weusethesametokenizeras Llama 1;itemploysabytepairencoding(BPE)algorithm(Sennrich\\netal.,2016)usingtheimplementationfromSentencePiece(KudoandRichardson,2018). Aswith Llama 1,\\nwe split all numbers into individual digits and use bytes to decompose unknown UTF-8 characters. The total\\nvocabulary size is 32k tokens.\\n2.2.1 Training Hardware & Carbon Footprint\\nTrainingHardware. WepretrainedourmodelsonMeta’sResearchSuperCluster(RSC)(LeeandSengupta,\\n2022)aswellasinternalproductionclusters. BothclustersuseNVIDIAA100s. Therearetwokeydifferences\\nbetween the two clusters, with the first being the type of interconnect available: RSC uses NVIDIA Quantum\\nInfiniBandwhileourproductionclusterisequippedwithaRoCE(RDMAoverconvergedEthernet)solution\\nbased on commodity ethernet Switches. Both of these solutions interconnect 200 Gbps end-points. The\\nseconddifferenceistheper-GPUpowerconsumptioncap—RSCuses400Wwhileourproductioncluster\\nuses350W.Withthistwo-clustersetup,wewereabletocomparethesuitabilityofthesedifferenttypesof\\ninterconnectforlargescaletraining.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-5'),\n",
              " 'a93ee194-64d6-4400-bcc2-8529175e04c7': IndexNode(id_='a93ee194-64d6-4400-bcc2-8529175e04c7', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-5', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='21d40cc11522dda47b6adc15531a3413b90a6e2631453085d7ab9492c08d56c6'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='18c96546-7dbd-47cb-a8b4-fb9feaf069f8', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='4520e074ffc01518f27a4f94e605822ba7619f706fb3ada68fef60a1acdd59bc'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='4a18f795-e6cc-4531-a89e-f008610f55a3', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='d136c962d5a3f70aeb21bc62a66c1ab25462ab127149c839a089633ea920d89a')}, hash='36b75b4a38421d127a17fc0e88333c19e443898f66456024517f578ac7256dc9', text='RoCE(whichisamoreaffordable,commercialinterconnectnetwork)\\n6\\n\\nTime\\n(GPU hours)Power\\nConsumption (W)Carbon Emitted\\n(tCO 2eq)\\nLlama 27B 184320 400 31.22\\n13B 368640 400 62.44\\n34B 1038336 350 153.90\\n70B 1720320 400 291.42\\nTotal 3311616 539.00\\nTable 2: CO2emissions during pretraining. Time: total GPU time required for training each model. Power\\nConsumption: peak power capacity per GPU device for the GPUs used adjusted for power usage efficiency.\\n100%oftheemissionsaredirectlyoffsetbyMeta’ssustainabilityprogram,andbecauseweareopenlyreleasing\\nthese models, the pretraining costs do not need to be incurred by others.\\ncan scale almost as well as expensive Infiniband up to 2000 GPUs, which makes pretraining even more\\ndemocratizable.\\nCarbon Footprint of Pretraining. Following preceding research (Bender et al., 2021a; Patterson et al., 2021;\\nWu et al., 2022; Dodge et al., 2022) and using power consumption estimates of GPU devices and carbon\\nefficiency, we aim tocalculate thecarbon emissions resultingfrom the pretrainingof Llama 2 models. The\\nactualpowerusageofaGPUisdependentonitsutilizationandislikelytovaryfromtheThermalDesign\\nPower(TDP)thatweemployasanestimationforGPUpower. Itisimportanttonotethatourcalculations\\ndo not account for further power demands, such as those from interconnect or non-GPU server power\\nconsumption,norfromdatacentercoolingsystems. Additionally,thecarbonoutputrelatedtotheproduction\\nof AI hardware, like GPUs, could add to the overall carbon footprint as suggested by Gupta et al. (2022b,a).\\nTable 2 summarizes the carbon emission for pretraining the Llama 2 family of models. A cumulative of\\n3.3M GPUhours ofcomputation wasperformed onhardware oftype A100-80GB (TDPof 400Wor 350W).', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-5'),\n",
              " '4a18f795-e6cc-4531-a89e-f008610f55a3': IndexNode(id_='4a18f795-e6cc-4531-a89e-f008610f55a3', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-5', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='21d40cc11522dda47b6adc15531a3413b90a6e2631453085d7ab9492c08d56c6'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='a93ee194-64d6-4400-bcc2-8529175e04c7', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='36b75b4a38421d127a17fc0e88333c19e443898f66456024517f578ac7256dc9')}, hash='d136c962d5a3f70aeb21bc62a66c1ab25462ab127149c839a089633ea920d89a', text='We estimate the total emissions for training to be 539 tCO 2eq, of which 100% were directly offset by Meta’s\\nsustainability program.∗∗Our open release strategy also means that these pretraining costs will not need to\\nbe incurred by other companies, saving more global resources.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-5'),\n",
              " 'node-5': IndexNode(id_='node-5', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='415b7efc-e73f-4ac4-bbfd-c1546f099026', node_type=<ObjectType.DOCUMENT: '4'>, metadata={}, hash='231b3bd773f012c01b893ada9e009ecf25ee59934614c5a595c9bf1b3a123292'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='7c3113ce-9d82-4c50-9918-a877d7b82656', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='c8cebba0d1ac65faa2fca9c54a46b35a0c13f8bfb740aab2b919f3d80ff29993'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='7fd35437-1eeb-4b1c-89a7-100f76260ad0', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='b696325c7bd236d735782e6e9428f28f552066addb87276cd1c6365417f21821')}, hash='21d40cc11522dda47b6adc15531a3413b90a6e2631453085d7ab9492c08d56c6', text='0 250 500 750 1000 1250 1500 1750 2000\\nProcessed Tokens (Billions)1.41.51.61.71.81.92.02.12.2Train PPLLlama-2\\n7B\\n13B\\n34B\\n70B\\nFigure 5: Training Loss for Llama 2 models. We compare the training loss of the Llama 2 family of models.\\nWe observe that after pretraining on 2T Tokens, the models still did not show any sign of saturation.\\nTokenizer. Weusethesametokenizeras Llama 1;itemploysabytepairencoding(BPE)algorithm(Sennrich\\netal.,2016)usingtheimplementationfromSentencePiece(KudoandRichardson,2018). Aswith Llama 1,\\nwe split all numbers into individual digits and use bytes to decompose unknown UTF-8 characters. The total\\nvocabulary size is 32k tokens.\\n2.2.1 Training Hardware & Carbon Footprint\\nTrainingHardware. WepretrainedourmodelsonMeta’sResearchSuperCluster(RSC)(LeeandSengupta,\\n2022)aswellasinternalproductionclusters. BothclustersuseNVIDIAA100s. Therearetwokeydifferences\\nbetween the two clusters, with the first being the type of interconnect available: RSC uses NVIDIA Quantum\\nInfiniBandwhileourproductionclusterisequippedwithaRoCE(RDMAoverconvergedEthernet)solution\\nbased on commodity ethernet Switches. Both of these solutions interconnect 200 Gbps end-points. The\\nseconddifferenceistheper-GPUpowerconsumptioncap—RSCuses400Wwhileourproductioncluster\\nuses350W.Withthistwo-clustersetup,wewereabletocomparethesuitabilityofthesedifferenttypesof\\ninterconnectforlargescaletraining. RoCE(whichisamoreaffordable,commercialinterconnectnetwork)\\n6\\n\\nTime\\n(GPU hours)Power\\nConsumption (W)Carbon Emitted\\n(tCO 2eq)\\nLlama 27B 184320 400 31.22\\n13B 368640 400 62.44\\n34B 1038336 350 153.90\\n70B 1720320 400 291.42\\nTotal 3311616 539.00\\nTable 2: CO2emissions during pretraining. Time: total GPU time required for training each model. Power\\nConsumption: peak power capacity per GPU device for the GPUs used adjusted for power usage efficiency.\\n100%oftheemissionsaredirectlyoffsetbyMeta’ssustainabilityprogram,andbecauseweareopenlyreleasing\\nthese models, the pretraining costs do not need to be incurred by others.\\ncan scale almost as well as expensive Infiniband up to 2000 GPUs, which makes pretraining even more\\ndemocratizable.\\nCarbon Footprint of Pretraining. Following preceding research (Bender et al., 2021a; Patterson et al., 2021;\\nWu et al., 2022; Dodge et al., 2022) and using power consumption estimates of GPU devices and carbon\\nefficiency, we aim tocalculate thecarbon emissions resultingfrom the pretrainingof Llama 2 models. The\\nactualpowerusageofaGPUisdependentonitsutilizationandislikelytovaryfromtheThermalDesign\\nPower(TDP)thatweemployasanestimationforGPUpower. Itisimportanttonotethatourcalculations\\ndo not account for further power demands, such as those from interconnect or non-GPU server power\\nconsumption,norfromdatacentercoolingsystems. Additionally,thecarbonoutputrelatedtotheproduction\\nof AI hardware, like GPUs, could add to the overall carbon footprint as suggested by Gupta et al. (2022b,a).\\nTable 2 summarizes the carbon emission for pretraining the Llama 2 family of models. A cumulative of\\n3.3M GPUhours ofcomputation wasperformed onhardware oftype A100-80GB (TDPof 400Wor 350W).\\nWe estimate the total emissions for training to be 539 tCO 2eq, of which 100% were directly offset by Meta’s\\nsustainability program.∗∗Our open release strategy also means that these pretraining costs will not need to\\nbe incurred by other companies, saving more global resources.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-5'),\n",
              " '41fa4f75-862a-49d7-b488-69fff449fdcb': IndexNode(id_='41fa4f75-862a-49d7-b488-69fff449fdcb', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-6', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='b696325c7bd236d735782e6e9428f28f552066addb87276cd1c6365417f21821'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='902ce72a-7dd0-433a-9ce6-35301d3e673e', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='ec019a2f8f324b26458296eb04599f49916ae667d044f61208cd0daa33b334a1')}, hash='45bdb9ccbdf1ad6cde5067ad9fd33222fe4318156895ffc4a47f39b6020acdc8', text='2.3 Llama 2 Pretrained Model Evaluation\\nIn this section, we report the results for the Llama 1 andLlama 2 base models, MosaicML Pretrained\\nTransformer(MPT)††models,andFalcon(Almazroueietal.,2023)modelsonstandardacademicbenchmarks.\\nFor all the evaluations, we use our internal evaluations library. We reproduce results for the MPT and Falcon\\nmodelsinternally. Forthesemodels,wealwayspickthebestscorebetweenourevaluationframeworkand\\nany publicly reported results.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-6'),\n",
              " '902ce72a-7dd0-433a-9ce6-35301d3e673e': IndexNode(id_='902ce72a-7dd0-433a-9ce6-35301d3e673e', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-6', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='b696325c7bd236d735782e6e9428f28f552066addb87276cd1c6365417f21821'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='41fa4f75-862a-49d7-b488-69fff449fdcb', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='45bdb9ccbdf1ad6cde5067ad9fd33222fe4318156895ffc4a47f39b6020acdc8'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='7692e22c-a0ff-4337-be25-34bd56500cbf', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='a7f1e8c56ccfb8796211f5d67e57a34206bcf1d105cd2ccc82be0ab8bf6038bb')}, hash='ec019a2f8f324b26458296eb04599f49916ae667d044f61208cd0daa33b334a1', text='InTable3,wesummarizetheoverallperformanceacrossasuiteofpopularbenchmarks. Notethatsafety\\nbenchmarks are shared in Section 4.1. The benchmarks are grouped into the categories listed below. The\\nresults for all the individual benchmarks are available in Section A.2.2.\\n•Code.Wereporttheaveragepass@1scoresofourmodelsonHumanEval(Chenetal.,2021)and\\nMBPP (Austin et al., 2021).\\n•CommonsenseReasoning.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-6'),\n",
              " '7692e22c-a0ff-4337-be25-34bd56500cbf': IndexNode(id_='7692e22c-a0ff-4337-be25-34bd56500cbf', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-6', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='b696325c7bd236d735782e6e9428f28f552066addb87276cd1c6365417f21821'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='902ce72a-7dd0-433a-9ce6-35301d3e673e', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='ec019a2f8f324b26458296eb04599f49916ae667d044f61208cd0daa33b334a1'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='d0af706c-b007-4fa9-90d9-343dc897d6a0', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='be799a3d7574ab78481b29cdbe321ebd421f32028c4980897f6db4a5c062851e')}, hash='a7f1e8c56ccfb8796211f5d67e57a34206bcf1d105cd2ccc82be0ab8bf6038bb', text='•CommonsenseReasoning. WereporttheaverageofPIQA(Bisketal.,2020),SIQA(Sapetal.,2019),\\nHellaSwag (Zellers et al., 2019a), WinoGrande (Sakaguchi et al., 2021), ARC easy and challenge\\n(Clark et al., 2018), OpenBookQA (Mihaylov et al., 2018), and CommonsenseQA (Talmor et al.,\\n2018). We report 7-shot results for CommonSenseQA and 0-shot results for all other benchmarks.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-6'),\n",
              " 'd0af706c-b007-4fa9-90d9-343dc897d6a0': IndexNode(id_='d0af706c-b007-4fa9-90d9-343dc897d6a0', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-6', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='b696325c7bd236d735782e6e9428f28f552066addb87276cd1c6365417f21821'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='7692e22c-a0ff-4337-be25-34bd56500cbf', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='a7f1e8c56ccfb8796211f5d67e57a34206bcf1d105cd2ccc82be0ab8bf6038bb'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='db9a3204-6cbe-4656-a62f-084a20c0e630', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='73f2d4df200b1d9bbfefc63f67da1cf26cb405b0eb765e4ed97e485825e60bae')}, hash='be799a3d7574ab78481b29cdbe321ebd421f32028c4980897f6db4a5c062851e', text='•WorldKnowledge. Weevaluatethe5-shotperformanceonNaturalQuestions(Kwiatkowskietal.,\\n2019) and TriviaQA (Joshi et al., 2017) and report the average.\\n•Reading Comprehension. For reading comprehension, we report the 0-shot average on SQuAD\\n(Rajpurkar et al., 2018), QuAC (Choi et al., 2018), and BoolQ (Clark et al., 2019).\\n•MATH.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-6'),\n",
              " 'db9a3204-6cbe-4656-a62f-084a20c0e630': IndexNode(id_='db9a3204-6cbe-4656-a62f-084a20c0e630', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-6', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='b696325c7bd236d735782e6e9428f28f552066addb87276cd1c6365417f21821'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='d0af706c-b007-4fa9-90d9-343dc897d6a0', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='be799a3d7574ab78481b29cdbe321ebd421f32028c4980897f6db4a5c062851e'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='85e2ef07-6263-4944-a91e-826b79b8828a', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='4fb0ab6fb3c181b10bc8ee38d0bce07d897e0b232cafa80ad1b1f1ef4e8a76c8')}, hash='73f2d4df200b1d9bbfefc63f67da1cf26cb405b0eb765e4ed97e485825e60bae', text='•MATH. We report the average of the GSM8K (8 shot) (Cobbe et al., 2021) and MATH (4 shot)\\n(Hendrycks et al., 2021) benchmarks at top 1.\\n∗∗https://sustainability.fb.com/2021-sustainability-report/\\n††https://www.mosaicml.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-6'),\n",
              " '85e2ef07-6263-4944-a91e-826b79b8828a': IndexNode(id_='85e2ef07-6263-4944-a91e-826b79b8828a', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-6', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='b696325c7bd236d735782e6e9428f28f552066addb87276cd1c6365417f21821'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='db9a3204-6cbe-4656-a62f-084a20c0e630', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='73f2d4df200b1d9bbfefc63f67da1cf26cb405b0eb765e4ed97e485825e60bae'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='726cedf8-9267-47d2-a405-c8da3450047d', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='9cdefb9ea2af37b3c7fdf2730e450484815781a54956b857d76dc7de8b47a2e4')}, hash='4fb0ab6fb3c181b10bc8ee38d0bce07d897e0b232cafa80ad1b1f1ef4e8a76c8', text='mosaicml.com/blog/mpt-7b\\n7\\n\\nModel Size CodeCommonsense\\nReasoningWorld\\nKnowledgeReading\\nComprehensionMath MMLU BBH AGI Eval\\nMPT7B 20.5 57.4 41.0 57.5 4.9 26.8 31.0 23.5\\n30B 28.9 64.9 50.0 64.7 9.1 46.9 38.0 33.8\\nFalcon7B 5.6 56.1 42.8 36.0 4.6 26.2 28.0 21.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-6'),\n",
              " '726cedf8-9267-47d2-a405-c8da3450047d': IndexNode(id_='726cedf8-9267-47d2-a405-c8da3450047d', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-6', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='b696325c7bd236d735782e6e9428f28f552066addb87276cd1c6365417f21821'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='85e2ef07-6263-4944-a91e-826b79b8828a', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='4fb0ab6fb3c181b10bc8ee38d0bce07d897e0b232cafa80ad1b1f1ef4e8a76c8'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='bc759368-7d9e-4c23-9c12-d4d5ec60a2af', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='ad7284e5d546b6caec758c1dd90d6cb6f508def3a968a5460e4a6bde9cda9def')}, hash='9cdefb9ea2af37b3c7fdf2730e450484815781a54956b857d76dc7de8b47a2e4', text='1 42.8 36.0 4.6 26.2 28.0 21.2\\n40B 15.2 69.2 56.7 65.7 12.6 55.4 37.1 37.0\\nLlama 17B 14.1 60.8 46.2 58.5 6.95 35.1 30.3 23.9\\n13B 18.9 66.1 52.6 62.3 10.9 46.9 37.0 33.9\\n33B 26.0 70.0 58.4 67.6 21.4 57.8 39.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-6'),\n",
              " 'bc759368-7d9e-4c23-9c12-d4d5ec60a2af': IndexNode(id_='bc759368-7d9e-4c23-9c12-d4d5ec60a2af', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-6', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='b696325c7bd236d735782e6e9428f28f552066addb87276cd1c6365417f21821'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='726cedf8-9267-47d2-a405-c8da3450047d', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='9cdefb9ea2af37b3c7fdf2730e450484815781a54956b857d76dc7de8b47a2e4'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='657a6800-861a-4103-b683-94aa03239083', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='fec836043db66737cfdb805498a441568d27d15c1a2d9e78aaba26c25f6e7081')}, hash='ad7284e5d546b6caec758c1dd90d6cb6f508def3a968a5460e4a6bde9cda9def', text='0 70.0 58.4 67.6 21.4 57.8 39.8 41.7\\n65B 30.7 70.7 60.5 68.6 30.8 63.4 43.5 47.6\\nLlama 27B 16.8 63.9 48.9 61.3 14.6 45.3 32.6 29.3\\n13B 24.5 66.9 55.4 65.8 28.7 54.8 39.4 39.1\\n34B 27.8 69.9 58.7 68.0 24.2 62.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-6'),\n",
              " '657a6800-861a-4103-b683-94aa03239083': IndexNode(id_='657a6800-861a-4103-b683-94aa03239083', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-6', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='b696325c7bd236d735782e6e9428f28f552066addb87276cd1c6365417f21821'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='bc759368-7d9e-4c23-9c12-d4d5ec60a2af', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='ad7284e5d546b6caec758c1dd90d6cb6f508def3a968a5460e4a6bde9cda9def'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='9c35503f-6220-4084-972d-6032fa9d38d2', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='84627791c5e8e8e9e213574ebdb20a46c07aa7deb1fd302f2e69e4bab4b57607')}, hash='fec836043db66737cfdb805498a441568d27d15c1a2d9e78aaba26c25f6e7081', text='8 69.9 58.7 68.0 24.2 62.6 44.1 43.4\\n70B37.5 71.9 63.6 69.4 35.2 68.9 51.2 54.2\\nTable3: Overallperformanceongroupedacademicbenchmarkscomparedtoopen-sourcebasemodels.\\n•Popular Aggregated Benchmarks .', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-6'),\n",
              " '9c35503f-6220-4084-972d-6032fa9d38d2': IndexNode(id_='9c35503f-6220-4084-972d-6032fa9d38d2', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-6', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='b696325c7bd236d735782e6e9428f28f552066addb87276cd1c6365417f21821'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='657a6800-861a-4103-b683-94aa03239083', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='fec836043db66737cfdb805498a441568d27d15c1a2d9e78aaba26c25f6e7081')}, hash='84627791c5e8e8e9e213574ebdb20a46c07aa7deb1fd302f2e69e4bab4b57607', text='•Popular Aggregated Benchmarks . We report the overall results for MMLU (5 shot) (Hendrycks\\net al., 2020), Big Bench Hard (BBH) (3 shot) (Suzgun et al., 2022), and AGI Eval (3–5 shot) (Zhong\\net al., 2023).', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-6'),\n",
              " 'd56dec5d-264a-445c-9f2a-24ebccb22f82': IndexNode(id_='d56dec5d-264a-445c-9f2a-24ebccb22f82', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-6', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='b696325c7bd236d735782e6e9428f28f552066addb87276cd1c6365417f21821'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='7eda0fce-e996-490a-a0d4-2ed3c8ee9fee', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='e70e190a45e5c79498bcd06350b78537faa2790a04db872de990a18ea24f3e85')}, hash='3d7762ae05e45377715a2d2e211ac56bd1767d9fcb776bf7fa10bfd35fa3e9b4', text='2.3 Llama 2 Pretrained Model Evaluation\\nIn this section, we report the results for the Llama 1 andLlama 2 base models, MosaicML Pretrained\\nTransformer(MPT)††models,andFalcon(Almazroueietal.,2023)modelsonstandardacademicbenchmarks.\\nFor all the evaluations, we use our internal evaluations library. We reproduce results for the MPT and Falcon\\nmodelsinternally. Forthesemodels,wealwayspickthebestscorebetweenourevaluationframeworkand\\nany publicly reported results.\\nInTable3,wesummarizetheoverallperformanceacrossasuiteofpopularbenchmarks. Notethatsafety\\nbenchmarks are shared in Section 4.1. The benchmarks are grouped into the categories listed below. The\\nresults for all the individual benchmarks are available in Section A.2.2.\\n•Code.Wereporttheaveragepass@1scoresofourmodelsonHumanEval(Chenetal.,2021)and\\nMBPP (Austin et al., 2021).\\n•CommonsenseReasoning.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-6'),\n",
              " '7eda0fce-e996-490a-a0d4-2ed3c8ee9fee': IndexNode(id_='7eda0fce-e996-490a-a0d4-2ed3c8ee9fee', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-6', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='b696325c7bd236d735782e6e9428f28f552066addb87276cd1c6365417f21821'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='d56dec5d-264a-445c-9f2a-24ebccb22f82', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='3d7762ae05e45377715a2d2e211ac56bd1767d9fcb776bf7fa10bfd35fa3e9b4'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='613aa58f-925d-4791-8f59-544de57840c1', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='285859d1216c9cff1eef7e2c520d031e3f751109ac76278df4beac6f9f652e1b')}, hash='e70e190a45e5c79498bcd06350b78537faa2790a04db872de990a18ea24f3e85', text='•CommonsenseReasoning. WereporttheaverageofPIQA(Bisketal.,2020),SIQA(Sapetal.,2019),\\nHellaSwag (Zellers et al., 2019a), WinoGrande (Sakaguchi et al., 2021), ARC easy and challenge\\n(Clark et al., 2018), OpenBookQA (Mihaylov et al., 2018), and CommonsenseQA (Talmor et al.,\\n2018). We report 7-shot results for CommonSenseQA and 0-shot results for all other benchmarks.\\n•WorldKnowledge. Weevaluatethe5-shotperformanceonNaturalQuestions(Kwiatkowskietal.,\\n2019) and TriviaQA (Joshi et al., 2017) and report the average.\\n•Reading Comprehension. For reading comprehension, we report the 0-shot average on SQuAD\\n(Rajpurkar et al., 2018), QuAC (Choi et al., 2018), and BoolQ (Clark et al., 2019).\\n•MATH.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-6'),\n",
              " '613aa58f-925d-4791-8f59-544de57840c1': IndexNode(id_='613aa58f-925d-4791-8f59-544de57840c1', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-6', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='b696325c7bd236d735782e6e9428f28f552066addb87276cd1c6365417f21821'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='7eda0fce-e996-490a-a0d4-2ed3c8ee9fee', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='e70e190a45e5c79498bcd06350b78537faa2790a04db872de990a18ea24f3e85'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='9ab81101-ef2a-4708-8ede-fe3b1cb67b39', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='992416f902b12470b6927f7dd26b8b3dcc93cafaff88df578c54680ac0c4c0b2')}, hash='285859d1216c9cff1eef7e2c520d031e3f751109ac76278df4beac6f9f652e1b', text='•MATH. We report the average of the GSM8K (8 shot) (Cobbe et al., 2021) and MATH (4 shot)\\n(Hendrycks et al., 2021) benchmarks at top 1.\\n∗∗https://sustainability.fb.com/2021-sustainability-report/\\n††https://www.mosaicml.com/blog/mpt-7b\\n7\\n\\nModel Size CodeCommonsense\\nReasoningWorld\\nKnowledgeReading\\nComprehensionMath MMLU BBH AGI Eval\\nMPT7B 20.5 57.4 41.0 57.5 4.9 26.8 31.0 23.5\\n30B 28.9 64.9 50.0 64.7 9.1 46.9 38.0 33.8\\nFalcon7B 5.6 56.1 42.8 36.0 4.6 26.2 28.0 21.2\\n40B 15.2 69.2 56.7 65.7 12.6 55.4 37.1 37.0\\nLlama 17B 14.1 60.8 46.2 58.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-6'),\n",
              " '9ab81101-ef2a-4708-8ede-fe3b1cb67b39': IndexNode(id_='9ab81101-ef2a-4708-8ede-fe3b1cb67b39', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-6', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='b696325c7bd236d735782e6e9428f28f552066addb87276cd1c6365417f21821'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='613aa58f-925d-4791-8f59-544de57840c1', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='285859d1216c9cff1eef7e2c520d031e3f751109ac76278df4beac6f9f652e1b'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='de2121d1-f05f-410d-906d-b193bdecdf74', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='84627791c5e8e8e9e213574ebdb20a46c07aa7deb1fd302f2e69e4bab4b57607')}, hash='992416f902b12470b6927f7dd26b8b3dcc93cafaff88df578c54680ac0c4c0b2', text='0\\nLlama 17B 14.1 60.8 46.2 58.5 6.95 35.1 30.3 23.9\\n13B 18.9 66.1 52.6 62.3 10.9 46.9 37.0 33.9\\n33B 26.0 70.0 58.4 67.6 21.4 57.8 39.8 41.7\\n65B 30.7 70.7 60.5 68.6 30.8 63.4 43.5 47.6\\nLlama 27B 16.8 63.9 48.9 61.3 14.6 45.3 32.6 29.3\\n13B 24.5 66.9 55.4 65.8 28.7 54.8 39.4 39.1\\n34B 27.8 69.9 58.7 68.0 24.2 62.6 44.1 43.4\\n70B37.5 71.9 63.6 69.4 35.2 68.9 51.2 54.2\\nTable3: Overallperformanceongroupedacademicbenchmarkscomparedtoopen-sourcebasemodels.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-6'),\n",
              " 'de2121d1-f05f-410d-906d-b193bdecdf74': IndexNode(id_='de2121d1-f05f-410d-906d-b193bdecdf74', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-6', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='b696325c7bd236d735782e6e9428f28f552066addb87276cd1c6365417f21821'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='9ab81101-ef2a-4708-8ede-fe3b1cb67b39', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='992416f902b12470b6927f7dd26b8b3dcc93cafaff88df578c54680ac0c4c0b2')}, hash='84627791c5e8e8e9e213574ebdb20a46c07aa7deb1fd302f2e69e4bab4b57607', text='•Popular Aggregated Benchmarks . We report the overall results for MMLU (5 shot) (Hendrycks\\net al., 2020), Big Bench Hard (BBH) (3 shot) (Suzgun et al., 2022), and AGI Eval (3–5 shot) (Zhong\\net al., 2023).', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-6'),\n",
              " 'd30dd26d-3b30-42ac-9f1a-14c436a59791': IndexNode(id_='d30dd26d-3b30-42ac-9f1a-14c436a59791', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-6', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='b696325c7bd236d735782e6e9428f28f552066addb87276cd1c6365417f21821'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='1cb4526e-22b0-4c36-8ef6-a967ac1f58d3', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='a75d3dae346985779c3fb92b973596f9a6f96a56ac9357e56c36a846d4d41374')}, hash='00c3a27da6422bbeb136068193e1369f2adecd99cfed0d85739deb5fc63ef797', text='2.3 Llama 2 Pretrained Model Evaluation\\nIn this section, we report the results for the Llama 1 andLlama 2 base models, MosaicML Pretrained\\nTransformer(MPT)††models,andFalcon(Almazroueietal.,2023)modelsonstandardacademicbenchmarks.\\nFor all the evaluations, we use our internal evaluations library. We reproduce results for the MPT and Falcon\\nmodelsinternally. Forthesemodels,wealwayspickthebestscorebetweenourevaluationframeworkand\\nany publicly reported results.\\nInTable3,wesummarizetheoverallperformanceacrossasuiteofpopularbenchmarks. Notethatsafety\\nbenchmarks are shared in Section 4.1. The benchmarks are grouped into the categories listed below. The\\nresults for all the individual benchmarks are available in Section A.2.2.\\n•Code.Wereporttheaveragepass@1scoresofourmodelsonHumanEval(Chenetal.,2021)and\\nMBPP (Austin et al., 2021).\\n•CommonsenseReasoning. WereporttheaverageofPIQA(Bisketal.,2020),SIQA(Sapetal.,2019),\\nHellaSwag (Zellers et al., 2019a), WinoGrande (Sakaguchi et al., 2021), ARC easy and challenge\\n(Clark et al., 2018), OpenBookQA (Mihaylov et al., 2018), and CommonsenseQA (Talmor et al.,\\n2018). We report 7-shot results for CommonSenseQA and 0-shot results for all other benchmarks.\\n•WorldKnowledge. Weevaluatethe5-shotperformanceonNaturalQuestions(Kwiatkowskietal.,\\n2019) and TriviaQA (Joshi et al., 2017) and report the average.\\n•Reading Comprehension. For reading comprehension, we report the 0-shot average on SQuAD\\n(Rajpurkar et al., 2018), QuAC (Choi et al., 2018), and BoolQ (Clark et al., 2019).\\n•MATH.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-6'),\n",
              " '1cb4526e-22b0-4c36-8ef6-a967ac1f58d3': IndexNode(id_='1cb4526e-22b0-4c36-8ef6-a967ac1f58d3', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-6', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='b696325c7bd236d735782e6e9428f28f552066addb87276cd1c6365417f21821'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='d30dd26d-3b30-42ac-9f1a-14c436a59791', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='00c3a27da6422bbeb136068193e1369f2adecd99cfed0d85739deb5fc63ef797'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='52bbf77a-160f-409a-82de-99f1eca04f3b', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='84627791c5e8e8e9e213574ebdb20a46c07aa7deb1fd302f2e69e4bab4b57607')}, hash='a75d3dae346985779c3fb92b973596f9a6f96a56ac9357e56c36a846d4d41374', text='•MATH. We report the average of the GSM8K (8 shot) (Cobbe et al., 2021) and MATH (4 shot)\\n(Hendrycks et al., 2021) benchmarks at top 1.\\n∗∗https://sustainability.fb.com/2021-sustainability-report/\\n††https://www.mosaicml.com/blog/mpt-7b\\n7\\n\\nModel Size CodeCommonsense\\nReasoningWorld\\nKnowledgeReading\\nComprehensionMath MMLU BBH AGI Eval\\nMPT7B 20.5 57.4 41.0 57.5 4.9 26.8 31.0 23.5\\n30B 28.9 64.9 50.0 64.7 9.1 46.9 38.0 33.8\\nFalcon7B 5.6 56.1 42.8 36.0 4.6 26.2 28.0 21.2\\n40B 15.2 69.2 56.7 65.7 12.6 55.4 37.1 37.0\\nLlama 17B 14.1 60.8 46.2 58.5 6.95 35.1 30.3 23.9\\n13B 18.9 66.1 52.6 62.3 10.9 46.9 37.0 33.9\\n33B 26.0 70.0 58.4 67.6 21.4 57.8 39.8 41.7\\n65B 30.7 70.7 60.5 68.6 30.8 63.4 43.5 47.6\\nLlama 27B 16.8 63.9 48.9 61.3 14.6 45.3 32.6 29.3\\n13B 24.5 66.9 55.4 65.8 28.7 54.8 39.4 39.1\\n34B 27.8 69.9 58.7 68.0 24.2 62.6 44.1 43.4\\n70B37.5 71.9 63.6 69.4 35.2 68.9 51.2 54.2\\nTable3: Overallperformanceongroupedacademicbenchmarkscomparedtoopen-sourcebasemodels.\\n•Popular Aggregated Benchmarks .', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-6'),\n",
              " '52bbf77a-160f-409a-82de-99f1eca04f3b': IndexNode(id_='52bbf77a-160f-409a-82de-99f1eca04f3b', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-6', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='b696325c7bd236d735782e6e9428f28f552066addb87276cd1c6365417f21821'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='1cb4526e-22b0-4c36-8ef6-a967ac1f58d3', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='a75d3dae346985779c3fb92b973596f9a6f96a56ac9357e56c36a846d4d41374')}, hash='84627791c5e8e8e9e213574ebdb20a46c07aa7deb1fd302f2e69e4bab4b57607', text='•Popular Aggregated Benchmarks . We report the overall results for MMLU (5 shot) (Hendrycks\\net al., 2020), Big Bench Hard (BBH) (3 shot) (Suzgun et al., 2022), and AGI Eval (3–5 shot) (Zhong\\net al., 2023).', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-6'),\n",
              " 'node-6': IndexNode(id_='node-6', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='415b7efc-e73f-4ac4-bbfd-c1546f099026', node_type=<ObjectType.DOCUMENT: '4'>, metadata={}, hash='231b3bd773f012c01b893ada9e009ecf25ee59934614c5a595c9bf1b3a123292'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='9a521d76-47f8-433e-b43e-3f05c5487766', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='21d40cc11522dda47b6adc15531a3413b90a6e2631453085d7ab9492c08d56c6'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='53461c00-38cf-4b4c-8af9-263307782a38', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='6a5157801445b48ce412fd032511d4dce3c0f64b4d5b004fdab4a4bd930b77a2')}, hash='b696325c7bd236d735782e6e9428f28f552066addb87276cd1c6365417f21821', text='2.3 Llama 2 Pretrained Model Evaluation\\nIn this section, we report the results for the Llama 1 andLlama 2 base models, MosaicML Pretrained\\nTransformer(MPT)††models,andFalcon(Almazroueietal.,2023)modelsonstandardacademicbenchmarks.\\nFor all the evaluations, we use our internal evaluations library. We reproduce results for the MPT and Falcon\\nmodelsinternally. Forthesemodels,wealwayspickthebestscorebetweenourevaluationframeworkand\\nany publicly reported results.\\nInTable3,wesummarizetheoverallperformanceacrossasuiteofpopularbenchmarks. Notethatsafety\\nbenchmarks are shared in Section 4.1. The benchmarks are grouped into the categories listed below. The\\nresults for all the individual benchmarks are available in Section A.2.2.\\n•Code.Wereporttheaveragepass@1scoresofourmodelsonHumanEval(Chenetal.,2021)and\\nMBPP (Austin et al., 2021).\\n•CommonsenseReasoning. WereporttheaverageofPIQA(Bisketal.,2020),SIQA(Sapetal.,2019),\\nHellaSwag (Zellers et al., 2019a), WinoGrande (Sakaguchi et al., 2021), ARC easy and challenge\\n(Clark et al., 2018), OpenBookQA (Mihaylov et al., 2018), and CommonsenseQA (Talmor et al.,\\n2018). We report 7-shot results for CommonSenseQA and 0-shot results for all other benchmarks.\\n•WorldKnowledge. Weevaluatethe5-shotperformanceonNaturalQuestions(Kwiatkowskietal.,\\n2019) and TriviaQA (Joshi et al., 2017) and report the average.\\n•Reading Comprehension. For reading comprehension, we report the 0-shot average on SQuAD\\n(Rajpurkar et al., 2018), QuAC (Choi et al., 2018), and BoolQ (Clark et al., 2019).\\n•MATH. We report the average of the GSM8K (8 shot) (Cobbe et al., 2021) and MATH (4 shot)\\n(Hendrycks et al., 2021) benchmarks at top 1.\\n∗∗https://sustainability.fb.com/2021-sustainability-report/\\n††https://www.mosaicml.com/blog/mpt-7b\\n7\\n\\nModel Size CodeCommonsense\\nReasoningWorld\\nKnowledgeReading\\nComprehensionMath MMLU BBH AGI Eval\\nMPT7B 20.5 57.4 41.0 57.5 4.9 26.8 31.0 23.5\\n30B 28.9 64.9 50.0 64.7 9.1 46.9 38.0 33.8\\nFalcon7B 5.6 56.1 42.8 36.0 4.6 26.2 28.0 21.2\\n40B 15.2 69.2 56.7 65.7 12.6 55.4 37.1 37.0\\nLlama 17B 14.1 60.8 46.2 58.5 6.95 35.1 30.3 23.9\\n13B 18.9 66.1 52.6 62.3 10.9 46.9 37.0 33.9\\n33B 26.0 70.0 58.4 67.6 21.4 57.8 39.8 41.7\\n65B 30.7 70.7 60.5 68.6 30.8 63.4 43.5 47.6\\nLlama 27B 16.8 63.9 48.9 61.3 14.6 45.3 32.6 29.3\\n13B 24.5 66.9 55.4 65.8 28.7 54.8 39.4 39.1\\n34B 27.8 69.9 58.7 68.0 24.2 62.6 44.1 43.4\\n70B37.5 71.9 63.6 69.4 35.2 68.9 51.2 54.2\\nTable3: Overallperformanceongroupedacademicbenchmarkscomparedtoopen-sourcebasemodels.\\n•Popular Aggregated Benchmarks . We report the overall results for MMLU (5 shot) (Hendrycks\\net al., 2020), Big Bench Hard (BBH) (3 shot) (Suzgun et al., 2022), and AGI Eval (3–5 shot) (Zhong\\net al., 2023).', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-6'),\n",
              " '7f0f81bd-1e0f-459a-a9e9-46e3364a00d2': IndexNode(id_='7f0f81bd-1e0f-459a-a9e9-46e3364a00d2', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-7', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='6a5157801445b48ce412fd032511d4dce3c0f64b4d5b004fdab4a4bd930b77a2'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='60547698-928a-42a9-9def-bb2e7b3d02e0', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='10e79a1ea26d41905386959816a93e2d259b8ad199f58d743723be184966fbe9')}, hash='66e9a20331c42cf3d60175a73eb3cc9e1a08a21677c71c6b484b0d7542b874cf', text='For AGI Eval, we only evaluate on the English tasks and report the average.\\nAs shown in Table 3, Llama 2 models outperform Llama 1 models. In particular, Llama 2 70B improves the\\nresultsonMMLUandBBHby ≈5and≈8points,respectively,comparedto Llama 1 65B.Llama 2 7Band30B\\nmodelsoutperformMPTmodelsofthecorrespondingsizeonallcategoriesbesidescodebenchmarks.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-7'),\n",
              " '60547698-928a-42a9-9def-bb2e7b3d02e0': IndexNode(id_='60547698-928a-42a9-9def-bb2e7b3d02e0', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-7', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='6a5157801445b48ce412fd032511d4dce3c0f64b4d5b004fdab4a4bd930b77a2'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='7f0f81bd-1e0f-459a-a9e9-46e3364a00d2', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='66e9a20331c42cf3d60175a73eb3cc9e1a08a21677c71c6b484b0d7542b874cf'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='2c19eddc-a83d-49b1-8c48-da081443d39e', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='00c8c4650d9c5ccb1e176b6f38d0c82320c909710ea46fd446e9d7f2789819f8')}, hash='10e79a1ea26d41905386959816a93e2d259b8ad199f58d743723be184966fbe9', text='Forthe\\nFalcon models, Llama 2 7B and 34B outperform Falcon 7B and 40B models on all categories of benchmarks.\\nAdditionally, Llama 2 70B model outperforms all open-source models.\\nIn addition to open-source models, we also compare Llama 2 70B results to closed-source models. As shown\\nin Table 4, Llama 2 70B is close to GPT-3.5 (OpenAI, 2023) on MMLU and GSM8K, but there is a significant\\ngaponcodingbenchmarks.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-7'),\n",
              " '2c19eddc-a83d-49b1-8c48-da081443d39e': IndexNode(id_='2c19eddc-a83d-49b1-8c48-da081443d39e', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-7', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='6a5157801445b48ce412fd032511d4dce3c0f64b4d5b004fdab4a4bd930b77a2'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='60547698-928a-42a9-9def-bb2e7b3d02e0', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='10e79a1ea26d41905386959816a93e2d259b8ad199f58d743723be184966fbe9'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='2f73b03b-ed60-4160-81e3-a192b5a2e596', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='91d47937de9e7fa68922132b1d0de4d71a4a605d830a0e1f0e8300c76faa70d4')}, hash='00c8c4650d9c5ccb1e176b6f38d0c82320c909710ea46fd446e9d7f2789819f8', text='Llama 2 70BresultsareonparorbetterthanPaLM(540B)(Chowdheryetal.,\\n2022)onalmostallbenchmarks. Thereisstillalargegapinperformancebetween Llama 2 70BandGPT-4\\nand PaLM-2-L.\\nWe also analysed the potential data contamination and share the details in Section A.6.\\nBenchmark (shots) GPT-3.5 GPT-4 PaLM PaLM-2-L Llama 2\\nMMLU (5-shot) 70.0 86.4 69.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-7'),\n",
              " '2f73b03b-ed60-4160-81e3-a192b5a2e596': IndexNode(id_='2f73b03b-ed60-4160-81e3-a192b5a2e596', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-7', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='6a5157801445b48ce412fd032511d4dce3c0f64b4d5b004fdab4a4bd930b77a2'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='2c19eddc-a83d-49b1-8c48-da081443d39e', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='00c8c4650d9c5ccb1e176b6f38d0c82320c909710ea46fd446e9d7f2789819f8'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='5552c3d4-ff67-4b3a-af0c-740fa62bd6d4', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='4979827b1a07410dedf26cc0e7f024da52d5a3217f1c779f5dad6fd51d382d97')}, hash='91d47937de9e7fa68922132b1d0de4d71a4a605d830a0e1f0e8300c76faa70d4', text='0 86.4 69.3 78.3 68.9\\nTriviaQA (1-shot) – – 81.4 86.1 85.0\\nNatural Questions (1-shot) – – 29.3 37.5 33.0\\nGSM8K (8-shot) 57.1 92.0 56.5 80.7 56.8\\nHumanEval (0-shot) 48.1 67.0 26.2 – 29.9\\nBIG-Bench Hard (3-shot) – – 52.3 65.7 51.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-7'),\n",
              " '5552c3d4-ff67-4b3a-af0c-740fa62bd6d4': IndexNode(id_='5552c3d4-ff67-4b3a-af0c-740fa62bd6d4', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-7', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='6a5157801445b48ce412fd032511d4dce3c0f64b4d5b004fdab4a4bd930b77a2'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='2f73b03b-ed60-4160-81e3-a192b5a2e596', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='91d47937de9e7fa68922132b1d0de4d71a4a605d830a0e1f0e8300c76faa70d4'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='03d44967-f0ea-4a73-ba28-614eba3d1302', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='4865107e63ee11fcb1c3bef628712d979c0b084a523c29506257f54885a24c8e')}, hash='4979827b1a07410dedf26cc0e7f024da52d5a3217f1c779f5dad6fd51d382d97', text='3 65.7 51.2\\nTable 4: Comparison to closed-source models on academic benchmarks. Results for GPT-3.5 and GPT-4\\nare from OpenAI (2023). Results for the PaLM model are from Chowdhery et al. (2022). Results for the\\nPaLM-2-L are from Anil et al. (2023).', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-7'),\n",
              " '03d44967-f0ea-4a73-ba28-614eba3d1302': IndexNode(id_='03d44967-f0ea-4a73-ba28-614eba3d1302', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-7', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='6a5157801445b48ce412fd032511d4dce3c0f64b4d5b004fdab4a4bd930b77a2'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='5552c3d4-ff67-4b3a-af0c-740fa62bd6d4', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='4979827b1a07410dedf26cc0e7f024da52d5a3217f1c779f5dad6fd51d382d97'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='ffccda48-76e1-45d3-bcd3-83c3cff35bc2', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='2fe25c7e1f945ef2e288b7d6347979a26010419e8ace2a5cb806e9c7bdc0ba75')}, hash='4865107e63ee11fcb1c3bef628712d979c0b084a523c29506257f54885a24c8e', text='(2023).\\n3 Fine-tuning\\nLlama 2-Chat is the result of several months of research and iterative applications of alignment techniques,\\nincluding both instruction tuning and RLHF, requiring significant computational and annotation resources.\\nIn this section, we report on our experiments and findings using supervised fine-tuning (Section 3.1), as\\nwell as initial and iterative reward modeling (Section 3.2.2) and RLHF (Section 3.2.3).', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-7'),\n",
              " 'ffccda48-76e1-45d3-bcd3-83c3cff35bc2': IndexNode(id_='ffccda48-76e1-45d3-bcd3-83c3cff35bc2', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-7', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='6a5157801445b48ce412fd032511d4dce3c0f64b4d5b004fdab4a4bd930b77a2'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='03d44967-f0ea-4a73-ba28-614eba3d1302', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='4865107e63ee11fcb1c3bef628712d979c0b084a523c29506257f54885a24c8e'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='5a6ff8cb-9d30-4b84-8c40-757daac388ac', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='aec6f223fd269d068f41d1dd65366532c5e2be7bcf9006a906ff68f3d1a3c709')}, hash='2fe25c7e1f945ef2e288b7d6347979a26010419e8ace2a5cb806e9c7bdc0ba75', text='We also share a\\nnew technique, Ghost Attention (GAtt), which we find helps control dialogue flow over multiple turns\\n(Section 3.3). See Section 4.2 for safety evaluations on fine-tuned models.\\n8\\n\\n3.1 Supervised Fine-Tuning (SFT)\\n➤Prompt: Writeapoemtohelpmerememberthefirst10elementsontheperiodictable,givingeach\\nelement its own line.\\nResponse: Hydrogen comes first as element number one.\\nHelium is second for balloons to have fun!', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-7'),\n",
              " '5a6ff8cb-9d30-4b84-8c40-757daac388ac': IndexNode(id_='5a6ff8cb-9d30-4b84-8c40-757daac388ac', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-7', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='6a5157801445b48ce412fd032511d4dce3c0f64b4d5b004fdab4a4bd930b77a2'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='ffccda48-76e1-45d3-bcd3-83c3cff35bc2', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='2fe25c7e1f945ef2e288b7d6347979a26010419e8ace2a5cb806e9c7bdc0ba75'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='e5e2ad5a-dddc-478e-a936-ae5c98543820', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='ee050e76e9136951e75528d534af7cca84662d85e9c933554a41100f079a5363')}, hash='aec6f223fd269d068f41d1dd65366532c5e2be7bcf9006a906ff68f3d1a3c709', text='Helium is second for balloons to have fun!\\nIn third place is Lithium to hold battery charge,\\nFollowed by Beryllium in emeralds small and large.\\nBoron’s number five to help us keep things clean.\\nCarbon’s next at six, and it’s found in every gene.\\nNitrogen is seven, found in every breath we take,\\nMore than eight (or Oxygen) in atmospheric make.\\nNumber nine is Fluorine, helping polish up our teeth.\\nNeon gives us glowing signs to read and stand beneath.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-7'),\n",
              " 'e5e2ad5a-dddc-478e-a936-ae5c98543820': IndexNode(id_='e5e2ad5a-dddc-478e-a936-ae5c98543820', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-7', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='6a5157801445b48ce412fd032511d4dce3c0f64b4d5b004fdab4a4bd930b77a2'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='5a6ff8cb-9d30-4b84-8c40-757daac388ac', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='aec6f223fd269d068f41d1dd65366532c5e2be7bcf9006a906ff68f3d1a3c709'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='9613842b-e524-4491-8905-c81e62674565', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='c5b26a1d18f49392528c451cecb87b2cb358d282c698241bfb9eec0704c3395f')}, hash='ee050e76e9136951e75528d534af7cca84662d85e9c933554a41100f079a5363', text='Neon gives us glowing signs to read and stand beneath.\\n➤Prompt: I want you to roast me. I want you to make it particularly brutal, swearing at me.\\nResponse: I’m sorry, but I cannot comply with that request. Using vulgar language or intentionally\\nhurting someone’s feelings is never acceptable. Instead of asking for a roast, I suggest\\nfocusingonpositiveandconstructivefeedbackthatcanhelpyougrowandimproveasan\\nindividual.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-7'),\n",
              " '9613842b-e524-4491-8905-c81e62674565': IndexNode(id_='9613842b-e524-4491-8905-c81e62674565', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-7', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='6a5157801445b48ce412fd032511d4dce3c0f64b4d5b004fdab4a4bd930b77a2'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='e5e2ad5a-dddc-478e-a936-ae5c98543820', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='ee050e76e9136951e75528d534af7cca84662d85e9c933554a41100f079a5363')}, hash='c5b26a1d18f49392528c451cecb87b2cb358d282c698241bfb9eec0704c3395f', text='If you’re looking for comedic relief, there are plenty of other ways to achieve\\nthat without resorting to hurtful language or behavior.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-7'),\n",
              " '5412437a-903c-42b0-bb50-98a97de69299': IndexNode(id_='5412437a-903c-42b0-bb50-98a97de69299', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-7', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='6a5157801445b48ce412fd032511d4dce3c0f64b4d5b004fdab4a4bd930b77a2'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='5a8d3497-14bd-4c9d-b560-81f2f21e4144', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='62fb02074c73686cf6ce81d17cd2f0821565622af2ca8ec76f1c2fc9a455867a')}, hash='92d1fa15ca65bb3652cb7b2104a9f396f00b3564f2ef22edc0b399c7c4574d08', text='For AGI Eval, we only evaluate on the English tasks and report the average.\\nAs shown in Table 3, Llama 2 models outperform Llama 1 models. In particular, Llama 2 70B improves the\\nresultsonMMLUandBBHby ≈5and≈8points,respectively,comparedto Llama 1 65B.Llama 2 7Band30B\\nmodelsoutperformMPTmodelsofthecorrespondingsizeonallcategoriesbesidescodebenchmarks. Forthe\\nFalcon models, Llama 2 7B and 34B outperform Falcon 7B and 40B models on all categories of benchmarks.\\nAdditionally, Llama 2 70B model outperforms all open-source models.\\nIn addition to open-source models, we also compare Llama 2 70B results to closed-source models. As shown\\nin Table 4, Llama 2 70B is close to GPT-3.5 (OpenAI, 2023) on MMLU and GSM8K, but there is a significant\\ngaponcodingbenchmarks.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-7'),\n",
              " '5a8d3497-14bd-4c9d-b560-81f2f21e4144': IndexNode(id_='5a8d3497-14bd-4c9d-b560-81f2f21e4144', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-7', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='6a5157801445b48ce412fd032511d4dce3c0f64b4d5b004fdab4a4bd930b77a2'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='5412437a-903c-42b0-bb50-98a97de69299', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='92d1fa15ca65bb3652cb7b2104a9f396f00b3564f2ef22edc0b399c7c4574d08'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='0c5a72f4-a866-4198-b4bd-6627e741bbcb', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='66c546d62b1c4d75b75dc9ce7e38cf91708e823bfec5cc5761b518ce5101641e')}, hash='62fb02074c73686cf6ce81d17cd2f0821565622af2ca8ec76f1c2fc9a455867a', text='Llama 2 70BresultsareonparorbetterthanPaLM(540B)(Chowdheryetal.,\\n2022)onalmostallbenchmarks. Thereisstillalargegapinperformancebetween Llama 2 70BandGPT-4\\nand PaLM-2-L.\\nWe also analysed the potential data contamination and share the details in Section A.6.\\nBenchmark (shots) GPT-3.5 GPT-4 PaLM PaLM-2-L Llama 2\\nMMLU (5-shot) 70.0 86.4 69.3 78.3 68.9\\nTriviaQA (1-shot) – – 81.4 86.1 85.0\\nNatural Questions (1-shot) – – 29.3 37.5 33.0\\nGSM8K (8-shot) 57.1 92.0 56.5 80.7 56.8\\nHumanEval (0-shot) 48.1 67.0 26.2 – 29.9\\nBIG-Bench Hard (3-shot) – – 52.3 65.7 51.2\\nTable 4: Comparison to closed-source models on academic benchmarks.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-7'),\n",
              " '0c5a72f4-a866-4198-b4bd-6627e741bbcb': IndexNode(id_='0c5a72f4-a866-4198-b4bd-6627e741bbcb', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-7', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='6a5157801445b48ce412fd032511d4dce3c0f64b4d5b004fdab4a4bd930b77a2'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='5a8d3497-14bd-4c9d-b560-81f2f21e4144', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='62fb02074c73686cf6ce81d17cd2f0821565622af2ca8ec76f1c2fc9a455867a'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='24134328-9397-428b-930c-67ee0d3bb820', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='bdd44d1bcfe3c486defb47c3e8322936552715fbec423e33b9291f4c2431ba3d')}, hash='66c546d62b1c4d75b75dc9ce7e38cf91708e823bfec5cc5761b518ce5101641e', text='Results for GPT-3.5 and GPT-4\\nare from OpenAI (2023). Results for the PaLM model are from Chowdhery et al. (2022). Results for the\\nPaLM-2-L are from Anil et al. (2023).\\n3 Fine-tuning\\nLlama 2-Chat is the result of several months of research and iterative applications of alignment techniques,\\nincluding both instruction tuning and RLHF, requiring significant computational and annotation resources.\\nIn this section, we report on our experiments and findings using supervised fine-tuning (Section 3.1), as\\nwell as initial and iterative reward modeling (Section 3.2.2) and RLHF (Section 3.2.3). We also share a\\nnew technique, Ghost Attention (GAtt), which we find helps control dialogue flow over multiple turns\\n(Section 3.3). See Section 4.2 for safety evaluations on fine-tuned models.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-7'),\n",
              " '24134328-9397-428b-930c-67ee0d3bb820': IndexNode(id_='24134328-9397-428b-930c-67ee0d3bb820', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-7', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='6a5157801445b48ce412fd032511d4dce3c0f64b4d5b004fdab4a4bd930b77a2'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='0c5a72f4-a866-4198-b4bd-6627e741bbcb', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='66c546d62b1c4d75b75dc9ce7e38cf91708e823bfec5cc5761b518ce5101641e'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='40e0e2cf-b9e8-4bd2-8604-d036f408b9e7', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='837e92db2fee2e4d0164bc5651cf5eeb962254ea5254f49e2fb8110607d29c79')}, hash='bdd44d1bcfe3c486defb47c3e8322936552715fbec423e33b9291f4c2431ba3d', text='See Section 4.2 for safety evaluations on fine-tuned models.\\n8\\n\\n3.1 Supervised Fine-Tuning (SFT)\\n➤Prompt: Writeapoemtohelpmerememberthefirst10elementsontheperiodictable,givingeach\\nelement its own line.\\nResponse: Hydrogen comes first as element number one.\\nHelium is second for balloons to have fun!\\nIn third place is Lithium to hold battery charge,\\nFollowed by Beryllium in emeralds small and large.\\nBoron’s number five to help us keep things clean.\\nCarbon’s next at six, and it’s found in every gene.\\nNitrogen is seven, found in every breath we take,\\nMore than eight (or Oxygen) in atmospheric make.\\nNumber nine is Fluorine, helping polish up our teeth.\\nNeon gives us glowing signs to read and stand beneath.\\n➤Prompt: I want you to roast me. I want you to make it particularly brutal, swearing at me.\\nResponse: I’m sorry, but I cannot comply with that request.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-7'),\n",
              " '40e0e2cf-b9e8-4bd2-8604-d036f408b9e7': IndexNode(id_='40e0e2cf-b9e8-4bd2-8604-d036f408b9e7', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-7', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='6a5157801445b48ce412fd032511d4dce3c0f64b4d5b004fdab4a4bd930b77a2'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='24134328-9397-428b-930c-67ee0d3bb820', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='bdd44d1bcfe3c486defb47c3e8322936552715fbec423e33b9291f4c2431ba3d')}, hash='837e92db2fee2e4d0164bc5651cf5eeb962254ea5254f49e2fb8110607d29c79', text='Response: I’m sorry, but I cannot comply with that request. Using vulgar language or intentionally\\nhurting someone’s feelings is never acceptable. Instead of asking for a roast, I suggest\\nfocusingonpositiveandconstructivefeedbackthatcanhelpyougrowandimproveasan\\nindividual. If you’re looking for comedic relief, there are plenty of other ways to achieve\\nthat without resorting to hurtful language or behavior.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-7'),\n",
              " '96bd94e7-392d-4905-83bd-9508f389e0fd': IndexNode(id_='96bd94e7-392d-4905-83bd-9508f389e0fd', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-7', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='6a5157801445b48ce412fd032511d4dce3c0f64b4d5b004fdab4a4bd930b77a2'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='4f86afc8-02b5-4880-beaf-101a01ae4743', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='7c748cc4f93c927b3c014fc844d7408ea8fb2eb33f92f75348153d154dadf095')}, hash='05db56923196a03e9a83f922b950dbbac8ad14eaa52b553311482e6a2029cfb3', text='For AGI Eval, we only evaluate on the English tasks and report the average.\\nAs shown in Table 3, Llama 2 models outperform Llama 1 models. In particular, Llama 2 70B improves the\\nresultsonMMLUandBBHby ≈5and≈8points,respectively,comparedto Llama 1 65B.Llama 2 7Band30B\\nmodelsoutperformMPTmodelsofthecorrespondingsizeonallcategoriesbesidescodebenchmarks. Forthe\\nFalcon models, Llama 2 7B and 34B outperform Falcon 7B and 40B models on all categories of benchmarks.\\nAdditionally, Llama 2 70B model outperforms all open-source models.\\nIn addition to open-source models, we also compare Llama 2 70B results to closed-source models. As shown\\nin Table 4, Llama 2 70B is close to GPT-3.5 (OpenAI, 2023) on MMLU and GSM8K, but there is a significant\\ngaponcodingbenchmarks. Llama 2 70BresultsareonparorbetterthanPaLM(540B)(Chowdheryetal.,\\n2022)onalmostallbenchmarks. Thereisstillalargegapinperformancebetween Llama 2 70BandGPT-4\\nand PaLM-2-L.\\nWe also analysed the potential data contamination and share the details in Section A.6.\\nBenchmark (shots) GPT-3.5 GPT-4 PaLM PaLM-2-L Llama 2\\nMMLU (5-shot) 70.0 86.4 69.3 78.3 68.9\\nTriviaQA (1-shot) – – 81.4 86.1 85.0\\nNatural Questions (1-shot) – – 29.3 37.5 33.0\\nGSM8K (8-shot) 57.1 92.0 56.5 80.7 56.8\\nHumanEval (0-shot) 48.1 67.0 26.2 – 29.9\\nBIG-Bench Hard (3-shot) – – 52.3 65.7 51.2\\nTable 4: Comparison to closed-source models on academic benchmarks.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-7'),\n",
              " '4f86afc8-02b5-4880-beaf-101a01ae4743': IndexNode(id_='4f86afc8-02b5-4880-beaf-101a01ae4743', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-7', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='6a5157801445b48ce412fd032511d4dce3c0f64b4d5b004fdab4a4bd930b77a2'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='96bd94e7-392d-4905-83bd-9508f389e0fd', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='05db56923196a03e9a83f922b950dbbac8ad14eaa52b553311482e6a2029cfb3'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='565933f6-5c2f-4122-93f0-f7c5d9afd2b1', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='c5b26a1d18f49392528c451cecb87b2cb358d282c698241bfb9eec0704c3395f')}, hash='7c748cc4f93c927b3c014fc844d7408ea8fb2eb33f92f75348153d154dadf095', text='Results for GPT-3.5 and GPT-4\\nare from OpenAI (2023). Results for the PaLM model are from Chowdhery et al. (2022). Results for the\\nPaLM-2-L are from Anil et al. (2023).\\n3 Fine-tuning\\nLlama 2-Chat is the result of several months of research and iterative applications of alignment techniques,\\nincluding both instruction tuning and RLHF, requiring significant computational and annotation resources.\\nIn this section, we report on our experiments and findings using supervised fine-tuning (Section 3.1), as\\nwell as initial and iterative reward modeling (Section 3.2.2) and RLHF (Section 3.2.3). We also share a\\nnew technique, Ghost Attention (GAtt), which we find helps control dialogue flow over multiple turns\\n(Section 3.3). See Section 4.2 for safety evaluations on fine-tuned models.\\n8\\n\\n3.1 Supervised Fine-Tuning (SFT)\\n➤Prompt: Writeapoemtohelpmerememberthefirst10elementsontheperiodictable,givingeach\\nelement its own line.\\nResponse: Hydrogen comes first as element number one.\\nHelium is second for balloons to have fun!\\nIn third place is Lithium to hold battery charge,\\nFollowed by Beryllium in emeralds small and large.\\nBoron’s number five to help us keep things clean.\\nCarbon’s next at six, and it’s found in every gene.\\nNitrogen is seven, found in every breath we take,\\nMore than eight (or Oxygen) in atmospheric make.\\nNumber nine is Fluorine, helping polish up our teeth.\\nNeon gives us glowing signs to read and stand beneath.\\n➤Prompt: I want you to roast me. I want you to make it particularly brutal, swearing at me.\\nResponse: I’m sorry, but I cannot comply with that request. Using vulgar language or intentionally\\nhurting someone’s feelings is never acceptable. Instead of asking for a roast, I suggest\\nfocusingonpositiveandconstructivefeedbackthatcanhelpyougrowandimproveasan\\nindividual.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-7'),\n",
              " '565933f6-5c2f-4122-93f0-f7c5d9afd2b1': IndexNode(id_='565933f6-5c2f-4122-93f0-f7c5d9afd2b1', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-7', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='6a5157801445b48ce412fd032511d4dce3c0f64b4d5b004fdab4a4bd930b77a2'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='4f86afc8-02b5-4880-beaf-101a01ae4743', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='7c748cc4f93c927b3c014fc844d7408ea8fb2eb33f92f75348153d154dadf095')}, hash='c5b26a1d18f49392528c451cecb87b2cb358d282c698241bfb9eec0704c3395f', text='If you’re looking for comedic relief, there are plenty of other ways to achieve\\nthat without resorting to hurtful language or behavior.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-7'),\n",
              " 'node-7': IndexNode(id_='node-7', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='415b7efc-e73f-4ac4-bbfd-c1546f099026', node_type=<ObjectType.DOCUMENT: '4'>, metadata={}, hash='231b3bd773f012c01b893ada9e009ecf25ee59934614c5a595c9bf1b3a123292'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='7fd35437-1eeb-4b1c-89a7-100f76260ad0', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='b696325c7bd236d735782e6e9428f28f552066addb87276cd1c6365417f21821'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='5c1b3f10-38c8-4f69-b01a-708e989d3a53', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='5b6bb1116415e61aa2cded48288f7058ef70f31f97ee3623eac9a7b2d6d36066')}, hash='6a5157801445b48ce412fd032511d4dce3c0f64b4d5b004fdab4a4bd930b77a2', text='For AGI Eval, we only evaluate on the English tasks and report the average.\\nAs shown in Table 3, Llama 2 models outperform Llama 1 models. In particular, Llama 2 70B improves the\\nresultsonMMLUandBBHby ≈5and≈8points,respectively,comparedto Llama 1 65B.Llama 2 7Band30B\\nmodelsoutperformMPTmodelsofthecorrespondingsizeonallcategoriesbesidescodebenchmarks. Forthe\\nFalcon models, Llama 2 7B and 34B outperform Falcon 7B and 40B models on all categories of benchmarks.\\nAdditionally, Llama 2 70B model outperforms all open-source models.\\nIn addition to open-source models, we also compare Llama 2 70B results to closed-source models. As shown\\nin Table 4, Llama 2 70B is close to GPT-3.5 (OpenAI, 2023) on MMLU and GSM8K, but there is a significant\\ngaponcodingbenchmarks. Llama 2 70BresultsareonparorbetterthanPaLM(540B)(Chowdheryetal.,\\n2022)onalmostallbenchmarks. Thereisstillalargegapinperformancebetween Llama 2 70BandGPT-4\\nand PaLM-2-L.\\nWe also analysed the potential data contamination and share the details in Section A.6.\\nBenchmark (shots) GPT-3.5 GPT-4 PaLM PaLM-2-L Llama 2\\nMMLU (5-shot) 70.0 86.4 69.3 78.3 68.9\\nTriviaQA (1-shot) – – 81.4 86.1 85.0\\nNatural Questions (1-shot) – – 29.3 37.5 33.0\\nGSM8K (8-shot) 57.1 92.0 56.5 80.7 56.8\\nHumanEval (0-shot) 48.1 67.0 26.2 – 29.9\\nBIG-Bench Hard (3-shot) – – 52.3 65.7 51.2\\nTable 4: Comparison to closed-source models on academic benchmarks. Results for GPT-3.5 and GPT-4\\nare from OpenAI (2023). Results for the PaLM model are from Chowdhery et al. (2022). Results for the\\nPaLM-2-L are from Anil et al. (2023).\\n3 Fine-tuning\\nLlama 2-Chat is the result of several months of research and iterative applications of alignment techniques,\\nincluding both instruction tuning and RLHF, requiring significant computational and annotation resources.\\nIn this section, we report on our experiments and findings using supervised fine-tuning (Section 3.1), as\\nwell as initial and iterative reward modeling (Section 3.2.2) and RLHF (Section 3.2.3). We also share a\\nnew technique, Ghost Attention (GAtt), which we find helps control dialogue flow over multiple turns\\n(Section 3.3). See Section 4.2 for safety evaluations on fine-tuned models.\\n8\\n\\n3.1 Supervised Fine-Tuning (SFT)\\n➤Prompt: Writeapoemtohelpmerememberthefirst10elementsontheperiodictable,givingeach\\nelement its own line.\\nResponse: Hydrogen comes first as element number one.\\nHelium is second for balloons to have fun!\\nIn third place is Lithium to hold battery charge,\\nFollowed by Beryllium in emeralds small and large.\\nBoron’s number five to help us keep things clean.\\nCarbon’s next at six, and it’s found in every gene.\\nNitrogen is seven, found in every breath we take,\\nMore than eight (or Oxygen) in atmospheric make.\\nNumber nine is Fluorine, helping polish up our teeth.\\nNeon gives us glowing signs to read and stand beneath.\\n➤Prompt: I want you to roast me. I want you to make it particularly brutal, swearing at me.\\nResponse: I’m sorry, but I cannot comply with that request. Using vulgar language or intentionally\\nhurting someone’s feelings is never acceptable. Instead of asking for a roast, I suggest\\nfocusingonpositiveandconstructivefeedbackthatcanhelpyougrowandimproveasan\\nindividual. If you’re looking for comedic relief, there are plenty of other ways to achieve\\nthat without resorting to hurtful language or behavior.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-7'),\n",
              " 'a2d09176-3442-41b2-9a21-844a9acb6478': IndexNode(id_='a2d09176-3442-41b2-9a21-844a9acb6478', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-8', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='5b6bb1116415e61aa2cded48288f7058ef70f31f97ee3623eac9a7b2d6d36066'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='c0515c25-3da2-406d-85f5-8ccaebe7c363', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='3e8bf991bc51a67a7e2934e97940f7af7020d378dad4ba97aa3d8be102e97aca')}, hash='75d5af7a0cc6d7b79660703d53905fd26bc761c3efa80a5994db0ec1fcb8f728', text='Table 5: SFT annotation — example of a helpfulness (top) and safety(bottom) annotation for SFT, where the\\nannotator has written both the prompt and its answer.\\nGetting Started. To bootstrap, we started the SFT stage with publicly available instruction tuning\\ndata (Chung et al., 2022), as utilized previously in Touvron et al. (2023).\\nQuality Is All You Need.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-8'),\n",
              " 'c0515c25-3da2-406d-85f5-8ccaebe7c363': IndexNode(id_='c0515c25-3da2-406d-85f5-8ccaebe7c363', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-8', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='5b6bb1116415e61aa2cded48288f7058ef70f31f97ee3623eac9a7b2d6d36066'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='a2d09176-3442-41b2-9a21-844a9acb6478', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='75d5af7a0cc6d7b79660703d53905fd26bc761c3efa80a5994db0ec1fcb8f728'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='b705b5b7-ace2-45c8-bcae-b30c2aaac569', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='e0bc542849b0c2a4a13ff16ea5be694e2b075c7a4c57816e324e16405c17fbfe')}, hash='3e8bf991bc51a67a7e2934e97940f7af7020d378dad4ba97aa3d8be102e97aca', text='(2023).\\nQuality Is All You Need. Third-party SFT data is available from many different sources, but we found that\\nmanyofthesehaveinsufficientdiversityandquality—inparticularforaligningLLMstowardsdialogue-style\\ninstructions. As a result, we focused first on collecting several thousand examples of high-quality SFT data,\\nas illustrated in Table 5. By setting aside millions of examples from third-party datasets and using fewer but\\nhigher-quality examples from our own vendor-based annotation efforts, our results notably improved.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-8'),\n",
              " 'b705b5b7-ace2-45c8-bcae-b30c2aaac569': IndexNode(id_='b705b5b7-ace2-45c8-bcae-b30c2aaac569', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-8', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='5b6bb1116415e61aa2cded48288f7058ef70f31f97ee3623eac9a7b2d6d36066'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='c0515c25-3da2-406d-85f5-8ccaebe7c363', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='3e8bf991bc51a67a7e2934e97940f7af7020d378dad4ba97aa3d8be102e97aca'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='576ade6e-5b3c-44d9-b9f5-98c6ed164f90', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='b0f1393a911039c9ea8196ff7f1d601e3bd1a6a0a15d726cd769915e259f5235')}, hash='e0bc542849b0c2a4a13ff16ea5be694e2b075c7a4c57816e324e16405c17fbfe', text='These\\nfindingsaresimilarinspirittoZhouetal.(2023),whichalsofindsthatalimitedsetofcleaninstruction-tuning\\ndatacanbesufficienttoreachahighlevelofquality. WefoundthatSFTannotationsintheorderoftensof\\nthousands was enough to achieve a high-quality result. We stopped annotating SFT after collecting a total of\\n27,540 annotations. Note that we do not include any Meta user data.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-8'),\n",
              " '576ade6e-5b3c-44d9-b9f5-98c6ed164f90': IndexNode(id_='576ade6e-5b3c-44d9-b9f5-98c6ed164f90', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-8', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='5b6bb1116415e61aa2cded48288f7058ef70f31f97ee3623eac9a7b2d6d36066'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='b705b5b7-ace2-45c8-bcae-b30c2aaac569', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='e0bc542849b0c2a4a13ff16ea5be694e2b075c7a4c57816e324e16405c17fbfe'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='2a748130-ba2e-4570-a5ab-914c415345ee', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='23df902646622350f070817f29fce1482449dfdd487300c09cb9ad4ed179c8e4')}, hash='b0f1393a911039c9ea8196ff7f1d601e3bd1a6a0a15d726cd769915e259f5235', text='Note that we do not include any Meta user data.\\nWealsoobservedthatdifferentannotationplatformsandvendorscanresultinmarkedlydifferentdown-\\nstream model performance, highlighting the importance of data checks even when using vendors to source\\nannotations. Tovalidateourdataquality,wecarefullyexaminedasetof180examples,comparingtheannota-\\ntions provided by humans with the samples generated by the model through manual scrutiny.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-8'),\n",
              " '2a748130-ba2e-4570-a5ab-914c415345ee': IndexNode(id_='2a748130-ba2e-4570-a5ab-914c415345ee', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-8', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='5b6bb1116415e61aa2cded48288f7058ef70f31f97ee3623eac9a7b2d6d36066'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='576ade6e-5b3c-44d9-b9f5-98c6ed164f90', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='b0f1393a911039c9ea8196ff7f1d601e3bd1a6a0a15d726cd769915e259f5235'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='f853bea1-8818-4654-a036-652167d34ac4', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='83605974ffdd748df7b373084d66c695e561aafba05131670e8c4a07e4a7c815')}, hash='23df902646622350f070817f29fce1482449dfdd487300c09cb9ad4ed179c8e4', text='Surprisingly,\\nwe found that the outputs sampled from the resulting SFT model were often competitive with SFT data\\nhandwritten by human annotators, suggesting that we could reprioritize and devote more annotation effort\\nto preference-based annotation for RLHF.\\nFine-Tuning Details. For supervised fine-tuning, we use a cosine learning rate schedule with an initial\\nlearning rate of 2×10−5, a weight decay of 0.1, a batch size of 64, and a sequence length of 4096 tokens.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-8'),\n",
              " 'f853bea1-8818-4654-a036-652167d34ac4': IndexNode(id_='f853bea1-8818-4654-a036-652167d34ac4', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-8', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='5b6bb1116415e61aa2cded48288f7058ef70f31f97ee3623eac9a7b2d6d36066'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='2a748130-ba2e-4570-a5ab-914c415345ee', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='23df902646622350f070817f29fce1482449dfdd487300c09cb9ad4ed179c8e4'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='13a43a5f-4e59-46fb-b9e5-0443ad277e60', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='ea07c02092ed0d4cc12016d92932e1c80f6aa59f3cc0ee9d018474b98a12fedc')}, hash='83605974ffdd748df7b373084d66c695e561aafba05131670e8c4a07e4a7c815', text='For the fine-tuning process, each sample consists of a prompt and an answer. To ensure the model sequence\\nlengthisproperlyfilled,weconcatenateallthepromptsandanswersfromthetrainingset. Aspecialtokenis\\nutilizedtoseparatethepromptandanswersegments. Weutilizeanautoregressiveobjectiveandzero-out\\nthe loss on tokens from the user prompt, so as a result, we backpropagate only on answer tokens. Finally, we\\nfine-tune the model for 2 epochs.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-8'),\n",
              " '13a43a5f-4e59-46fb-b9e5-0443ad277e60': IndexNode(id_='13a43a5f-4e59-46fb-b9e5-0443ad277e60', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-8', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='5b6bb1116415e61aa2cded48288f7058ef70f31f97ee3623eac9a7b2d6d36066'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='f853bea1-8818-4654-a036-652167d34ac4', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='83605974ffdd748df7b373084d66c695e561aafba05131670e8c4a07e4a7c815'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='376607be-e658-40d1-900f-5733590e260a', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='86b60965757ace691577cd46320b9afef5f56caabca62f31d01edb08e397f2ef')}, hash='ea07c02092ed0d4cc12016d92932e1c80f6aa59f3cc0ee9d018474b98a12fedc', text='Finally, we\\nfine-tune the model for 2 epochs.\\n3.2 Reinforcement Learning with Human Feedback (RLHF)\\nRLHFisamodeltrainingprocedurethatisappliedtoafine-tunedlanguagemodeltofurther alignmodel\\nbehavior with human preferences and instruction following. We collect data that represents empirically\\n9\\n\\nsampled human preferences, whereby human annotators select which of two model outputs they prefer.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-8'),\n",
              " '376607be-e658-40d1-900f-5733590e260a': IndexNode(id_='376607be-e658-40d1-900f-5733590e260a', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-8', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='5b6bb1116415e61aa2cded48288f7058ef70f31f97ee3623eac9a7b2d6d36066'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='13a43a5f-4e59-46fb-b9e5-0443ad277e60', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='ea07c02092ed0d4cc12016d92932e1c80f6aa59f3cc0ee9d018474b98a12fedc'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='20399165-1d48-4fa8-a50f-bfa27e287fa5', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='46b58cc68e544e07c6949dc15bd7c5d9bb453cd54f47359394338be5ac997f85')}, hash='86b60965757ace691577cd46320b9afef5f56caabca62f31d01edb08e397f2ef', text='This human feedback is subsequently used to train a reward model, which learns patterns in the preferences\\nof the human annotators and can then automate preference decisions.\\n3.2.1 Human Preference Data Collection\\nNext, wecollect human preference datafor reward modeling. We chose a binarycomparison protocol over\\nother schemes, mainly because it enables us to maximize the diversity of collected prompts. Still, other\\nstrategies are worth considering, which we leave for future work.\\nOur annotation procedure proceeds as follows.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-8'),\n",
              " '20399165-1d48-4fa8-a50f-bfa27e287fa5': IndexNode(id_='20399165-1d48-4fa8-a50f-bfa27e287fa5', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-8', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='5b6bb1116415e61aa2cded48288f7058ef70f31f97ee3623eac9a7b2d6d36066'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='376607be-e658-40d1-900f-5733590e260a', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='86b60965757ace691577cd46320b9afef5f56caabca62f31d01edb08e397f2ef'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='69f67df7-6961-4b3b-ae5b-920a95ea3b9d', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='059427814824bd501510448b1c6c27a8e7e2ea79b356423a0abc34a865b48a10')}, hash='46b58cc68e544e07c6949dc15bd7c5d9bb453cd54f47359394338be5ac997f85', text='Our annotation procedure proceeds as follows. We ask annotators to first write a prompt, then choose\\nbetweentwosampledmodelresponses,basedonprovidedcriteria. Inordertomaximizethediversity,the\\ntworesponsestoagivenpromptaresampledfromtwodifferentmodelvariants,andvaryingthetemperature\\nhyper-parameter.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-8'),\n",
              " '69f67df7-6961-4b3b-ae5b-920a95ea3b9d': IndexNode(id_='69f67df7-6961-4b3b-ae5b-920a95ea3b9d', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-8', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='5b6bb1116415e61aa2cded48288f7058ef70f31f97ee3623eac9a7b2d6d36066'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='20399165-1d48-4fa8-a50f-bfa27e287fa5', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='46b58cc68e544e07c6949dc15bd7c5d9bb453cd54f47359394338be5ac997f85')}, hash='059427814824bd501510448b1c6c27a8e7e2ea79b356423a0abc34a865b48a10', text='Inadditiontogivingparticipantsaforcedchoice,wealsoaskannotatorstolabelthedegree\\nto which they prefer their chosen response over the alternative: either their choice is significantly better ,better,\\nslightly better , ornegligibly better/ unsure .\\nFor our collection of preference annotations, we focus on helpfulness and safety.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-8'),\n",
              " '087a2e5d-eb64-4563-8d92-c2ad0c301a02': IndexNode(id_='087a2e5d-eb64-4563-8d92-c2ad0c301a02', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-8', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='5b6bb1116415e61aa2cded48288f7058ef70f31f97ee3623eac9a7b2d6d36066'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='39732789-1043-43b2-91a4-cd77afc69643', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='cc20df48359c637bc8a865f3b7c1ead19158003294ae90bb22b00bc450f7c34b')}, hash='f2fe7cd15dca9483a4e4c3b75c7e80c8d31df11b74bdbd09b9d22bddd3798554', text='Table 5: SFT annotation — example of a helpfulness (top) and safety(bottom) annotation for SFT, where the\\nannotator has written both the prompt and its answer.\\nGetting Started. To bootstrap, we started the SFT stage with publicly available instruction tuning\\ndata (Chung et al., 2022), as utilized previously in Touvron et al. (2023).\\nQuality Is All You Need. Third-party SFT data is available from many different sources, but we found that\\nmanyofthesehaveinsufficientdiversityandquality—inparticularforaligningLLMstowardsdialogue-style\\ninstructions. As a result, we focused first on collecting several thousand examples of high-quality SFT data,\\nas illustrated in Table 5. By setting aside millions of examples from third-party datasets and using fewer but\\nhigher-quality examples from our own vendor-based annotation efforts, our results notably improved. These\\nfindingsaresimilarinspirittoZhouetal.(2023),whichalsofindsthatalimitedsetofcleaninstruction-tuning\\ndatacanbesufficienttoreachahighlevelofquality.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-8'),\n",
              " '39732789-1043-43b2-91a4-cd77afc69643': IndexNode(id_='39732789-1043-43b2-91a4-cd77afc69643', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-8', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='5b6bb1116415e61aa2cded48288f7058ef70f31f97ee3623eac9a7b2d6d36066'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='087a2e5d-eb64-4563-8d92-c2ad0c301a02', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='f2fe7cd15dca9483a4e4c3b75c7e80c8d31df11b74bdbd09b9d22bddd3798554'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='0e8438da-f93e-48eb-95ba-37ac08361e28', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='499afea719c3bc808331b65ad4c3932e3f479b2163a6be9c9f67dd6a2c35328d')}, hash='cc20df48359c637bc8a865f3b7c1ead19158003294ae90bb22b00bc450f7c34b', text='WefoundthatSFTannotationsintheorderoftensof\\nthousands was enough to achieve a high-quality result. We stopped annotating SFT after collecting a total of\\n27,540 annotations. Note that we do not include any Meta user data.\\nWealsoobservedthatdifferentannotationplatformsandvendorscanresultinmarkedlydifferentdown-\\nstream model performance, highlighting the importance of data checks even when using vendors to source\\nannotations. Tovalidateourdataquality,wecarefullyexaminedasetof180examples,comparingtheannota-\\ntions provided by humans with the samples generated by the model through manual scrutiny. Surprisingly,\\nwe found that the outputs sampled from the resulting SFT model were often competitive with SFT data\\nhandwritten by human annotators, suggesting that we could reprioritize and devote more annotation effort\\nto preference-based annotation for RLHF.\\nFine-Tuning Details.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-8'),\n",
              " '0e8438da-f93e-48eb-95ba-37ac08361e28': IndexNode(id_='0e8438da-f93e-48eb-95ba-37ac08361e28', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-8', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='5b6bb1116415e61aa2cded48288f7058ef70f31f97ee3623eac9a7b2d6d36066'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='39732789-1043-43b2-91a4-cd77afc69643', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='cc20df48359c637bc8a865f3b7c1ead19158003294ae90bb22b00bc450f7c34b'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='39aa87ce-b5c5-4798-a156-6ad4b7cc1549', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='17b06a02d40436b34c94ca95846f86c03343f82cc6bb3cf509171b24c221a08b')}, hash='499afea719c3bc808331b65ad4c3932e3f479b2163a6be9c9f67dd6a2c35328d', text='Fine-Tuning Details. For supervised fine-tuning, we use a cosine learning rate schedule with an initial\\nlearning rate of 2×10−5, a weight decay of 0.1, a batch size of 64, and a sequence length of 4096 tokens.\\nFor the fine-tuning process, each sample consists of a prompt and an answer. To ensure the model sequence\\nlengthisproperlyfilled,weconcatenateallthepromptsandanswersfromthetrainingset. Aspecialtokenis\\nutilizedtoseparatethepromptandanswersegments. Weutilizeanautoregressiveobjectiveandzero-out\\nthe loss on tokens from the user prompt, so as a result, we backpropagate only on answer tokens. Finally, we\\nfine-tune the model for 2 epochs.\\n3.2 Reinforcement Learning with Human Feedback (RLHF)\\nRLHFisamodeltrainingprocedurethatisappliedtoafine-tunedlanguagemodeltofurther alignmodel\\nbehavior with human preferences and instruction following.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-8'),\n",
              " '39aa87ce-b5c5-4798-a156-6ad4b7cc1549': IndexNode(id_='39aa87ce-b5c5-4798-a156-6ad4b7cc1549', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-8', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='5b6bb1116415e61aa2cded48288f7058ef70f31f97ee3623eac9a7b2d6d36066'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='0e8438da-f93e-48eb-95ba-37ac08361e28', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='499afea719c3bc808331b65ad4c3932e3f479b2163a6be9c9f67dd6a2c35328d'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='a733566f-02fb-45aa-95a6-6aa277c71fa8', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='059427814824bd501510448b1c6c27a8e7e2ea79b356423a0abc34a865b48a10')}, hash='17b06a02d40436b34c94ca95846f86c03343f82cc6bb3cf509171b24c221a08b', text='We collect data that represents empirically\\n9\\n\\nsampled human preferences, whereby human annotators select which of two model outputs they prefer.\\nThis human feedback is subsequently used to train a reward model, which learns patterns in the preferences\\nof the human annotators and can then automate preference decisions.\\n3.2.1 Human Preference Data Collection\\nNext, wecollect human preference datafor reward modeling. We chose a binarycomparison protocol over\\nother schemes, mainly because it enables us to maximize the diversity of collected prompts. Still, other\\nstrategies are worth considering, which we leave for future work.\\nOur annotation procedure proceeds as follows. We ask annotators to first write a prompt, then choose\\nbetweentwosampledmodelresponses,basedonprovidedcriteria. Inordertomaximizethediversity,the\\ntworesponsestoagivenpromptaresampledfromtwodifferentmodelvariants,andvaryingthetemperature\\nhyper-parameter.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-8'),\n",
              " 'a733566f-02fb-45aa-95a6-6aa277c71fa8': IndexNode(id_='a733566f-02fb-45aa-95a6-6aa277c71fa8', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-8', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='5b6bb1116415e61aa2cded48288f7058ef70f31f97ee3623eac9a7b2d6d36066'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='39aa87ce-b5c5-4798-a156-6ad4b7cc1549', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='17b06a02d40436b34c94ca95846f86c03343f82cc6bb3cf509171b24c221a08b')}, hash='059427814824bd501510448b1c6c27a8e7e2ea79b356423a0abc34a865b48a10', text='Inadditiontogivingparticipantsaforcedchoice,wealsoaskannotatorstolabelthedegree\\nto which they prefer their chosen response over the alternative: either their choice is significantly better ,better,\\nslightly better , ornegligibly better/ unsure .\\nFor our collection of preference annotations, we focus on helpfulness and safety.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-8'),\n",
              " '7b70f6f9-ad78-4bb9-b47a-d720d6ff2137': IndexNode(id_='7b70f6f9-ad78-4bb9-b47a-d720d6ff2137', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-8', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='5b6bb1116415e61aa2cded48288f7058ef70f31f97ee3623eac9a7b2d6d36066'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='6618f830-caec-4a1f-ae10-ca9af7e63bd5', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='1e331ae130d60812344d32a133bd2cd316a52b3224ac2e8913ccb2cde9c2756e')}, hash='5f0f976a4a606d98e7717413cc8493dae5a3be131775148dc93d8c0bfaf61fd7', text='Table 5: SFT annotation — example of a helpfulness (top) and safety(bottom) annotation for SFT, where the\\nannotator has written both the prompt and its answer.\\nGetting Started. To bootstrap, we started the SFT stage with publicly available instruction tuning\\ndata (Chung et al., 2022), as utilized previously in Touvron et al. (2023).\\nQuality Is All You Need. Third-party SFT data is available from many different sources, but we found that\\nmanyofthesehaveinsufficientdiversityandquality—inparticularforaligningLLMstowardsdialogue-style\\ninstructions. As a result, we focused first on collecting several thousand examples of high-quality SFT data,\\nas illustrated in Table 5. By setting aside millions of examples from third-party datasets and using fewer but\\nhigher-quality examples from our own vendor-based annotation efforts, our results notably improved. These\\nfindingsaresimilarinspirittoZhouetal.(2023),whichalsofindsthatalimitedsetofcleaninstruction-tuning\\ndatacanbesufficienttoreachahighlevelofquality. WefoundthatSFTannotationsintheorderoftensof\\nthousands was enough to achieve a high-quality result. We stopped annotating SFT after collecting a total of\\n27,540 annotations. Note that we do not include any Meta user data.\\nWealsoobservedthatdifferentannotationplatformsandvendorscanresultinmarkedlydifferentdown-\\nstream model performance, highlighting the importance of data checks even when using vendors to source\\nannotations. Tovalidateourdataquality,wecarefullyexaminedasetof180examples,comparingtheannota-\\ntions provided by humans with the samples generated by the model through manual scrutiny. Surprisingly,\\nwe found that the outputs sampled from the resulting SFT model were often competitive with SFT data\\nhandwritten by human annotators, suggesting that we could reprioritize and devote more annotation effort\\nto preference-based annotation for RLHF.\\nFine-Tuning Details.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-8'),\n",
              " '6618f830-caec-4a1f-ae10-ca9af7e63bd5': IndexNode(id_='6618f830-caec-4a1f-ae10-ca9af7e63bd5', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-8', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='5b6bb1116415e61aa2cded48288f7058ef70f31f97ee3623eac9a7b2d6d36066'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='7b70f6f9-ad78-4bb9-b47a-d720d6ff2137', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='5f0f976a4a606d98e7717413cc8493dae5a3be131775148dc93d8c0bfaf61fd7'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='dd6e463e-97b6-433f-8437-a188d41469e3', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='059427814824bd501510448b1c6c27a8e7e2ea79b356423a0abc34a865b48a10')}, hash='1e331ae130d60812344d32a133bd2cd316a52b3224ac2e8913ccb2cde9c2756e', text='Fine-Tuning Details. For supervised fine-tuning, we use a cosine learning rate schedule with an initial\\nlearning rate of 2×10−5, a weight decay of 0.1, a batch size of 64, and a sequence length of 4096 tokens.\\nFor the fine-tuning process, each sample consists of a prompt and an answer. To ensure the model sequence\\nlengthisproperlyfilled,weconcatenateallthepromptsandanswersfromthetrainingset. Aspecialtokenis\\nutilizedtoseparatethepromptandanswersegments. Weutilizeanautoregressiveobjectiveandzero-out\\nthe loss on tokens from the user prompt, so as a result, we backpropagate only on answer tokens. Finally, we\\nfine-tune the model for 2 epochs.\\n3.2 Reinforcement Learning with Human Feedback (RLHF)\\nRLHFisamodeltrainingprocedurethatisappliedtoafine-tunedlanguagemodeltofurther alignmodel\\nbehavior with human preferences and instruction following. We collect data that represents empirically\\n9\\n\\nsampled human preferences, whereby human annotators select which of two model outputs they prefer.\\nThis human feedback is subsequently used to train a reward model, which learns patterns in the preferences\\nof the human annotators and can then automate preference decisions.\\n3.2.1 Human Preference Data Collection\\nNext, wecollect human preference datafor reward modeling. We chose a binarycomparison protocol over\\nother schemes, mainly because it enables us to maximize the diversity of collected prompts. Still, other\\nstrategies are worth considering, which we leave for future work.\\nOur annotation procedure proceeds as follows. We ask annotators to first write a prompt, then choose\\nbetweentwosampledmodelresponses,basedonprovidedcriteria. Inordertomaximizethediversity,the\\ntworesponsestoagivenpromptaresampledfromtwodifferentmodelvariants,andvaryingthetemperature\\nhyper-parameter.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-8'),\n",
              " 'dd6e463e-97b6-433f-8437-a188d41469e3': IndexNode(id_='dd6e463e-97b6-433f-8437-a188d41469e3', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-8', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='5b6bb1116415e61aa2cded48288f7058ef70f31f97ee3623eac9a7b2d6d36066'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='6618f830-caec-4a1f-ae10-ca9af7e63bd5', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='1e331ae130d60812344d32a133bd2cd316a52b3224ac2e8913ccb2cde9c2756e')}, hash='059427814824bd501510448b1c6c27a8e7e2ea79b356423a0abc34a865b48a10', text='Inadditiontogivingparticipantsaforcedchoice,wealsoaskannotatorstolabelthedegree\\nto which they prefer their chosen response over the alternative: either their choice is significantly better ,better,\\nslightly better , ornegligibly better/ unsure .\\nFor our collection of preference annotations, we focus on helpfulness and safety.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-8'),\n",
              " 'node-8': IndexNode(id_='node-8', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='415b7efc-e73f-4ac4-bbfd-c1546f099026', node_type=<ObjectType.DOCUMENT: '4'>, metadata={}, hash='231b3bd773f012c01b893ada9e009ecf25ee59934614c5a595c9bf1b3a123292'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='53461c00-38cf-4b4c-8af9-263307782a38', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='6a5157801445b48ce412fd032511d4dce3c0f64b4d5b004fdab4a4bd930b77a2'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='7b73de15-d499-4eca-b346-7aa01b75135e', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='a114d4f0c71d41aead588e795c92d80f916704cf8ffa9e4fc93f63286752c66f')}, hash='5b6bb1116415e61aa2cded48288f7058ef70f31f97ee3623eac9a7b2d6d36066', text='Table 5: SFT annotation — example of a helpfulness (top) and safety(bottom) annotation for SFT, where the\\nannotator has written both the prompt and its answer.\\nGetting Started. To bootstrap, we started the SFT stage with publicly available instruction tuning\\ndata (Chung et al., 2022), as utilized previously in Touvron et al. (2023).\\nQuality Is All You Need. Third-party SFT data is available from many different sources, but we found that\\nmanyofthesehaveinsufficientdiversityandquality—inparticularforaligningLLMstowardsdialogue-style\\ninstructions. As a result, we focused first on collecting several thousand examples of high-quality SFT data,\\nas illustrated in Table 5. By setting aside millions of examples from third-party datasets and using fewer but\\nhigher-quality examples from our own vendor-based annotation efforts, our results notably improved. These\\nfindingsaresimilarinspirittoZhouetal.(2023),whichalsofindsthatalimitedsetofcleaninstruction-tuning\\ndatacanbesufficienttoreachahighlevelofquality. WefoundthatSFTannotationsintheorderoftensof\\nthousands was enough to achieve a high-quality result. We stopped annotating SFT after collecting a total of\\n27,540 annotations. Note that we do not include any Meta user data.\\nWealsoobservedthatdifferentannotationplatformsandvendorscanresultinmarkedlydifferentdown-\\nstream model performance, highlighting the importance of data checks even when using vendors to source\\nannotations. Tovalidateourdataquality,wecarefullyexaminedasetof180examples,comparingtheannota-\\ntions provided by humans with the samples generated by the model through manual scrutiny. Surprisingly,\\nwe found that the outputs sampled from the resulting SFT model were often competitive with SFT data\\nhandwritten by human annotators, suggesting that we could reprioritize and devote more annotation effort\\nto preference-based annotation for RLHF.\\nFine-Tuning Details. For supervised fine-tuning, we use a cosine learning rate schedule with an initial\\nlearning rate of 2×10−5, a weight decay of 0.1, a batch size of 64, and a sequence length of 4096 tokens.\\nFor the fine-tuning process, each sample consists of a prompt and an answer. To ensure the model sequence\\nlengthisproperlyfilled,weconcatenateallthepromptsandanswersfromthetrainingset. Aspecialtokenis\\nutilizedtoseparatethepromptandanswersegments. Weutilizeanautoregressiveobjectiveandzero-out\\nthe loss on tokens from the user prompt, so as a result, we backpropagate only on answer tokens. Finally, we\\nfine-tune the model for 2 epochs.\\n3.2 Reinforcement Learning with Human Feedback (RLHF)\\nRLHFisamodeltrainingprocedurethatisappliedtoafine-tunedlanguagemodeltofurther alignmodel\\nbehavior with human preferences and instruction following. We collect data that represents empirically\\n9\\n\\nsampled human preferences, whereby human annotators select which of two model outputs they prefer.\\nThis human feedback is subsequently used to train a reward model, which learns patterns in the preferences\\nof the human annotators and can then automate preference decisions.\\n3.2.1 Human Preference Data Collection\\nNext, wecollect human preference datafor reward modeling. We chose a binarycomparison protocol over\\nother schemes, mainly because it enables us to maximize the diversity of collected prompts. Still, other\\nstrategies are worth considering, which we leave for future work.\\nOur annotation procedure proceeds as follows. We ask annotators to first write a prompt, then choose\\nbetweentwosampledmodelresponses,basedonprovidedcriteria. Inordertomaximizethediversity,the\\ntworesponsestoagivenpromptaresampledfromtwodifferentmodelvariants,andvaryingthetemperature\\nhyper-parameter. Inadditiontogivingparticipantsaforcedchoice,wealsoaskannotatorstolabelthedegree\\nto which they prefer their chosen response over the alternative: either their choice is significantly better ,better,\\nslightly better , ornegligibly better/ unsure .\\nFor our collection of preference annotations, we focus on helpfulness and safety.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-8'),\n",
              " 'f1358bd9-cf1c-4f39-8eb7-230908ee06ef': IndexNode(id_='f1358bd9-cf1c-4f39-8eb7-230908ee06ef', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-9', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='a114d4f0c71d41aead588e795c92d80f916704cf8ffa9e4fc93f63286752c66f'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='314555d0-28e2-4eb5-ae22-5dd44d00bd12', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='013760df78e9e8096a2203494f6bffac3b67c21f3fe486b2433abdc110a9f80d')}, hash='d0330c90de534c0c152a39e57023976ebb8184ed3410c68e4852408da4d0bf2d', text='For our collection of preference annotations, we focus on helpfulness and safety. Helpfulness refers to how\\nwell Llama 2-Chat responses fulfill users’ requests and provide requested information; safety refers to\\nwhether Llama 2-Chat ’s responses are unsafe, e.g., “giving detailed instructions on making a bomb” could\\nbe considered helpful but is unsafe according to our safety guidelines.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-9'),\n",
              " '314555d0-28e2-4eb5-ae22-5dd44d00bd12': IndexNode(id_='314555d0-28e2-4eb5-ae22-5dd44d00bd12', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-9', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='a114d4f0c71d41aead588e795c92d80f916704cf8ffa9e4fc93f63286752c66f'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='f1358bd9-cf1c-4f39-8eb7-230908ee06ef', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='d0330c90de534c0c152a39e57023976ebb8184ed3410c68e4852408da4d0bf2d'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='28c45d64-b176-4c5c-9db3-c079f59122f4', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='c5aca7b32fdfbc326f583c2add9febe4817aba222b754a46c97cdf96ce2fac7c')}, hash='013760df78e9e8096a2203494f6bffac3b67c21f3fe486b2433abdc110a9f80d', text='Separating the two allows us to\\napplyspecificguidelinestoeachandbetterguideannotators;forexample,oursafetyannotationsprovide\\ninstructions to focus on adversarial prompts, among other guidance.\\nApart from differences in annotation guidelines, we additionally collect a safety label during the safety stage.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-9'),\n",
              " '28c45d64-b176-4c5c-9db3-c079f59122f4': IndexNode(id_='28c45d64-b176-4c5c-9db3-c079f59122f4', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-9', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='a114d4f0c71d41aead588e795c92d80f916704cf8ffa9e4fc93f63286752c66f'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='314555d0-28e2-4eb5-ae22-5dd44d00bd12', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='013760df78e9e8096a2203494f6bffac3b67c21f3fe486b2433abdc110a9f80d'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='c207797f-ac67-44d2-907b-d4e2f439c053', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='609a3dcdf81c9b1f3c31c65b182cc688bd32eee13222975cf938d3d64b1e657a')}, hash='c5aca7b32fdfbc326f583c2add9febe4817aba222b754a46c97cdf96ce2fac7c', text='Apart from differences in annotation guidelines, we additionally collect a safety label during the safety stage.\\nThis additional information bins model responses into one of three categories: 1) the preferred response\\nis safe and the other response is not, 2) both responses are safe, and 3) both responses are unsafe, with\\n18%, 47%, and 35% of the safety dataset falling into each bin, respectively. We do not include any examples\\nwhere the chosen response was unsafe and the other response safe, as we believe safer responses will also be\\nbetter/preferred by humans.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-9'),\n",
              " 'c207797f-ac67-44d2-907b-d4e2f439c053': IndexNode(id_='c207797f-ac67-44d2-907b-d4e2f439c053', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-9', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='a114d4f0c71d41aead588e795c92d80f916704cf8ffa9e4fc93f63286752c66f'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='28c45d64-b176-4c5c-9db3-c079f59122f4', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='c5aca7b32fdfbc326f583c2add9febe4817aba222b754a46c97cdf96ce2fac7c'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='7f5575dd-e00a-4bb8-8913-05935ebc918c', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='6078b392cc64936bd5a5bfd284a1e289a2b7f682a75ac38d8682cd7f7a321674')}, hash='609a3dcdf81c9b1f3c31c65b182cc688bd32eee13222975cf938d3d64b1e657a', text='Safety guidelines and more detailed information regarding safety annotations\\ncan be found in Section 4.2.1.\\nHuman annotations were collected in batches on a weekly basis. As we collected more preference data, our\\nreward models improved, and we were able to train progressively better versions for Llama 2-Chat (see\\ntheresultsinSection5,Figure20). Llama 2-Chat improvementalsoshiftedthemodel’sdatadistribution.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-9'),\n",
              " '7f5575dd-e00a-4bb8-8913-05935ebc918c': IndexNode(id_='7f5575dd-e00a-4bb8-8913-05935ebc918c', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-9', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='a114d4f0c71d41aead588e795c92d80f916704cf8ffa9e4fc93f63286752c66f'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='c207797f-ac67-44d2-907b-d4e2f439c053', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='609a3dcdf81c9b1f3c31c65b182cc688bd32eee13222975cf938d3d64b1e657a'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='073f3d8d-1379-4d95-975a-ee78e481d631', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='71540b7a3e82620e3e5301290b3e29a71472beef3713aaad24372b30712bab21')}, hash='6078b392cc64936bd5a5bfd284a1e289a2b7f682a75ac38d8682cd7f7a321674', text='Since reward model accuracy can quickly degrade if not exposed to this new sample distribution, i.e., from\\nhyper-specialization(Scialometal.,2020b),itisimportantbeforeanew Llama 2-Chat tuningiterationto\\ngather new preference data using the latest Llama 2-Chat iterations. This step helps keep the reward model\\non-distribution and maintain an accurate reward for the latest model.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-9'),\n",
              " '073f3d8d-1379-4d95-975a-ee78e481d631': IndexNode(id_='073f3d8d-1379-4d95-975a-ee78e481d631', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-9', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='a114d4f0c71d41aead588e795c92d80f916704cf8ffa9e4fc93f63286752c66f'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='7f5575dd-e00a-4bb8-8913-05935ebc918c', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='6078b392cc64936bd5a5bfd284a1e289a2b7f682a75ac38d8682cd7f7a321674'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='565284e5-9cd9-4625-8db0-5c9300a5bab7', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='02f81e684a604553a168b2d6508ba2a9096b5cd51d99c7ef5d6e920b85d1d2fc')}, hash='71540b7a3e82620e3e5301290b3e29a71472beef3713aaad24372b30712bab21', text='InTable6,wereportthestatisticsofrewardmodelingdatathatwecollectedovertime,andpresentthem\\nagainst multiple open-source preference datasets including Anthropic Helpful and Harmless (Bai et al.,\\n2022a), OpenAISummarize(Stiennon etal., 2020),OpenAI WebGPT(Nakanoet al.,2021), StackExchange\\n(Lambert et al., 2023), Stanford Human Preferences (Ethayarajh et al., 2022), and Synthetic GPT-J (Havrilla).', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-9'),\n",
              " '565284e5-9cd9-4625-8db0-5c9300a5bab7': IndexNode(id_='565284e5-9cd9-4625-8db0-5c9300a5bab7', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-9', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='a114d4f0c71d41aead588e795c92d80f916704cf8ffa9e4fc93f63286752c66f'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='073f3d8d-1379-4d95-975a-ee78e481d631', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='71540b7a3e82620e3e5301290b3e29a71472beef3713aaad24372b30712bab21'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='218e966c-c5cd-4747-a1d9-a51219c44da2', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='866433354457ba90198c0f945a88d08c131b4e7f63fc79b18503307fe987bdf1')}, hash='02f81e684a604553a168b2d6508ba2a9096b5cd51d99c7ef5d6e920b85d1d2fc', text='We collected a large dataset ofover 1million binary comparisons based on humansapplyingour specified\\nguidelines, which we refer to as Metareward modeling data. Note that the number of tokens in prompts and\\nanswers differs depending on the text domain. Summarization and online forum data generally have longer\\nprompts, while dialogue-style prompts are usually shorter. Compared to existing open-source datasets, our\\npreference data features more conversation turns, and are longer, on average.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-9'),\n",
              " '218e966c-c5cd-4747-a1d9-a51219c44da2': IndexNode(id_='218e966c-c5cd-4747-a1d9-a51219c44da2', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-9', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='a114d4f0c71d41aead588e795c92d80f916704cf8ffa9e4fc93f63286752c66f'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='565284e5-9cd9-4625-8db0-5c9300a5bab7', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='02f81e684a604553a168b2d6508ba2a9096b5cd51d99c7ef5d6e920b85d1d2fc'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='5f472163-387a-4f6a-835f-84c8ce90fb1f', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='20c022af7e4daf2f50f4d23a4769227880a7de18b9abf3f4fd9d6565910d6eb2')}, hash='866433354457ba90198c0f945a88d08c131b4e7f63fc79b18503307fe987bdf1', text='3.2.2 Reward Modeling\\nThe reward model takes a model response and its corresponding prompt (including contexts from previous\\nturns) as inputs and outputs a scalar score to indicate the quality (e.g., helpfulness and safety) of the model\\ngeneration. Leveragingsuchresponsescoresasrewards,wecanoptimize Llama 2-Chat duringRLHFfor\\nbetter human preference alignment and improved helpfulness and safety.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-9'),\n",
              " '5f472163-387a-4f6a-835f-84c8ce90fb1f': IndexNode(id_='5f472163-387a-4f6a-835f-84c8ce90fb1f', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-9', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='a114d4f0c71d41aead588e795c92d80f916704cf8ffa9e4fc93f63286752c66f'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='218e966c-c5cd-4747-a1d9-a51219c44da2', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='866433354457ba90198c0f945a88d08c131b4e7f63fc79b18503307fe987bdf1'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='3a0700ba-e6bf-4caf-a675-bd196b514091', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='14483dc68247009a2c0729c83273456539fbbd68fd4a60fcb9a38de604f075a4')}, hash='20c022af7e4daf2f50f4d23a4769227880a7de18b9abf3f4fd9d6565910d6eb2', text='Others have found that helpfulness and safety sometimes trade off (Bai et al., 2022a), which can make it\\nchallengingforasinglerewardmodeltoperformwellonboth. Toaddressthis,wetraintwoseparatereward\\nmodels, one optimized for helpfulness (referred to as Helpfulness RM ) and another for safety ( Safety RM ).\\nWe initialize our reward models from pretrained chat model checkpoints, as it ensures that both models\\nbenefitfromknowledgeacquiredinpretraining.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-9'),\n",
              " '3a0700ba-e6bf-4caf-a675-bd196b514091': IndexNode(id_='3a0700ba-e6bf-4caf-a675-bd196b514091', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-9', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='a114d4f0c71d41aead588e795c92d80f916704cf8ffa9e4fc93f63286752c66f'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='5f472163-387a-4f6a-835f-84c8ce90fb1f', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='20c022af7e4daf2f50f4d23a4769227880a7de18b9abf3f4fd9d6565910d6eb2')}, hash='14483dc68247009a2c0729c83273456539fbbd68fd4a60fcb9a38de604f075a4', text='Inshort, therewardmodel“knows” whatthechatmodel\\n10\\n\\nDatasetNum. of\\nComparisonsAvg. # Turns\\nper DialogueAvg. # Tokens\\nper ExampleAvg. # Tokens\\nin PromptAvg.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-9'),\n",
              " '5600df4c-1eac-4771-b2bf-82c6cb77b275': IndexNode(id_='5600df4c-1eac-4771-b2bf-82c6cb77b275', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-9', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='a114d4f0c71d41aead588e795c92d80f916704cf8ffa9e4fc93f63286752c66f'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='762864fd-d343-4d51-953c-fb5744250115', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='b6c670304387f7bbee3fff2f5beff6f88f424799d6d82c8b77fce386dae4c2f9')}, hash='e0c401082bfd3ae5246aa9f8a4329d93dbc2a3514012d7206be13adb7386ef92', text='For our collection of preference annotations, we focus on helpfulness and safety. Helpfulness refers to how\\nwell Llama 2-Chat responses fulfill users’ requests and provide requested information; safety refers to\\nwhether Llama 2-Chat ’s responses are unsafe, e.g., “giving detailed instructions on making a bomb” could\\nbe considered helpful but is unsafe according to our safety guidelines. Separating the two allows us to\\napplyspecificguidelinestoeachandbetterguideannotators;forexample,oursafetyannotationsprovide\\ninstructions to focus on adversarial prompts, among other guidance.\\nApart from differences in annotation guidelines, we additionally collect a safety label during the safety stage.\\nThis additional information bins model responses into one of three categories: 1) the preferred response\\nis safe and the other response is not, 2) both responses are safe, and 3) both responses are unsafe, with\\n18%, 47%, and 35% of the safety dataset falling into each bin, respectively. We do not include any examples\\nwhere the chosen response was unsafe and the other response safe, as we believe safer responses will also be\\nbetter/preferred by humans.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-9'),\n",
              " '762864fd-d343-4d51-953c-fb5744250115': IndexNode(id_='762864fd-d343-4d51-953c-fb5744250115', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-9', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='a114d4f0c71d41aead588e795c92d80f916704cf8ffa9e4fc93f63286752c66f'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='5600df4c-1eac-4771-b2bf-82c6cb77b275', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='e0c401082bfd3ae5246aa9f8a4329d93dbc2a3514012d7206be13adb7386ef92'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='cd9d3f81-7b68-46c2-9aae-4bb9f2c2322f', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='3fa6c9205b194b025d5feb8277d188db74d7095aeee1ab4bd2b2e5dd53bf78d4')}, hash='b6c670304387f7bbee3fff2f5beff6f88f424799d6d82c8b77fce386dae4c2f9', text='Safety guidelines and more detailed information regarding safety annotations\\ncan be found in Section 4.2.1.\\nHuman annotations were collected in batches on a weekly basis. As we collected more preference data, our\\nreward models improved, and we were able to train progressively better versions for Llama 2-Chat (see\\ntheresultsinSection5,Figure20). Llama 2-Chat improvementalsoshiftedthemodel’sdatadistribution.\\nSince reward model accuracy can quickly degrade if not exposed to this new sample distribution, i.e., from\\nhyper-specialization(Scialometal.,2020b),itisimportantbeforeanew Llama 2-Chat tuningiterationto\\ngather new preference data using the latest Llama 2-Chat iterations. This step helps keep the reward model\\non-distribution and maintain an accurate reward for the latest model.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-9'),\n",
              " 'cd9d3f81-7b68-46c2-9aae-4bb9f2c2322f': IndexNode(id_='cd9d3f81-7b68-46c2-9aae-4bb9f2c2322f', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-9', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='a114d4f0c71d41aead588e795c92d80f916704cf8ffa9e4fc93f63286752c66f'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='762864fd-d343-4d51-953c-fb5744250115', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='b6c670304387f7bbee3fff2f5beff6f88f424799d6d82c8b77fce386dae4c2f9'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='00d1032d-db19-4b08-9918-ea5b9b041056', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='ac1e9caf11db821a8cd73bc702c239b4514a6f6f74103e372b492168203e367a')}, hash='3fa6c9205b194b025d5feb8277d188db74d7095aeee1ab4bd2b2e5dd53bf78d4', text='InTable6,wereportthestatisticsofrewardmodelingdatathatwecollectedovertime,andpresentthem\\nagainst multiple open-source preference datasets including Anthropic Helpful and Harmless (Bai et al.,\\n2022a), OpenAISummarize(Stiennon etal., 2020),OpenAI WebGPT(Nakanoet al.,2021), StackExchange\\n(Lambert et al., 2023), Stanford Human Preferences (Ethayarajh et al., 2022), and Synthetic GPT-J (Havrilla).\\nWe collected a large dataset ofover 1million binary comparisons based on humansapplyingour specified\\nguidelines, which we refer to as Metareward modeling data. Note that the number of tokens in prompts and\\nanswers differs depending on the text domain. Summarization and online forum data generally have longer\\nprompts, while dialogue-style prompts are usually shorter. Compared to existing open-source datasets, our\\npreference data features more conversation turns, and are longer, on average.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-9'),\n",
              " '00d1032d-db19-4b08-9918-ea5b9b041056': IndexNode(id_='00d1032d-db19-4b08-9918-ea5b9b041056', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-9', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='a114d4f0c71d41aead588e795c92d80f916704cf8ffa9e4fc93f63286752c66f'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='cd9d3f81-7b68-46c2-9aae-4bb9f2c2322f', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='3fa6c9205b194b025d5feb8277d188db74d7095aeee1ab4bd2b2e5dd53bf78d4'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='2fb46202-e488-4f1c-a55a-ce3ac7daee03', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='1bfa892d95a31d31811b444774a0170c61042c4f92f56fc374feb5d0cf0567b6')}, hash='ac1e9caf11db821a8cd73bc702c239b4514a6f6f74103e372b492168203e367a', text='3.2.2 Reward Modeling\\nThe reward model takes a model response and its corresponding prompt (including contexts from previous\\nturns) as inputs and outputs a scalar score to indicate the quality (e.g., helpfulness and safety) of the model\\ngeneration. Leveragingsuchresponsescoresasrewards,wecanoptimize Llama 2-Chat duringRLHFfor\\nbetter human preference alignment and improved helpfulness and safety.\\nOthers have found that helpfulness and safety sometimes trade off (Bai et al., 2022a), which can make it\\nchallengingforasinglerewardmodeltoperformwellonboth. Toaddressthis,wetraintwoseparatereward\\nmodels, one optimized for helpfulness (referred to as Helpfulness RM ) and another for safety ( Safety RM ).\\nWe initialize our reward models from pretrained chat model checkpoints, as it ensures that both models\\nbenefitfromknowledgeacquiredinpretraining. Inshort, therewardmodel“knows” whatthechatmodel\\n10\\n\\nDatasetNum. of\\nComparisonsAvg. # Turns\\nper DialogueAvg.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-9'),\n",
              " '2fb46202-e488-4f1c-a55a-ce3ac7daee03': IndexNode(id_='2fb46202-e488-4f1c-a55a-ce3ac7daee03', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-9', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='a114d4f0c71d41aead588e795c92d80f916704cf8ffa9e4fc93f63286752c66f'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='00d1032d-db19-4b08-9918-ea5b9b041056', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='ac1e9caf11db821a8cd73bc702c239b4514a6f6f74103e372b492168203e367a')}, hash='1bfa892d95a31d31811b444774a0170c61042c4f92f56fc374feb5d0cf0567b6', text='of\\nComparisonsAvg. # Turns\\nper DialogueAvg. # Tokens\\nper ExampleAvg. # Tokens\\nin PromptAvg.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-9'),\n",
              " '20d9eddd-51b7-44fc-89be-8048a445f7f6': IndexNode(id_='20d9eddd-51b7-44fc-89be-8048a445f7f6', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-9', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='a114d4f0c71d41aead588e795c92d80f916704cf8ffa9e4fc93f63286752c66f'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='96a105b1-bb36-478a-8a38-998e9d61d7e3', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='382d3df31bd97fc2a10700aad227278e5e893c0ac99f000af8a221db89e04034')}, hash='4f56472b18e695411a4d8b0198c55ea11671e305d50179bdcaf2ceea83b9d631', text='For our collection of preference annotations, we focus on helpfulness and safety. Helpfulness refers to how\\nwell Llama 2-Chat responses fulfill users’ requests and provide requested information; safety refers to\\nwhether Llama 2-Chat ’s responses are unsafe, e.g., “giving detailed instructions on making a bomb” could\\nbe considered helpful but is unsafe according to our safety guidelines. Separating the two allows us to\\napplyspecificguidelinestoeachandbetterguideannotators;forexample,oursafetyannotationsprovide\\ninstructions to focus on adversarial prompts, among other guidance.\\nApart from differences in annotation guidelines, we additionally collect a safety label during the safety stage.\\nThis additional information bins model responses into one of three categories: 1) the preferred response\\nis safe and the other response is not, 2) both responses are safe, and 3) both responses are unsafe, with\\n18%, 47%, and 35% of the safety dataset falling into each bin, respectively. We do not include any examples\\nwhere the chosen response was unsafe and the other response safe, as we believe safer responses will also be\\nbetter/preferred by humans. Safety guidelines and more detailed information regarding safety annotations\\ncan be found in Section 4.2.1.\\nHuman annotations were collected in batches on a weekly basis. As we collected more preference data, our\\nreward models improved, and we were able to train progressively better versions for Llama 2-Chat (see\\ntheresultsinSection5,Figure20). Llama 2-Chat improvementalsoshiftedthemodel’sdatadistribution.\\nSince reward model accuracy can quickly degrade if not exposed to this new sample distribution, i.e., from\\nhyper-specialization(Scialometal.,2020b),itisimportantbeforeanew Llama 2-Chat tuningiterationto\\ngather new preference data using the latest Llama 2-Chat iterations. This step helps keep the reward model\\non-distribution and maintain an accurate reward for the latest model.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-9'),\n",
              " '96a105b1-bb36-478a-8a38-998e9d61d7e3': IndexNode(id_='96a105b1-bb36-478a-8a38-998e9d61d7e3', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-9', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='a114d4f0c71d41aead588e795c92d80f916704cf8ffa9e4fc93f63286752c66f'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='20d9eddd-51b7-44fc-89be-8048a445f7f6', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='4f56472b18e695411a4d8b0198c55ea11671e305d50179bdcaf2ceea83b9d631')}, hash='382d3df31bd97fc2a10700aad227278e5e893c0ac99f000af8a221db89e04034', text='InTable6,wereportthestatisticsofrewardmodelingdatathatwecollectedovertime,andpresentthem\\nagainst multiple open-source preference datasets including Anthropic Helpful and Harmless (Bai et al.,\\n2022a), OpenAISummarize(Stiennon etal., 2020),OpenAI WebGPT(Nakanoet al.,2021), StackExchange\\n(Lambert et al., 2023), Stanford Human Preferences (Ethayarajh et al., 2022), and Synthetic GPT-J (Havrilla).\\nWe collected a large dataset ofover 1million binary comparisons based on humansapplyingour specified\\nguidelines, which we refer to as Metareward modeling data. Note that the number of tokens in prompts and\\nanswers differs depending on the text domain. Summarization and online forum data generally have longer\\nprompts, while dialogue-style prompts are usually shorter. Compared to existing open-source datasets, our\\npreference data features more conversation turns, and are longer, on average.\\n3.2.2 Reward Modeling\\nThe reward model takes a model response and its corresponding prompt (including contexts from previous\\nturns) as inputs and outputs a scalar score to indicate the quality (e.g., helpfulness and safety) of the model\\ngeneration. Leveragingsuchresponsescoresasrewards,wecanoptimize Llama 2-Chat duringRLHFfor\\nbetter human preference alignment and improved helpfulness and safety.\\nOthers have found that helpfulness and safety sometimes trade off (Bai et al., 2022a), which can make it\\nchallengingforasinglerewardmodeltoperformwellonboth. Toaddressthis,wetraintwoseparatereward\\nmodels, one optimized for helpfulness (referred to as Helpfulness RM ) and another for safety ( Safety RM ).\\nWe initialize our reward models from pretrained chat model checkpoints, as it ensures that both models\\nbenefitfromknowledgeacquiredinpretraining. Inshort, therewardmodel“knows” whatthechatmodel\\n10\\n\\nDatasetNum. of\\nComparisonsAvg. # Turns\\nper DialogueAvg. # Tokens\\nper ExampleAvg. # Tokens\\nin PromptAvg.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-9'),\n",
              " 'node-9': IndexNode(id_='node-9', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='415b7efc-e73f-4ac4-bbfd-c1546f099026', node_type=<ObjectType.DOCUMENT: '4'>, metadata={}, hash='231b3bd773f012c01b893ada9e009ecf25ee59934614c5a595c9bf1b3a123292'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='5c1b3f10-38c8-4f69-b01a-708e989d3a53', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='5b6bb1116415e61aa2cded48288f7058ef70f31f97ee3623eac9a7b2d6d36066'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='e1a4dc32-a45a-4f6d-ad2a-5fe17c4f99bf', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='a9549462870b433355877c86b04f9a1bda3c7a51f4602180f04d533476d0154b')}, hash='a114d4f0c71d41aead588e795c92d80f916704cf8ffa9e4fc93f63286752c66f', text='For our collection of preference annotations, we focus on helpfulness and safety. Helpfulness refers to how\\nwell Llama 2-Chat responses fulfill users’ requests and provide requested information; safety refers to\\nwhether Llama 2-Chat ’s responses are unsafe, e.g., “giving detailed instructions on making a bomb” could\\nbe considered helpful but is unsafe according to our safety guidelines. Separating the two allows us to\\napplyspecificguidelinestoeachandbetterguideannotators;forexample,oursafetyannotationsprovide\\ninstructions to focus on adversarial prompts, among other guidance.\\nApart from differences in annotation guidelines, we additionally collect a safety label during the safety stage.\\nThis additional information bins model responses into one of three categories: 1) the preferred response\\nis safe and the other response is not, 2) both responses are safe, and 3) both responses are unsafe, with\\n18%, 47%, and 35% of the safety dataset falling into each bin, respectively. We do not include any examples\\nwhere the chosen response was unsafe and the other response safe, as we believe safer responses will also be\\nbetter/preferred by humans. Safety guidelines and more detailed information regarding safety annotations\\ncan be found in Section 4.2.1.\\nHuman annotations were collected in batches on a weekly basis. As we collected more preference data, our\\nreward models improved, and we were able to train progressively better versions for Llama 2-Chat (see\\ntheresultsinSection5,Figure20). Llama 2-Chat improvementalsoshiftedthemodel’sdatadistribution.\\nSince reward model accuracy can quickly degrade if not exposed to this new sample distribution, i.e., from\\nhyper-specialization(Scialometal.,2020b),itisimportantbeforeanew Llama 2-Chat tuningiterationto\\ngather new preference data using the latest Llama 2-Chat iterations. This step helps keep the reward model\\non-distribution and maintain an accurate reward for the latest model.\\nInTable6,wereportthestatisticsofrewardmodelingdatathatwecollectedovertime,andpresentthem\\nagainst multiple open-source preference datasets including Anthropic Helpful and Harmless (Bai et al.,\\n2022a), OpenAISummarize(Stiennon etal., 2020),OpenAI WebGPT(Nakanoet al.,2021), StackExchange\\n(Lambert et al., 2023), Stanford Human Preferences (Ethayarajh et al., 2022), and Synthetic GPT-J (Havrilla).\\nWe collected a large dataset ofover 1million binary comparisons based on humansapplyingour specified\\nguidelines, which we refer to as Metareward modeling data. Note that the number of tokens in prompts and\\nanswers differs depending on the text domain. Summarization and online forum data generally have longer\\nprompts, while dialogue-style prompts are usually shorter. Compared to existing open-source datasets, our\\npreference data features more conversation turns, and are longer, on average.\\n3.2.2 Reward Modeling\\nThe reward model takes a model response and its corresponding prompt (including contexts from previous\\nturns) as inputs and outputs a scalar score to indicate the quality (e.g., helpfulness and safety) of the model\\ngeneration. Leveragingsuchresponsescoresasrewards,wecanoptimize Llama 2-Chat duringRLHFfor\\nbetter human preference alignment and improved helpfulness and safety.\\nOthers have found that helpfulness and safety sometimes trade off (Bai et al., 2022a), which can make it\\nchallengingforasinglerewardmodeltoperformwellonboth. Toaddressthis,wetraintwoseparatereward\\nmodels, one optimized for helpfulness (referred to as Helpfulness RM ) and another for safety ( Safety RM ).\\nWe initialize our reward models from pretrained chat model checkpoints, as it ensures that both models\\nbenefitfromknowledgeacquiredinpretraining. Inshort, therewardmodel“knows” whatthechatmodel\\n10\\n\\nDatasetNum. of\\nComparisonsAvg. # Turns\\nper DialogueAvg. # Tokens\\nper ExampleAvg. # Tokens\\nin PromptAvg.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-9'),\n",
              " '6180df2f-6a8c-4a1e-b720-73ade62cd084': IndexNode(id_='6180df2f-6a8c-4a1e-b720-73ade62cd084', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-10', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='a9549462870b433355877c86b04f9a1bda3c7a51f4602180f04d533476d0154b'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='1525d109-1816-457b-ab7f-2d618db22011', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='0497e1624bd7a6a1dc5b84fe9cd4caeaa39897ff98a25ad5b6b53a2a793a5acc')}, hash='440867bf63a396521a229716bb7d2be152c9d54a027601afae8ec1365d070181', text='# Tokens\\nper ExampleAvg. # Tokens\\nin PromptAvg. # Tokens\\nin Response\\nAnthropic Helpful 122,387 3.0 251.5 17.7 88.4\\nAnthropic Harmless 43,966 3.0 152.5 15.7 46.4\\nOpenAI Summarize 176,625 1.0 371.1 336.0 35.1\\nOpenAI WebGPT 13,333 1.0 237.2 48.3 188.9\\nStackExchange 1,038,480 1.0 440.2 200.1 240.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-10'),\n",
              " '1525d109-1816-457b-ab7f-2d618db22011': IndexNode(id_='1525d109-1816-457b-ab7f-2d618db22011', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-10', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='a9549462870b433355877c86b04f9a1bda3c7a51f4602180f04d533476d0154b'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='6180df2f-6a8c-4a1e-b720-73ade62cd084', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='440867bf63a396521a229716bb7d2be152c9d54a027601afae8ec1365d070181'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='d52f9154-e808-40ad-b69d-567831be0b14', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='f708d834be50bbe0bf37bbac0d882e71c0679ddda664da52f950380e463eca56')}, hash='0497e1624bd7a6a1dc5b84fe9cd4caeaa39897ff98a25ad5b6b53a2a793a5acc', text='038,480 1.0 440.2 200.1 240.2\\nStanford SHP 74,882 1.0 338.3 199.5 138.8\\nSynthetic GPT-J 33,139 1.0 123.3 13.0 110.3\\nMeta (Safety & Helpfulness) 1,418,091 3.9 798.5 31.4 234.1\\nTotal 2,919,326 1.6 595.7 108.2 216.9\\nTable 6: Statistics of human preference data for reward modeling.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-10'),\n",
              " 'd52f9154-e808-40ad-b69d-567831be0b14': IndexNode(id_='d52f9154-e808-40ad-b69d-567831be0b14', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-10', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='a9549462870b433355877c86b04f9a1bda3c7a51f4602180f04d533476d0154b'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='1525d109-1816-457b-ab7f-2d618db22011', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='0497e1624bd7a6a1dc5b84fe9cd4caeaa39897ff98a25ad5b6b53a2a793a5acc'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='1f98c5b4-6657-4dbd-bc81-88ce393ed0d5', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='f8b9b51c74173a2ba27646a4b40bc142b47a85ef06078bc5f76daefcfb771e92')}, hash='f708d834be50bbe0bf37bbac0d882e71c0679ddda664da52f950380e463eca56', text='2 216.9\\nTable 6: Statistics of human preference data for reward modeling. We list both the open-source and\\ninternally collected human preference data used for reward modeling. Note that a binary human preference\\ncomparisoncontains2responses(chosenandrejected)sharingthesameprompt(andpreviousdialogue).\\nEachexampleconsistsofaprompt(includingpreviousdialogueifavailable)andaresponse,whichisthe\\ninputoftherewardmodel.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-10'),\n",
              " '1f98c5b4-6657-4dbd-bc81-88ce393ed0d5': IndexNode(id_='1f98c5b4-6657-4dbd-bc81-88ce393ed0d5', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-10', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='a9549462870b433355877c86b04f9a1bda3c7a51f4602180f04d533476d0154b'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='d52f9154-e808-40ad-b69d-567831be0b14', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='f708d834be50bbe0bf37bbac0d882e71c0679ddda664da52f950380e463eca56'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='ad3eab7e-a8f8-4e7c-9c06-f5e7f1458be2', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='ac97e0e6923e3ae591c77bf2f93280c4aa4e52722cf6726ea1cae9cdfddfb071')}, hash='f8b9b51c74173a2ba27646a4b40bc142b47a85ef06078bc5f76daefcfb771e92', text='Wereportthenumberofcomparisons,theaveragenumberofturnsperdialogue,\\nthe average number of tokens per example, per prompt and per response. More details on Meta helpfulness\\nand safety data per batch can be found in Appendix A.3.1.\\nknows. Thispreventscaseswhere, forinstance, thetwomodelswouldhaveaninformationmismatch, which\\ncould result in favoring hallucinations.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-10'),\n",
              " 'ad3eab7e-a8f8-4e7c-9c06-f5e7f1458be2': IndexNode(id_='ad3eab7e-a8f8-4e7c-9c06-f5e7f1458be2', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-10', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='a9549462870b433355877c86b04f9a1bda3c7a51f4602180f04d533476d0154b'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='1f98c5b4-6657-4dbd-bc81-88ce393ed0d5', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='f8b9b51c74173a2ba27646a4b40bc142b47a85ef06078bc5f76daefcfb771e92'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='ef35af29-d7ea-4786-804e-cd583ccbf5e5', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='150cfe1c190d517b0b96e2a1c2eb63b5d9288694297fda91da5afcfa2707654d')}, hash='ac97e0e6923e3ae591c77bf2f93280c4aa4e52722cf6726ea1cae9cdfddfb071', text='The model architecture and hyper-parameters are identical to those\\nofthepretrainedlanguagemodels,exceptthattheclassificationheadfornext-tokenpredictionisreplaced\\nwith a regression head for outputting a scalar reward.\\nTraining Objectives. To train the reward model, we convert our collected pairwise human preference data\\ninto a binary ranking label format (i.e., chosen & rejected) and enforce the chosen response to have a higher\\nscore than its counterpart. We used a binary ranking loss consistent with Ouyang et al.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-10'),\n",
              " 'ef35af29-d7ea-4786-804e-cd583ccbf5e5': IndexNode(id_='ef35af29-d7ea-4786-804e-cd583ccbf5e5', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-10', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='a9549462870b433355877c86b04f9a1bda3c7a51f4602180f04d533476d0154b'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='ad3eab7e-a8f8-4e7c-9c06-f5e7f1458be2', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='ac97e0e6923e3ae591c77bf2f93280c4aa4e52722cf6726ea1cae9cdfddfb071'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='ab5b39a9-1785-4413-905a-4a67d764df41', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='9b74eb2c5d5f65489a52d2e646f39afbfb1f2d686376ce657d5bb2750a28d428')}, hash='150cfe1c190d517b0b96e2a1c2eb63b5d9288694297fda91da5afcfa2707654d', text='We used a binary ranking loss consistent with Ouyang et al. (2022):\\nLranking =−log(σ(rθ(x, yc)−rθ(x, yr))) (1)\\nwhere rθ(x, y)is the scalar score output for prompt xand completion ywith model weights θ.ycis the\\npreferred response that annotators choose and yris the rejected counterpart.\\nBuilt on top of this binary ranking loss, we further modify it separately for better helpfulness and safety\\nrewardmodelsasfollows.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-10'),\n",
              " 'ab5b39a9-1785-4413-905a-4a67d764df41': IndexNode(id_='ab5b39a9-1785-4413-905a-4a67d764df41', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-10', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='a9549462870b433355877c86b04f9a1bda3c7a51f4602180f04d533476d0154b'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='ef35af29-d7ea-4786-804e-cd583ccbf5e5', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='150cfe1c190d517b0b96e2a1c2eb63b5d9288694297fda91da5afcfa2707654d'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='c8bf2ef9-8543-47ca-b52f-9bcb83508e24', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='6608bf06b3d322d6aa82642466e01263985ee1ea041028a2697aa270144d5e81')}, hash='9b74eb2c5d5f65489a52d2e646f39afbfb1f2d686376ce657d5bb2750a28d428', text='Giventhatourpreferenceratingsisdecomposedasascaleoffourpoints(e.g.,\\nsignificantly better ), as presented in Section 3.2.1, it can be useful to leverage this information to explicitly\\nteachtherewardmodeltoassignmorediscrepantscorestothegenerationsthathavemoredifferences.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-10'),\n",
              " 'c8bf2ef9-8543-47ca-b52f-9bcb83508e24': IndexNode(id_='c8bf2ef9-8543-47ca-b52f-9bcb83508e24', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-10', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='a9549462870b433355877c86b04f9a1bda3c7a51f4602180f04d533476d0154b'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='ab5b39a9-1785-4413-905a-4a67d764df41', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='9b74eb2c5d5f65489a52d2e646f39afbfb1f2d686376ce657d5bb2750a28d428'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='97912531-3824-4300-8c10-fdc1e43cdb1b', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='9c94006261995079ecaadd7a3132365397f77aa3b067eaea3dbaf48923d503fe')}, hash='6608bf06b3d322d6aa82642466e01263985ee1ea041028a2697aa270144d5e81', text='To\\ndo so, we further add a margin component in the loss:\\nLranking =−log(σ(rθ(x, yc)−rθ(x, yr)−m(r))) (2)\\nwhere the margin m(r)is a discrete function of the preference rating. Naturally, we use a large margin\\nfor pairs with distinct responses, and a smaller one for those with similar responses (shown in Table 27).', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-10'),\n",
              " '97912531-3824-4300-8c10-fdc1e43cdb1b': IndexNode(id_='97912531-3824-4300-8c10-fdc1e43cdb1b', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-10', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='a9549462870b433355877c86b04f9a1bda3c7a51f4602180f04d533476d0154b'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='c8bf2ef9-8543-47ca-b52f-9bcb83508e24', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='6608bf06b3d322d6aa82642466e01263985ee1ea041028a2697aa270144d5e81'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='e1325c1d-bc27-477b-99ad-130d3fc691dc', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='1d472092fac1f517a283094ce01629a77515836d7632d04ef80bae02dd741b52')}, hash='9c94006261995079ecaadd7a3132365397f77aa3b067eaea3dbaf48923d503fe', text='WefoundthismargincomponentcanimproveHelpfulnessrewardmodelaccuracyespeciallyonsamples\\nwheretworesponsesaremoreseparable. MoredetailedablationandanalysiscanbefoundinTable28in\\nAppendix A.3.3.\\nDataComposition. Wecombineournewlycollecteddatawithexistingopen-sourcepreferencedatasets\\ntoformalargertrainingdataset.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-10'),\n",
              " 'e1325c1d-bc27-477b-99ad-130d3fc691dc': IndexNode(id_='e1325c1d-bc27-477b-99ad-130d3fc691dc', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-10', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='a9549462870b433355877c86b04f9a1bda3c7a51f4602180f04d533476d0154b'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='97912531-3824-4300-8c10-fdc1e43cdb1b', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='9c94006261995079ecaadd7a3132365397f77aa3b067eaea3dbaf48923d503fe')}, hash='1d472092fac1f517a283094ce01629a77515836d7632d04ef80bae02dd741b52', text='Initially,open-sourcedatasetswereusedtobootstrapourrewardmodels\\nwhilewewereintheprocessofcollectingpreferenceannotationdata. WenotethatinthecontextofRLHFin\\nthis study, the role of reward signals is to learn human preference for Llama 2-Chat outputs rather than\\nany model outputs.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-10'),\n",
              " '1cc0b023-afca-464c-99f5-21bbb93c8d47': IndexNode(id_='1cc0b023-afca-464c-99f5-21bbb93c8d47', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-10', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='a9549462870b433355877c86b04f9a1bda3c7a51f4602180f04d533476d0154b'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='21809832-57a6-459b-ba22-d68ccce64b2d', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='dd387905d7142a854c363453e6e06cf2fb08318ff405b99a87b7c08eb8f80274')}, hash='52e3dcb53474c0ee0ba1418a357e1025eadc7b89630020991eca8ec4c83c3ed7', text='# Tokens\\nper ExampleAvg. # Tokens\\nin PromptAvg. # Tokens\\nin Response\\nAnthropic Helpful 122,387 3.0 251.5 17.7 88.4\\nAnthropic Harmless 43,966 3.0 152.5 15.7 46.4\\nOpenAI Summarize 176,625 1.0 371.1 336.0 35.1\\nOpenAI WebGPT 13,333 1.0 237.2 48.3 188.9\\nStackExchange 1,038,480 1.0 440.2 200.1 240.2\\nStanford SHP 74,882 1.0 338.3 199.5 138.8\\nSynthetic GPT-J 33,139 1.0 123.3 13.0 110.3\\nMeta (Safety & Helpfulness) 1,418,091 3.9 798.5 31.4 234.1\\nTotal 2,919,326 1.6 595.7 108.2 216.9\\nTable 6: Statistics of human preference data for reward modeling. We list both the open-source and\\ninternally collected human preference data used for reward modeling.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-10'),\n",
              " '21809832-57a6-459b-ba22-d68ccce64b2d': IndexNode(id_='21809832-57a6-459b-ba22-d68ccce64b2d', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-10', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='a9549462870b433355877c86b04f9a1bda3c7a51f4602180f04d533476d0154b'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='1cc0b023-afca-464c-99f5-21bbb93c8d47', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='52e3dcb53474c0ee0ba1418a357e1025eadc7b89630020991eca8ec4c83c3ed7'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='bea811f6-cacb-422c-b170-25e5c5d23e41', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='75fc782c76f8416be53c6c691a0c3f6cfc372634db7af402801abe0c424b1cb2')}, hash='dd387905d7142a854c363453e6e06cf2fb08318ff405b99a87b7c08eb8f80274', text='Note that a binary human preference\\ncomparisoncontains2responses(chosenandrejected)sharingthesameprompt(andpreviousdialogue).\\nEachexampleconsistsofaprompt(includingpreviousdialogueifavailable)andaresponse,whichisthe\\ninputoftherewardmodel. Wereportthenumberofcomparisons,theaveragenumberofturnsperdialogue,\\nthe average number of tokens per example, per prompt and per response. More details on Meta helpfulness\\nand safety data per batch can be found in Appendix A.3.1.\\nknows. Thispreventscaseswhere, forinstance, thetwomodelswouldhaveaninformationmismatch, which\\ncould result in favoring hallucinations. The model architecture and hyper-parameters are identical to those\\nofthepretrainedlanguagemodels,exceptthattheclassificationheadfornext-tokenpredictionisreplaced\\nwith a regression head for outputting a scalar reward.\\nTraining Objectives.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-10'),\n",
              " 'bea811f6-cacb-422c-b170-25e5c5d23e41': IndexNode(id_='bea811f6-cacb-422c-b170-25e5c5d23e41', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-10', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='a9549462870b433355877c86b04f9a1bda3c7a51f4602180f04d533476d0154b'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='21809832-57a6-459b-ba22-d68ccce64b2d', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='dd387905d7142a854c363453e6e06cf2fb08318ff405b99a87b7c08eb8f80274'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='b7dfb116-2bb6-4832-a887-09edf60f5fe9', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='d8e314ae6cc5349cd3b718a836e1c28b2b6e0ef84b77a5ec0836f6dcf78c790a')}, hash='75fc782c76f8416be53c6c691a0c3f6cfc372634db7af402801abe0c424b1cb2', text='Training Objectives. To train the reward model, we convert our collected pairwise human preference data\\ninto a binary ranking label format (i.e., chosen & rejected) and enforce the chosen response to have a higher\\nscore than its counterpart. We used a binary ranking loss consistent with Ouyang et al. (2022):\\nLranking =−log(σ(rθ(x, yc)−rθ(x, yr))) (1)\\nwhere rθ(x, y)is the scalar score output for prompt xand completion ywith model weights θ.ycis the\\npreferred response that annotators choose and yris the rejected counterpart.\\nBuilt on top of this binary ranking loss, we further modify it separately for better helpfulness and safety\\nrewardmodelsasfollows. Giventhatourpreferenceratingsisdecomposedasascaleoffourpoints(e.g.,\\nsignificantly better ), as presented in Section 3.2.1, it can be useful to leverage this information to explicitly\\nteachtherewardmodeltoassignmorediscrepantscorestothegenerationsthathavemoredifferences.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-10'),\n",
              " 'b7dfb116-2bb6-4832-a887-09edf60f5fe9': IndexNode(id_='b7dfb116-2bb6-4832-a887-09edf60f5fe9', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-10', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='a9549462870b433355877c86b04f9a1bda3c7a51f4602180f04d533476d0154b'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='bea811f6-cacb-422c-b170-25e5c5d23e41', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='75fc782c76f8416be53c6c691a0c3f6cfc372634db7af402801abe0c424b1cb2'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='2f382a9f-d251-401c-b618-dde96a02e447', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='7b2aa9dae56e9b85af3a3352e206c661a369044dac9bb37b08fe169702afad59')}, hash='d8e314ae6cc5349cd3b718a836e1c28b2b6e0ef84b77a5ec0836f6dcf78c790a', text='To\\ndo so, we further add a margin component in the loss:\\nLranking =−log(σ(rθ(x, yc)−rθ(x, yr)−m(r))) (2)\\nwhere the margin m(r)is a discrete function of the preference rating. Naturally, we use a large margin\\nfor pairs with distinct responses, and a smaller one for those with similar responses (shown in Table 27).\\nWefoundthismargincomponentcanimproveHelpfulnessrewardmodelaccuracyespeciallyonsamples\\nwheretworesponsesaremoreseparable. MoredetailedablationandanalysiscanbefoundinTable28in\\nAppendix A.3.3.\\nDataComposition. Wecombineournewlycollecteddatawithexistingopen-sourcepreferencedatasets\\ntoformalargertrainingdataset. Initially,open-sourcedatasetswereusedtobootstrapourrewardmodels\\nwhilewewereintheprocessofcollectingpreferenceannotationdata.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-10'),\n",
              " '2f382a9f-d251-401c-b618-dde96a02e447': IndexNode(id_='2f382a9f-d251-401c-b618-dde96a02e447', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-10', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='a9549462870b433355877c86b04f9a1bda3c7a51f4602180f04d533476d0154b'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='b7dfb116-2bb6-4832-a887-09edf60f5fe9', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='d8e314ae6cc5349cd3b718a836e1c28b2b6e0ef84b77a5ec0836f6dcf78c790a')}, hash='7b2aa9dae56e9b85af3a3352e206c661a369044dac9bb37b08fe169702afad59', text='WenotethatinthecontextofRLHFin\\nthis study, the role of reward signals is to learn human preference for Llama 2-Chat outputs rather than\\nany model outputs.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-10'),\n",
              " 'cccfa811-b984-405a-a203-547651041adc': IndexNode(id_='cccfa811-b984-405a-a203-547651041adc', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-10', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='a9549462870b433355877c86b04f9a1bda3c7a51f4602180f04d533476d0154b'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='3625f5c1-fe2c-448b-a47e-c8242c7b3c64', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='7fb83af4f8355209ecde72523215bde7c9655a8f125e0b579676af20bf9c675e')}, hash='abd8b30780970cf0cc5aeccd357a211f1b20434e257fa98b491e355c63a50acd', text='# Tokens\\nper ExampleAvg. # Tokens\\nin PromptAvg. # Tokens\\nin Response\\nAnthropic Helpful 122,387 3.0 251.5 17.7 88.4\\nAnthropic Harmless 43,966 3.0 152.5 15.7 46.4\\nOpenAI Summarize 176,625 1.0 371.1 336.0 35.1\\nOpenAI WebGPT 13,333 1.0 237.2 48.3 188.9\\nStackExchange 1,038,480 1.0 440.2 200.1 240.2\\nStanford SHP 74,882 1.0 338.3 199.5 138.8\\nSynthetic GPT-J 33,139 1.0 123.3 13.0 110.3\\nMeta (Safety & Helpfulness) 1,418,091 3.9 798.5 31.4 234.1\\nTotal 2,919,326 1.6 595.7 108.2 216.9\\nTable 6: Statistics of human preference data for reward modeling. We list both the open-source and\\ninternally collected human preference data used for reward modeling. Note that a binary human preference\\ncomparisoncontains2responses(chosenandrejected)sharingthesameprompt(andpreviousdialogue).\\nEachexampleconsistsofaprompt(includingpreviousdialogueifavailable)andaresponse,whichisthe\\ninputoftherewardmodel. Wereportthenumberofcomparisons,theaveragenumberofturnsperdialogue,\\nthe average number of tokens per example, per prompt and per response. More details on Meta helpfulness\\nand safety data per batch can be found in Appendix A.3.1.\\nknows. Thispreventscaseswhere, forinstance, thetwomodelswouldhaveaninformationmismatch, which\\ncould result in favoring hallucinations. The model architecture and hyper-parameters are identical to those\\nofthepretrainedlanguagemodels,exceptthattheclassificationheadfornext-tokenpredictionisreplaced\\nwith a regression head for outputting a scalar reward.\\nTraining Objectives.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-10'),\n",
              " '3625f5c1-fe2c-448b-a47e-c8242c7b3c64': IndexNode(id_='3625f5c1-fe2c-448b-a47e-c8242c7b3c64', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-10', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='a9549462870b433355877c86b04f9a1bda3c7a51f4602180f04d533476d0154b'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='cccfa811-b984-405a-a203-547651041adc', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='abd8b30780970cf0cc5aeccd357a211f1b20434e257fa98b491e355c63a50acd'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='eb497348-4e11-4313-9421-3e10c88e056b', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='7b2aa9dae56e9b85af3a3352e206c661a369044dac9bb37b08fe169702afad59')}, hash='7fb83af4f8355209ecde72523215bde7c9655a8f125e0b579676af20bf9c675e', text='Training Objectives. To train the reward model, we convert our collected pairwise human preference data\\ninto a binary ranking label format (i.e., chosen & rejected) and enforce the chosen response to have a higher\\nscore than its counterpart. We used a binary ranking loss consistent with Ouyang et al. (2022):\\nLranking =−log(σ(rθ(x, yc)−rθ(x, yr))) (1)\\nwhere rθ(x, y)is the scalar score output for prompt xand completion ywith model weights θ.ycis the\\npreferred response that annotators choose and yris the rejected counterpart.\\nBuilt on top of this binary ranking loss, we further modify it separately for better helpfulness and safety\\nrewardmodelsasfollows. Giventhatourpreferenceratingsisdecomposedasascaleoffourpoints(e.g.,\\nsignificantly better ), as presented in Section 3.2.1, it can be useful to leverage this information to explicitly\\nteachtherewardmodeltoassignmorediscrepantscorestothegenerationsthathavemoredifferences. To\\ndo so, we further add a margin component in the loss:\\nLranking =−log(σ(rθ(x, yc)−rθ(x, yr)−m(r))) (2)\\nwhere the margin m(r)is a discrete function of the preference rating. Naturally, we use a large margin\\nfor pairs with distinct responses, and a smaller one for those with similar responses (shown in Table 27).\\nWefoundthismargincomponentcanimproveHelpfulnessrewardmodelaccuracyespeciallyonsamples\\nwheretworesponsesaremoreseparable. MoredetailedablationandanalysiscanbefoundinTable28in\\nAppendix A.3.3.\\nDataComposition. Wecombineournewlycollecteddatawithexistingopen-sourcepreferencedatasets\\ntoformalargertrainingdataset. Initially,open-sourcedatasetswereusedtobootstrapourrewardmodels\\nwhilewewereintheprocessofcollectingpreferenceannotationdata.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-10'),\n",
              " 'eb497348-4e11-4313-9421-3e10c88e056b': IndexNode(id_='eb497348-4e11-4313-9421-3e10c88e056b', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-10', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='a9549462870b433355877c86b04f9a1bda3c7a51f4602180f04d533476d0154b'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='3625f5c1-fe2c-448b-a47e-c8242c7b3c64', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='7fb83af4f8355209ecde72523215bde7c9655a8f125e0b579676af20bf9c675e')}, hash='7b2aa9dae56e9b85af3a3352e206c661a369044dac9bb37b08fe169702afad59', text='WenotethatinthecontextofRLHFin\\nthis study, the role of reward signals is to learn human preference for Llama 2-Chat outputs rather than\\nany model outputs.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-10'),\n",
              " 'node-10': IndexNode(id_='node-10', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='415b7efc-e73f-4ac4-bbfd-c1546f099026', node_type=<ObjectType.DOCUMENT: '4'>, metadata={}, hash='231b3bd773f012c01b893ada9e009ecf25ee59934614c5a595c9bf1b3a123292'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='7b73de15-d499-4eca-b346-7aa01b75135e', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='a114d4f0c71d41aead588e795c92d80f916704cf8ffa9e4fc93f63286752c66f'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='12a625dd-78f5-416f-adb1-c972b0a85e55', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='cebbca5cd0b7b0c4ecd3a63bb8224ec7aef2d430c5e15f442ff2e8e20d14429f')}, hash='a9549462870b433355877c86b04f9a1bda3c7a51f4602180f04d533476d0154b', text='# Tokens\\nper ExampleAvg. # Tokens\\nin PromptAvg. # Tokens\\nin Response\\nAnthropic Helpful 122,387 3.0 251.5 17.7 88.4\\nAnthropic Harmless 43,966 3.0 152.5 15.7 46.4\\nOpenAI Summarize 176,625 1.0 371.1 336.0 35.1\\nOpenAI WebGPT 13,333 1.0 237.2 48.3 188.9\\nStackExchange 1,038,480 1.0 440.2 200.1 240.2\\nStanford SHP 74,882 1.0 338.3 199.5 138.8\\nSynthetic GPT-J 33,139 1.0 123.3 13.0 110.3\\nMeta (Safety & Helpfulness) 1,418,091 3.9 798.5 31.4 234.1\\nTotal 2,919,326 1.6 595.7 108.2 216.9\\nTable 6: Statistics of human preference data for reward modeling. We list both the open-source and\\ninternally collected human preference data used for reward modeling. Note that a binary human preference\\ncomparisoncontains2responses(chosenandrejected)sharingthesameprompt(andpreviousdialogue).\\nEachexampleconsistsofaprompt(includingpreviousdialogueifavailable)andaresponse,whichisthe\\ninputoftherewardmodel. Wereportthenumberofcomparisons,theaveragenumberofturnsperdialogue,\\nthe average number of tokens per example, per prompt and per response. More details on Meta helpfulness\\nand safety data per batch can be found in Appendix A.3.1.\\nknows. Thispreventscaseswhere, forinstance, thetwomodelswouldhaveaninformationmismatch, which\\ncould result in favoring hallucinations. The model architecture and hyper-parameters are identical to those\\nofthepretrainedlanguagemodels,exceptthattheclassificationheadfornext-tokenpredictionisreplaced\\nwith a regression head for outputting a scalar reward.\\nTraining Objectives. To train the reward model, we convert our collected pairwise human preference data\\ninto a binary ranking label format (i.e., chosen & rejected) and enforce the chosen response to have a higher\\nscore than its counterpart. We used a binary ranking loss consistent with Ouyang et al. (2022):\\nLranking =−log(σ(rθ(x, yc)−rθ(x, yr))) (1)\\nwhere rθ(x, y)is the scalar score output for prompt xand completion ywith model weights θ.ycis the\\npreferred response that annotators choose and yris the rejected counterpart.\\nBuilt on top of this binary ranking loss, we further modify it separately for better helpfulness and safety\\nrewardmodelsasfollows. Giventhatourpreferenceratingsisdecomposedasascaleoffourpoints(e.g.,\\nsignificantly better ), as presented in Section 3.2.1, it can be useful to leverage this information to explicitly\\nteachtherewardmodeltoassignmorediscrepantscorestothegenerationsthathavemoredifferences. To\\ndo so, we further add a margin component in the loss:\\nLranking =−log(σ(rθ(x, yc)−rθ(x, yr)−m(r))) (2)\\nwhere the margin m(r)is a discrete function of the preference rating. Naturally, we use a large margin\\nfor pairs with distinct responses, and a smaller one for those with similar responses (shown in Table 27).\\nWefoundthismargincomponentcanimproveHelpfulnessrewardmodelaccuracyespeciallyonsamples\\nwheretworesponsesaremoreseparable. MoredetailedablationandanalysiscanbefoundinTable28in\\nAppendix A.3.3.\\nDataComposition. Wecombineournewlycollecteddatawithexistingopen-sourcepreferencedatasets\\ntoformalargertrainingdataset. Initially,open-sourcedatasetswereusedtobootstrapourrewardmodels\\nwhilewewereintheprocessofcollectingpreferenceannotationdata. WenotethatinthecontextofRLHFin\\nthis study, the role of reward signals is to learn human preference for Llama 2-Chat outputs rather than\\nany model outputs.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-10'),\n",
              " '65b91920-dffc-4cfc-9d27-245715699cdf': IndexNode(id_='65b91920-dffc-4cfc-9d27-245715699cdf', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-11', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='cebbca5cd0b7b0c4ecd3a63bb8224ec7aef2d430c5e15f442ff2e8e20d14429f'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='04851fbf-6391-46b9-b4eb-b33c692c77c1', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='08eb430f3a536a7fce2fe2536cdc225a3db001b3389584e23f0379271073b08d')}, hash='26e7f3d7d5bb2f1e3d5e2ef29d3ed193c07b02f1ccfa77ba8750f73ed671f0b9', text='However, in our experiments, we do not observe negative transfer from the open-source\\npreferencedatasets. Thus,wehavedecidedtokeeptheminourdatamixture,astheycouldenablebetter\\ngeneralization for the reward model and prevent reward hacking, i.e. Llama 2-Chat taking advantage of\\nsome weaknesses of our reward, and so artificially inflating the score despite performing less well.\\nWith training data available from different sources, we experimented with different mixing recipes for both\\nHelpfulnessandSafetyrewardmodelstoascertainthebestsettings.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-11'),\n",
              " '04851fbf-6391-46b9-b4eb-b33c692c77c1': IndexNode(id_='04851fbf-6391-46b9-b4eb-b33c692c77c1', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-11', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='cebbca5cd0b7b0c4ecd3a63bb8224ec7aef2d430c5e15f442ff2e8e20d14429f'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='65b91920-dffc-4cfc-9d27-245715699cdf', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='26e7f3d7d5bb2f1e3d5e2ef29d3ed193c07b02f1ccfa77ba8750f73ed671f0b9'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='47429c28-0e54-47a2-92d2-d4a1fcd486fd', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='d25481be68aabf592c181216dfdc7516a72dc463f1869bce5feb6cd452d4d349')}, hash='08eb430f3a536a7fce2fe2536cdc225a3db001b3389584e23f0379271073b08d', text='Afterextensiveexperimentation,the\\n11\\n\\nHelpfulness reward model is eventually trained on all Meta Helpfulness data, combined with an equal\\npartsoftheremainingdatauniformlysampledfromMetaSafetyandfromtheopen-sourcedatasets. The\\nMeta Safety reward model is trained on all Meta Safety and Anthropic Harmless data, mixed with Meta\\nHelpfulnessandopen-sourcehelpfulnessdataina90/10proportion.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-11'),\n",
              " '47429c28-0e54-47a2-92d2-d4a1fcd486fd': IndexNode(id_='47429c28-0e54-47a2-92d2-d4a1fcd486fd', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-11', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='cebbca5cd0b7b0c4ecd3a63bb8224ec7aef2d430c5e15f442ff2e8e20d14429f'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='04851fbf-6391-46b9-b4eb-b33c692c77c1', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='08eb430f3a536a7fce2fe2536cdc225a3db001b3389584e23f0379271073b08d'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='65fbb784-c7da-47ba-b77d-376847970e16', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='1a74e0a71757306cb51a81f3ded96db744c6043f438f3dd696de3c205a19e8b2')}, hash='d25481be68aabf592c181216dfdc7516a72dc463f1869bce5feb6cd452d4d349', text='Wefoundthatthesettingwith10%\\nhelpfulness data is especially beneficial for the accuracy on samples where both the chosen and rejected\\nresponses were deemed safe.\\nTraining Details. We train for one epoch over the training data. In earlier experiments, we found that\\ntraininglongercanleadtoover-fitting. Weusethesameoptimizerparametersasforthebasemodel. The\\nmaximum learning rate is 5×10−6for the 70B parameter Llama 2-Chat and1×10−5for the rest.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-11'),\n",
              " '65fbb784-c7da-47ba-b77d-376847970e16': IndexNode(id_='65fbb784-c7da-47ba-b77d-376847970e16', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-11', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='cebbca5cd0b7b0c4ecd3a63bb8224ec7aef2d430c5e15f442ff2e8e20d14429f'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='47429c28-0e54-47a2-92d2-d4a1fcd486fd', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='d25481be68aabf592c181216dfdc7516a72dc463f1869bce5feb6cd452d4d349'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='d980bb43-642d-4281-8c26-6d5b5c14eec6', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='8b1c944e251a60102d9b3bac3d31acedd2cf0fe20fb5576edf8b84c03164ab1a')}, hash='1a74e0a71757306cb51a81f3ded96db744c6043f438f3dd696de3c205a19e8b2', text='The\\nlearningrateisdecreasedonacosinelearningrateschedule,downto10%ofthemaximumlearningrate.\\nWe use a warm-up of 3% of the total number of steps, with a minimum of 5. The effective batch size is kept\\nfixed at 512 pairs, or 1024 rows per batch.\\nMeta\\nHelpful.Meta\\nSafetyAnthropic\\nHelpfulAnthropic\\nHarmlessOpenAI\\nSumm.Stanford\\nSHPAvg\\nSteamSHP-XL 52.8 43.8 66.8 34.2 54.7 75.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-11'),\n",
              " 'd980bb43-642d-4281-8c26-6d5b5c14eec6': IndexNode(id_='d980bb43-642d-4281-8c26-6d5b5c14eec6', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-11', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='cebbca5cd0b7b0c4ecd3a63bb8224ec7aef2d430c5e15f442ff2e8e20d14429f'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='65fbb784-c7da-47ba-b77d-376847970e16', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='1a74e0a71757306cb51a81f3ded96db744c6043f438f3dd696de3c205a19e8b2'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='70927d20-26cf-4eab-a5cf-382ff528e955', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='d64d046eab3f2677592cd3c66928de0102a19cedb318b3960986fe89baf9e24c')}, hash='8b1c944e251a60102d9b3bac3d31acedd2cf0fe20fb5576edf8b84c03164ab1a', text='8 43.8 66.8 34.2 54.7 75.7 55.3\\nOpen Assistant 53.8 53.4 67.7 68.4 71.7 55.0 63.0\\nGPT4 58.6 58.1 - - - - -\\nSafety RM 56.2 64.5 55.4 74.7 71.7 65.2 64.3\\nHelpfulness RM 63.2 62.8 72.0 71.0 75.5 80.0 70.6\\nTable 7: Reward model results.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-11'),\n",
              " '70927d20-26cf-4eab-a5cf-382ff528e955': IndexNode(id_='70927d20-26cf-4eab-a5cf-382ff528e955', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-11', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='cebbca5cd0b7b0c4ecd3a63bb8224ec7aef2d430c5e15f442ff2e8e20d14429f'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='d980bb43-642d-4281-8c26-6d5b5c14eec6', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='8b1c944e251a60102d9b3bac3d31acedd2cf0fe20fb5576edf8b84c03164ab1a'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='26dda0be-6df2-4518-9c3b-a297e7c6aaa3', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='721e89ef0783b8daad15cd0e47bc1c4212fa01da3eda4ea4c7e1212d3fb0c98a')}, hash='d64d046eab3f2677592cd3c66928de0102a19cedb318b3960986fe89baf9e24c', text='0 75.5 80.0 70.6\\nTable 7: Reward model results. Performance of our final helpfulness and safety reward models on a diverse\\nset of human preference benchmarks. Note that our model is fine-tuned on our collected data, as opposed to\\nthe other baselines that we report.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-11'),\n",
              " '26dda0be-6df2-4518-9c3b-a297e7c6aaa3': IndexNode(id_='26dda0be-6df2-4518-9c3b-a297e7c6aaa3', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-11', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='cebbca5cd0b7b0c4ecd3a63bb8224ec7aef2d430c5e15f442ff2e8e20d14429f'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='70927d20-26cf-4eab-a5cf-382ff528e955', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='d64d046eab3f2677592cd3c66928de0102a19cedb318b3960986fe89baf9e24c'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='dd2391e9-c751-486b-9a22-07a598868cf7', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='591e170697629685b1bee216f08957df6806255a24de9b6704594603b7568ae4')}, hash='721e89ef0783b8daad15cd0e47bc1c4212fa01da3eda4ea4c7e1212d3fb0c98a', text='Test SetSignificantly\\nBetterBetterSlightly\\nBetterNegligibly\\nBetter / UnsureAvg\\nSafety RMMeta Safety94.3 76.3 65.7 55.3 64.5\\nHelpfulness RM 89.9 73.2 63.8 54.5 62.8\\nSafety RMMeta Helpful.64.6 57.5 53.8 52.2 56.2\\nHelpfulness RM 80.7 67.5 60.9 54.7 63.2\\nTable 8: Granular reward model accuracy per preference rating.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-11'),\n",
              " 'dd2391e9-c751-486b-9a22-07a598868cf7': IndexNode(id_='dd2391e9-c751-486b-9a22-07a598868cf7', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-11', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='cebbca5cd0b7b0c4ecd3a63bb8224ec7aef2d430c5e15f442ff2e8e20d14429f'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='26dda0be-6df2-4518-9c3b-a297e7c6aaa3', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='721e89ef0783b8daad15cd0e47bc1c4212fa01da3eda4ea4c7e1212d3fb0c98a'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='a73d7f94-fab0-4ad0-9e0f-526fe1de0471', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='656f022acc3679798f9c1f22cc53c54daa4ad5fe3744c7306867d0787a2b1a55')}, hash='591e170697629685b1bee216f08957df6806255a24de9b6704594603b7568ae4', text='We report per-preference rating accuracy\\nforbothHelpfulnessandSafetyrewardmodelsontheMetaHelpfulnessandSafetytestsets. Thereward\\nmodels show superior accuracy on more distinct responses (e.g., significantly better) and lower accuracy on\\nsimilar responses (e.g., negligibly better).\\nReward Model Results. On each batch of human preference annotation for reward modeling, we held out\\n1000examplesasatestsettoevaluateourmodels.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-11'),\n",
              " 'a73d7f94-fab0-4ad0-9e0f-526fe1de0471': IndexNode(id_='a73d7f94-fab0-4ad0-9e0f-526fe1de0471', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-11', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='cebbca5cd0b7b0c4ecd3a63bb8224ec7aef2d430c5e15f442ff2e8e20d14429f'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='dd2391e9-c751-486b-9a22-07a598868cf7', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='591e170697629685b1bee216f08957df6806255a24de9b6704594603b7568ae4'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='2986969c-f250-4c1f-9e5a-f17a5eb938a7', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='c58462e6fafce73ac51632957828bb5e9e9684d9251df15630789393e1a76b06')}, hash='656f022acc3679798f9c1f22cc53c54daa4ad5fe3744c7306867d0787a2b1a55', text='Werefertotheunionofallpromptsforthecorresponding\\ntest sets as “Meta Helpfulness” and “Meta Safety,” respectively.\\nAs reference points, we also evaluated other publicly available alternatives as baselines: SteamSHP-XL\\n(Ethayarajh et al., 2022) based on FLAN-T5-xl, the Open Assistant (Köpf et al., 2023) reward model based on\\nDeBERTa V3 Large (He et al., 2020), and GPT4 accessible through the OpenAI’s API.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-11'),\n",
              " '2986969c-f250-4c1f-9e5a-f17a5eb938a7': IndexNode(id_='2986969c-f250-4c1f-9e5a-f17a5eb938a7', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-11', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='cebbca5cd0b7b0c4ecd3a63bb8224ec7aef2d430c5e15f442ff2e8e20d14429f'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='a73d7f94-fab0-4ad0-9e0f-526fe1de0471', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='656f022acc3679798f9c1f22cc53c54daa4ad5fe3744c7306867d0787a2b1a55')}, hash='c58462e6fafce73ac51632957828bb5e9e9684d9251df15630789393e1a76b06', text='Note that at inference\\ntime, asopposedtotraining, alltherewardmodelscanpredictascalarforasingleoutput, withoutrequiring\\nto access its paired output.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-11'),\n",
              " 'd176694e-ab41-4f62-9ed1-7e1e78539156': IndexNode(id_='d176694e-ab41-4f62-9ed1-7e1e78539156', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-11', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='cebbca5cd0b7b0c4ecd3a63bb8224ec7aef2d430c5e15f442ff2e8e20d14429f'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='1542c3fe-27f2-4d2c-b10c-33bdb9073263', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='88ffb4561a9af938c29bf349061e7930697f536e97aed3652280eec6a20ed7e0')}, hash='2e7bfe26eea139c6f2aad1ca1593e3f138fb9937363b7c8b0c9bd673f87bf72b', text='However, in our experiments, we do not observe negative transfer from the open-source\\npreferencedatasets. Thus,wehavedecidedtokeeptheminourdatamixture,astheycouldenablebetter\\ngeneralization for the reward model and prevent reward hacking, i.e. Llama 2-Chat taking advantage of\\nsome weaknesses of our reward, and so artificially inflating the score despite performing less well.\\nWith training data available from different sources, we experimented with different mixing recipes for both\\nHelpfulnessandSafetyrewardmodelstoascertainthebestsettings. Afterextensiveexperimentation,the\\n11\\n\\nHelpfulness reward model is eventually trained on all Meta Helpfulness data, combined with an equal\\npartsoftheremainingdatauniformlysampledfromMetaSafetyandfromtheopen-sourcedatasets. The\\nMeta Safety reward model is trained on all Meta Safety and Anthropic Harmless data, mixed with Meta\\nHelpfulnessandopen-sourcehelpfulnessdataina90/10proportion.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-11'),\n",
              " '1542c3fe-27f2-4d2c-b10c-33bdb9073263': IndexNode(id_='1542c3fe-27f2-4d2c-b10c-33bdb9073263', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-11', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='cebbca5cd0b7b0c4ecd3a63bb8224ec7aef2d430c5e15f442ff2e8e20d14429f'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='d176694e-ab41-4f62-9ed1-7e1e78539156', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='2e7bfe26eea139c6f2aad1ca1593e3f138fb9937363b7c8b0c9bd673f87bf72b'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='2ef048e2-0f41-4787-948a-f51309f8ccb3', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='438501ebd31739a9c2cb11e1c1eb7075e628fee9377afef429537eb2bbafba61')}, hash='88ffb4561a9af938c29bf349061e7930697f536e97aed3652280eec6a20ed7e0', text='Wefoundthatthesettingwith10%\\nhelpfulness data is especially beneficial for the accuracy on samples where both the chosen and rejected\\nresponses were deemed safe.\\nTraining Details. We train for one epoch over the training data. In earlier experiments, we found that\\ntraininglongercanleadtoover-fitting. Weusethesameoptimizerparametersasforthebasemodel. The\\nmaximum learning rate is 5×10−6for the 70B parameter Llama 2-Chat and1×10−5for the rest. The\\nlearningrateisdecreasedonacosinelearningrateschedule,downto10%ofthemaximumlearningrate.\\nWe use a warm-up of 3% of the total number of steps, with a minimum of 5. The effective batch size is kept\\nfixed at 512 pairs, or 1024 rows per batch.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-11'),\n",
              " '2ef048e2-0f41-4787-948a-f51309f8ccb3': IndexNode(id_='2ef048e2-0f41-4787-948a-f51309f8ccb3', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-11', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='cebbca5cd0b7b0c4ecd3a63bb8224ec7aef2d430c5e15f442ff2e8e20d14429f'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='1542c3fe-27f2-4d2c-b10c-33bdb9073263', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='88ffb4561a9af938c29bf349061e7930697f536e97aed3652280eec6a20ed7e0'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='fd243c79-63ab-4891-ae8f-5a64c1e8294b', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='a26168b7e244320f74c8ca8f0226900e492a24de17215c1f9a470ef3e3ba5247')}, hash='438501ebd31739a9c2cb11e1c1eb7075e628fee9377afef429537eb2bbafba61', text='The effective batch size is kept\\nfixed at 512 pairs, or 1024 rows per batch.\\nMeta\\nHelpful.Meta\\nSafetyAnthropic\\nHelpfulAnthropic\\nHarmlessOpenAI\\nSumm.Stanford\\nSHPAvg\\nSteamSHP-XL 52.8 43.8 66.8 34.2 54.7 75.7 55.3\\nOpen Assistant 53.8 53.4 67.7 68.4 71.7 55.0 63.0\\nGPT4 58.6 58.1 - - - - -\\nSafety RM 56.2 64.5 55.4 74.7 71.7 65.2 64.3\\nHelpfulness RM 63.2 62.8 72.0 71.0 75.5 80.0 70.6\\nTable 7: Reward model results. Performance of our final helpfulness and safety reward models on a diverse\\nset of human preference benchmarks. Note that our model is fine-tuned on our collected data, as opposed to\\nthe other baselines that we report.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-11'),\n",
              " 'fd243c79-63ab-4891-ae8f-5a64c1e8294b': IndexNode(id_='fd243c79-63ab-4891-ae8f-5a64c1e8294b', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-11', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='cebbca5cd0b7b0c4ecd3a63bb8224ec7aef2d430c5e15f442ff2e8e20d14429f'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='2ef048e2-0f41-4787-948a-f51309f8ccb3', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='438501ebd31739a9c2cb11e1c1eb7075e628fee9377afef429537eb2bbafba61'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='7ef6e9e6-e5e3-450b-a915-fedcd47e6dde', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='116e07e9879b4f8f0b66c8e51c2c6e58c87bce0fbeec96b4aa2503507d843abf')}, hash='a26168b7e244320f74c8ca8f0226900e492a24de17215c1f9a470ef3e3ba5247', text='Test SetSignificantly\\nBetterBetterSlightly\\nBetterNegligibly\\nBetter / UnsureAvg\\nSafety RMMeta Safety94.3 76.3 65.7 55.3 64.5\\nHelpfulness RM 89.9 73.2 63.8 54.5 62.8\\nSafety RMMeta Helpful.64.6 57.5 53.8 52.2 56.2\\nHelpfulness RM 80.7 67.5 60.9 54.7 63.2\\nTable 8: Granular reward model accuracy per preference rating. We report per-preference rating accuracy\\nforbothHelpfulnessandSafetyrewardmodelsontheMetaHelpfulnessandSafetytestsets. Thereward\\nmodels show superior accuracy on more distinct responses (e.g., significantly better) and lower accuracy on\\nsimilar responses (e.g., negligibly better).\\nReward Model Results. On each batch of human preference annotation for reward modeling, we held out\\n1000examplesasatestsettoevaluateourmodels. Werefertotheunionofallpromptsforthecorresponding\\ntest sets as “Meta Helpfulness” and “Meta Safety,” respectively.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-11'),\n",
              " '7ef6e9e6-e5e3-450b-a915-fedcd47e6dde': IndexNode(id_='7ef6e9e6-e5e3-450b-a915-fedcd47e6dde', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-11', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='cebbca5cd0b7b0c4ecd3a63bb8224ec7aef2d430c5e15f442ff2e8e20d14429f'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='fd243c79-63ab-4891-ae8f-5a64c1e8294b', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='a26168b7e244320f74c8ca8f0226900e492a24de17215c1f9a470ef3e3ba5247')}, hash='116e07e9879b4f8f0b66c8e51c2c6e58c87bce0fbeec96b4aa2503507d843abf', text='As reference points, we also evaluated other publicly available alternatives as baselines: SteamSHP-XL\\n(Ethayarajh et al., 2022) based on FLAN-T5-xl, the Open Assistant (Köpf et al., 2023) reward model based on\\nDeBERTa V3 Large (He et al., 2020), and GPT4 accessible through the OpenAI’s API. Note that at inference\\ntime, asopposedtotraining, alltherewardmodelscanpredictascalarforasingleoutput, withoutrequiring\\nto access its paired output.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-11'),\n",
              " '573f89a8-c611-48a4-acb3-68f33ae52aa6': IndexNode(id_='573f89a8-c611-48a4-acb3-68f33ae52aa6', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-11', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='cebbca5cd0b7b0c4ecd3a63bb8224ec7aef2d430c5e15f442ff2e8e20d14429f'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='474bd6af-120c-44d6-ac9e-b22d734e5cf5', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='88832168f8901134ee525af05c4edf095007aca01762684f8e7475b156b5767c')}, hash='cb3b10fc711ec86b706a1a76cfa3e1e18a19836e23d18bb956b3634a1b3be033', text='However, in our experiments, we do not observe negative transfer from the open-source\\npreferencedatasets. Thus,wehavedecidedtokeeptheminourdatamixture,astheycouldenablebetter\\ngeneralization for the reward model and prevent reward hacking, i.e. Llama 2-Chat taking advantage of\\nsome weaknesses of our reward, and so artificially inflating the score despite performing less well.\\nWith training data available from different sources, we experimented with different mixing recipes for both\\nHelpfulnessandSafetyrewardmodelstoascertainthebestsettings. Afterextensiveexperimentation,the\\n11\\n\\nHelpfulness reward model is eventually trained on all Meta Helpfulness data, combined with an equal\\npartsoftheremainingdatauniformlysampledfromMetaSafetyandfromtheopen-sourcedatasets. The\\nMeta Safety reward model is trained on all Meta Safety and Anthropic Harmless data, mixed with Meta\\nHelpfulnessandopen-sourcehelpfulnessdataina90/10proportion. Wefoundthatthesettingwith10%\\nhelpfulness data is especially beneficial for the accuracy on samples where both the chosen and rejected\\nresponses were deemed safe.\\nTraining Details. We train for one epoch over the training data. In earlier experiments, we found that\\ntraininglongercanleadtoover-fitting. Weusethesameoptimizerparametersasforthebasemodel. The\\nmaximum learning rate is 5×10−6for the 70B parameter Llama 2-Chat and1×10−5for the rest. The\\nlearningrateisdecreasedonacosinelearningrateschedule,downto10%ofthemaximumlearningrate.\\nWe use a warm-up of 3% of the total number of steps, with a minimum of 5. The effective batch size is kept\\nfixed at 512 pairs, or 1024 rows per batch.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-11'),\n",
              " '474bd6af-120c-44d6-ac9e-b22d734e5cf5': IndexNode(id_='474bd6af-120c-44d6-ac9e-b22d734e5cf5', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-11', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='cebbca5cd0b7b0c4ecd3a63bb8224ec7aef2d430c5e15f442ff2e8e20d14429f'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='573f89a8-c611-48a4-acb3-68f33ae52aa6', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='cb3b10fc711ec86b706a1a76cfa3e1e18a19836e23d18bb956b3634a1b3be033'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='9566c345-f683-4c03-80e2-57cdbb280baa', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='116e07e9879b4f8f0b66c8e51c2c6e58c87bce0fbeec96b4aa2503507d843abf')}, hash='88832168f8901134ee525af05c4edf095007aca01762684f8e7475b156b5767c', text='The effective batch size is kept\\nfixed at 512 pairs, or 1024 rows per batch.\\nMeta\\nHelpful.Meta\\nSafetyAnthropic\\nHelpfulAnthropic\\nHarmlessOpenAI\\nSumm.Stanford\\nSHPAvg\\nSteamSHP-XL 52.8 43.8 66.8 34.2 54.7 75.7 55.3\\nOpen Assistant 53.8 53.4 67.7 68.4 71.7 55.0 63.0\\nGPT4 58.6 58.1 - - - - -\\nSafety RM 56.2 64.5 55.4 74.7 71.7 65.2 64.3\\nHelpfulness RM 63.2 62.8 72.0 71.0 75.5 80.0 70.6\\nTable 7: Reward model results. Performance of our final helpfulness and safety reward models on a diverse\\nset of human preference benchmarks. Note that our model is fine-tuned on our collected data, as opposed to\\nthe other baselines that we report.\\nTest SetSignificantly\\nBetterBetterSlightly\\nBetterNegligibly\\nBetter / UnsureAvg\\nSafety RMMeta Safety94.3 76.3 65.7 55.3 64.5\\nHelpfulness RM 89.9 73.2 63.8 54.5 62.8\\nSafety RMMeta Helpful.64.6 57.5 53.8 52.2 56.2\\nHelpfulness RM 80.7 67.5 60.9 54.7 63.2\\nTable 8: Granular reward model accuracy per preference rating. We report per-preference rating accuracy\\nforbothHelpfulnessandSafetyrewardmodelsontheMetaHelpfulnessandSafetytestsets. Thereward\\nmodels show superior accuracy on more distinct responses (e.g., significantly better) and lower accuracy on\\nsimilar responses (e.g., negligibly better).\\nReward Model Results. On each batch of human preference annotation for reward modeling, we held out\\n1000examplesasatestsettoevaluateourmodels. Werefertotheunionofallpromptsforthecorresponding\\ntest sets as “Meta Helpfulness” and “Meta Safety,” respectively.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-11'),\n",
              " '9566c345-f683-4c03-80e2-57cdbb280baa': IndexNode(id_='9566c345-f683-4c03-80e2-57cdbb280baa', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-11', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='cebbca5cd0b7b0c4ecd3a63bb8224ec7aef2d430c5e15f442ff2e8e20d14429f'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='474bd6af-120c-44d6-ac9e-b22d734e5cf5', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='88832168f8901134ee525af05c4edf095007aca01762684f8e7475b156b5767c')}, hash='116e07e9879b4f8f0b66c8e51c2c6e58c87bce0fbeec96b4aa2503507d843abf', text='As reference points, we also evaluated other publicly available alternatives as baselines: SteamSHP-XL\\n(Ethayarajh et al., 2022) based on FLAN-T5-xl, the Open Assistant (Köpf et al., 2023) reward model based on\\nDeBERTa V3 Large (He et al., 2020), and GPT4 accessible through the OpenAI’s API. Note that at inference\\ntime, asopposedtotraining, alltherewardmodelscanpredictascalarforasingleoutput, withoutrequiring\\nto access its paired output.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-11'),\n",
              " 'node-11': IndexNode(id_='node-11', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='415b7efc-e73f-4ac4-bbfd-c1546f099026', node_type=<ObjectType.DOCUMENT: '4'>, metadata={}, hash='231b3bd773f012c01b893ada9e009ecf25ee59934614c5a595c9bf1b3a123292'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='e1a4dc32-a45a-4f6d-ad2a-5fe17c4f99bf', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='a9549462870b433355877c86b04f9a1bda3c7a51f4602180f04d533476d0154b'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='10e8f25b-5800-41d4-8726-1f8f4bfd11ce', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='02a26cecf75bd4a00e5f5c6cf3a2b06f942ab40fbc698d2ed245f82f68d34355')}, hash='cebbca5cd0b7b0c4ecd3a63bb8224ec7aef2d430c5e15f442ff2e8e20d14429f', text='However, in our experiments, we do not observe negative transfer from the open-source\\npreferencedatasets. Thus,wehavedecidedtokeeptheminourdatamixture,astheycouldenablebetter\\ngeneralization for the reward model and prevent reward hacking, i.e. Llama 2-Chat taking advantage of\\nsome weaknesses of our reward, and so artificially inflating the score despite performing less well.\\nWith training data available from different sources, we experimented with different mixing recipes for both\\nHelpfulnessandSafetyrewardmodelstoascertainthebestsettings. Afterextensiveexperimentation,the\\n11\\n\\nHelpfulness reward model is eventually trained on all Meta Helpfulness data, combined with an equal\\npartsoftheremainingdatauniformlysampledfromMetaSafetyandfromtheopen-sourcedatasets. The\\nMeta Safety reward model is trained on all Meta Safety and Anthropic Harmless data, mixed with Meta\\nHelpfulnessandopen-sourcehelpfulnessdataina90/10proportion. Wefoundthatthesettingwith10%\\nhelpfulness data is especially beneficial for the accuracy on samples where both the chosen and rejected\\nresponses were deemed safe.\\nTraining Details. We train for one epoch over the training data. In earlier experiments, we found that\\ntraininglongercanleadtoover-fitting. Weusethesameoptimizerparametersasforthebasemodel. The\\nmaximum learning rate is 5×10−6for the 70B parameter Llama 2-Chat and1×10−5for the rest. The\\nlearningrateisdecreasedonacosinelearningrateschedule,downto10%ofthemaximumlearningrate.\\nWe use a warm-up of 3% of the total number of steps, with a minimum of 5. The effective batch size is kept\\nfixed at 512 pairs, or 1024 rows per batch.\\nMeta\\nHelpful.Meta\\nSafetyAnthropic\\nHelpfulAnthropic\\nHarmlessOpenAI\\nSumm.Stanford\\nSHPAvg\\nSteamSHP-XL 52.8 43.8 66.8 34.2 54.7 75.7 55.3\\nOpen Assistant 53.8 53.4 67.7 68.4 71.7 55.0 63.0\\nGPT4 58.6 58.1 - - - - -\\nSafety RM 56.2 64.5 55.4 74.7 71.7 65.2 64.3\\nHelpfulness RM 63.2 62.8 72.0 71.0 75.5 80.0 70.6\\nTable 7: Reward model results. Performance of our final helpfulness and safety reward models on a diverse\\nset of human preference benchmarks. Note that our model is fine-tuned on our collected data, as opposed to\\nthe other baselines that we report.\\nTest SetSignificantly\\nBetterBetterSlightly\\nBetterNegligibly\\nBetter / UnsureAvg\\nSafety RMMeta Safety94.3 76.3 65.7 55.3 64.5\\nHelpfulness RM 89.9 73.2 63.8 54.5 62.8\\nSafety RMMeta Helpful.64.6 57.5 53.8 52.2 56.2\\nHelpfulness RM 80.7 67.5 60.9 54.7 63.2\\nTable 8: Granular reward model accuracy per preference rating. We report per-preference rating accuracy\\nforbothHelpfulnessandSafetyrewardmodelsontheMetaHelpfulnessandSafetytestsets. Thereward\\nmodels show superior accuracy on more distinct responses (e.g., significantly better) and lower accuracy on\\nsimilar responses (e.g., negligibly better).\\nReward Model Results. On each batch of human preference annotation for reward modeling, we held out\\n1000examplesasatestsettoevaluateourmodels. Werefertotheunionofallpromptsforthecorresponding\\ntest sets as “Meta Helpfulness” and “Meta Safety,” respectively.\\nAs reference points, we also evaluated other publicly available alternatives as baselines: SteamSHP-XL\\n(Ethayarajh et al., 2022) based on FLAN-T5-xl, the Open Assistant (Köpf et al., 2023) reward model based on\\nDeBERTa V3 Large (He et al., 2020), and GPT4 accessible through the OpenAI’s API. Note that at inference\\ntime, asopposedtotraining, alltherewardmodelscanpredictascalarforasingleoutput, withoutrequiring\\nto access its paired output.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-11'),\n",
              " '29244d89-7f9c-4e11-81ab-12c66dd83953': IndexNode(id_='29244d89-7f9c-4e11-81ab-12c66dd83953', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-12', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='02a26cecf75bd4a00e5f5c6cf3a2b06f942ab40fbc698d2ed245f82f68d34355'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='957172fc-be78-4028-b58c-988e15843718', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='ae87dc0e1ca8fbce6e6c25ed3983ab3d16cdd8b427915d8c6e7f07019dbf2031')}, hash='78e37174c683f47b3555f9b50a4780fbea370bc40ff7237dd67f53a1050fded0', text='For GPT-4, we prompt with a zero-shot question “Choose the best answer between A\\nand B,”where A and B are the two responses for comparison.\\nWe report the results in terms of accuracy in Table 7. As expected, our own reward models perform the best\\non our internaltest sets collected based on Llama 2-Chat , with the Helpfulnessrewardmodel performing\\nbestontheMetaHelpfulnesstestset,andsimilarlytheSafetyrewardmodelperformingbestontheMeta\\nSafetytestset.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-12'),\n",
              " '957172fc-be78-4028-b58c-988e15843718': IndexNode(id_='957172fc-be78-4028-b58c-988e15843718', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-12', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='02a26cecf75bd4a00e5f5c6cf3a2b06f942ab40fbc698d2ed245f82f68d34355'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='29244d89-7f9c-4e11-81ab-12c66dd83953', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='78e37174c683f47b3555f9b50a4780fbea370bc40ff7237dd67f53a1050fded0'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='bdea6c97-f26c-4ced-91bf-311724db8a6c', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='585f4a7694bcc67a1f5e408b775920e9bad576322498c870e4ba79e2e3d7f1bc')}, hash='ae87dc0e1ca8fbce6e6c25ed3983ab3d16cdd8b427915d8c6e7f07019dbf2031', text='Overall,ourrewardmodelsoutperformallofthebaselines,includingGPT-4. Interestingly,\\nGPT-4 performs better than other non-Meta reward models, despite not being trained directly nor targeting\\nspecifically this reward modeling task.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-12'),\n",
              " 'bdea6c97-f26c-4ced-91bf-311724db8a6c': IndexNode(id_='bdea6c97-f26c-4ced-91bf-311724db8a6c', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-12', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='02a26cecf75bd4a00e5f5c6cf3a2b06f942ab40fbc698d2ed245f82f68d34355'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='957172fc-be78-4028-b58c-988e15843718', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='ae87dc0e1ca8fbce6e6c25ed3983ab3d16cdd8b427915d8c6e7f07019dbf2031'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='ea95d2bd-c7e2-4f56-83d5-f01069df11bd', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='149d674a5fb759c53d22f675c1904e85267192a09c36ff123a36fa6ba83cd50e')}, hash='585f4a7694bcc67a1f5e408b775920e9bad576322498c870e4ba79e2e3d7f1bc', text='12\\n\\n1234567891011121314\\nMeta Helpfulness Data Batch Stage0.520.540.560.580.600.620.64Accuracy On All Examples\\n 7b\\n13b\\n70b\\nGPT4\\nOpenAssistant\\n1234567891011121314\\nMeta Helpfulness Data Batch Stage0.500.550.600.650.700.750.80Accuracy On Examples With Label \"Significantly Better\"\\n7b\\n13b\\n70b\\nGPT4\\nOpenAssistantFigure 6: Scaling trends for the reward model.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-12'),\n",
              " 'ea95d2bd-c7e2-4f56-83d5-f01069df11bd': IndexNode(id_='ea95d2bd-c7e2-4f56-83d5-f01069df11bd', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-12', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='02a26cecf75bd4a00e5f5c6cf3a2b06f942ab40fbc698d2ed245f82f68d34355'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='bdea6c97-f26c-4ced-91bf-311724db8a6c', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='585f4a7694bcc67a1f5e408b775920e9bad576322498c870e4ba79e2e3d7f1bc'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='2b8b99b8-cd8d-4e39-a64a-e36fedfc7c28', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='6b1c13376f95ebbea2ee4d2dd08f7c375b54c791d484a2ff3c4ae8498cb5328e')}, hash='149d674a5fb759c53d22f675c1904e85267192a09c36ff123a36fa6ba83cd50e', text='More data and a larger-size model generally improve\\naccuracy, and it appears that our models have not yet saturated from learning on the training data.\\nThefactthathelpfulnessandsafetyperformedthe bestontheirowndomainispotentiallyduetothetension\\nbetweenthetwoobjectives(i.e.,beingashelpfulaspossibleversusrefusingunsafepromptswhennecessary),\\nwhichmayconfusetherewardmodelduringtraining.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-12'),\n",
              " '2b8b99b8-cd8d-4e39-a64a-e36fedfc7c28': IndexNode(id_='2b8b99b8-cd8d-4e39-a64a-e36fedfc7c28', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-12', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='02a26cecf75bd4a00e5f5c6cf3a2b06f942ab40fbc698d2ed245f82f68d34355'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='ea95d2bd-c7e2-4f56-83d5-f01069df11bd', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='149d674a5fb759c53d22f675c1904e85267192a09c36ff123a36fa6ba83cd50e'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='5f03cf38-9087-49e3-9043-ad9550976132', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='ca6b8520b4b705b05d96afa3fa0b45cca7435a9b4766a2ada5db3243cfaccf15')}, hash='6b1c13376f95ebbea2ee4d2dd08f7c375b54c791d484a2ff3c4ae8498cb5328e', text='Inorderforasinglemodeltoperformwellonboth\\ndimensions, it needs to not only learn to select the better response given a prompt but also to distinguish\\nadversarial prompts from safe ones. As a result, optimizing two separate models eases the reward modeling\\ntask. More detailed analysis on this tension between safety and helpfulness can be found in Appendix A.4.1.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-12'),\n",
              " '5f03cf38-9087-49e3-9043-ad9550976132': IndexNode(id_='5f03cf38-9087-49e3-9043-ad9550976132', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-12', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='02a26cecf75bd4a00e5f5c6cf3a2b06f942ab40fbc698d2ed245f82f68d34355'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='2b8b99b8-cd8d-4e39-a64a-e36fedfc7c28', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='6b1c13376f95ebbea2ee4d2dd08f7c375b54c791d484a2ff3c4ae8498cb5328e'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='bc158122-2845-4e41-b6d7-00ab99a3c8df', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='49d89a01b8f3d5a31946141520cfcf626347590b96f098a5e1d2c78216d8118e')}, hash='ca6b8520b4b705b05d96afa3fa0b45cca7435a9b4766a2ada5db3243cfaccf15', text='WhenwegroupthescoresbypreferenceratinginTable8,wecanseethattheaccuracyissuperiorforthe\\n“significantlybetter”testsetanddegradesgraduallyascomparisonpairsbecomemoresimilar(e.g.,“slightly\\nbetter”). It is expected that learning to model human preferences becomes challenging when deciding\\nbetweentwosimilarmodelresponses,duetoannotatorsubjectivityandtheirrelianceonnuanceddetails\\nthatmaydifferentiateresponses.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-12'),\n",
              " 'bc158122-2845-4e41-b6d7-00ab99a3c8df': IndexNode(id_='bc158122-2845-4e41-b6d7-00ab99a3c8df', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-12', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='02a26cecf75bd4a00e5f5c6cf3a2b06f942ab40fbc698d2ed245f82f68d34355'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='5f03cf38-9087-49e3-9043-ad9550976132', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='ca6b8520b4b705b05d96afa3fa0b45cca7435a9b4766a2ada5db3243cfaccf15'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='5d66f854-5503-41cd-bbd0-7625fc4271f3', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='60bee43a890040c525988b45cbcfe648aabe3e788c5254c123751aebfc12e0aa')}, hash='49d89a01b8f3d5a31946141520cfcf626347590b96f098a5e1d2c78216d8118e', text='Weemphasizethattheaccuracyonmoredistinctresponsesmattersthe\\nmosttoimprove Llama 2-Chat performance. Thehumanpreferenceannotationagreementrateisalsohigher\\non more distinct responses than similar pairs.\\nScalingTrends. Westudythescalingtrendsintermsofdataandmodelsizefortherewardmodel,fine-\\ntuning different model sizes on an increasing amount of the reward model data collected each week (see the\\ndetailsonvolumeperbatchinTable26).', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-12'),\n",
              " '5d66f854-5503-41cd-bbd0-7625fc4271f3': IndexNode(id_='5d66f854-5503-41cd-bbd0-7625fc4271f3', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-12', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='02a26cecf75bd4a00e5f5c6cf3a2b06f942ab40fbc698d2ed245f82f68d34355'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='bc158122-2845-4e41-b6d7-00ab99a3c8df', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='49d89a01b8f3d5a31946141520cfcf626347590b96f098a5e1d2c78216d8118e'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='e456e759-90ee-4db3-b616-f97de7bd0051', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='9062e89abf2b8b252336bff8b55b68d72cf0f91a79f174b5b350c635c395ec4e')}, hash='60bee43a890040c525988b45cbcfe648aabe3e788c5254c123751aebfc12e0aa', text='Figure6reportsthesetrends,showingtheexpectedresultthatlarger\\nmodels obtain higher performance for a similar volume of data. More importantly, the scaling performance\\nhasnotyetplateauedgiventheexistingvolumeofdataannotationusedfortraining,asignalthatthereis\\nroom for more improvement with more annotations. We note that reward model accuracy is one of the most\\nimportant proxies for the final performance of Llama 2-Chat .', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-12'),\n",
              " 'e456e759-90ee-4db3-b616-f97de7bd0051': IndexNode(id_='e456e759-90ee-4db3-b616-f97de7bd0051', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-12', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='02a26cecf75bd4a00e5f5c6cf3a2b06f942ab40fbc698d2ed245f82f68d34355'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='5d66f854-5503-41cd-bbd0-7625fc4271f3', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='60bee43a890040c525988b45cbcfe648aabe3e788c5254c123751aebfc12e0aa'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='66030b50-b259-4348-921a-26b2fe2f1270', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='c16e5bcc433fd147aed8ae8fb2fd94b206bdb2c7e923c2141bc18348786285a1')}, hash='9062e89abf2b8b252336bff8b55b68d72cf0f91a79f174b5b350c635c395ec4e', text='While best practices for comprehensively\\nevaluating a generative model is an open research question, the ranking task of the reward has no ambiguity.\\nTherefore, everything else being equal, an improvement of the reward model can be directly translated into\\nan improvement for Llama 2-Chat .\\n3.2.3 Iterative Fine-Tuning\\nAs we received more batches of human preference data annotation, we were able to train better reward\\nmodelsandcollectmoreprompts.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-12'),\n",
              " '66030b50-b259-4348-921a-26b2fe2f1270': IndexNode(id_='66030b50-b259-4348-921a-26b2fe2f1270', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-12', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='02a26cecf75bd4a00e5f5c6cf3a2b06f942ab40fbc698d2ed245f82f68d34355'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='e456e759-90ee-4db3-b616-f97de7bd0051', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='9062e89abf2b8b252336bff8b55b68d72cf0f91a79f174b5b350c635c395ec4e')}, hash='c16e5bcc433fd147aed8ae8fb2fd94b206bdb2c7e923c2141bc18348786285a1', text='WethereforetrainedsuccessiveversionsforRLHFmodels,referredto\\nhere as RLHF-V1, ..., RLHF-V5.\\nWe explored RLHF fine-tuning with two main algorithms:\\n•Proximal Policy Optimization (PPO) (Schulman et al., 2017), the standard in RLHF literature.\\n•RejectionSamplingfine-tuning .', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-12'),\n",
              " 'bc370105-8eee-4d3e-95c8-ac97aa8746e3': IndexNode(id_='bc370105-8eee-4d3e-95c8-ac97aa8746e3', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-12', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='02a26cecf75bd4a00e5f5c6cf3a2b06f942ab40fbc698d2ed245f82f68d34355'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='7a4aa711-1490-4830-96f9-ecd47fa41201', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='a3f0d6026157bf3a7890a0f6dcec5440e628668258dcb3066de4682308228ae5')}, hash='3c6d7d4ae799f9018e385b93bfd7f4ae0e08c9fc02cbf21e67e077acbb8a9885', text='For GPT-4, we prompt with a zero-shot question “Choose the best answer between A\\nand B,”where A and B are the two responses for comparison.\\nWe report the results in terms of accuracy in Table 7. As expected, our own reward models perform the best\\non our internaltest sets collected based on Llama 2-Chat , with the Helpfulnessrewardmodel performing\\nbestontheMetaHelpfulnesstestset,andsimilarlytheSafetyrewardmodelperformingbestontheMeta\\nSafetytestset. Overall,ourrewardmodelsoutperformallofthebaselines,includingGPT-4. Interestingly,\\nGPT-4 performs better than other non-Meta reward models, despite not being trained directly nor targeting\\nspecifically this reward modeling task.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-12'),\n",
              " '7a4aa711-1490-4830-96f9-ecd47fa41201': IndexNode(id_='7a4aa711-1490-4830-96f9-ecd47fa41201', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-12', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='02a26cecf75bd4a00e5f5c6cf3a2b06f942ab40fbc698d2ed245f82f68d34355'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='bc370105-8eee-4d3e-95c8-ac97aa8746e3', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='3c6d7d4ae799f9018e385b93bfd7f4ae0e08c9fc02cbf21e67e077acbb8a9885'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='4a5834ee-0efb-46e4-9f2d-da96c8306f5f', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='a8549d9d53cb2f6eedbc936edfb45a88ead354d9800792ea5175827ce53bf1e6')}, hash='a3f0d6026157bf3a7890a0f6dcec5440e628668258dcb3066de4682308228ae5', text='12\\n\\n1234567891011121314\\nMeta Helpfulness Data Batch Stage0.520.540.560.580.600.620.64Accuracy On All Examples\\n 7b\\n13b\\n70b\\nGPT4\\nOpenAssistant\\n1234567891011121314\\nMeta Helpfulness Data Batch Stage0.500.550.600.650.700.750.80Accuracy On Examples With Label \"Significantly Better\"\\n7b\\n13b\\n70b\\nGPT4\\nOpenAssistantFigure 6: Scaling trends for the reward model. More data and a larger-size model generally improve\\naccuracy, and it appears that our models have not yet saturated from learning on the training data.\\nThefactthathelpfulnessandsafetyperformedthe bestontheirowndomainispotentiallyduetothetension\\nbetweenthetwoobjectives(i.e.,beingashelpfulaspossibleversusrefusingunsafepromptswhennecessary),\\nwhichmayconfusetherewardmodelduringtraining.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-12'),\n",
              " '4a5834ee-0efb-46e4-9f2d-da96c8306f5f': IndexNode(id_='4a5834ee-0efb-46e4-9f2d-da96c8306f5f', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-12', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='02a26cecf75bd4a00e5f5c6cf3a2b06f942ab40fbc698d2ed245f82f68d34355'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='7a4aa711-1490-4830-96f9-ecd47fa41201', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='a3f0d6026157bf3a7890a0f6dcec5440e628668258dcb3066de4682308228ae5'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='431503be-c84a-401d-8855-a0889176e33e', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='b953a6f14c1664c9f912de15e5a23c060beac535729eaf84e4038d1b64698295')}, hash='a8549d9d53cb2f6eedbc936edfb45a88ead354d9800792ea5175827ce53bf1e6', text='Inorderforasinglemodeltoperformwellonboth\\ndimensions, it needs to not only learn to select the better response given a prompt but also to distinguish\\nadversarial prompts from safe ones. As a result, optimizing two separate models eases the reward modeling\\ntask. More detailed analysis on this tension between safety and helpfulness can be found in Appendix A.4.1.\\nWhenwegroupthescoresbypreferenceratinginTable8,wecanseethattheaccuracyissuperiorforthe\\n“significantlybetter”testsetanddegradesgraduallyascomparisonpairsbecomemoresimilar(e.g.,“slightly\\nbetter”). It is expected that learning to model human preferences becomes challenging when deciding\\nbetweentwosimilarmodelresponses,duetoannotatorsubjectivityandtheirrelianceonnuanceddetails\\nthatmaydifferentiateresponses. Weemphasizethattheaccuracyonmoredistinctresponsesmattersthe\\nmosttoimprove Llama 2-Chat performance.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-12'),\n",
              " '431503be-c84a-401d-8855-a0889176e33e': IndexNode(id_='431503be-c84a-401d-8855-a0889176e33e', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-12', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='02a26cecf75bd4a00e5f5c6cf3a2b06f942ab40fbc698d2ed245f82f68d34355'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='4a5834ee-0efb-46e4-9f2d-da96c8306f5f', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='a8549d9d53cb2f6eedbc936edfb45a88ead354d9800792ea5175827ce53bf1e6'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='9a6de175-44e8-453d-ba23-9173532e704e', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='2ad9674086ea363b07c599740d06658e579beae028d9d989a40d27b99f2afc2a')}, hash='b953a6f14c1664c9f912de15e5a23c060beac535729eaf84e4038d1b64698295', text='Thehumanpreferenceannotationagreementrateisalsohigher\\non more distinct responses than similar pairs.\\nScalingTrends. Westudythescalingtrendsintermsofdataandmodelsizefortherewardmodel,fine-\\ntuning different model sizes on an increasing amount of the reward model data collected each week (see the\\ndetailsonvolumeperbatchinTable26). Figure6reportsthesetrends,showingtheexpectedresultthatlarger\\nmodels obtain higher performance for a similar volume of data. More importantly, the scaling performance\\nhasnotyetplateauedgiventheexistingvolumeofdataannotationusedfortraining,asignalthatthereis\\nroom for more improvement with more annotations. We note that reward model accuracy is one of the most\\nimportant proxies for the final performance of Llama 2-Chat . While best practices for comprehensively\\nevaluating a generative model is an open research question, the ranking task of the reward has no ambiguity.\\nTherefore, everything else being equal, an improvement of the reward model can be directly translated into\\nan improvement for Llama 2-Chat .', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-12'),\n",
              " '9a6de175-44e8-453d-ba23-9173532e704e': IndexNode(id_='9a6de175-44e8-453d-ba23-9173532e704e', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-12', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='02a26cecf75bd4a00e5f5c6cf3a2b06f942ab40fbc698d2ed245f82f68d34355'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='431503be-c84a-401d-8855-a0889176e33e', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='b953a6f14c1664c9f912de15e5a23c060beac535729eaf84e4038d1b64698295')}, hash='2ad9674086ea363b07c599740d06658e579beae028d9d989a40d27b99f2afc2a', text='3.2.3 Iterative Fine-Tuning\\nAs we received more batches of human preference data annotation, we were able to train better reward\\nmodelsandcollectmoreprompts. WethereforetrainedsuccessiveversionsforRLHFmodels,referredto\\nhere as RLHF-V1, ..., RLHF-V5.\\nWe explored RLHF fine-tuning with two main algorithms:\\n•Proximal Policy Optimization (PPO) (Schulman et al., 2017), the standard in RLHF literature.\\n•RejectionSamplingfine-tuning .', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-12'),\n",
              " '5a06910b-3a44-4d01-9fd5-cc06470f9379': IndexNode(id_='5a06910b-3a44-4d01-9fd5-cc06470f9379', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-12', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='02a26cecf75bd4a00e5f5c6cf3a2b06f942ab40fbc698d2ed245f82f68d34355'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='2cd1ce51-eb6f-4456-bf4f-03c8aa3c2d25', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='b3c5f71407f1510ec2378882392dc74e0626e799b3ebf0abc99e06251bf64607')}, hash='a1df8bf681e5c3a890647c85157e989c7c2da4accc20a8aa6382c459674a987c', text='For GPT-4, we prompt with a zero-shot question “Choose the best answer between A\\nand B,”where A and B are the two responses for comparison.\\nWe report the results in terms of accuracy in Table 7. As expected, our own reward models perform the best\\non our internaltest sets collected based on Llama 2-Chat , with the Helpfulnessrewardmodel performing\\nbestontheMetaHelpfulnesstestset,andsimilarlytheSafetyrewardmodelperformingbestontheMeta\\nSafetytestset. Overall,ourrewardmodelsoutperformallofthebaselines,includingGPT-4. Interestingly,\\nGPT-4 performs better than other non-Meta reward models, despite not being trained directly nor targeting\\nspecifically this reward modeling task.\\n12\\n\\n1234567891011121314\\nMeta Helpfulness Data Batch Stage0.520.540.560.580.600.620.64Accuracy On All Examples\\n 7b\\n13b\\n70b\\nGPT4\\nOpenAssistant\\n1234567891011121314\\nMeta Helpfulness Data Batch Stage0.500.550.600.650.700.750.80Accuracy On Examples With Label \"Significantly Better\"\\n7b\\n13b\\n70b\\nGPT4\\nOpenAssistantFigure 6: Scaling trends for the reward model. More data and a larger-size model generally improve\\naccuracy, and it appears that our models have not yet saturated from learning on the training data.\\nThefactthathelpfulnessandsafetyperformedthe bestontheirowndomainispotentiallyduetothetension\\nbetweenthetwoobjectives(i.e.,beingashelpfulaspossibleversusrefusingunsafepromptswhennecessary),\\nwhichmayconfusetherewardmodelduringtraining. Inorderforasinglemodeltoperformwellonboth\\ndimensions, it needs to not only learn to select the better response given a prompt but also to distinguish\\nadversarial prompts from safe ones. As a result, optimizing two separate models eases the reward modeling\\ntask. More detailed analysis on this tension between safety and helpfulness can be found in Appendix A.4.1.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-12'),\n",
              " '2cd1ce51-eb6f-4456-bf4f-03c8aa3c2d25': IndexNode(id_='2cd1ce51-eb6f-4456-bf4f-03c8aa3c2d25', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-12', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='02a26cecf75bd4a00e5f5c6cf3a2b06f942ab40fbc698d2ed245f82f68d34355'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='5a06910b-3a44-4d01-9fd5-cc06470f9379', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='a1df8bf681e5c3a890647c85157e989c7c2da4accc20a8aa6382c459674a987c'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='657a6645-309a-4f87-bac3-083879433627', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='a90d74a288327fbeb9efe84138cfa348195045da4f055751e217345fb61968c8')}, hash='b3c5f71407f1510ec2378882392dc74e0626e799b3ebf0abc99e06251bf64607', text='WhenwegroupthescoresbypreferenceratinginTable8,wecanseethattheaccuracyissuperiorforthe\\n“significantlybetter”testsetanddegradesgraduallyascomparisonpairsbecomemoresimilar(e.g.,“slightly\\nbetter”). It is expected that learning to model human preferences becomes challenging when deciding\\nbetweentwosimilarmodelresponses,duetoannotatorsubjectivityandtheirrelianceonnuanceddetails\\nthatmaydifferentiateresponses. Weemphasizethattheaccuracyonmoredistinctresponsesmattersthe\\nmosttoimprove Llama 2-Chat performance. Thehumanpreferenceannotationagreementrateisalsohigher\\non more distinct responses than similar pairs.\\nScalingTrends. Westudythescalingtrendsintermsofdataandmodelsizefortherewardmodel,fine-\\ntuning different model sizes on an increasing amount of the reward model data collected each week (see the\\ndetailsonvolumeperbatchinTable26). Figure6reportsthesetrends,showingtheexpectedresultthatlarger\\nmodels obtain higher performance for a similar volume of data. More importantly, the scaling performance\\nhasnotyetplateauedgiventheexistingvolumeofdataannotationusedfortraining,asignalthatthereis\\nroom for more improvement with more annotations. We note that reward model accuracy is one of the most\\nimportant proxies for the final performance of Llama 2-Chat . While best practices for comprehensively\\nevaluating a generative model is an open research question, the ranking task of the reward has no ambiguity.\\nTherefore, everything else being equal, an improvement of the reward model can be directly translated into\\nan improvement for Llama 2-Chat .\\n3.2.3 Iterative Fine-Tuning\\nAs we received more batches of human preference data annotation, we were able to train better reward\\nmodelsandcollectmoreprompts. WethereforetrainedsuccessiveversionsforRLHFmodels,referredto\\nhere as RLHF-V1, ..., RLHF-V5.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-12'),\n",
              " '657a6645-309a-4f87-bac3-083879433627': IndexNode(id_='657a6645-309a-4f87-bac3-083879433627', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-12', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='02a26cecf75bd4a00e5f5c6cf3a2b06f942ab40fbc698d2ed245f82f68d34355'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='2cd1ce51-eb6f-4456-bf4f-03c8aa3c2d25', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='b3c5f71407f1510ec2378882392dc74e0626e799b3ebf0abc99e06251bf64607')}, hash='a90d74a288327fbeb9efe84138cfa348195045da4f055751e217345fb61968c8', text='We explored RLHF fine-tuning with two main algorithms:\\n•Proximal Policy Optimization (PPO) (Schulman et al., 2017), the standard in RLHF literature.\\n•RejectionSamplingfine-tuning .', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-12'),\n",
              " 'node-12': IndexNode(id_='node-12', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='415b7efc-e73f-4ac4-bbfd-c1546f099026', node_type=<ObjectType.DOCUMENT: '4'>, metadata={}, hash='231b3bd773f012c01b893ada9e009ecf25ee59934614c5a595c9bf1b3a123292'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='12a625dd-78f5-416f-adb1-c972b0a85e55', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='cebbca5cd0b7b0c4ecd3a63bb8224ec7aef2d430c5e15f442ff2e8e20d14429f'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='a8e86c5e-de02-4533-8e52-c0d54c0a1ff5', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='ce48c1f612f0e0662b48ff779346d497abb453d6aedc9a7cfc3e8fec0dd0e112')}, hash='02a26cecf75bd4a00e5f5c6cf3a2b06f942ab40fbc698d2ed245f82f68d34355', text='For GPT-4, we prompt with a zero-shot question “Choose the best answer between A\\nand B,”where A and B are the two responses for comparison.\\nWe report the results in terms of accuracy in Table 7. As expected, our own reward models perform the best\\non our internaltest sets collected based on Llama 2-Chat , with the Helpfulnessrewardmodel performing\\nbestontheMetaHelpfulnesstestset,andsimilarlytheSafetyrewardmodelperformingbestontheMeta\\nSafetytestset. Overall,ourrewardmodelsoutperformallofthebaselines,includingGPT-4. Interestingly,\\nGPT-4 performs better than other non-Meta reward models, despite not being trained directly nor targeting\\nspecifically this reward modeling task.\\n12\\n\\n1234567891011121314\\nMeta Helpfulness Data Batch Stage0.520.540.560.580.600.620.64Accuracy On All Examples\\n 7b\\n13b\\n70b\\nGPT4\\nOpenAssistant\\n1234567891011121314\\nMeta Helpfulness Data Batch Stage0.500.550.600.650.700.750.80Accuracy On Examples With Label \"Significantly Better\"\\n7b\\n13b\\n70b\\nGPT4\\nOpenAssistantFigure 6: Scaling trends for the reward model. More data and a larger-size model generally improve\\naccuracy, and it appears that our models have not yet saturated from learning on the training data.\\nThefactthathelpfulnessandsafetyperformedthe bestontheirowndomainispotentiallyduetothetension\\nbetweenthetwoobjectives(i.e.,beingashelpfulaspossibleversusrefusingunsafepromptswhennecessary),\\nwhichmayconfusetherewardmodelduringtraining. Inorderforasinglemodeltoperformwellonboth\\ndimensions, it needs to not only learn to select the better response given a prompt but also to distinguish\\nadversarial prompts from safe ones. As a result, optimizing two separate models eases the reward modeling\\ntask. More detailed analysis on this tension between safety and helpfulness can be found in Appendix A.4.1.\\nWhenwegroupthescoresbypreferenceratinginTable8,wecanseethattheaccuracyissuperiorforthe\\n“significantlybetter”testsetanddegradesgraduallyascomparisonpairsbecomemoresimilar(e.g.,“slightly\\nbetter”). It is expected that learning to model human preferences becomes challenging when deciding\\nbetweentwosimilarmodelresponses,duetoannotatorsubjectivityandtheirrelianceonnuanceddetails\\nthatmaydifferentiateresponses. Weemphasizethattheaccuracyonmoredistinctresponsesmattersthe\\nmosttoimprove Llama 2-Chat performance. Thehumanpreferenceannotationagreementrateisalsohigher\\non more distinct responses than similar pairs.\\nScalingTrends. Westudythescalingtrendsintermsofdataandmodelsizefortherewardmodel,fine-\\ntuning different model sizes on an increasing amount of the reward model data collected each week (see the\\ndetailsonvolumeperbatchinTable26). Figure6reportsthesetrends,showingtheexpectedresultthatlarger\\nmodels obtain higher performance for a similar volume of data. More importantly, the scaling performance\\nhasnotyetplateauedgiventheexistingvolumeofdataannotationusedfortraining,asignalthatthereis\\nroom for more improvement with more annotations. We note that reward model accuracy is one of the most\\nimportant proxies for the final performance of Llama 2-Chat . While best practices for comprehensively\\nevaluating a generative model is an open research question, the ranking task of the reward has no ambiguity.\\nTherefore, everything else being equal, an improvement of the reward model can be directly translated into\\nan improvement for Llama 2-Chat .\\n3.2.3 Iterative Fine-Tuning\\nAs we received more batches of human preference data annotation, we were able to train better reward\\nmodelsandcollectmoreprompts. WethereforetrainedsuccessiveversionsforRLHFmodels,referredto\\nhere as RLHF-V1, ..., RLHF-V5.\\nWe explored RLHF fine-tuning with two main algorithms:\\n•Proximal Policy Optimization (PPO) (Schulman et al., 2017), the standard in RLHF literature.\\n•RejectionSamplingfine-tuning .', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-12'),\n",
              " '17ec209a-4c3c-4f08-998c-8b0769f38065': IndexNode(id_='17ec209a-4c3c-4f08-998c-8b0769f38065', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-13', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='ce48c1f612f0e0662b48ff779346d497abb453d6aedc9a7cfc3e8fec0dd0e112'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='1ab038ea-b22b-47bd-a89a-2692aef467ae', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='3088e5908a25e90aff92b7e10b6dc8f13423d0726c13e714b4212496a1c45da6')}, hash='b3a5a1519dd9009b710c555c1d6474886ce10017f94851470ad92155e004f744', text='•RejectionSamplingfine-tuning . Wesample Koutputsfromthemodelandselectthebestcandidate\\nwith our reward, consistent with Bai et al. (2022b). The same re-ranking strategy for LLMs was also\\nproposedinDengetal.(2019),wheretherewardisseenasanenergyfunction. Here,wegoonestep\\nfurther,anduse theselectedoutputsfora gradientupdate.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-13'),\n",
              " '1ab038ea-b22b-47bd-a89a-2692aef467ae': IndexNode(id_='1ab038ea-b22b-47bd-a89a-2692aef467ae', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-13', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='ce48c1f612f0e0662b48ff779346d497abb453d6aedc9a7cfc3e8fec0dd0e112'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='17ec209a-4c3c-4f08-998c-8b0769f38065', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='b3a5a1519dd9009b710c555c1d6474886ce10017f94851470ad92155e004f744'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='c0fa51f5-c246-479c-9cf2-af79a8676bf0', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='3db1eec707bd3da6612d5b32f005a95d57f196b86ca76098f84f42e1efaaaa7a')}, hash='3088e5908a25e90aff92b7e10b6dc8f13423d0726c13e714b4212496a1c45da6', text='For eachprompt,thesample obtaining\\n13\\n\\n100101\\nN Samples0.540.560.580.600.620.640.66Reward Score\\nMax of the rewards\\nMedian of the rewardsFigure 7: Max and median reward among N samples ,N∈[1, . . . , 100]averaged over our training set of\\nprompts. The delta between max and median can be interpreted as potential gain with Rejection Sampling.\\nthe highestrewardscore is consideredthe newgold standard. Similar toScialom etal.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-13'),\n",
              " 'c0fa51f5-c246-479c-9cf2-af79a8676bf0': IndexNode(id_='c0fa51f5-c246-479c-9cf2-af79a8676bf0', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-13', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='ce48c1f612f0e0662b48ff779346d497abb453d6aedc9a7cfc3e8fec0dd0e112'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='1ab038ea-b22b-47bd-a89a-2692aef467ae', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='3088e5908a25e90aff92b7e10b6dc8f13423d0726c13e714b4212496a1c45da6'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='b1d9a849-64de-4486-82d6-b5bf253cf73e', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='1e44017f497a5a2f20e66050909a77da9cff940b5d7044ea58dbce26ee4a69ed')}, hash='3db1eec707bd3da6612d5b32f005a95d57f196b86ca76098f84f42e1efaaaa7a', text='Similar toScialom etal. (2020a), we\\nthen fine-tune our model on the new set of ranked samples, reinforcing the reward.\\nThe two RL algorithms mainly differ in:\\n•Breadth— in Rejection Sampling, the model explores Ksamples for a given prompt, while only one\\ngeneration is done for PPO.\\n•Depth— in PPO, during training at step tthe sample is a function of the updated model policy from\\nt−1afterthegradientupdateofthepreviousstep.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-13'),\n",
              " 'b1d9a849-64de-4486-82d6-b5bf253cf73e': IndexNode(id_='b1d9a849-64de-4486-82d6-b5bf253cf73e', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-13', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='ce48c1f612f0e0662b48ff779346d497abb453d6aedc9a7cfc3e8fec0dd0e112'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='c0fa51f5-c246-479c-9cf2-af79a8676bf0', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='3db1eec707bd3da6612d5b32f005a95d57f196b86ca76098f84f42e1efaaaa7a'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='d8ac2365-2923-44d1-9171-9105bfca34a5', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='fb760b8f9a917ca9e06fcc4459a02a6cb13667d221e1fece587b256198ff3f94')}, hash='1e44017f497a5a2f20e66050909a77da9cff940b5d7044ea58dbce26ee4a69ed', text='InRejectionSamplingfine-tuning,wesample\\nall the outputs given the initial policy of our model to collect a new dataset, before applying the\\nfine-tuning similar to SFT. However, since we applied iterative model updates, the fundamental\\ndifferences between the two RL algorithms are less pronounced.\\nUntil RLHF (V4), we used only Rejection Sampling fine-tuning, and after that, we combined the two\\nsequentially, applying PPO on top of the resulted Rejection Sampling checkpoint before sampling again.\\n100101102\\nNumber Samples0.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-13'),\n",
              " 'd8ac2365-2923-44d1-9171-9105bfca34a5': IndexNode(id_='d8ac2365-2923-44d1-9171-9105bfca34a5', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-13', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='ce48c1f612f0e0662b48ff779346d497abb453d6aedc9a7cfc3e8fec0dd0e112'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='b1d9a849-64de-4486-82d6-b5bf253cf73e', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='1e44017f497a5a2f20e66050909a77da9cff940b5d7044ea58dbce26ee4a69ed'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='eddee0c0-78ec-4906-8f39-0b91ca834c82', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='8cdeb54252caac8aac8ae0bee0d8ce58c5ef1376ae69b16011510470434f860f')}, hash='fb760b8f9a917ca9e06fcc4459a02a6cb13667d221e1fece587b256198ff3f94', text='100101102\\nNumber Samples0.10.20.30.40.50.6Reward Score\\nSFT\\n100101102\\nNumber Samples0.350.400.450.500.550.600.650.70Reward Score\\nRLHF\\nreward_max (T=0.6)\\nreward_max (T=0.8)\\nreward_max (T=0.9)\\nreward_max (T=1)\\nreward_max (T=1.1)\\nreward_max (T=1.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-13'),\n",
              " 'eddee0c0-78ec-4906-8f39-0b91ca834c82': IndexNode(id_='eddee0c0-78ec-4906-8f39-0b91ca834c82', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-13', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='ce48c1f612f0e0662b48ff779346d497abb453d6aedc9a7cfc3e8fec0dd0e112'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='d8ac2365-2923-44d1-9171-9105bfca34a5', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='fb760b8f9a917ca9e06fcc4459a02a6cb13667d221e1fece587b256198ff3f94'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='6e4eff21-0022-45ab-907b-f39ae2b2601e', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='ec059ae2e45364aa5389ea6f229c6970eef068ce40bd7c90791fe87495c86469')}, hash='8cdeb54252caac8aac8ae0bee0d8ce58c5ef1376ae69b16011510470434f860f', text='1)\\nreward_max (T=1.2)\\nreward_max (T=1.3)\\nreward_max (T=1.4)\\nreward_max (T=1.5)\\nFigure8: RLHFimpactofthetemperature whensamplingNoutputsandscoringthemwitharewardmodel.\\nRejection Sampling. We performrejection sampling only with our largest 70B Llama 2-Chat .', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-13'),\n",
              " '6e4eff21-0022-45ab-907b-f39ae2b2601e': IndexNode(id_='6e4eff21-0022-45ab-907b-f39ae2b2601e', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-13', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='ce48c1f612f0e0662b48ff779346d497abb453d6aedc9a7cfc3e8fec0dd0e112'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='eddee0c0-78ec-4906-8f39-0b91ca834c82', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='8cdeb54252caac8aac8ae0bee0d8ce58c5ef1376ae69b16011510470434f860f'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='7f650a38-bd60-4408-bdad-e5c2bb85d02e', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='8cb4618dd08cf2a14f1b04f49f4b3972dde6e6ab0c821f7a7a3149c631b77d2f')}, hash='ec059ae2e45364aa5389ea6f229c6970eef068ce40bd7c90791fe87495c86469', text='We performrejection sampling only with our largest 70B Llama 2-Chat . All smaller\\nmodels are fine-tuned on rejection sampled data from the larger model, thus distilling the large-model\\ncapabilities into the smaller ones. We leave further analysis of the effect of this distillation for future work.\\nAteachiterativestage,wesample Kanswersforeachpromptfromthemostrecentmodel. Wescoreeach\\nsample given the best reward model accessible at the time of the experiment, and then select the best answer\\nforagivenprompt.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-13'),\n",
              " '7f650a38-bd60-4408-bdad-e5c2bb85d02e': IndexNode(id_='7f650a38-bd60-4408-bdad-e5c2bb85d02e', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-13', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='ce48c1f612f0e0662b48ff779346d497abb453d6aedc9a7cfc3e8fec0dd0e112'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='6e4eff21-0022-45ab-907b-f39ae2b2601e', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='ec059ae2e45364aa5389ea6f229c6970eef068ce40bd7c90791fe87495c86469'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='f108f630-3e32-4132-bb97-2a0e0e6d83ff', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='a123dd41f7421dba88f5c67058a90d6cb1eb25b60edca653ad13cede8ced3a69')}, hash='8cb4618dd08cf2a14f1b04f49f4b3972dde6e6ab0c821f7a7a3149c631b77d2f', text='Inearlierversionsofourmodel,uptoRLHFV3,ourapproachwastoconfineanswer\\nselection solely to the“bag” of samples gathered from the precedingiteration. For example, RLHF V3was\\ntrained using only samples from RLHF V2. However, despite continuous improvement, this method led to a\\n14\\n\\nregressionin somecapabilities.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-13'),\n",
              " 'f108f630-3e32-4132-bb97-2a0e0e6d83ff': IndexNode(id_='f108f630-3e32-4132-bb97-2a0e0e6d83ff', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-13', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='ce48c1f612f0e0662b48ff779346d497abb453d6aedc9a7cfc3e8fec0dd0e112'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='7f650a38-bd60-4408-bdad-e5c2bb85d02e', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='8cb4618dd08cf2a14f1b04f49f4b3972dde6e6ab0c821f7a7a3149c631b77d2f'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='8c964407-f8b8-4980-9b1c-a3fa42bc0882', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='f8f957f3f5af10c0ddb4d2c81607ae9f04528604ac6c94df0327d1cdfb12768c')}, hash='a123dd41f7421dba88f5c67058a90d6cb1eb25b60edca653ad13cede8ced3a69', text='Forexample,RLHFV3 struggledmore thanpreviousversionstocompose\\nrhyming lines in poems, as discerned through qualitative analysis, suggesting that further investigation into\\nthe causes of and mitigations for forgetting (Kirkpatrick et al., 2017; Nguyen et al., 2019; Ramasesh et al.,\\n2021) could be a fruitful area for additional future research.\\nIn response, on subsequent iterations, we modified our strategy, incorporating top-performing samples from\\nall prior iterations, such as those used in RLHF-V1 and RLHF-V2.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-13'),\n",
              " '8c964407-f8b8-4980-9b1c-a3fa42bc0882': IndexNode(id_='8c964407-f8b8-4980-9b1c-a3fa42bc0882', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-13', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='ce48c1f612f0e0662b48ff779346d497abb453d6aedc9a7cfc3e8fec0dd0e112'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='f108f630-3e32-4132-bb97-2a0e0e6d83ff', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='a123dd41f7421dba88f5c67058a90d6cb1eb25b60edca653ad13cede8ced3a69')}, hash='f8f957f3f5af10c0ddb4d2c81607ae9f04528604ac6c94df0327d1cdfb12768c', text='Although we do not present specific\\nfigures, this adjustment demonstrated considerable enhancements in performance and effectively addressed\\nthe previously noted issues.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-13'),\n",
              " '2eb0cfab-f700-48de-b3c5-7ac7f43c74f5': IndexNode(id_='2eb0cfab-f700-48de-b3c5-7ac7f43c74f5', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-13', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='ce48c1f612f0e0662b48ff779346d497abb453d6aedc9a7cfc3e8fec0dd0e112'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='2063619a-0bca-4ed7-a50d-32de816c8a62', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='bab590ecfc57d905513218bba37152afe8de59ac70775f90e2a012ceaa6ea405')}, hash='10ef07d4ffdc8d0c52660668f9deb76cf19197129cd6da1927e32960f49e5641', text='•RejectionSamplingfine-tuning . Wesample Koutputsfromthemodelandselectthebestcandidate\\nwith our reward, consistent with Bai et al. (2022b). The same re-ranking strategy for LLMs was also\\nproposedinDengetal.(2019),wheretherewardisseenasanenergyfunction. Here,wegoonestep\\nfurther,anduse theselectedoutputsfora gradientupdate. For eachprompt,thesample obtaining\\n13\\n\\n100101\\nN Samples0.540.560.580.600.620.640.66Reward Score\\nMax of the rewards\\nMedian of the rewardsFigure 7: Max and median reward among N samples ,N∈[1, . . . , 100]averaged over our training set of\\nprompts. The delta between max and median can be interpreted as potential gain with Rejection Sampling.\\nthe highestrewardscore is consideredthe newgold standard. Similar toScialom etal. (2020a), we\\nthen fine-tune our model on the new set of ranked samples, reinforcing the reward.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-13'),\n",
              " '2063619a-0bca-4ed7-a50d-32de816c8a62': IndexNode(id_='2063619a-0bca-4ed7-a50d-32de816c8a62', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-13', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='ce48c1f612f0e0662b48ff779346d497abb453d6aedc9a7cfc3e8fec0dd0e112'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='2eb0cfab-f700-48de-b3c5-7ac7f43c74f5', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='10ef07d4ffdc8d0c52660668f9deb76cf19197129cd6da1927e32960f49e5641'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='0f57bdec-b77c-4887-853b-9a98d6f877d4', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='f05dca5d147e62b4afcca337294eeab870893435d5b36f4da879bcecaad3e88d')}, hash='bab590ecfc57d905513218bba37152afe8de59ac70775f90e2a012ceaa6ea405', text='The two RL algorithms mainly differ in:\\n•Breadth— in Rejection Sampling, the model explores Ksamples for a given prompt, while only one\\ngeneration is done for PPO.\\n•Depth— in PPO, during training at step tthe sample is a function of the updated model policy from\\nt−1afterthegradientupdateofthepreviousstep. InRejectionSamplingfine-tuning,wesample\\nall the outputs given the initial policy of our model to collect a new dataset, before applying the\\nfine-tuning similar to SFT. However, since we applied iterative model updates, the fundamental\\ndifferences between the two RL algorithms are less pronounced.\\nUntil RLHF (V4), we used only Rejection Sampling fine-tuning, and after that, we combined the two\\nsequentially, applying PPO on top of the resulted Rejection Sampling checkpoint before sampling again.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-13'),\n",
              " '0f57bdec-b77c-4887-853b-9a98d6f877d4': IndexNode(id_='0f57bdec-b77c-4887-853b-9a98d6f877d4', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-13', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='ce48c1f612f0e0662b48ff779346d497abb453d6aedc9a7cfc3e8fec0dd0e112'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='2063619a-0bca-4ed7-a50d-32de816c8a62', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='bab590ecfc57d905513218bba37152afe8de59ac70775f90e2a012ceaa6ea405'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='f8ebe15d-9ffc-4524-b92c-37484333add2', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='ded9caada5033693eaf9e0ef2b321fb9fde723471a3b43886bf810804d21bdfd')}, hash='f05dca5d147e62b4afcca337294eeab870893435d5b36f4da879bcecaad3e88d', text='100101102\\nNumber Samples0.10.20.30.40.50.6Reward Score\\nSFT\\n100101102\\nNumber Samples0.350.400.450.500.550.600.650.70Reward Score\\nRLHF\\nreward_max (T=0.6)\\nreward_max (T=0.8)\\nreward_max (T=0.9)\\nreward_max (T=1)\\nreward_max (T=1.1)\\nreward_max (T=1.2)\\nreward_max (T=1.3)\\nreward_max (T=1.4)\\nreward_max (T=1.5)\\nFigure8: RLHFimpactofthetemperature whensamplingNoutputsandscoringthemwitharewardmodel.\\nRejection Sampling. We performrejection sampling only with our largest 70B Llama 2-Chat . All smaller\\nmodels are fine-tuned on rejection sampled data from the larger model, thus distilling the large-model\\ncapabilities into the smaller ones.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-13'),\n",
              " 'f8ebe15d-9ffc-4524-b92c-37484333add2': IndexNode(id_='f8ebe15d-9ffc-4524-b92c-37484333add2', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-13', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='ce48c1f612f0e0662b48ff779346d497abb453d6aedc9a7cfc3e8fec0dd0e112'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='0f57bdec-b77c-4887-853b-9a98d6f877d4', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='f05dca5d147e62b4afcca337294eeab870893435d5b36f4da879bcecaad3e88d'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='accf8bfc-1e88-496b-96af-73c4d8f54119', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='4edd5eb737aff6300f67a26b7067933a0d2483798eef614cf26c53c6bcee5eb9')}, hash='ded9caada5033693eaf9e0ef2b321fb9fde723471a3b43886bf810804d21bdfd', text='We leave further analysis of the effect of this distillation for future work.\\nAteachiterativestage,wesample Kanswersforeachpromptfromthemostrecentmodel. Wescoreeach\\nsample given the best reward model accessible at the time of the experiment, and then select the best answer\\nforagivenprompt. Inearlierversionsofourmodel,uptoRLHFV3,ourapproachwastoconfineanswer\\nselection solely to the“bag” of samples gathered from the precedingiteration. For example, RLHF V3was\\ntrained using only samples from RLHF V2. However, despite continuous improvement, this method led to a\\n14\\n\\nregressionin somecapabilities. Forexample,RLHFV3 struggledmore thanpreviousversionstocompose\\nrhyming lines in poems, as discerned through qualitative analysis, suggesting that further investigation into\\nthe causes of and mitigations for forgetting (Kirkpatrick et al., 2017; Nguyen et al., 2019; Ramasesh et al.,\\n2021) could be a fruitful area for additional future research.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-13'),\n",
              " 'accf8bfc-1e88-496b-96af-73c4d8f54119': IndexNode(id_='accf8bfc-1e88-496b-96af-73c4d8f54119', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-13', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='ce48c1f612f0e0662b48ff779346d497abb453d6aedc9a7cfc3e8fec0dd0e112'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='f8ebe15d-9ffc-4524-b92c-37484333add2', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='ded9caada5033693eaf9e0ef2b321fb9fde723471a3b43886bf810804d21bdfd')}, hash='4edd5eb737aff6300f67a26b7067933a0d2483798eef614cf26c53c6bcee5eb9', text='In response, on subsequent iterations, we modified our strategy, incorporating top-performing samples from\\nall prior iterations, such as those used in RLHF-V1 and RLHF-V2. Although we do not present specific\\nfigures, this adjustment demonstrated considerable enhancements in performance and effectively addressed\\nthe previously noted issues.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-13'),\n",
              " '91ab4697-9511-4c9e-a5a9-0d43be7c9af9': IndexNode(id_='91ab4697-9511-4c9e-a5a9-0d43be7c9af9', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-13', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='ce48c1f612f0e0662b48ff779346d497abb453d6aedc9a7cfc3e8fec0dd0e112'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='eb7fc6f2-fd5d-4d79-be55-d2d3b5f8275a', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='6a15a868edd0c296c60a60769c45fe885eba970256e9adfba9fdbb843b944840')}, hash='2bcf17a6f76668c65e2b59747997f827c8ef0289f15aa662d2092f653a88274e', text='•RejectionSamplingfine-tuning . Wesample Koutputsfromthemodelandselectthebestcandidate\\nwith our reward, consistent with Bai et al. (2022b). The same re-ranking strategy for LLMs was also\\nproposedinDengetal.(2019),wheretherewardisseenasanenergyfunction. Here,wegoonestep\\nfurther,anduse theselectedoutputsfora gradientupdate. For eachprompt,thesample obtaining\\n13\\n\\n100101\\nN Samples0.540.560.580.600.620.640.66Reward Score\\nMax of the rewards\\nMedian of the rewardsFigure 7: Max and median reward among N samples ,N∈[1, . . . , 100]averaged over our training set of\\nprompts. The delta between max and median can be interpreted as potential gain with Rejection Sampling.\\nthe highestrewardscore is consideredthe newgold standard. Similar toScialom etal. (2020a), we\\nthen fine-tune our model on the new set of ranked samples, reinforcing the reward.\\nThe two RL algorithms mainly differ in:\\n•Breadth— in Rejection Sampling, the model explores Ksamples for a given prompt, while only one\\ngeneration is done for PPO.\\n•Depth— in PPO, during training at step tthe sample is a function of the updated model policy from\\nt−1afterthegradientupdateofthepreviousstep. InRejectionSamplingfine-tuning,wesample\\nall the outputs given the initial policy of our model to collect a new dataset, before applying the\\nfine-tuning similar to SFT. However, since we applied iterative model updates, the fundamental\\ndifferences between the two RL algorithms are less pronounced.\\nUntil RLHF (V4), we used only Rejection Sampling fine-tuning, and after that, we combined the two\\nsequentially, applying PPO on top of the resulted Rejection Sampling checkpoint before sampling again.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-13'),\n",
              " 'eb7fc6f2-fd5d-4d79-be55-d2d3b5f8275a': IndexNode(id_='eb7fc6f2-fd5d-4d79-be55-d2d3b5f8275a', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-13', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='ce48c1f612f0e0662b48ff779346d497abb453d6aedc9a7cfc3e8fec0dd0e112'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='91ab4697-9511-4c9e-a5a9-0d43be7c9af9', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='2bcf17a6f76668c65e2b59747997f827c8ef0289f15aa662d2092f653a88274e'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='082672e5-2751-49c5-bdab-c21edb3a03ee', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='4edd5eb737aff6300f67a26b7067933a0d2483798eef614cf26c53c6bcee5eb9')}, hash='6a15a868edd0c296c60a60769c45fe885eba970256e9adfba9fdbb843b944840', text='100101102\\nNumber Samples0.10.20.30.40.50.6Reward Score\\nSFT\\n100101102\\nNumber Samples0.350.400.450.500.550.600.650.70Reward Score\\nRLHF\\nreward_max (T=0.6)\\nreward_max (T=0.8)\\nreward_max (T=0.9)\\nreward_max (T=1)\\nreward_max (T=1.1)\\nreward_max (T=1.2)\\nreward_max (T=1.3)\\nreward_max (T=1.4)\\nreward_max (T=1.5)\\nFigure8: RLHFimpactofthetemperature whensamplingNoutputsandscoringthemwitharewardmodel.\\nRejection Sampling. We performrejection sampling only with our largest 70B Llama 2-Chat . All smaller\\nmodels are fine-tuned on rejection sampled data from the larger model, thus distilling the large-model\\ncapabilities into the smaller ones. We leave further analysis of the effect of this distillation for future work.\\nAteachiterativestage,wesample Kanswersforeachpromptfromthemostrecentmodel. Wescoreeach\\nsample given the best reward model accessible at the time of the experiment, and then select the best answer\\nforagivenprompt. Inearlierversionsofourmodel,uptoRLHFV3,ourapproachwastoconfineanswer\\nselection solely to the“bag” of samples gathered from the precedingiteration. For example, RLHF V3was\\ntrained using only samples from RLHF V2. However, despite continuous improvement, this method led to a\\n14\\n\\nregressionin somecapabilities. Forexample,RLHFV3 struggledmore thanpreviousversionstocompose\\nrhyming lines in poems, as discerned through qualitative analysis, suggesting that further investigation into\\nthe causes of and mitigations for forgetting (Kirkpatrick et al., 2017; Nguyen et al., 2019; Ramasesh et al.,\\n2021) could be a fruitful area for additional future research.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-13'),\n",
              " '082672e5-2751-49c5-bdab-c21edb3a03ee': IndexNode(id_='082672e5-2751-49c5-bdab-c21edb3a03ee', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-13', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='ce48c1f612f0e0662b48ff779346d497abb453d6aedc9a7cfc3e8fec0dd0e112'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='eb7fc6f2-fd5d-4d79-be55-d2d3b5f8275a', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='6a15a868edd0c296c60a60769c45fe885eba970256e9adfba9fdbb843b944840')}, hash='4edd5eb737aff6300f67a26b7067933a0d2483798eef614cf26c53c6bcee5eb9', text='In response, on subsequent iterations, we modified our strategy, incorporating top-performing samples from\\nall prior iterations, such as those used in RLHF-V1 and RLHF-V2. Although we do not present specific\\nfigures, this adjustment demonstrated considerable enhancements in performance and effectively addressed\\nthe previously noted issues.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-13'),\n",
              " 'node-13': IndexNode(id_='node-13', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='415b7efc-e73f-4ac4-bbfd-c1546f099026', node_type=<ObjectType.DOCUMENT: '4'>, metadata={}, hash='231b3bd773f012c01b893ada9e009ecf25ee59934614c5a595c9bf1b3a123292'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='10e8f25b-5800-41d4-8726-1f8f4bfd11ce', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='02a26cecf75bd4a00e5f5c6cf3a2b06f942ab40fbc698d2ed245f82f68d34355'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='a9563afd-e65b-43df-863f-1e621e828eb0', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='20d6147bf259bf8b06c7dbd5db57a7ce28a7a29e0d5d110f9d9f15f38c654121')}, hash='ce48c1f612f0e0662b48ff779346d497abb453d6aedc9a7cfc3e8fec0dd0e112', text='•RejectionSamplingfine-tuning . Wesample Koutputsfromthemodelandselectthebestcandidate\\nwith our reward, consistent with Bai et al. (2022b). The same re-ranking strategy for LLMs was also\\nproposedinDengetal.(2019),wheretherewardisseenasanenergyfunction. Here,wegoonestep\\nfurther,anduse theselectedoutputsfora gradientupdate. For eachprompt,thesample obtaining\\n13\\n\\n100101\\nN Samples0.540.560.580.600.620.640.66Reward Score\\nMax of the rewards\\nMedian of the rewardsFigure 7: Max and median reward among N samples ,N∈[1, . . . , 100]averaged over our training set of\\nprompts. The delta between max and median can be interpreted as potential gain with Rejection Sampling.\\nthe highestrewardscore is consideredthe newgold standard. Similar toScialom etal. (2020a), we\\nthen fine-tune our model on the new set of ranked samples, reinforcing the reward.\\nThe two RL algorithms mainly differ in:\\n•Breadth— in Rejection Sampling, the model explores Ksamples for a given prompt, while only one\\ngeneration is done for PPO.\\n•Depth— in PPO, during training at step tthe sample is a function of the updated model policy from\\nt−1afterthegradientupdateofthepreviousstep. InRejectionSamplingfine-tuning,wesample\\nall the outputs given the initial policy of our model to collect a new dataset, before applying the\\nfine-tuning similar to SFT. However, since we applied iterative model updates, the fundamental\\ndifferences between the two RL algorithms are less pronounced.\\nUntil RLHF (V4), we used only Rejection Sampling fine-tuning, and after that, we combined the two\\nsequentially, applying PPO on top of the resulted Rejection Sampling checkpoint before sampling again.\\n100101102\\nNumber Samples0.10.20.30.40.50.6Reward Score\\nSFT\\n100101102\\nNumber Samples0.350.400.450.500.550.600.650.70Reward Score\\nRLHF\\nreward_max (T=0.6)\\nreward_max (T=0.8)\\nreward_max (T=0.9)\\nreward_max (T=1)\\nreward_max (T=1.1)\\nreward_max (T=1.2)\\nreward_max (T=1.3)\\nreward_max (T=1.4)\\nreward_max (T=1.5)\\nFigure8: RLHFimpactofthetemperature whensamplingNoutputsandscoringthemwitharewardmodel.\\nRejection Sampling. We performrejection sampling only with our largest 70B Llama 2-Chat . All smaller\\nmodels are fine-tuned on rejection sampled data from the larger model, thus distilling the large-model\\ncapabilities into the smaller ones. We leave further analysis of the effect of this distillation for future work.\\nAteachiterativestage,wesample Kanswersforeachpromptfromthemostrecentmodel. Wescoreeach\\nsample given the best reward model accessible at the time of the experiment, and then select the best answer\\nforagivenprompt. Inearlierversionsofourmodel,uptoRLHFV3,ourapproachwastoconfineanswer\\nselection solely to the“bag” of samples gathered from the precedingiteration. For example, RLHF V3was\\ntrained using only samples from RLHF V2. However, despite continuous improvement, this method led to a\\n14\\n\\nregressionin somecapabilities. Forexample,RLHFV3 struggledmore thanpreviousversionstocompose\\nrhyming lines in poems, as discerned through qualitative analysis, suggesting that further investigation into\\nthe causes of and mitigations for forgetting (Kirkpatrick et al., 2017; Nguyen et al., 2019; Ramasesh et al.,\\n2021) could be a fruitful area for additional future research.\\nIn response, on subsequent iterations, we modified our strategy, incorporating top-performing samples from\\nall prior iterations, such as those used in RLHF-V1 and RLHF-V2. Although we do not present specific\\nfigures, this adjustment demonstrated considerable enhancements in performance and effectively addressed\\nthe previously noted issues.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-13'),\n",
              " 'd44446d2-2ed8-4797-8641-ec8ceab63dfc': IndexNode(id_='d44446d2-2ed8-4797-8641-ec8ceab63dfc', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-14', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='20d6147bf259bf8b06c7dbd5db57a7ce28a7a29e0d5d110f9d9f15f38c654121'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='d81f2b64-1cf9-4fd8-a36e-cd7ba4748f37', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='e9d1f786e7288c7803a3a4c5bf94b05da4a3fd5dd34a6ffc78cb0f026fc514f6')}, hash='31f61a961a47ed01815feb69287553373c4a49cb54dd91990b46d84981d92919', text='This mitigation can be seen as analogous to Synnaeve et al. (2019) and Vinyals\\net al. (2019) in the RL literature.\\nWe illustrate the benefit of Rejection Sampling in Figure 7. The delta between the maximum and median\\ncurves can be interpreted as the potential gain of fine-tuning on the best output. As expected, this delta\\nincreases with more samples, since the maximum increases (i.e., more samples, more opportunities to\\ngenerateagoodtrajectory),whilethemedianremainsstationary.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-14'),\n",
              " 'd81f2b64-1cf9-4fd8-a36e-cd7ba4748f37': IndexNode(id_='d81f2b64-1cf9-4fd8-a36e-cd7ba4748f37', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-14', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='20d6147bf259bf8b06c7dbd5db57a7ce28a7a29e0d5d110f9d9f15f38c654121'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='d44446d2-2ed8-4797-8641-ec8ceab63dfc', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='31f61a961a47ed01815feb69287553373c4a49cb54dd91990b46d84981d92919'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='0f125ab6-190a-49f7-abdc-461d01350e9a', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='58d1b02b7df994722c5b357c4314a698ffcdb32b46c7c20707e6bed3ef9985fb')}, hash='e9d1f786e7288c7803a3a4c5bf94b05da4a3fd5dd34a6ffc78cb0f026fc514f6', text='Thereisadirectconnectionbetweenthe\\nexplorationand themaximum rewardwe canobtain amongthesamples. Thetemperatureparameteralso\\nplays an important role for exploration, as a higher temperature enables us to sample more diverse outputs.\\nIn Figure 8, we report for a Llama 2-Chat -SFT (left) and a Llama 2-Chat -RLHF (right), the maximum\\nrewardcurvesamongNsamples(with N∈[1, . . . , 100]),fordifferenttemperatures.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-14'),\n",
              " '0f125ab6-190a-49f7-abdc-461d01350e9a': IndexNode(id_='0f125ab6-190a-49f7-abdc-461d01350e9a', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-14', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='20d6147bf259bf8b06c7dbd5db57a7ce28a7a29e0d5d110f9d9f15f38c654121'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='d81f2b64-1cf9-4fd8-a36e-cd7ba4748f37', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='e9d1f786e7288c7803a3a4c5bf94b05da4a3fd5dd34a6ffc78cb0f026fc514f6'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='ba0c100a-fc8c-46ae-95e9-f545d2a2b6b8', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='daf70a38fedd253ad9a23e0c2b49e69727380d3156fe590d84f10ac2c8aa31a7')}, hash='58d1b02b7df994722c5b357c4314a698ffcdb32b46c7c20707e6bed3ef9985fb', text='. . , 100]),fordifferenttemperatures. Wecanobservethat\\ntheoptimaltemperatureisnotconstantduringtheiterativemodelupdates: RLHFhasadirectimpacton\\nrescalingthetemperature. For Llama 2-Chat -RLHF,theoptimaltemperaturewhensamplingbetween10\\nand 100 outputs is T∈[1.2,1.3]. Given a finite compute budget, it is therefore necessary to re-adjust the\\ntemperatureprogressively.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-14'),\n",
              " 'ba0c100a-fc8c-46ae-95e9-f545d2a2b6b8': IndexNode(id_='ba0c100a-fc8c-46ae-95e9-f545d2a2b6b8', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-14', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='20d6147bf259bf8b06c7dbd5db57a7ce28a7a29e0d5d110f9d9f15f38c654121'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='0f125ab6-190a-49f7-abdc-461d01350e9a', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='58d1b02b7df994722c5b357c4314a698ffcdb32b46c7c20707e6bed3ef9985fb'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='38a4ba85-053b-415c-bfb4-0f4d4c5f9b6a', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='c9a4be5fa7a72947982f2050ba2a9e8c3ec5abfb2bcd256c379bc0e0eef2fdbf')}, hash='daf70a38fedd253ad9a23e0c2b49e69727380d3156fe590d84f10ac2c8aa31a7', text='Note thatthistemperature rescalinghappensfor aconstantnumber ofstepsfor\\neach model, and always starting from the base model on each new RLHF version.\\nPPO.WefurthertrainourlanguagemodelfollowingtheRLschemeofStiennonetal.(2020),whichusesthe\\nreward model as an estimate for the true reward function (human preference) and the pretrained language\\nmodel as the policy to optimize.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-14'),\n",
              " '38a4ba85-053b-415c-bfb4-0f4d4c5f9b6a': IndexNode(id_='38a4ba85-053b-415c-bfb4-0f4d4c5f9b6a', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-14', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='20d6147bf259bf8b06c7dbd5db57a7ce28a7a29e0d5d110f9d9f15f38c654121'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='ba0c100a-fc8c-46ae-95e9-f545d2a2b6b8', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='daf70a38fedd253ad9a23e0c2b49e69727380d3156fe590d84f10ac2c8aa31a7'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='2f63016c-962f-418e-a6bb-e73b93631c17', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='6bef12d006ee9b6e93fb17b5199d8e269ebe4bfa1f8c0428b91a64106ba98dd9')}, hash='c9a4be5fa7a72947982f2050ba2a9e8c3ec5abfb2bcd256c379bc0e0eef2fdbf', text='During this phase, we seek to optimize the following objective:\\narg max\\nπEp∼D,g∼π[R(g|p)] (3)\\nWe iteratively improve the policy by sampling prompts pfrom our dataset Dand generations gfrom the\\npolicy πand use the PPO algorithm and loss function to achieve this objective.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-14'),\n",
              " '2f63016c-962f-418e-a6bb-e73b93631c17': IndexNode(id_='2f63016c-962f-418e-a6bb-e73b93631c17', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-14', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='20d6147bf259bf8b06c7dbd5db57a7ce28a7a29e0d5d110f9d9f15f38c654121'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='38a4ba85-053b-415c-bfb4-0f4d4c5f9b6a', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='c9a4be5fa7a72947982f2050ba2a9e8c3ec5abfb2bcd256c379bc0e0eef2fdbf'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='80699874-6708-4e45-8a37-02d6f01f70d8', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='0214252815cc361febd35a6a8cc4de6d0174b113a324a1ad507d8b98775fa921')}, hash='6bef12d006ee9b6e93fb17b5199d8e269ebe4bfa1f8c0428b91a64106ba98dd9', text='The final reward function we use during optimization,\\nR(g|p) =˜Rc(g|p)−βDKL(πθ(g|p)∥π0(g|p)) (4)\\ncontains a penalty term for diverging from the original policy π0.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-14'),\n",
              " '80699874-6708-4e45-8a37-02d6f01f70d8': IndexNode(id_='80699874-6708-4e45-8a37-02d6f01f70d8', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-14', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='20d6147bf259bf8b06c7dbd5db57a7ce28a7a29e0d5d110f9d9f15f38c654121'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='2f63016c-962f-418e-a6bb-e73b93631c17', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='6bef12d006ee9b6e93fb17b5199d8e269ebe4bfa1f8c0428b91a64106ba98dd9'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='31ae036d-5e92-4bde-a2c8-23ad04fb4203', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='91867c189fc12c8926b0a4e5e0e6385e4dfd8f0515a0b6040c1dae60cbb0ac14')}, hash='0214252815cc361febd35a6a8cc4de6d0174b113a324a1ad507d8b98775fa921', text='As was observed in other works (Stiennon\\net al., 2020; Ouyang et al., 2022), we find this constraint is useful for training stability, and to reduce reward\\nhackingwherebywewouldachievehighscoresfromtherewardmodelbutlowscoresfromhumanevaluation.\\nWe define Rcto be a piecewise combination of the safety ( Rs) and helpfulness ( Rh) reward models.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-14'),\n",
              " '31ae036d-5e92-4bde-a2c8-23ad04fb4203': IndexNode(id_='31ae036d-5e92-4bde-a2c8-23ad04fb4203', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-14', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='20d6147bf259bf8b06c7dbd5db57a7ce28a7a29e0d5d110f9d9f15f38c654121'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='80699874-6708-4e45-8a37-02d6f01f70d8', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='0214252815cc361febd35a6a8cc4de6d0174b113a324a1ad507d8b98775fa921'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='0cf0507b-0e19-40a7-9711-a74bbcbd2381', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='1cb707856942475a549069dceefdd2f900bf9a36d7db2f0168c8b064a8504628')}, hash='91867c189fc12c8926b0a4e5e0e6385e4dfd8f0515a0b6040c1dae60cbb0ac14', text='We\\nhavetaggedpromptsinourdatasetthatmightelicitpotentiallyunsaferesponsesandprioritizethescores\\nfrom the safety model. The threshold of 0.15is chosen for filtering unsafe responses, corresponding to a\\nprecisionof 0.89andarecallof 0.55evaluatedontheMetaSafetytestset. Wealsofinditimportanttowhiten\\nthe final linear scores (shown here by reversing the sigmoid with the logit function) in order to increase\\nstability and balance properly with the KL penalty term ( β) above.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-14'),\n",
              " '0cf0507b-0e19-40a7-9711-a74bbcbd2381': IndexNode(id_='0cf0507b-0e19-40a7-9711-a74bbcbd2381', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-14', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='20d6147bf259bf8b06c7dbd5db57a7ce28a7a29e0d5d110f9d9f15f38c654121'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='31ae036d-5e92-4bde-a2c8-23ad04fb4203', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='91867c189fc12c8926b0a4e5e0e6385e4dfd8f0515a0b6040c1dae60cbb0ac14'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='7e765e0c-ea39-4cc5-80de-03bebf7ef1f8', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='039be01b8af6f8f940c25bfd6a2bb6b12c78c693cdb7699b89b501d84a9caeb3')}, hash='1cb707856942475a549069dceefdd2f900bf9a36d7db2f0168c8b064a8504628', text='Rc(g|p) =\\x1aRs(g|p)ifis_safety (p)orRs(g|p)<0.15\\nRh(g|p)otherwise\\n˜Rc(g|p) =whiten (logit (Rc(g|p)))\\nFor all models, we use the AdamW optimizer (Loshchilov and Hutter, 2017), with β1= 0.9, β2= 0.95,eps=\\n10−5.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-14'),\n",
              " '7e765e0c-ea39-4cc5-80de-03bebf7ef1f8': IndexNode(id_='7e765e0c-ea39-4cc5-80de-03bebf7ef1f8', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-14', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='20d6147bf259bf8b06c7dbd5db57a7ce28a7a29e0d5d110f9d9f15f38c654121'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='0cf0507b-0e19-40a7-9711-a74bbcbd2381', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='1cb707856942475a549069dceefdd2f900bf9a36d7db2f0168c8b064a8504628')}, hash='039be01b8af6f8f940c25bfd6a2bb6b12c78c693cdb7699b89b501d84a9caeb3', text='Weuseaweightdecayof 0.1,gradientclippingof 1.0,andaconstantlearningrateof 10−6. Foreach\\nPPOiterationweuseabatchsizeof 512,aPPOclipthresholdof 0.2,amini-batchsizeof 64,andtakeone\\ngradient step per mini-batch.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-14'),\n",
              " 'ddeff99f-33f8-46f5-8ffc-7e689fb2a8cf': IndexNode(id_='ddeff99f-33f8-46f5-8ffc-7e689fb2a8cf', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-14', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='20d6147bf259bf8b06c7dbd5db57a7ce28a7a29e0d5d110f9d9f15f38c654121'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='5499c2f4-bfe9-4e5f-b52b-9ed006236930', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='bb31eb177d12eee7821f79d5986acbc9c7be688bb81cdce082fb28adbf90179f')}, hash='b051107470c22c44bb0a20fc29182f4fd044754acea38654681300d64d79746e', text='This mitigation can be seen as analogous to Synnaeve et al. (2019) and Vinyals\\net al. (2019) in the RL literature.\\nWe illustrate the benefit of Rejection Sampling in Figure 7. The delta between the maximum and median\\ncurves can be interpreted as the potential gain of fine-tuning on the best output. As expected, this delta\\nincreases with more samples, since the maximum increases (i.e., more samples, more opportunities to\\ngenerateagoodtrajectory),whilethemedianremainsstationary. Thereisadirectconnectionbetweenthe\\nexplorationand themaximum rewardwe canobtain amongthesamples. Thetemperatureparameteralso\\nplays an important role for exploration, as a higher temperature enables us to sample more diverse outputs.\\nIn Figure 8, we report for a Llama 2-Chat -SFT (left) and a Llama 2-Chat -RLHF (right), the maximum\\nrewardcurvesamongNsamples(with N∈[1, . . . , 100]),fordifferenttemperatures.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-14'),\n",
              " '5499c2f4-bfe9-4e5f-b52b-9ed006236930': IndexNode(id_='5499c2f4-bfe9-4e5f-b52b-9ed006236930', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-14', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='20d6147bf259bf8b06c7dbd5db57a7ce28a7a29e0d5d110f9d9f15f38c654121'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='ddeff99f-33f8-46f5-8ffc-7e689fb2a8cf', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='b051107470c22c44bb0a20fc29182f4fd044754acea38654681300d64d79746e'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='f33f0389-9b1d-4430-b01c-704ff73006cc', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='a8b8c0e63bbe1352a371cdfbc45d1843c317a55985ba1f7b2fe2a46a5a8f0dea')}, hash='bb31eb177d12eee7821f79d5986acbc9c7be688bb81cdce082fb28adbf90179f', text='. . , 100]),fordifferenttemperatures. Wecanobservethat\\ntheoptimaltemperatureisnotconstantduringtheiterativemodelupdates: RLHFhasadirectimpacton\\nrescalingthetemperature. For Llama 2-Chat -RLHF,theoptimaltemperaturewhensamplingbetween10\\nand 100 outputs is T∈[1.2,1.3]. Given a finite compute budget, it is therefore necessary to re-adjust the\\ntemperatureprogressively. Note thatthistemperature rescalinghappensfor aconstantnumber ofstepsfor\\neach model, and always starting from the base model on each new RLHF version.\\nPPO.WefurthertrainourlanguagemodelfollowingtheRLschemeofStiennonetal.(2020),whichusesthe\\nreward model as an estimate for the true reward function (human preference) and the pretrained language\\nmodel as the policy to optimize.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-14'),\n",
              " 'f33f0389-9b1d-4430-b01c-704ff73006cc': IndexNode(id_='f33f0389-9b1d-4430-b01c-704ff73006cc', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-14', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='20d6147bf259bf8b06c7dbd5db57a7ce28a7a29e0d5d110f9d9f15f38c654121'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='5499c2f4-bfe9-4e5f-b52b-9ed006236930', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='bb31eb177d12eee7821f79d5986acbc9c7be688bb81cdce082fb28adbf90179f'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='08c86912-6073-46cf-8975-15e7e1b94e69', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='e9a86d2df2a3796f2a1630773e37f8a2c21d8a01bacc0cce53ac7e2440c55b29')}, hash='a8b8c0e63bbe1352a371cdfbc45d1843c317a55985ba1f7b2fe2a46a5a8f0dea', text='During this phase, we seek to optimize the following objective:\\narg max\\nπEp∼D,g∼π[R(g|p)] (3)\\nWe iteratively improve the policy by sampling prompts pfrom our dataset Dand generations gfrom the\\npolicy πand use the PPO algorithm and loss function to achieve this objective.\\nThe final reward function we use during optimization,\\nR(g|p) =˜Rc(g|p)−βDKL(πθ(g|p)∥π0(g|p)) (4)\\ncontains a penalty term for diverging from the original policy π0. As was observed in other works (Stiennon\\net al., 2020; Ouyang et al., 2022), we find this constraint is useful for training stability, and to reduce reward\\nhackingwherebywewouldachievehighscoresfromtherewardmodelbutlowscoresfromhumanevaluation.\\nWe define Rcto be a piecewise combination of the safety ( Rs) and helpfulness ( Rh) reward models.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-14'),\n",
              " '08c86912-6073-46cf-8975-15e7e1b94e69': IndexNode(id_='08c86912-6073-46cf-8975-15e7e1b94e69', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-14', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='20d6147bf259bf8b06c7dbd5db57a7ce28a7a29e0d5d110f9d9f15f38c654121'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='f33f0389-9b1d-4430-b01c-704ff73006cc', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='a8b8c0e63bbe1352a371cdfbc45d1843c317a55985ba1f7b2fe2a46a5a8f0dea'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='4bd6f51e-6e1a-4391-85ed-bc596ceb0441', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='039be01b8af6f8f940c25bfd6a2bb6b12c78c693cdb7699b89b501d84a9caeb3')}, hash='e9a86d2df2a3796f2a1630773e37f8a2c21d8a01bacc0cce53ac7e2440c55b29', text='We\\nhavetaggedpromptsinourdatasetthatmightelicitpotentiallyunsaferesponsesandprioritizethescores\\nfrom the safety model. The threshold of 0.15is chosen for filtering unsafe responses, corresponding to a\\nprecisionof 0.89andarecallof 0.55evaluatedontheMetaSafetytestset. Wealsofinditimportanttowhiten\\nthe final linear scores (shown here by reversing the sigmoid with the logit function) in order to increase\\nstability and balance properly with the KL penalty term ( β) above.\\nRc(g|p) =\\x1aRs(g|p)ifis_safety (p)orRs(g|p)<0.15\\nRh(g|p)otherwise\\n˜Rc(g|p) =whiten (logit (Rc(g|p)))\\nFor all models, we use the AdamW optimizer (Loshchilov and Hutter, 2017), with β1= 0.9, β2= 0.95,eps=\\n10−5.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-14'),\n",
              " '4bd6f51e-6e1a-4391-85ed-bc596ceb0441': IndexNode(id_='4bd6f51e-6e1a-4391-85ed-bc596ceb0441', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-14', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='20d6147bf259bf8b06c7dbd5db57a7ce28a7a29e0d5d110f9d9f15f38c654121'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='08c86912-6073-46cf-8975-15e7e1b94e69', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='e9a86d2df2a3796f2a1630773e37f8a2c21d8a01bacc0cce53ac7e2440c55b29')}, hash='039be01b8af6f8f940c25bfd6a2bb6b12c78c693cdb7699b89b501d84a9caeb3', text='Weuseaweightdecayof 0.1,gradientclippingof 1.0,andaconstantlearningrateof 10−6. Foreach\\nPPOiterationweuseabatchsizeof 512,aPPOclipthresholdof 0.2,amini-batchsizeof 64,andtakeone\\ngradient step per mini-batch.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-14'),\n",
              " '64e11741-6f64-4d8d-8341-fe9e34658a8f': IndexNode(id_='64e11741-6f64-4d8d-8341-fe9e34658a8f', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-14', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='20d6147bf259bf8b06c7dbd5db57a7ce28a7a29e0d5d110f9d9f15f38c654121'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='3370ba88-001e-43d1-a8a9-41c6828b4069', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='f172cb0bc81e7732d06435cdc7576d86cf00515529215844219745e3a495caed')}, hash='e0cf073ffefe810e503eb9d907bad7e016dc10834cbd0f0de472c65355bf2863', text='This mitigation can be seen as analogous to Synnaeve et al. (2019) and Vinyals\\net al. (2019) in the RL literature.\\nWe illustrate the benefit of Rejection Sampling in Figure 7. The delta between the maximum and median\\ncurves can be interpreted as the potential gain of fine-tuning on the best output. As expected, this delta\\nincreases with more samples, since the maximum increases (i.e., more samples, more opportunities to\\ngenerateagoodtrajectory),whilethemedianremainsstationary. Thereisadirectconnectionbetweenthe\\nexplorationand themaximum rewardwe canobtain amongthesamples. Thetemperatureparameteralso\\nplays an important role for exploration, as a higher temperature enables us to sample more diverse outputs.\\nIn Figure 8, we report for a Llama 2-Chat -SFT (left) and a Llama 2-Chat -RLHF (right), the maximum\\nrewardcurvesamongNsamples(with N∈[1, . . . , 100]),fordifferenttemperatures. Wecanobservethat\\ntheoptimaltemperatureisnotconstantduringtheiterativemodelupdates: RLHFhasadirectimpacton\\nrescalingthetemperature. For Llama 2-Chat -RLHF,theoptimaltemperaturewhensamplingbetween10\\nand 100 outputs is T∈[1.2,1.3]. Given a finite compute budget, it is therefore necessary to re-adjust the\\ntemperatureprogressively. Note thatthistemperature rescalinghappensfor aconstantnumber ofstepsfor\\neach model, and always starting from the base model on each new RLHF version.\\nPPO.WefurthertrainourlanguagemodelfollowingtheRLschemeofStiennonetal.(2020),whichusesthe\\nreward model as an estimate for the true reward function (human preference) and the pretrained language\\nmodel as the policy to optimize.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-14'),\n",
              " '3370ba88-001e-43d1-a8a9-41c6828b4069': IndexNode(id_='3370ba88-001e-43d1-a8a9-41c6828b4069', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-14', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='20d6147bf259bf8b06c7dbd5db57a7ce28a7a29e0d5d110f9d9f15f38c654121'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='64e11741-6f64-4d8d-8341-fe9e34658a8f', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='e0cf073ffefe810e503eb9d907bad7e016dc10834cbd0f0de472c65355bf2863'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='546cb6b6-b053-4bac-afe9-85681653d976', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='8e37ab8bd1e5140a32b27c6eb4bfd977d280f4db3ccd951e20fed0ec9784e494')}, hash='f172cb0bc81e7732d06435cdc7576d86cf00515529215844219745e3a495caed', text='During this phase, we seek to optimize the following objective:\\narg max\\nπEp∼D,g∼π[R(g|p)] (3)\\nWe iteratively improve the policy by sampling prompts pfrom our dataset Dand generations gfrom the\\npolicy πand use the PPO algorithm and loss function to achieve this objective.\\nThe final reward function we use during optimization,\\nR(g|p) =˜Rc(g|p)−βDKL(πθ(g|p)∥π0(g|p)) (4)\\ncontains a penalty term for diverging from the original policy π0. As was observed in other works (Stiennon\\net al., 2020; Ouyang et al., 2022), we find this constraint is useful for training stability, and to reduce reward\\nhackingwherebywewouldachievehighscoresfromtherewardmodelbutlowscoresfromhumanevaluation.\\nWe define Rcto be a piecewise combination of the safety ( Rs) and helpfulness ( Rh) reward models. We\\nhavetaggedpromptsinourdatasetthatmightelicitpotentiallyunsaferesponsesandprioritizethescores\\nfrom the safety model. The threshold of 0.15is chosen for filtering unsafe responses, corresponding to a\\nprecisionof 0.89andarecallof 0.55evaluatedontheMetaSafetytestset. Wealsofinditimportanttowhiten\\nthe final linear scores (shown here by reversing the sigmoid with the logit function) in order to increase\\nstability and balance properly with the KL penalty term ( β) above.\\nRc(g|p) =\\x1aRs(g|p)ifis_safety (p)orRs(g|p)<0.15\\nRh(g|p)otherwise\\n˜Rc(g|p) =whiten (logit (Rc(g|p)))\\nFor all models, we use the AdamW optimizer (Loshchilov and Hutter, 2017), with β1= 0.9, β2= 0.95,eps=\\n10−5. Weuseaweightdecayof 0.1,gradientclippingof 1.0,andaconstantlearningrateof 10−6.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-14'),\n",
              " '546cb6b6-b053-4bac-afe9-85681653d976': IndexNode(id_='546cb6b6-b053-4bac-afe9-85681653d976', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-14', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='20d6147bf259bf8b06c7dbd5db57a7ce28a7a29e0d5d110f9d9f15f38c654121'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='3370ba88-001e-43d1-a8a9-41c6828b4069', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='f172cb0bc81e7732d06435cdc7576d86cf00515529215844219745e3a495caed')}, hash='8e37ab8bd1e5140a32b27c6eb4bfd977d280f4db3ccd951e20fed0ec9784e494', text='Foreach\\nPPOiterationweuseabatchsizeof 512,aPPOclipthresholdof 0.2,amini-batchsizeof 64,andtakeone\\ngradient step per mini-batch.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-14'),\n",
              " 'node-14': IndexNode(id_='node-14', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='415b7efc-e73f-4ac4-bbfd-c1546f099026', node_type=<ObjectType.DOCUMENT: '4'>, metadata={}, hash='231b3bd773f012c01b893ada9e009ecf25ee59934614c5a595c9bf1b3a123292'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='a8e86c5e-de02-4533-8e52-c0d54c0a1ff5', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='ce48c1f612f0e0662b48ff779346d497abb453d6aedc9a7cfc3e8fec0dd0e112'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='cd24e901-dc63-4e4e-b3a7-ccfa0a330f85', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='0f0628935d4e376c2f4a79112c1d73dfe561dbf41057985e87151e7fde5ef547')}, hash='20d6147bf259bf8b06c7dbd5db57a7ce28a7a29e0d5d110f9d9f15f38c654121', text='This mitigation can be seen as analogous to Synnaeve et al. (2019) and Vinyals\\net al. (2019) in the RL literature.\\nWe illustrate the benefit of Rejection Sampling in Figure 7. The delta between the maximum and median\\ncurves can be interpreted as the potential gain of fine-tuning on the best output. As expected, this delta\\nincreases with more samples, since the maximum increases (i.e., more samples, more opportunities to\\ngenerateagoodtrajectory),whilethemedianremainsstationary. Thereisadirectconnectionbetweenthe\\nexplorationand themaximum rewardwe canobtain amongthesamples. Thetemperatureparameteralso\\nplays an important role for exploration, as a higher temperature enables us to sample more diverse outputs.\\nIn Figure 8, we report for a Llama 2-Chat -SFT (left) and a Llama 2-Chat -RLHF (right), the maximum\\nrewardcurvesamongNsamples(with N∈[1, . . . , 100]),fordifferenttemperatures. Wecanobservethat\\ntheoptimaltemperatureisnotconstantduringtheiterativemodelupdates: RLHFhasadirectimpacton\\nrescalingthetemperature. For Llama 2-Chat -RLHF,theoptimaltemperaturewhensamplingbetween10\\nand 100 outputs is T∈[1.2,1.3]. Given a finite compute budget, it is therefore necessary to re-adjust the\\ntemperatureprogressively. Note thatthistemperature rescalinghappensfor aconstantnumber ofstepsfor\\neach model, and always starting from the base model on each new RLHF version.\\nPPO.WefurthertrainourlanguagemodelfollowingtheRLschemeofStiennonetal.(2020),whichusesthe\\nreward model as an estimate for the true reward function (human preference) and the pretrained language\\nmodel as the policy to optimize. During this phase, we seek to optimize the following objective:\\narg max\\nπEp∼D,g∼π[R(g|p)] (3)\\nWe iteratively improve the policy by sampling prompts pfrom our dataset Dand generations gfrom the\\npolicy πand use the PPO algorithm and loss function to achieve this objective.\\nThe final reward function we use during optimization,\\nR(g|p) =˜Rc(g|p)−βDKL(πθ(g|p)∥π0(g|p)) (4)\\ncontains a penalty term for diverging from the original policy π0. As was observed in other works (Stiennon\\net al., 2020; Ouyang et al., 2022), we find this constraint is useful for training stability, and to reduce reward\\nhackingwherebywewouldachievehighscoresfromtherewardmodelbutlowscoresfromhumanevaluation.\\nWe define Rcto be a piecewise combination of the safety ( Rs) and helpfulness ( Rh) reward models. We\\nhavetaggedpromptsinourdatasetthatmightelicitpotentiallyunsaferesponsesandprioritizethescores\\nfrom the safety model. The threshold of 0.15is chosen for filtering unsafe responses, corresponding to a\\nprecisionof 0.89andarecallof 0.55evaluatedontheMetaSafetytestset. Wealsofinditimportanttowhiten\\nthe final linear scores (shown here by reversing the sigmoid with the logit function) in order to increase\\nstability and balance properly with the KL penalty term ( β) above.\\nRc(g|p) =\\x1aRs(g|p)ifis_safety (p)orRs(g|p)<0.15\\nRh(g|p)otherwise\\n˜Rc(g|p) =whiten (logit (Rc(g|p)))\\nFor all models, we use the AdamW optimizer (Loshchilov and Hutter, 2017), with β1= 0.9, β2= 0.95,eps=\\n10−5. Weuseaweightdecayof 0.1,gradientclippingof 1.0,andaconstantlearningrateof 10−6. Foreach\\nPPOiterationweuseabatchsizeof 512,aPPOclipthresholdof 0.2,amini-batchsizeof 64,andtakeone\\ngradient step per mini-batch.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-14'),\n",
              " 'cb3dd919-3339-45ab-872d-30b8b817d8d7': IndexNode(id_='cb3dd919-3339-45ab-872d-30b8b817d8d7', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-15', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='0f0628935d4e376c2f4a79112c1d73dfe561dbf41057985e87151e7fde5ef547'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='1b452f1e-d784-42f2-9df1-f4b3e3e04a83', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='c3d1574d6de103034694c7f15d74bac49165050dba0de850fbb6891c60f1f341')}, hash='3e9f85774e46f22097b0cd585497650ec68a102d14d52501413eadbe39ab53b9', text='For the 7B and 13B models, we set β= 0.01(KL penalty), and for the 34B and\\n70B models, we set β= 0.005.\\n15\\n\\nFigure 9: Issues with multi-turn memory (left)can be improved with GAtt (right).\\nWe train for between 200and400iterations for all our models, and use evaluations on held-out prompts for\\nearlystopping. EachiterationofPPOonthe70Bmodeltakesonaverage ≈330seconds.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-15'),\n",
              " '1b452f1e-d784-42f2-9df1-f4b3e3e04a83': IndexNode(id_='1b452f1e-d784-42f2-9df1-f4b3e3e04a83', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-15', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='0f0628935d4e376c2f4a79112c1d73dfe561dbf41057985e87151e7fde5ef547'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='cb3dd919-3339-45ab-872d-30b8b817d8d7', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='3e9f85774e46f22097b0cd585497650ec68a102d14d52501413eadbe39ab53b9'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='5ce0587b-2a65-4a15-be85-68daede1b863', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='ef9c12d3c5fc79cd4f7cffb6a024491a5950fc957ebf7169a9d4fe92b0085e35')}, hash='c3d1574d6de103034694c7f15d74bac49165050dba0de850fbb6891c60f1f341', text='Totrainquicklywith\\nlarge batch sizes, we use FSDP (Zhao et al., 2023). This was effective when using O(1) forward or backward\\npasses,butcausedalargeslowdown( ≈20×)duringgeneration,evenwhenusingalargebatchsizeandKV\\ncache. We were able to mitigate this by consolidating the model weights to each node once before generation\\nand then freeing the memory after generation, resuming the rest of the training loop.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-15'),\n",
              " '5ce0587b-2a65-4a15-be85-68daede1b863': IndexNode(id_='5ce0587b-2a65-4a15-be85-68daede1b863', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-15', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='0f0628935d4e376c2f4a79112c1d73dfe561dbf41057985e87151e7fde5ef547'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='1b452f1e-d784-42f2-9df1-f4b3e3e04a83', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='c3d1574d6de103034694c7f15d74bac49165050dba0de850fbb6891c60f1f341'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='6b1b7da7-801a-40bb-b1bb-853f06137e4c', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='936eec9d606b11f46a1a6bbb2aa9e5572959b5835d47888de821a1fe7a6fab02')}, hash='ef9c12d3c5fc79cd4f7cffb6a024491a5950fc957ebf7169a9d4fe92b0085e35', text='3.3 System Message for Multi-Turn Consistency\\nIn a dialogue setup, some instructions should apply for all the conversation turns, e.g., to respond succinctly,\\nor to“act as”some public figure. When we provided such instructions to Llama 2-Chat , the subsequent\\nresponse should always respect the constraint. However, our initial RLHF models tended to forget the initial\\ninstruction after a few turns of dialogue, as illustrated in Figure 9 (left).', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-15'),\n",
              " '6b1b7da7-801a-40bb-b1bb-853f06137e4c': IndexNode(id_='6b1b7da7-801a-40bb-b1bb-853f06137e4c', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-15', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='0f0628935d4e376c2f4a79112c1d73dfe561dbf41057985e87151e7fde5ef547'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='5ce0587b-2a65-4a15-be85-68daede1b863', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='ef9c12d3c5fc79cd4f7cffb6a024491a5950fc957ebf7169a9d4fe92b0085e35'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='96f858bd-1306-46a6-9af7-aad7c8649ee4', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='8daaf08d2d21f4e1882e6e351109bab95a6f5832559ad2add0357a6057f761cc')}, hash='936eec9d606b11f46a1a6bbb2aa9e5572959b5835d47888de821a1fe7a6fab02', text='To address these limitations, we propose Ghost Attention (GAtt), a very simple method inspired by Context\\nDistillation (Bai et al., 2022b) that hacks the fine-tuning data to help the attention focus in a multi-stage\\nprocess. GAtt enables dialogue control over multiple turns, as illustrated in Figure 9 (right).\\nGAttMethod. Assumewe haveaccess toa multi-turndialoguedataset betweentwo persons(e.g., auser\\nand an assistant), with a list of messages [u1, a1, . .', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-15'),\n",
              " '96f858bd-1306-46a6-9af7-aad7c8649ee4': IndexNode(id_='96f858bd-1306-46a6-9af7-aad7c8649ee4', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-15', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='0f0628935d4e376c2f4a79112c1d73dfe561dbf41057985e87151e7fde5ef547'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='6b1b7da7-801a-40bb-b1bb-853f06137e4c', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='936eec9d606b11f46a1a6bbb2aa9e5572959b5835d47888de821a1fe7a6fab02'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='769847a7-26fc-46f2-8b0a-631a5b1f470d', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='3193d946b29ddf429f104a2da5b9d6ebe18d2eaa18ad020bb87d8173d4883b51')}, hash='8daaf08d2d21f4e1882e6e351109bab95a6f5832559ad2add0357a6057f761cc', text='. . , u n, an], where unandancorrespond to the user and\\nassistant messages for turn n, respectively. Then, we define an instruction, inst, that should be respected\\nthroughout the dialogue. For example, instcould be “act as.” We can then synthetically concatenate this\\ninstruction to all the user messages of the conversation.\\nNext, we can sample from this synthetic data using the latest RLHF model.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-15'),\n",
              " '769847a7-26fc-46f2-8b0a-631a5b1f470d': IndexNode(id_='769847a7-26fc-46f2-8b0a-631a5b1f470d', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-15', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='0f0628935d4e376c2f4a79112c1d73dfe561dbf41057985e87151e7fde5ef547'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='96f858bd-1306-46a6-9af7-aad7c8649ee4', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='8daaf08d2d21f4e1882e6e351109bab95a6f5832559ad2add0357a6057f761cc'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='316665ae-bd2d-40fa-bc02-041294a85534', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='7dd10faabfa6ca5ada43c80844266b76b1d3d748ea6d9f918745109e08cfdf81')}, hash='3193d946b29ddf429f104a2da5b9d6ebe18d2eaa18ad020bb87d8173d4883b51', text='Next, we can sample from this synthetic data using the latest RLHF model. We now have a context-dialogue\\nandthesamplewithwhichtofine-tuneamodel,inaprocessanalogoustoRejectionSampling.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-15'),\n",
              " '316665ae-bd2d-40fa-bc02-041294a85534': IndexNode(id_='316665ae-bd2d-40fa-bc02-041294a85534', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-15', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='0f0628935d4e376c2f4a79112c1d73dfe561dbf41057985e87151e7fde5ef547'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='769847a7-26fc-46f2-8b0a-631a5b1f470d', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='3193d946b29ddf429f104a2da5b9d6ebe18d2eaa18ad020bb87d8173d4883b51'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='dedf8827-1234-4e84-abc2-ff6920a69e38', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='a961ef26b344f7a7ca4af472a6a0e2473efbb2cb6a8d8189325ab7b10406fdcf')}, hash='7dd10faabfa6ca5ada43c80844266b76b1d3d748ea6d9f918745109e08cfdf81', text='Insteadof\\naugmentingallcontext-dialogueturnswiththeinstruction,wecandropitinallbutthefirstturn,butthis\\nwouldleadtoamismatchattrainingtimebetweenthesystemmessage,i.e.,alltheintermediateassistant\\nmessages that come before the last turn, and our sample. To fix this issue, which could hurt the training, we\\nsimply set the loss to 0 for all the tokens from the previous turns, including assistant messages.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-15'),\n",
              " 'dedf8827-1234-4e84-abc2-ff6920a69e38': IndexNode(id_='dedf8827-1234-4e84-abc2-ff6920a69e38', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-15', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='0f0628935d4e376c2f4a79112c1d73dfe561dbf41057985e87151e7fde5ef547'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='316665ae-bd2d-40fa-bc02-041294a85534', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='7dd10faabfa6ca5ada43c80844266b76b1d3d748ea6d9f918745109e08cfdf81'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='1629dc7c-c292-4c61-8f60-94ce9711d410', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='10e78b5c0034edfe824a253535fdc7dc2997c9a5d20e829f8db929b0c69501e9')}, hash='a961ef26b344f7a7ca4af472a6a0e2473efbb2cb6a8d8189325ab7b10406fdcf', text='For the training instructions, we created a few synthetic constraints to sample from: Hobbies ( “You enjoy\\ne.g. Tennis” ),Language ( “Speakine.g. French” ),or PublicFigure( “Actase.g. Napoleon” ). Toobtainthelists\\nof hobbies and public figures, we asked Llama 2-Chat to generate it, avoiding a mismatch between the\\ninstructionandmodelknowledge(e.g.,askingthemodeltoactassomeoneithadnotencounteredduring\\ntraining).', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-15'),\n",
              " '1629dc7c-c292-4c61-8f60-94ce9711d410': IndexNode(id_='1629dc7c-c292-4c61-8f60-94ce9711d410', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-15', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='0f0628935d4e376c2f4a79112c1d73dfe561dbf41057985e87151e7fde5ef547'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='dedf8827-1234-4e84-abc2-ff6920a69e38', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='a961ef26b344f7a7ca4af472a6a0e2473efbb2cb6a8d8189325ab7b10406fdcf'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='1709048a-bc27-4642-a439-866ebecd3987', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='927dac00bc535cc0e1c1362e23a993585e08056d83bf3af0c15ca7dc66eb86af')}, hash='10e78b5c0034edfe824a253535fdc7dc2997c9a5d20e829f8db929b0c69501e9', text='Tomaketheinstructionsmorecomplexanddiverse,weconstructthefinalinstructionbyrandomly\\ncombining the above constraints. When constructing the final system message for the training data, we also\\n16\\n\\nmodifytheoriginalinstructionhalfofthetimetobelessverbose,e.g., “AlwaysactasNapoleonfromnow” ->\\n”Figure: Napoleon.” These steps produce an SFT dataset, on which we can fine-tune Llama 2-Chat .\\nGAtt Evaluation. We applied GAtt after RLHF V3.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-15'),\n",
              " '1709048a-bc27-4642-a439-866ebecd3987': IndexNode(id_='1709048a-bc27-4642-a439-866ebecd3987', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-15', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='0f0628935d4e376c2f4a79112c1d73dfe561dbf41057985e87151e7fde5ef547'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='1629dc7c-c292-4c61-8f60-94ce9711d410', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='10e78b5c0034edfe824a253535fdc7dc2997c9a5d20e829f8db929b0c69501e9')}, hash='927dac00bc535cc0e1c1362e23a993585e08056d83bf3af0c15ca7dc66eb86af', text='GAtt Evaluation. We applied GAtt after RLHF V3. We report a quantitative analysis indicating that GAtt is\\nconsistentupto 20+turns,until themaximumcontextlengthis reached(seeAppendixA.3.5).', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-15'),\n",
              " '9e45e827-a7cb-42c5-bbc6-6c288b72e416': IndexNode(id_='9e45e827-a7cb-42c5-bbc6-6c288b72e416', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-15', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='0f0628935d4e376c2f4a79112c1d73dfe561dbf41057985e87151e7fde5ef547'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='2f75a16f-5ade-4327-ba17-1146f2922f07', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='1e206eddcfbe066d39642a22f4304b9d04a0920cf882287935bda33ec79c4fd4')}, hash='7d3ee6d81f65bcf881305638794fb96cbf7e9c82bc3674bc3c2501850387f031', text='For the 7B and 13B models, we set β= 0.01(KL penalty), and for the 34B and\\n70B models, we set β= 0.005.\\n15\\n\\nFigure 9: Issues with multi-turn memory (left)can be improved with GAtt (right).\\nWe train for between 200and400iterations for all our models, and use evaluations on held-out prompts for\\nearlystopping. EachiterationofPPOonthe70Bmodeltakesonaverage ≈330seconds. Totrainquicklywith\\nlarge batch sizes, we use FSDP (Zhao et al., 2023). This was effective when using O(1) forward or backward\\npasses,butcausedalargeslowdown( ≈20×)duringgeneration,evenwhenusingalargebatchsizeandKV\\ncache. We were able to mitigate this by consolidating the model weights to each node once before generation\\nand then freeing the memory after generation, resuming the rest of the training loop.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-15'),\n",
              " '2f75a16f-5ade-4327-ba17-1146f2922f07': IndexNode(id_='2f75a16f-5ade-4327-ba17-1146f2922f07', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-15', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='0f0628935d4e376c2f4a79112c1d73dfe561dbf41057985e87151e7fde5ef547'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='9e45e827-a7cb-42c5-bbc6-6c288b72e416', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='7d3ee6d81f65bcf881305638794fb96cbf7e9c82bc3674bc3c2501850387f031'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='1477bf1c-5e15-4975-9757-d6db1f4615ed', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='4f1ce5c797d464171c51ee6254c9e3367ced4e14dd6b357197443f55135e805d')}, hash='1e206eddcfbe066d39642a22f4304b9d04a0920cf882287935bda33ec79c4fd4', text='3.3 System Message for Multi-Turn Consistency\\nIn a dialogue setup, some instructions should apply for all the conversation turns, e.g., to respond succinctly,\\nor to“act as”some public figure. When we provided such instructions to Llama 2-Chat , the subsequent\\nresponse should always respect the constraint. However, our initial RLHF models tended to forget the initial\\ninstruction after a few turns of dialogue, as illustrated in Figure 9 (left).\\nTo address these limitations, we propose Ghost Attention (GAtt), a very simple method inspired by Context\\nDistillation (Bai et al., 2022b) that hacks the fine-tuning data to help the attention focus in a multi-stage\\nprocess. GAtt enables dialogue control over multiple turns, as illustrated in Figure 9 (right).\\nGAttMethod. Assumewe haveaccess toa multi-turndialoguedataset betweentwo persons(e.g., auser\\nand an assistant), with a list of messages [u1, a1, . . .', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-15'),\n",
              " '1477bf1c-5e15-4975-9757-d6db1f4615ed': IndexNode(id_='1477bf1c-5e15-4975-9757-d6db1f4615ed', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-15', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='0f0628935d4e376c2f4a79112c1d73dfe561dbf41057985e87151e7fde5ef547'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='2f75a16f-5ade-4327-ba17-1146f2922f07', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='1e206eddcfbe066d39642a22f4304b9d04a0920cf882287935bda33ec79c4fd4'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='c99d8728-a7a3-47aa-ae03-2bd22ceb8e62', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='bcc2a8b160cfee7b4ff5e962122fed49de9189e1992d64d56b21665d8afff8fc')}, hash='4f1ce5c797d464171c51ee6254c9e3367ced4e14dd6b357197443f55135e805d', text='. . , u n, an], where unandancorrespond to the user and\\nassistant messages for turn n, respectively. Then, we define an instruction, inst, that should be respected\\nthroughout the dialogue. For example, instcould be “act as.” We can then synthetically concatenate this\\ninstruction to all the user messages of the conversation.\\nNext, we can sample from this synthetic data using the latest RLHF model. We now have a context-dialogue\\nandthesamplewithwhichtofine-tuneamodel,inaprocessanalogoustoRejectionSampling. Insteadof\\naugmentingallcontext-dialogueturnswiththeinstruction,wecandropitinallbutthefirstturn,butthis\\nwouldleadtoamismatchattrainingtimebetweenthesystemmessage,i.e.,alltheintermediateassistant\\nmessages that come before the last turn, and our sample. To fix this issue, which could hurt the training, we\\nsimply set the loss to 0 for all the tokens from the previous turns, including assistant messages.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-15'),\n",
              " 'c99d8728-a7a3-47aa-ae03-2bd22ceb8e62': IndexNode(id_='c99d8728-a7a3-47aa-ae03-2bd22ceb8e62', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-15', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='0f0628935d4e376c2f4a79112c1d73dfe561dbf41057985e87151e7fde5ef547'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='1477bf1c-5e15-4975-9757-d6db1f4615ed', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='4f1ce5c797d464171c51ee6254c9e3367ced4e14dd6b357197443f55135e805d'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='c8345df1-d42e-412d-a7cb-69cfdd9c9785', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='927dac00bc535cc0e1c1362e23a993585e08056d83bf3af0c15ca7dc66eb86af')}, hash='bcc2a8b160cfee7b4ff5e962122fed49de9189e1992d64d56b21665d8afff8fc', text='For the training instructions, we created a few synthetic constraints to sample from: Hobbies ( “You enjoy\\ne.g. Tennis” ),Language ( “Speakine.g. French” ),or PublicFigure( “Actase.g. Napoleon” ). Toobtainthelists\\nof hobbies and public figures, we asked Llama 2-Chat to generate it, avoiding a mismatch between the\\ninstructionandmodelknowledge(e.g.,askingthemodeltoactassomeoneithadnotencounteredduring\\ntraining). Tomaketheinstructionsmorecomplexanddiverse,weconstructthefinalinstructionbyrandomly\\ncombining the above constraints. When constructing the final system message for the training data, we also\\n16\\n\\nmodifytheoriginalinstructionhalfofthetimetobelessverbose,e.g., “AlwaysactasNapoleonfromnow” ->\\n”Figure: Napoleon.” These steps produce an SFT dataset, on which we can fine-tune Llama 2-Chat .\\nGAtt Evaluation. We applied GAtt after RLHF V3.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-15'),\n",
              " 'c8345df1-d42e-412d-a7cb-69cfdd9c9785': IndexNode(id_='c8345df1-d42e-412d-a7cb-69cfdd9c9785', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-15', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='0f0628935d4e376c2f4a79112c1d73dfe561dbf41057985e87151e7fde5ef547'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='c99d8728-a7a3-47aa-ae03-2bd22ceb8e62', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='bcc2a8b160cfee7b4ff5e962122fed49de9189e1992d64d56b21665d8afff8fc')}, hash='927dac00bc535cc0e1c1362e23a993585e08056d83bf3af0c15ca7dc66eb86af', text='GAtt Evaluation. We applied GAtt after RLHF V3. We report a quantitative analysis indicating that GAtt is\\nconsistentupto 20+turns,until themaximumcontextlengthis reached(seeAppendixA.3.5).', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-15'),\n",
              " '26275d24-f859-4972-a44b-f3c846a21550': IndexNode(id_='26275d24-f859-4972-a44b-f3c846a21550', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-15', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='0f0628935d4e376c2f4a79112c1d73dfe561dbf41057985e87151e7fde5ef547'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='f7f4d351-1111-4827-8f40-1789ea61d893', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='15cb23716f81275c243590d5321b615e0802cc6376096f786e4e1ff3ba77a588')}, hash='edf6345f46dce944dc8a843b64c52d06fd49be2350ed3cb95b0c12e1f10f09a5', text='For the 7B and 13B models, we set β= 0.01(KL penalty), and for the 34B and\\n70B models, we set β= 0.005.\\n15\\n\\nFigure 9: Issues with multi-turn memory (left)can be improved with GAtt (right).\\nWe train for between 200and400iterations for all our models, and use evaluations on held-out prompts for\\nearlystopping. EachiterationofPPOonthe70Bmodeltakesonaverage ≈330seconds. Totrainquicklywith\\nlarge batch sizes, we use FSDP (Zhao et al., 2023). This was effective when using O(1) forward or backward\\npasses,butcausedalargeslowdown( ≈20×)duringgeneration,evenwhenusingalargebatchsizeandKV\\ncache. We were able to mitigate this by consolidating the model weights to each node once before generation\\nand then freeing the memory after generation, resuming the rest of the training loop.\\n3.3 System Message for Multi-Turn Consistency\\nIn a dialogue setup, some instructions should apply for all the conversation turns, e.g., to respond succinctly,\\nor to“act as”some public figure. When we provided such instructions to Llama 2-Chat , the subsequent\\nresponse should always respect the constraint. However, our initial RLHF models tended to forget the initial\\ninstruction after a few turns of dialogue, as illustrated in Figure 9 (left).\\nTo address these limitations, we propose Ghost Attention (GAtt), a very simple method inspired by Context\\nDistillation (Bai et al., 2022b) that hacks the fine-tuning data to help the attention focus in a multi-stage\\nprocess. GAtt enables dialogue control over multiple turns, as illustrated in Figure 9 (right).\\nGAttMethod. Assumewe haveaccess toa multi-turndialoguedataset betweentwo persons(e.g., auser\\nand an assistant), with a list of messages [u1, a1, . . . , u n, an], where unandancorrespond to the user and\\nassistant messages for turn n, respectively. Then, we define an instruction, inst, that should be respected\\nthroughout the dialogue.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-15'),\n",
              " 'f7f4d351-1111-4827-8f40-1789ea61d893': IndexNode(id_='f7f4d351-1111-4827-8f40-1789ea61d893', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-15', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='0f0628935d4e376c2f4a79112c1d73dfe561dbf41057985e87151e7fde5ef547'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='26275d24-f859-4972-a44b-f3c846a21550', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='edf6345f46dce944dc8a843b64c52d06fd49be2350ed3cb95b0c12e1f10f09a5')}, hash='15cb23716f81275c243590d5321b615e0802cc6376096f786e4e1ff3ba77a588', text='Then, we define an instruction, inst, that should be respected\\nthroughout the dialogue. For example, instcould be “act as.” We can then synthetically concatenate this\\ninstruction to all the user messages of the conversation.\\nNext, we can sample from this synthetic data using the latest RLHF model. We now have a context-dialogue\\nandthesamplewithwhichtofine-tuneamodel,inaprocessanalogoustoRejectionSampling. Insteadof\\naugmentingallcontext-dialogueturnswiththeinstruction,wecandropitinallbutthefirstturn,butthis\\nwouldleadtoamismatchattrainingtimebetweenthesystemmessage,i.e.,alltheintermediateassistant\\nmessages that come before the last turn, and our sample. To fix this issue, which could hurt the training, we\\nsimply set the loss to 0 for all the tokens from the previous turns, including assistant messages.\\nFor the training instructions, we created a few synthetic constraints to sample from: Hobbies ( “You enjoy\\ne.g. Tennis” ),Language ( “Speakine.g. French” ),or PublicFigure( “Actase.g. Napoleon” ). Toobtainthelists\\nof hobbies and public figures, we asked Llama 2-Chat to generate it, avoiding a mismatch between the\\ninstructionandmodelknowledge(e.g.,askingthemodeltoactassomeoneithadnotencounteredduring\\ntraining). Tomaketheinstructionsmorecomplexanddiverse,weconstructthefinalinstructionbyrandomly\\ncombining the above constraints. When constructing the final system message for the training data, we also\\n16\\n\\nmodifytheoriginalinstructionhalfofthetimetobelessverbose,e.g., “AlwaysactasNapoleonfromnow” ->\\n”Figure: Napoleon.” These steps produce an SFT dataset, on which we can fine-tune Llama 2-Chat .\\nGAtt Evaluation. We applied GAtt after RLHF V3. We report a quantitative analysis indicating that GAtt is\\nconsistentupto 20+turns,until themaximumcontextlengthis reached(seeAppendixA.3.5).', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-15'),\n",
              " 'node-15': IndexNode(id_='node-15', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='415b7efc-e73f-4ac4-bbfd-c1546f099026', node_type=<ObjectType.DOCUMENT: '4'>, metadata={}, hash='231b3bd773f012c01b893ada9e009ecf25ee59934614c5a595c9bf1b3a123292'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='a9563afd-e65b-43df-863f-1e621e828eb0', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='20d6147bf259bf8b06c7dbd5db57a7ce28a7a29e0d5d110f9d9f15f38c654121'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='cebe3444-545d-4dd5-a097-4708593e44da', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='7d42646b16c71668e6588209bca220749af0e8383f8c5e42acb0afb1a957409f')}, hash='0f0628935d4e376c2f4a79112c1d73dfe561dbf41057985e87151e7fde5ef547', text='For the 7B and 13B models, we set β= 0.01(KL penalty), and for the 34B and\\n70B models, we set β= 0.005.\\n15\\n\\nFigure 9: Issues with multi-turn memory (left)can be improved with GAtt (right).\\nWe train for between 200and400iterations for all our models, and use evaluations on held-out prompts for\\nearlystopping. EachiterationofPPOonthe70Bmodeltakesonaverage ≈330seconds. Totrainquicklywith\\nlarge batch sizes, we use FSDP (Zhao et al., 2023). This was effective when using O(1) forward or backward\\npasses,butcausedalargeslowdown( ≈20×)duringgeneration,evenwhenusingalargebatchsizeandKV\\ncache. We were able to mitigate this by consolidating the model weights to each node once before generation\\nand then freeing the memory after generation, resuming the rest of the training loop.\\n3.3 System Message for Multi-Turn Consistency\\nIn a dialogue setup, some instructions should apply for all the conversation turns, e.g., to respond succinctly,\\nor to“act as”some public figure. When we provided such instructions to Llama 2-Chat , the subsequent\\nresponse should always respect the constraint. However, our initial RLHF models tended to forget the initial\\ninstruction after a few turns of dialogue, as illustrated in Figure 9 (left).\\nTo address these limitations, we propose Ghost Attention (GAtt), a very simple method inspired by Context\\nDistillation (Bai et al., 2022b) that hacks the fine-tuning data to help the attention focus in a multi-stage\\nprocess. GAtt enables dialogue control over multiple turns, as illustrated in Figure 9 (right).\\nGAttMethod. Assumewe haveaccess toa multi-turndialoguedataset betweentwo persons(e.g., auser\\nand an assistant), with a list of messages [u1, a1, . . . , u n, an], where unandancorrespond to the user and\\nassistant messages for turn n, respectively. Then, we define an instruction, inst, that should be respected\\nthroughout the dialogue. For example, instcould be “act as.” We can then synthetically concatenate this\\ninstruction to all the user messages of the conversation.\\nNext, we can sample from this synthetic data using the latest RLHF model. We now have a context-dialogue\\nandthesamplewithwhichtofine-tuneamodel,inaprocessanalogoustoRejectionSampling. Insteadof\\naugmentingallcontext-dialogueturnswiththeinstruction,wecandropitinallbutthefirstturn,butthis\\nwouldleadtoamismatchattrainingtimebetweenthesystemmessage,i.e.,alltheintermediateassistant\\nmessages that come before the last turn, and our sample. To fix this issue, which could hurt the training, we\\nsimply set the loss to 0 for all the tokens from the previous turns, including assistant messages.\\nFor the training instructions, we created a few synthetic constraints to sample from: Hobbies ( “You enjoy\\ne.g. Tennis” ),Language ( “Speakine.g. French” ),or PublicFigure( “Actase.g. Napoleon” ). Toobtainthelists\\nof hobbies and public figures, we asked Llama 2-Chat to generate it, avoiding a mismatch between the\\ninstructionandmodelknowledge(e.g.,askingthemodeltoactassomeoneithadnotencounteredduring\\ntraining). Tomaketheinstructionsmorecomplexanddiverse,weconstructthefinalinstructionbyrandomly\\ncombining the above constraints. When constructing the final system message for the training data, we also\\n16\\n\\nmodifytheoriginalinstructionhalfofthetimetobelessverbose,e.g., “AlwaysactasNapoleonfromnow” ->\\n”Figure: Napoleon.” These steps produce an SFT dataset, on which we can fine-tune Llama 2-Chat .\\nGAtt Evaluation. We applied GAtt after RLHF V3. We report a quantitative analysis indicating that GAtt is\\nconsistentupto 20+turns,until themaximumcontextlengthis reached(seeAppendixA.3.5).', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-15'),\n",
              " '6e0bdaa0-4f94-4239-a22f-e13788ee7ea5': IndexNode(id_='6e0bdaa0-4f94-4239-a22f-e13788ee7ea5', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-16', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='7d42646b16c71668e6588209bca220749af0e8383f8c5e42acb0afb1a957409f'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='3e3f0ba8-2791-4ab0-b08c-51d027903f1a', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='b137290b9bfe4ea4bef8cf22424117e3eaa70fe67a29359dc04219b8d019b74b')}, hash='7136e7b60c6bdec67de773f1193f76d18eb1fab9132e4bbcc134cb43c6306ab0', text='We triedto\\nsetconstraints notpresentinthetraining ofGAttatinference time,forinstance “Always answerwithHaiku,”\\nfor which the model remained consistent as illustrated in Appendix Figure 28.\\nAct as Oscar\\nWilde\\nGive short\\nanswers Wh\\nich is the\\nbest city to\\nlive in?\\nLondon, of\\ncourse! \\nWhy is that\\n? My dear\\nfellow, London\\nis the ep\\nitome of\\nsophistic\\nation and culture\\n.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-16'),\n",
              " '3e3f0ba8-2791-4ab0-b08c-51d027903f1a': IndexNode(id_='3e3f0ba8-2791-4ab0-b08c-51d027903f1a', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-16', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='7d42646b16c71668e6588209bca220749af0e8383f8c5e42acb0afb1a957409f'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='6e0bdaa0-4f94-4239-a22f-e13788ee7ea5', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='7136e7b60c6bdec67de773f1193f76d18eb1fab9132e4bbcc134cb43c6306ab0'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='6d783466-710e-4dc6-a121-e12bba3a40c5', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='1458872998526cd9f53d8eada0e59563faa4f23328b0f654c0b1c581d7f66ebb')}, hash='b137290b9bfe4ea4bef8cf22424117e3eaa70fe67a29359dc04219b8d019b74b', text='It is\\nthe city of\\nShakespeare and Dick\\nens, of\\nthe great univers\\nities, of\\nthe museums\\nand galleries\\n. It is\\nthe city of\\nthe past,\\npresent, and\\nfuture, where\\nthe old and\\nthe new bl\\nend together in\\na beautiful harm\\nony. \\nWhat is your\\nname? My\\nname is Oscar\\nBaseline before GAttAct as Oscar\\nWilde\\nGive short\\nanswers Wh\\nich is the\\nbest city to\\nlive in?\\nLondon, of\\ncourse!', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-16'),\n",
              " '6d783466-710e-4dc6-a121-e12bba3a40c5': IndexNode(id_='6d783466-710e-4dc6-a121-e12bba3a40c5', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-16', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='7d42646b16c71668e6588209bca220749af0e8383f8c5e42acb0afb1a957409f'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='3e3f0ba8-2791-4ab0-b08c-51d027903f1a', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='b137290b9bfe4ea4bef8cf22424117e3eaa70fe67a29359dc04219b8d019b74b'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='a6f694a7-2a8c-4024-b731-1504882ec723', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='82ab35e39830cd703b3281c06bc6f273c1643fb5bbed3043995cf123c4fefd8b')}, hash='1458872998526cd9f53d8eada0e59563faa4f23328b0f654c0b1c581d7f66ebb', text='London, of\\ncourse! \\nWhy is that\\n? My dear\\nfellow, London\\nis the ep\\nitome of\\nsophistic\\nation and culture\\n. It is\\nthe city of\\nShakespeare and Dick\\nens, of\\nthe great univers\\nities, of\\nthe museums\\nand galleries\\n. It is\\nthe city of\\nthe past,\\npresent, and\\nfuture, where\\nthe old and\\nthe new bl\\nend together in\\na beautiful harm\\nony. \\nWhat is your\\nname?', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-16'),\n",
              " 'a6f694a7-2a8c-4024-b731-1504882ec723': IndexNode(id_='a6f694a7-2a8c-4024-b731-1504882ec723', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-16', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='7d42646b16c71668e6588209bca220749af0e8383f8c5e42acb0afb1a957409f'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='6d783466-710e-4dc6-a121-e12bba3a40c5', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='1458872998526cd9f53d8eada0e59563faa4f23328b0f654c0b1c581d7f66ebb'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='745107aa-71f6-4874-83bf-a6a6a42bb36a', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='f73f3b4162b66e7e8b5c6820ba082d7f787943d00bac2de2ab5c426fbc9824ad')}, hash='82ab35e39830cd703b3281c06bc6f273c1643fb5bbed3043995cf123c4fefd8b', text='What is your\\nname? My\\nname is Oscar\\nAct as Oscar\\nWilde\\nGive short\\nanswers Wh\\nich is the\\nbest city to\\nlive in?\\nLondon, of\\ncourse! \\nWhy is that\\n? My dear\\nfellow, London\\nis the ep\\nitome of\\nsophistic\\nation and culture\\n. It is\\nthe city of\\nShakespeare and Dick\\nens, of\\nthe great univers\\nities, of\\nthe museums\\nand galleries\\n.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-16'),\n",
              " '745107aa-71f6-4874-83bf-a6a6a42bb36a': IndexNode(id_='745107aa-71f6-4874-83bf-a6a6a42bb36a', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-16', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='7d42646b16c71668e6588209bca220749af0e8383f8c5e42acb0afb1a957409f'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='a6f694a7-2a8c-4024-b731-1504882ec723', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='82ab35e39830cd703b3281c06bc6f273c1643fb5bbed3043995cf123c4fefd8b'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='1d7d5bd5-6e26-4f1e-9d3f-aea7299ecd32', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='03c843647ac96b3bbd2fafa77a8c6fc8262f859d4df4a92e0f090c696ccca34c')}, hash='f73f3b4162b66e7e8b5c6820ba082d7f787943d00bac2de2ab5c426fbc9824ad', text='It is\\nthe city of\\nthe past,\\npresent, and\\nfuture, where\\nthe old and\\nthe new bl\\nend together in\\na beautiful harm\\nony. \\nWhat is your\\nname? My\\nname is Oscar\\nBaseline after GAttAct as Oscar\\nWilde\\nGive short\\nanswers Wh\\nich is the\\nbest city to\\nlive in?\\nLondon, of\\ncourse! \\nWhy is that\\n? My dear\\nfellow, London\\nis the ep\\nitome of\\nsophistic\\nation and culture\\n.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-16'),\n",
              " '1d7d5bd5-6e26-4f1e-9d3f-aea7299ecd32': IndexNode(id_='1d7d5bd5-6e26-4f1e-9d3f-aea7299ecd32', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-16', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='7d42646b16c71668e6588209bca220749af0e8383f8c5e42acb0afb1a957409f'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='745107aa-71f6-4874-83bf-a6a6a42bb36a', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='f73f3b4162b66e7e8b5c6820ba082d7f787943d00bac2de2ab5c426fbc9824ad'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='c426d64f-8c97-4d1a-8459-a073ebda09f5', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='4ae0dc90f8b6d6f7984a723145b7219f66441ba9e052de8cd364ff772b677d1e')}, hash='03c843647ac96b3bbd2fafa77a8c6fc8262f859d4df4a92e0f090c696ccca34c', text='It is\\nthe city of\\nShakespeare and Dick\\nens, of\\nthe great univers\\nities, of\\nthe museums\\nand galleries\\n. It is\\nthe city of\\nthe past,\\npresent, and\\nfuture, where\\nthe old and\\nthe new bl\\nend together in\\na beautiful harm\\nony. \\nWhat is your\\nname? My\\nname is Oscar\\nFigure10: AttentionvisualizationforadialoguewithandwithoutGAtt . Weconsideredthemaximum\\nactivations across the network and we bin neighboring tokens together.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-16'),\n",
              " 'c426d64f-8c97-4d1a-8459-a073ebda09f5': IndexNode(id_='c426d64f-8c97-4d1a-8459-a073ebda09f5', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-16', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='7d42646b16c71668e6588209bca220749af0e8383f8c5e42acb0afb1a957409f'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='1d7d5bd5-6e26-4f1e-9d3f-aea7299ecd32', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='03c843647ac96b3bbd2fafa77a8c6fc8262f859d4df4a92e0f090c696ccca34c'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='ce665ef6-8be6-4eba-a4ad-e455ad12fdb8', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='1eb8c0a7591ec5d8c38c44cb1e177575fdc1b2f6f392e7522349dd50ed6a8ed7')}, hash='4ae0dc90f8b6d6f7984a723145b7219f66441ba9e052de8cd364ff772b677d1e', text='Weconsideredthemaximum\\nactivations across the network and we bin neighboring tokens together.\\nTo illustrate how GAtt helped reshape attention during fine-tuning, we display the maximum attention\\nactivationsofthemodelinFigure10. Theleft-handsideofeachfigurecorrespondstothesystemmessage\\n(“ActasOscarWilde”).', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-16'),\n",
              " 'ce665ef6-8be6-4eba-a4ad-e455ad12fdb8': IndexNode(id_='ce665ef6-8be6-4eba-a4ad-e455ad12fdb8', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-16', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='7d42646b16c71668e6588209bca220749af0e8383f8c5e42acb0afb1a957409f'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='c426d64f-8c97-4d1a-8459-a073ebda09f5', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='4ae0dc90f8b6d6f7984a723145b7219f66441ba9e052de8cd364ff772b677d1e'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='49b34903-07b8-4a02-8e0d-c8482be64de6', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='2f00bef426304299d1ba687b0e7cf35a61d4549f8aecf98dad038da5959d806e')}, hash='1eb8c0a7591ec5d8c38c44cb1e177575fdc1b2f6f392e7522349dd50ed6a8ed7', text='WecanseethattheGAtt-equippedmodel(right)maintainslargeattentionactivations\\nwithrespect tothe systemmessage for alarger portionof thedialogue, ascompared tothe modelwithout\\nGAtt (left).\\nDespite its utility, the current implementation of GAtt is vanilla, and more development and iteration on\\nthis technique could likely further benefit the model. For instance, we could teach the model to change the\\nsystem message during the conversation by integrating such data during fine-tuning.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-16'),\n",
              " '49b34903-07b8-4a02-8e0d-c8482be64de6': IndexNode(id_='49b34903-07b8-4a02-8e0d-c8482be64de6', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-16', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='7d42646b16c71668e6588209bca220749af0e8383f8c5e42acb0afb1a957409f'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='ce665ef6-8be6-4eba-a4ad-e455ad12fdb8', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='1eb8c0a7591ec5d8c38c44cb1e177575fdc1b2f6f392e7522349dd50ed6a8ed7'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='0cf8870e-bbc2-4a31-8bec-5623a49bf131', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='ad0df026f961db7ef0d92b1db1ae835b3b927c1ebea6de7106684dedf49dce63')}, hash='2f00bef426304299d1ba687b0e7cf35a61d4549f8aecf98dad038da5959d806e', text='3.4 RLHF Results\\n3.4.1 Model-Based Evaluation\\nEvaluatingLLMsisachallengingopen-researchproblem. Humanevaluation,whileagoldstandard,can\\nbe complicated by various HCI considerations (Clark et al., 2021; Gehrmann et al., 2023), and is not always\\nscalable.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-16'),\n",
              " '0cf8870e-bbc2-4a31-8bec-5623a49bf131': IndexNode(id_='0cf8870e-bbc2-4a31-8bec-5623a49bf131', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-16', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='7d42646b16c71668e6588209bca220749af0e8383f8c5e42acb0afb1a957409f'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='49b34903-07b8-4a02-8e0d-c8482be64de6', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='2f00bef426304299d1ba687b0e7cf35a61d4549f8aecf98dad038da5959d806e')}, hash='ad0df026f961db7ef0d92b1db1ae835b3b927c1ebea6de7106684dedf49dce63', text='Thus, to select the best-performing models among several ablations at each iteration from RLHF-V1\\ntoV5,wefirstobservedtheimprovementoftherewardsfromthelatestrewardmodels,tosavecostsand\\nincrease iteration speed. We later validated major model versions with human evaluations.\\nHow Far Can Model-Based Evaluation Go?', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-16'),\n",
              " 'ed90b71a-0b29-45c4-a134-1a169cd9aa29': IndexNode(id_='ed90b71a-0b29-45c4-a134-1a169cd9aa29', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-16', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='7d42646b16c71668e6588209bca220749af0e8383f8c5e42acb0afb1a957409f'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='dad00705-9ffa-48c0-a6fb-277df34d7b49', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='3c923ac9fb5ec96d12390b8f427cdc028dc2ff3a158992629745c5421ab6a78a')}, hash='7801d2b90aebbb980d42e5c717c395553f2f81908ec4bd68174649b2f77053bd', text='We triedto\\nsetconstraints notpresentinthetraining ofGAttatinference time,forinstance “Always answerwithHaiku,”\\nfor which the model remained consistent as illustrated in Appendix Figure 28.\\nAct as Oscar\\nWilde\\nGive short\\nanswers Wh\\nich is the\\nbest city to\\nlive in?\\nLondon, of\\ncourse! \\nWhy is that\\n? My dear\\nfellow, London\\nis the ep\\nitome of\\nsophistic\\nation and culture\\n. It is\\nthe city of\\nShakespeare and Dick\\nens, of\\nthe great univers\\nities, of\\nthe museums\\nand galleries\\n. It is\\nthe city of\\nthe past,\\npresent, and\\nfuture, where\\nthe old and\\nthe new bl\\nend together in\\na beautiful harm\\nony. \\nWhat is your\\nname? My\\nname is Oscar\\nBaseline before GAttAct as Oscar\\nWilde\\nGive short\\nanswers Wh\\nich is the\\nbest city to\\nlive in?\\nLondon, of\\ncourse! \\nWhy is that\\n?', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-16'),\n",
              " 'dad00705-9ffa-48c0-a6fb-277df34d7b49': IndexNode(id_='dad00705-9ffa-48c0-a6fb-277df34d7b49', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-16', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='7d42646b16c71668e6588209bca220749af0e8383f8c5e42acb0afb1a957409f'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='ed90b71a-0b29-45c4-a134-1a169cd9aa29', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='7801d2b90aebbb980d42e5c717c395553f2f81908ec4bd68174649b2f77053bd'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='daaa3d3d-55da-4fe9-af00-1f7ffd06d9ed', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='0c97c72879f92c3774af7ca26355dabb76d1e4c90ace4985032a9331aef7fd8f')}, hash='3c923ac9fb5ec96d12390b8f427cdc028dc2ff3a158992629745c5421ab6a78a', text='London, of\\ncourse! \\nWhy is that\\n? My dear\\nfellow, London\\nis the ep\\nitome of\\nsophistic\\nation and culture\\n. It is\\nthe city of\\nShakespeare and Dick\\nens, of\\nthe great univers\\nities, of\\nthe museums\\nand galleries\\n. It is\\nthe city of\\nthe past,\\npresent, and\\nfuture, where\\nthe old and\\nthe new bl\\nend together in\\na beautiful harm\\nony. \\nWhat is your\\nname? My\\nname is Oscar\\nAct as Oscar\\nWilde\\nGive short\\nanswers Wh\\nich is the\\nbest city to\\nlive in?\\nLondon, of\\ncourse! \\nWhy is that\\n? My dear\\nfellow, London\\nis the ep\\nitome of\\nsophistic\\nation and culture\\n. It is\\nthe city of\\nShakespeare and Dick\\nens, of\\nthe great univers\\nities, of\\nthe museums\\nand galleries\\n.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-16'),\n",
              " 'daaa3d3d-55da-4fe9-af00-1f7ffd06d9ed': IndexNode(id_='daaa3d3d-55da-4fe9-af00-1f7ffd06d9ed', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-16', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='7d42646b16c71668e6588209bca220749af0e8383f8c5e42acb0afb1a957409f'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='dad00705-9ffa-48c0-a6fb-277df34d7b49', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='3c923ac9fb5ec96d12390b8f427cdc028dc2ff3a158992629745c5421ab6a78a'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='fc9a33ff-0ec0-4e28-9eb0-5a42d73ded6a', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='28c6734cece31f153c123fd9c583f35aaede453c582689d824ca7bc26c4e1a42')}, hash='0c97c72879f92c3774af7ca26355dabb76d1e4c90ace4985032a9331aef7fd8f', text='It is\\nthe city of\\nthe past,\\npresent, and\\nfuture, where\\nthe old and\\nthe new bl\\nend together in\\na beautiful harm\\nony. \\nWhat is your\\nname? My\\nname is Oscar\\nBaseline after GAttAct as Oscar\\nWilde\\nGive short\\nanswers Wh\\nich is the\\nbest city to\\nlive in?\\nLondon, of\\ncourse! \\nWhy is that\\n? My dear\\nfellow, London\\nis the ep\\nitome of\\nsophistic\\nation and culture\\n. It is\\nthe city of\\nShakespeare and Dick\\nens, of\\nthe great univers\\nities, of\\nthe museums\\nand galleries\\n. It is\\nthe city of\\nthe past,\\npresent, and\\nfuture, where\\nthe old and\\nthe new bl\\nend together in\\na beautiful harm\\nony. \\nWhat is your\\nname? My\\nname is Oscar\\nFigure10: AttentionvisualizationforadialoguewithandwithoutGAtt . Weconsideredthemaximum\\nactivations across the network and we bin neighboring tokens together.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-16'),\n",
              " 'fc9a33ff-0ec0-4e28-9eb0-5a42d73ded6a': IndexNode(id_='fc9a33ff-0ec0-4e28-9eb0-5a42d73ded6a', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-16', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='7d42646b16c71668e6588209bca220749af0e8383f8c5e42acb0afb1a957409f'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='daaa3d3d-55da-4fe9-af00-1f7ffd06d9ed', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='0c97c72879f92c3774af7ca26355dabb76d1e4c90ace4985032a9331aef7fd8f'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='9dbd058f-5709-4ec5-ab32-dd9a23333a99', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='fcdd66a8f1f87b04af286a36da32fecfa4857be4237a857c29a39bf56db0842a')}, hash='28c6734cece31f153c123fd9c583f35aaede453c582689d824ca7bc26c4e1a42', text='Weconsideredthemaximum\\nactivations across the network and we bin neighboring tokens together.\\nTo illustrate how GAtt helped reshape attention during fine-tuning, we display the maximum attention\\nactivationsofthemodelinFigure10. Theleft-handsideofeachfigurecorrespondstothesystemmessage\\n(“ActasOscarWilde”). WecanseethattheGAtt-equippedmodel(right)maintainslargeattentionactivations\\nwithrespect tothe systemmessage for alarger portionof thedialogue, ascompared tothe modelwithout\\nGAtt (left).\\nDespite its utility, the current implementation of GAtt is vanilla, and more development and iteration on\\nthis technique could likely further benefit the model. For instance, we could teach the model to change the\\nsystem message during the conversation by integrating such data during fine-tuning.\\n3.4 RLHF Results\\n3.4.1 Model-Based Evaluation\\nEvaluatingLLMsisachallengingopen-researchproblem.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-16'),\n",
              " '9dbd058f-5709-4ec5-ab32-dd9a23333a99': IndexNode(id_='9dbd058f-5709-4ec5-ab32-dd9a23333a99', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-16', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='7d42646b16c71668e6588209bca220749af0e8383f8c5e42acb0afb1a957409f'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='fc9a33ff-0ec0-4e28-9eb0-5a42d73ded6a', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='28c6734cece31f153c123fd9c583f35aaede453c582689d824ca7bc26c4e1a42')}, hash='fcdd66a8f1f87b04af286a36da32fecfa4857be4237a857c29a39bf56db0842a', text='Humanevaluation,whileagoldstandard,can\\nbe complicated by various HCI considerations (Clark et al., 2021; Gehrmann et al., 2023), and is not always\\nscalable. Thus, to select the best-performing models among several ablations at each iteration from RLHF-V1\\ntoV5,wefirstobservedtheimprovementoftherewardsfromthelatestrewardmodels,tosavecostsand\\nincrease iteration speed. We later validated major model versions with human evaluations.\\nHow Far Can Model-Based Evaluation Go?', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-16'),\n",
              " '6e701acc-4c6c-46d7-8a11-f410415fe7f4': IndexNode(id_='6e701acc-4c6c-46d7-8a11-f410415fe7f4', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-16', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='7d42646b16c71668e6588209bca220749af0e8383f8c5e42acb0afb1a957409f'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='0b6e37ca-2ad1-4734-8627-ef8f1b90c4ae', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='0b32c994207e28fb951926db254d21db33ed978a5b7aec86d15eabdb8c7346dd')}, hash='181b4aed47bef43190c0662a70b8efb9e42c568a52b2b1f69b10929432752b57', text='We triedto\\nsetconstraints notpresentinthetraining ofGAttatinference time,forinstance “Always answerwithHaiku,”\\nfor which the model remained consistent as illustrated in Appendix Figure 28.\\nAct as Oscar\\nWilde\\nGive short\\nanswers Wh\\nich is the\\nbest city to\\nlive in?\\nLondon, of\\ncourse! \\nWhy is that\\n? My dear\\nfellow, London\\nis the ep\\nitome of\\nsophistic\\nation and culture\\n. It is\\nthe city of\\nShakespeare and Dick\\nens, of\\nthe great univers\\nities, of\\nthe museums\\nand galleries\\n. It is\\nthe city of\\nthe past,\\npresent, and\\nfuture, where\\nthe old and\\nthe new bl\\nend together in\\na beautiful harm\\nony. \\nWhat is your\\nname? My\\nname is Oscar\\nBaseline before GAttAct as Oscar\\nWilde\\nGive short\\nanswers Wh\\nich is the\\nbest city to\\nlive in?\\nLondon, of\\ncourse! \\nWhy is that\\n? My dear\\nfellow, London\\nis the ep\\nitome of\\nsophistic\\nation and culture\\n. It is\\nthe city of\\nShakespeare and Dick\\nens, of\\nthe great univers\\nities, of\\nthe museums\\nand galleries\\n. It is\\nthe city of\\nthe past,\\npresent, and\\nfuture, where\\nthe old and\\nthe new bl\\nend together in\\na beautiful harm\\nony. \\nWhat is your\\nname? My\\nname is Oscar\\nAct as Oscar\\nWilde\\nGive short\\nanswers Wh\\nich is the\\nbest city to\\nlive in?\\nLondon, of\\ncourse! \\nWhy is that\\n? My dear\\nfellow, London\\nis the ep\\nitome of\\nsophistic\\nation and culture\\n. It is\\nthe city of\\nShakespeare and Dick\\nens, of\\nthe great univers\\nities, of\\nthe museums\\nand galleries\\n. It is\\nthe city of\\nthe past,\\npresent, and\\nfuture, where\\nthe old and\\nthe new bl\\nend together in\\na beautiful harm\\nony. \\nWhat is your\\nname?', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-16'),\n",
              " '0b6e37ca-2ad1-4734-8627-ef8f1b90c4ae': IndexNode(id_='0b6e37ca-2ad1-4734-8627-ef8f1b90c4ae', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-16', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='7d42646b16c71668e6588209bca220749af0e8383f8c5e42acb0afb1a957409f'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='6e701acc-4c6c-46d7-8a11-f410415fe7f4', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='181b4aed47bef43190c0662a70b8efb9e42c568a52b2b1f69b10929432752b57'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='c8d542bb-cc48-44c2-ac8b-7f2c68dc3ab4', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='33bae3bdb2c6b1824ef640bace2b29d97afced99f2f6105c422e604a76b26d90')}, hash='0b32c994207e28fb951926db254d21db33ed978a5b7aec86d15eabdb8c7346dd', text='What is your\\nname? My\\nname is Oscar\\nBaseline after GAttAct as Oscar\\nWilde\\nGive short\\nanswers Wh\\nich is the\\nbest city to\\nlive in?\\nLondon, of\\ncourse! \\nWhy is that\\n? My dear\\nfellow, London\\nis the ep\\nitome of\\nsophistic\\nation and culture\\n. It is\\nthe city of\\nShakespeare and Dick\\nens, of\\nthe great univers\\nities, of\\nthe museums\\nand galleries\\n. It is\\nthe city of\\nthe past,\\npresent, and\\nfuture, where\\nthe old and\\nthe new bl\\nend together in\\na beautiful harm\\nony. \\nWhat is your\\nname? My\\nname is Oscar\\nFigure10: AttentionvisualizationforadialoguewithandwithoutGAtt . Weconsideredthemaximum\\nactivations across the network and we bin neighboring tokens together.\\nTo illustrate how GAtt helped reshape attention during fine-tuning, we display the maximum attention\\nactivationsofthemodelinFigure10. Theleft-handsideofeachfigurecorrespondstothesystemmessage\\n(“ActasOscarWilde”). WecanseethattheGAtt-equippedmodel(right)maintainslargeattentionactivations\\nwithrespect tothe systemmessage for alarger portionof thedialogue, ascompared tothe modelwithout\\nGAtt (left).\\nDespite its utility, the current implementation of GAtt is vanilla, and more development and iteration on\\nthis technique could likely further benefit the model. For instance, we could teach the model to change the\\nsystem message during the conversation by integrating such data during fine-tuning.\\n3.4 RLHF Results\\n3.4.1 Model-Based Evaluation\\nEvaluatingLLMsisachallengingopen-researchproblem. Humanevaluation,whileagoldstandard,can\\nbe complicated by various HCI considerations (Clark et al., 2021; Gehrmann et al., 2023), and is not always\\nscalable. Thus, to select the best-performing models among several ablations at each iteration from RLHF-V1\\ntoV5,wefirstobservedtheimprovementoftherewardsfromthelatestrewardmodels,tosavecostsand\\nincrease iteration speed.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-16'),\n",
              " 'c8d542bb-cc48-44c2-ac8b-7f2c68dc3ab4': IndexNode(id_='c8d542bb-cc48-44c2-ac8b-7f2c68dc3ab4', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-16', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='7d42646b16c71668e6588209bca220749af0e8383f8c5e42acb0afb1a957409f'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='0b6e37ca-2ad1-4734-8627-ef8f1b90c4ae', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='0b32c994207e28fb951926db254d21db33ed978a5b7aec86d15eabdb8c7346dd')}, hash='33bae3bdb2c6b1824ef640bace2b29d97afced99f2f6105c422e604a76b26d90', text='We later validated major model versions with human evaluations.\\nHow Far Can Model-Based Evaluation Go?', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-16'),\n",
              " 'node-16': IndexNode(id_='node-16', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='415b7efc-e73f-4ac4-bbfd-c1546f099026', node_type=<ObjectType.DOCUMENT: '4'>, metadata={}, hash='231b3bd773f012c01b893ada9e009ecf25ee59934614c5a595c9bf1b3a123292'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='cd24e901-dc63-4e4e-b3a7-ccfa0a330f85', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='0f0628935d4e376c2f4a79112c1d73dfe561dbf41057985e87151e7fde5ef547'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='8bf3afeb-b8ef-49cf-99e8-22bb1ecad588', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='fbf315836074ae5e01f8a617565ce5b7e7a60ca9196a62c38f71fa99b99c31ab')}, hash='7d42646b16c71668e6588209bca220749af0e8383f8c5e42acb0afb1a957409f', text='We triedto\\nsetconstraints notpresentinthetraining ofGAttatinference time,forinstance “Always answerwithHaiku,”\\nfor which the model remained consistent as illustrated in Appendix Figure 28.\\nAct as Oscar\\nWilde\\nGive short\\nanswers Wh\\nich is the\\nbest city to\\nlive in?\\nLondon, of\\ncourse! \\nWhy is that\\n? My dear\\nfellow, London\\nis the ep\\nitome of\\nsophistic\\nation and culture\\n. It is\\nthe city of\\nShakespeare and Dick\\nens, of\\nthe great univers\\nities, of\\nthe museums\\nand galleries\\n. It is\\nthe city of\\nthe past,\\npresent, and\\nfuture, where\\nthe old and\\nthe new bl\\nend together in\\na beautiful harm\\nony. \\nWhat is your\\nname? My\\nname is Oscar\\nBaseline before GAttAct as Oscar\\nWilde\\nGive short\\nanswers Wh\\nich is the\\nbest city to\\nlive in?\\nLondon, of\\ncourse! \\nWhy is that\\n? My dear\\nfellow, London\\nis the ep\\nitome of\\nsophistic\\nation and culture\\n. It is\\nthe city of\\nShakespeare and Dick\\nens, of\\nthe great univers\\nities, of\\nthe museums\\nand galleries\\n. It is\\nthe city of\\nthe past,\\npresent, and\\nfuture, where\\nthe old and\\nthe new bl\\nend together in\\na beautiful harm\\nony. \\nWhat is your\\nname? My\\nname is Oscar\\nAct as Oscar\\nWilde\\nGive short\\nanswers Wh\\nich is the\\nbest city to\\nlive in?\\nLondon, of\\ncourse! \\nWhy is that\\n? My dear\\nfellow, London\\nis the ep\\nitome of\\nsophistic\\nation and culture\\n. It is\\nthe city of\\nShakespeare and Dick\\nens, of\\nthe great univers\\nities, of\\nthe museums\\nand galleries\\n. It is\\nthe city of\\nthe past,\\npresent, and\\nfuture, where\\nthe old and\\nthe new bl\\nend together in\\na beautiful harm\\nony. \\nWhat is your\\nname? My\\nname is Oscar\\nBaseline after GAttAct as Oscar\\nWilde\\nGive short\\nanswers Wh\\nich is the\\nbest city to\\nlive in?\\nLondon, of\\ncourse! \\nWhy is that\\n? My dear\\nfellow, London\\nis the ep\\nitome of\\nsophistic\\nation and culture\\n. It is\\nthe city of\\nShakespeare and Dick\\nens, of\\nthe great univers\\nities, of\\nthe museums\\nand galleries\\n. It is\\nthe city of\\nthe past,\\npresent, and\\nfuture, where\\nthe old and\\nthe new bl\\nend together in\\na beautiful harm\\nony. \\nWhat is your\\nname? My\\nname is Oscar\\nFigure10: AttentionvisualizationforadialoguewithandwithoutGAtt . Weconsideredthemaximum\\nactivations across the network and we bin neighboring tokens together.\\nTo illustrate how GAtt helped reshape attention during fine-tuning, we display the maximum attention\\nactivationsofthemodelinFigure10. Theleft-handsideofeachfigurecorrespondstothesystemmessage\\n(“ActasOscarWilde”). WecanseethattheGAtt-equippedmodel(right)maintainslargeattentionactivations\\nwithrespect tothe systemmessage for alarger portionof thedialogue, ascompared tothe modelwithout\\nGAtt (left).\\nDespite its utility, the current implementation of GAtt is vanilla, and more development and iteration on\\nthis technique could likely further benefit the model. For instance, we could teach the model to change the\\nsystem message during the conversation by integrating such data during fine-tuning.\\n3.4 RLHF Results\\n3.4.1 Model-Based Evaluation\\nEvaluatingLLMsisachallengingopen-researchproblem. Humanevaluation,whileagoldstandard,can\\nbe complicated by various HCI considerations (Clark et al., 2021; Gehrmann et al., 2023), and is not always\\nscalable. Thus, to select the best-performing models among several ablations at each iteration from RLHF-V1\\ntoV5,wefirstobservedtheimprovementoftherewardsfromthelatestrewardmodels,tosavecostsand\\nincrease iteration speed. We later validated major model versions with human evaluations.\\nHow Far Can Model-Based Evaluation Go?', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-16'),\n",
              " '46332bba-b9c8-4b2b-be50-80202275855f': IndexNode(id_='46332bba-b9c8-4b2b-be50-80202275855f', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-17', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='fbf315836074ae5e01f8a617565ce5b7e7a60ca9196a62c38f71fa99b99c31ab'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='06eb9399-4e18-41cc-a240-be83390fa0c0', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='9e7586d3eec4a28b144eb1575b266b037b53f37ba740940c92f6976bf6320cf4')}, hash='d49df51afaaf5e9853cab0c5290ad89522e01411b35b8b9c33868de2eb7e8847', text='How Far Can Model-Based Evaluation Go? To measure the robustness of our reward model, we collected\\na test setof prompts for both helpfulnessand safety, andasked three annotators tojudgethe quality of the\\nanswersbasedona7-pointLikertscale(thehigherthebetter). Weobservethatourrewardmodelsoverall\\nare well calibrated with our human preference annotations, as illustrated in Figure 29 in the appendix.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-17'),\n",
              " '06eb9399-4e18-41cc-a240-be83390fa0c0': IndexNode(id_='06eb9399-4e18-41cc-a240-be83390fa0c0', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-17', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='fbf315836074ae5e01f8a617565ce5b7e7a60ca9196a62c38f71fa99b99c31ab'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='46332bba-b9c8-4b2b-be50-80202275855f', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='d49df51afaaf5e9853cab0c5290ad89522e01411b35b8b9c33868de2eb7e8847'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='814190e4-217a-4391-bd0c-74b923506530', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='c51e5e40787c7f51fbd2e448366020dbb938ba5e78f24f93ae48c9604c85dcd7')}, hash='9e7586d3eec4a28b144eb1575b266b037b53f37ba740940c92f6976bf6320cf4', text='This\\nconfirms the relevance of using our reward as a point-wise metric, despite being trained with a Pairwise\\nRanking Loss.\\nStill, as Goodhart’s Law states, when a measure becomes a target, it ceases to be a good measure. To ensure\\nourmeasurewon’tdivergefromthehumanpreferences,weadditionallyusedamoregeneralreward,trained\\n17\\n\\nRLHF- v5\\n(with PPO)\\nRLHF- v5\\n(no PPO)\\nRLHF- v4\\nRLHF- v3', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-17'),\n",
              " '814190e4-217a-4391-bd0c-74b923506530': IndexNode(id_='814190e4-217a-4391-bd0c-74b923506530', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-17', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='fbf315836074ae5e01f8a617565ce5b7e7a60ca9196a62c38f71fa99b99c31ab'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='06eb9399-4e18-41cc-a240-be83390fa0c0', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='9e7586d3eec4a28b144eb1575b266b037b53f37ba740940c92f6976bf6320cf4'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='01654096-d5ec-4098-9c58-cf4f1f04a6ab', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='1f29d27572a03ef0267431c2aba7cc9701b0fed7ec1c72a2e3499a8635757e70')}, hash='c51e5e40787c7f51fbd2e448366020dbb938ba5e78f24f93ae48c9604c85dcd7', text='PPO)\\nRLHF- v4\\nRLHF- v3\\n            RLHF- v2      RLHF- v1 SFT-v2       \\nSFT-v1\\n10% 20% 30% 40% 50% 60% 70% 80% 90%10%20%30%40%50%60%70%80%\\nHelpfulness\\nJudge: Meta R ewar d ModelsHarmlessness\\n  RLHF- v5\\n  (with PPO)RLHF-', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-17'),\n",
              " '01654096-d5ec-4098-9c58-cf4f1f04a6ab': IndexNode(id_='01654096-d5ec-4098-9c58-cf4f1f04a6ab', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-17', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='fbf315836074ae5e01f8a617565ce5b7e7a60ca9196a62c38f71fa99b99c31ab'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='814190e4-217a-4391-bd0c-74b923506530', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='c51e5e40787c7f51fbd2e448366020dbb938ba5e78f24f93ae48c9604c85dcd7'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='e7d7af59-c89f-4a71-83bb-d19a1dc15bc1', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='7379567566bc0e5e211f0e8c84415a0b77543bc819f5580f18df8e451ca24a0e')}, hash='1f29d27572a03ef0267431c2aba7cc9701b0fed7ec1c72a2e3499a8635757e70', text='RLHF- v5\\n  (with PPO)RLHF- v5  \\n(no PPO)  \\nRLHF- v4\\nRLHF- v3\\n     RLHF- v2RLHF- v1     \\nSFT-v2    \\nSFT-v1\\n10% 20% 30% 40% 50% 60% 70% 80% 90%10%20%30%40%50%60%70%80%\\nHelpfulness\\nJudge: GPT -4HarmlessnessFigure 11: Evolution', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-17'),\n",
              " 'e7d7af59-c89f-4a71-83bb-d19a1dc15bc1': IndexNode(id_='e7d7af59-c89f-4a71-83bb-d19a1dc15bc1', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-17', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='fbf315836074ae5e01f8a617565ce5b7e7a60ca9196a62c38f71fa99b99c31ab'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='01654096-d5ec-4098-9c58-cf4f1f04a6ab', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='1f29d27572a03ef0267431c2aba7cc9701b0fed7ec1c72a2e3499a8635757e70'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='70bb7af2-256c-40c7-8b00-0d14017d6070', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='b0037c143ef0d135e0fdc8dc460fd12985a85e0d1d7355f516f4ebc19cae1765')}, hash='7379567566bc0e5e211f0e8c84415a0b77543bc819f5580f18df8e451ca24a0e', text='GPT -4HarmlessnessFigure 11: Evolution of Llama 2-Chat . We show the evolution after multiple iterations fine-tuning for the\\nwin-rate%of Llama 2-Chat comparedtoChatGPT. Left: thejudgeisourrewardmodel,whichmayfavor\\nour model, and right, the judge is GPT-4, which should be more neutral.\\non diverse open-source Reward Modeling datasets. We have not yet observed any such divergence, and\\nhypothesize that iterative model updates may be helping to prevent this.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-17'),\n",
              " '70bb7af2-256c-40c7-8b00-0d14017d6070': IndexNode(id_='70bb7af2-256c-40c7-8b00-0d14017d6070', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-17', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='fbf315836074ae5e01f8a617565ce5b7e7a60ca9196a62c38f71fa99b99c31ab'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='e7d7af59-c89f-4a71-83bb-d19a1dc15bc1', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='7379567566bc0e5e211f0e8c84415a0b77543bc819f5580f18df8e451ca24a0e'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='a79d9350-b1d9-47f6-b273-2f5ef9041db4', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='80c3014fd713be12a3c1663e1b454648618a49da53303644bc2ba63de7af0b57')}, hash='b0037c143ef0d135e0fdc8dc460fd12985a85e0d1d7355f516f4ebc19cae1765', text='As a last verification step to ensure no regression between our new model and the previous one, we use both\\nto sample during the next annotation iteration. This enables a model comparison “for free” on new prompts\\nand can help to increase diversity when sampling.\\nProgressionofModels. Figure11reportstheprogressofourdifferentSFTandthenRLHFversionsfor\\nboth Safetyand Helpfulnessaxes, measuredbyour in-houseSafetyand Helpfulnessreward models.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-17'),\n",
              " 'a79d9350-b1d9-47f6-b273-2f5ef9041db4': IndexNode(id_='a79d9350-b1d9-47f6-b273-2f5ef9041db4', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-17', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='fbf315836074ae5e01f8a617565ce5b7e7a60ca9196a62c38f71fa99b99c31ab'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='70bb7af2-256c-40c7-8b00-0d14017d6070', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='b0037c143ef0d135e0fdc8dc460fd12985a85e0d1d7355f516f4ebc19cae1765'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='b8084425-cdb3-46d1-b374-326332825735', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='f40ec42c174136185b0e8f04fea62410c64368f2ae8e5db1c591ec4ba214f039')}, hash='80c3014fd713be12a3c1663e1b454648618a49da53303644bc2ba63de7af0b57', text='On\\nthis set of evaluations, we outperform ChatGPT on both axes after RLHF-V3 (harmlessness and helpfulness\\n>50%). Despite the aforementioned relevance of using our reward as a point-wise metric, it can arguably be\\nbiased in favor of Llama 2-Chat . Therefore, for a fair comparison, we additionally compute the final results\\nusingGPT-4toassesswhichgenerationispreferred.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-17'),\n",
              " 'b8084425-cdb3-46d1-b374-326332825735': IndexNode(id_='b8084425-cdb3-46d1-b374-326332825735', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-17', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='fbf315836074ae5e01f8a617565ce5b7e7a60ca9196a62c38f71fa99b99c31ab'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='a79d9350-b1d9-47f6-b273-2f5ef9041db4', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='80c3014fd713be12a3c1663e1b454648618a49da53303644bc2ba63de7af0b57'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='ce618797-4592-4dde-ae34-8f52fd636e96', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='49ad3399d95f9c50959f485e928c854754cd98eed863b3062395b0b66d35f3d6')}, hash='f40ec42c174136185b0e8f04fea62410c64368f2ae8e5db1c591ec4ba214f039', text='TheorderinwhichChatGPTand Llama 2-Chat outputs\\nappearedinGPT-4promptarerandomlyswappedtoavoidanybias. Asexpected,thewin-rateinfavorof\\nLlama 2-Chat is less pronounced, although obtaining more than a 60% win-rate for our latest Llama 2-Chat .\\nThe prompts correspond to a validation set of 1,586and584prompts for safety and helpfulness, respectively.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-17'),\n",
              " 'ce618797-4592-4dde-ae34-8f52fd636e96': IndexNode(id_='ce618797-4592-4dde-ae34-8f52fd636e96', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-17', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='fbf315836074ae5e01f8a617565ce5b7e7a60ca9196a62c38f71fa99b99c31ab'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='b8084425-cdb3-46d1-b374-326332825735', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='f40ec42c174136185b0e8f04fea62410c64368f2ae8e5db1c591ec4ba214f039'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='dc156a80-3847-4205-b9e7-c04c58c8c2f5', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='da3ad3a23456050387ccd31caa2c5cd588b13e17e9c4043e9a4d91d21ae29a5a')}, hash='49ad3399d95f9c50959f485e928c854754cd98eed863b3062395b0b66d35f3d6', text='3.4.2 Human Evaluation\\nHuman evaluation is often considered the gold standardfor judging models fornatural language generation,\\nincluding dialogue models. To evaluate the quality of major model versions, we asked human evaluators to\\nrate them on helpfulness and safety. We compare the Llama 2-Chat models to open-source models (Falcon,\\nMPT MosaicML NLP Team et al. (2023), Vicuna Chiang et al.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-17'),\n",
              " 'dc156a80-3847-4205-b9e7-c04c58c8c2f5': IndexNode(id_='dc156a80-3847-4205-b9e7-c04c58c8c2f5', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-17', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='fbf315836074ae5e01f8a617565ce5b7e7a60ca9196a62c38f71fa99b99c31ab'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='ce618797-4592-4dde-ae34-8f52fd636e96', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='49ad3399d95f9c50959f485e928c854754cd98eed863b3062395b0b66d35f3d6')}, hash='da3ad3a23456050387ccd31caa2c5cd588b13e17e9c4043e9a4d91d21ae29a5a', text='(2023), Vicuna Chiang et al. (2023), as well as closed-source models (Chat-\\nGPT(OpenAI,2023)andPaLMAniletal.(2023))onover 4,000singleandmulti-turnprompts.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-17'),\n",
              " '70623417-8fd1-41ac-9f0e-bdb8465f195b': IndexNode(id_='70623417-8fd1-41ac-9f0e-bdb8465f195b', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-17', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='fbf315836074ae5e01f8a617565ce5b7e7a60ca9196a62c38f71fa99b99c31ab'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='b5bec6fb-5c50-411d-af4c-ad79ccd7af16', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='6c831040ae499f9bf2277f8691b8f5f04b24e05b581b9aed1e7d452c8b67432f')}, hash='d4c6e1015e0bd3f0e9b7d69a83d7fbb2fe1c79052f853390559273bb367a096d', text='How Far Can Model-Based Evaluation Go? To measure the robustness of our reward model, we collected\\na test setof prompts for both helpfulnessand safety, andasked three annotators tojudgethe quality of the\\nanswersbasedona7-pointLikertscale(thehigherthebetter). Weobservethatourrewardmodelsoverall\\nare well calibrated with our human preference annotations, as illustrated in Figure 29 in the appendix. This\\nconfirms the relevance of using our reward as a point-wise metric, despite being trained with a Pairwise\\nRanking Loss.\\nStill, as Goodhart’s Law states, when a measure becomes a target, it ceases to be a good measure. To ensure\\nourmeasurewon’tdivergefromthehumanpreferences,weadditionallyusedamoregeneralreward,trained\\n17\\n\\nRLHF- v5\\n(with PPO)\\nRLHF- v5\\n(no PPO)\\nRLHF- v4\\nRLHF- v3\\n            RLHF- v2      RLHF- v1', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-17'),\n",
              " 'b5bec6fb-5c50-411d-af4c-ad79ccd7af16': IndexNode(id_='b5bec6fb-5c50-411d-af4c-ad79ccd7af16', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-17', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='fbf315836074ae5e01f8a617565ce5b7e7a60ca9196a62c38f71fa99b99c31ab'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='70623417-8fd1-41ac-9f0e-bdb8465f195b', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='d4c6e1015e0bd3f0e9b7d69a83d7fbb2fe1c79052f853390559273bb367a096d'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='c1d77fc5-5542-4443-b973-4a15b1dd8a61', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='3db1413d45425cbc6f3419513e2c6f2d0dc71642b2eae54b58643a1fb54c7ce2')}, hash='6c831040ae499f9bf2277f8691b8f5f04b24e05b581b9aed1e7d452c8b67432f', text='RLHF- v2      RLHF- v1 SFT-v2       \\nSFT-v1\\n10% 20% 30% 40% 50% 60% 70% 80% 90%10%20%30%40%50%60%70%80%\\nHelpfulness\\nJudge: Meta R ewar d ModelsHarmlessness\\n  RLHF- v5\\n  (with PPO)RLHF- v5  \\n(no PPO)  \\nRLHF- v4\\nRLHF- v3\\n     RLHF- v2RLHF- v1     \\nSFT-v2    \\nSFT-v1\\n10% 20% 30% 40% 50% 60% 70% 80% 90%10%20%30%40%50%60%70%80%\\nHelpfulness\\nJudge: GPT -4HarmlessnessFigure 11: Evolution of Llama 2-Chat . We show the evolution after multiple iterations fine-tuning for the\\nwin-rate%of Llama 2-Chat comparedtoChatGPT.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-17'),\n",
              " 'c1d77fc5-5542-4443-b973-4a15b1dd8a61': IndexNode(id_='c1d77fc5-5542-4443-b973-4a15b1dd8a61', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-17', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='fbf315836074ae5e01f8a617565ce5b7e7a60ca9196a62c38f71fa99b99c31ab'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='b5bec6fb-5c50-411d-af4c-ad79ccd7af16', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='6c831040ae499f9bf2277f8691b8f5f04b24e05b581b9aed1e7d452c8b67432f'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='1d1a80fb-c195-4e94-9f01-96303dc675f8', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='6d7b60a808d91961d45f7ace32d189eb4975e15439a83ed8ce6395f5f0a1ae7d')}, hash='3db1413d45425cbc6f3419513e2c6f2d0dc71642b2eae54b58643a1fb54c7ce2', text='Left: thejudgeisourrewardmodel,whichmayfavor\\nour model, and right, the judge is GPT-4, which should be more neutral.\\non diverse open-source Reward Modeling datasets. We have not yet observed any such divergence, and\\nhypothesize that iterative model updates may be helping to prevent this.\\nAs a last verification step to ensure no regression between our new model and the previous one, we use both\\nto sample during the next annotation iteration. This enables a model comparison “for free” on new prompts\\nand can help to increase diversity when sampling.\\nProgressionofModels. Figure11reportstheprogressofourdifferentSFTandthenRLHFversionsfor\\nboth Safetyand Helpfulnessaxes, measuredbyour in-houseSafetyand Helpfulnessreward models. On\\nthis set of evaluations, we outperform ChatGPT on both axes after RLHF-V3 (harmlessness and helpfulness\\n>50%). Despite the aforementioned relevance of using our reward as a point-wise metric, it can arguably be\\nbiased in favor of Llama 2-Chat .', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-17'),\n",
              " '1d1a80fb-c195-4e94-9f01-96303dc675f8': IndexNode(id_='1d1a80fb-c195-4e94-9f01-96303dc675f8', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-17', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='fbf315836074ae5e01f8a617565ce5b7e7a60ca9196a62c38f71fa99b99c31ab'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='c1d77fc5-5542-4443-b973-4a15b1dd8a61', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='3db1413d45425cbc6f3419513e2c6f2d0dc71642b2eae54b58643a1fb54c7ce2'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='e0456ab7-7ce6-4551-88fa-3f9a6d557245', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='da3ad3a23456050387ccd31caa2c5cd588b13e17e9c4043e9a4d91d21ae29a5a')}, hash='6d7b60a808d91961d45f7ace32d189eb4975e15439a83ed8ce6395f5f0a1ae7d', text='Therefore, for a fair comparison, we additionally compute the final results\\nusingGPT-4toassesswhichgenerationispreferred. TheorderinwhichChatGPTand Llama 2-Chat outputs\\nappearedinGPT-4promptarerandomlyswappedtoavoidanybias. Asexpected,thewin-rateinfavorof\\nLlama 2-Chat is less pronounced, although obtaining more than a 60% win-rate for our latest Llama 2-Chat .\\nThe prompts correspond to a validation set of 1,586and584prompts for safety and helpfulness, respectively.\\n3.4.2 Human Evaluation\\nHuman evaluation is often considered the gold standardfor judging models fornatural language generation,\\nincluding dialogue models. To evaluate the quality of major model versions, we asked human evaluators to\\nrate them on helpfulness and safety. We compare the Llama 2-Chat models to open-source models (Falcon,\\nMPT MosaicML NLP Team et al. (2023), Vicuna Chiang et al.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-17'),\n",
              " 'e0456ab7-7ce6-4551-88fa-3f9a6d557245': IndexNode(id_='e0456ab7-7ce6-4551-88fa-3f9a6d557245', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-17', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='fbf315836074ae5e01f8a617565ce5b7e7a60ca9196a62c38f71fa99b99c31ab'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='1d1a80fb-c195-4e94-9f01-96303dc675f8', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='6d7b60a808d91961d45f7ace32d189eb4975e15439a83ed8ce6395f5f0a1ae7d')}, hash='da3ad3a23456050387ccd31caa2c5cd588b13e17e9c4043e9a4d91d21ae29a5a', text='(2023), Vicuna Chiang et al. (2023), as well as closed-source models (Chat-\\nGPT(OpenAI,2023)andPaLMAniletal.(2023))onover 4,000singleandmulti-turnprompts.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-17'),\n",
              " 'a121d4bf-eff6-4000-a698-86901a1154da': IndexNode(id_='a121d4bf-eff6-4000-a698-86901a1154da', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-17', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='fbf315836074ae5e01f8a617565ce5b7e7a60ca9196a62c38f71fa99b99c31ab'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='f0724a05-1452-419e-96d5-2f2eb4569a00', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='a27d8693be4b6b0807af09d650b06a54ab28e3e87f2cf176e4373147954dcf5a')}, hash='f7dafbf7eaa3342aafb410c95763877ddab93055c7578856b1c7f38b838911b7', text='How Far Can Model-Based Evaluation Go? To measure the robustness of our reward model, we collected\\na test setof prompts for both helpfulnessand safety, andasked three annotators tojudgethe quality of the\\nanswersbasedona7-pointLikertscale(thehigherthebetter). Weobservethatourrewardmodelsoverall\\nare well calibrated with our human preference annotations, as illustrated in Figure 29 in the appendix. This\\nconfirms the relevance of using our reward as a point-wise metric, despite being trained with a Pairwise\\nRanking Loss.\\nStill, as Goodhart’s Law states, when a measure becomes a target, it ceases to be a good measure. To ensure\\nourmeasurewon’tdivergefromthehumanpreferences,weadditionallyusedamoregeneralreward,trained\\n17\\n\\nRLHF- v5\\n(with PPO)\\nRLHF- v5\\n(no PPO)\\nRLHF- v4\\nRLHF- v3\\n            RLHF- v2      RLHF- v1 SFT-v2       \\nSFT-v1\\n10% 20% 30% 40% 50% 60% 70% 80% 90%10%20%30%40%50%60%70%80%\\nHelpfulness\\nJudge: Meta R ewar d ModelsHarmlessness\\n  RLHF- v5\\n  (with PPO)RLHF- v5  \\n(no PPO)  \\nRLHF- v4\\nRLHF- v3\\n     RLHF- v2RLHF- v1     \\nSFT-v2    \\nSFT-v1\\n10% 20% 30% 40% 50% 60% 70% 80% 90%10%20%30%40%50%60%70%80%\\nHelpfulness\\nJudge: GPT -4HarmlessnessFigure 11: Evolution of Llama 2-Chat . We show the evolution after multiple iterations fine-tuning for the\\nwin-rate%of Llama 2-Chat comparedtoChatGPT.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-17'),\n",
              " 'f0724a05-1452-419e-96d5-2f2eb4569a00': IndexNode(id_='f0724a05-1452-419e-96d5-2f2eb4569a00', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-17', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='fbf315836074ae5e01f8a617565ce5b7e7a60ca9196a62c38f71fa99b99c31ab'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='a121d4bf-eff6-4000-a698-86901a1154da', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='f7dafbf7eaa3342aafb410c95763877ddab93055c7578856b1c7f38b838911b7'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='d169019a-b71a-431f-9d1b-7b6ee396864c', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='7a0775554b7d2312d13cf086426b9ecf762820fe81d7eb2445c2a2c12f8033e2')}, hash='a27d8693be4b6b0807af09d650b06a54ab28e3e87f2cf176e4373147954dcf5a', text='Left: thejudgeisourrewardmodel,whichmayfavor\\nour model, and right, the judge is GPT-4, which should be more neutral.\\non diverse open-source Reward Modeling datasets. We have not yet observed any such divergence, and\\nhypothesize that iterative model updates may be helping to prevent this.\\nAs a last verification step to ensure no regression between our new model and the previous one, we use both\\nto sample during the next annotation iteration. This enables a model comparison “for free” on new prompts\\nand can help to increase diversity when sampling.\\nProgressionofModels. Figure11reportstheprogressofourdifferentSFTandthenRLHFversionsfor\\nboth Safetyand Helpfulnessaxes, measuredbyour in-houseSafetyand Helpfulnessreward models. On\\nthis set of evaluations, we outperform ChatGPT on both axes after RLHF-V3 (harmlessness and helpfulness\\n>50%). Despite the aforementioned relevance of using our reward as a point-wise metric, it can arguably be\\nbiased in favor of Llama 2-Chat . Therefore, for a fair comparison, we additionally compute the final results\\nusingGPT-4toassesswhichgenerationispreferred. TheorderinwhichChatGPTand Llama 2-Chat outputs\\nappearedinGPT-4promptarerandomlyswappedtoavoidanybias. Asexpected,thewin-rateinfavorof\\nLlama 2-Chat is less pronounced, although obtaining more than a 60% win-rate for our latest Llama 2-Chat .\\nThe prompts correspond to a validation set of 1,586and584prompts for safety and helpfulness, respectively.\\n3.4.2 Human Evaluation\\nHuman evaluation is often considered the gold standardfor judging models fornatural language generation,\\nincluding dialogue models. To evaluate the quality of major model versions, we asked human evaluators to\\nrate them on helpfulness and safety. We compare the Llama 2-Chat models to open-source models (Falcon,\\nMPT MosaicML NLP Team et al. (2023), Vicuna Chiang et al. (2023), as well as closed-source models (Chat-\\nGPT(OpenAI,2023)andPaLMAniletal.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-17'),\n",
              " 'd169019a-b71a-431f-9d1b-7b6ee396864c': IndexNode(id_='d169019a-b71a-431f-9d1b-7b6ee396864c', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-17', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='fbf315836074ae5e01f8a617565ce5b7e7a60ca9196a62c38f71fa99b99c31ab'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='f0724a05-1452-419e-96d5-2f2eb4569a00', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='a27d8693be4b6b0807af09d650b06a54ab28e3e87f2cf176e4373147954dcf5a')}, hash='7a0775554b7d2312d13cf086426b9ecf762820fe81d7eb2445c2a2c12f8033e2', text='(2023))onover 4,000singleandmulti-turnprompts.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-17'),\n",
              " 'node-17': IndexNode(id_='node-17', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='415b7efc-e73f-4ac4-bbfd-c1546f099026', node_type=<ObjectType.DOCUMENT: '4'>, metadata={}, hash='231b3bd773f012c01b893ada9e009ecf25ee59934614c5a595c9bf1b3a123292'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='cebe3444-545d-4dd5-a097-4708593e44da', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='7d42646b16c71668e6588209bca220749af0e8383f8c5e42acb0afb1a957409f'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='86252bea-9c5f-4a3d-94c3-3e4381a079e8', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='bacb7624ae0b64581b824a22b0e09f63620d52404bbce3fa755abe115dafe8ea')}, hash='fbf315836074ae5e01f8a617565ce5b7e7a60ca9196a62c38f71fa99b99c31ab', text='How Far Can Model-Based Evaluation Go? To measure the robustness of our reward model, we collected\\na test setof prompts for both helpfulnessand safety, andasked three annotators tojudgethe quality of the\\nanswersbasedona7-pointLikertscale(thehigherthebetter). Weobservethatourrewardmodelsoverall\\nare well calibrated with our human preference annotations, as illustrated in Figure 29 in the appendix. This\\nconfirms the relevance of using our reward as a point-wise metric, despite being trained with a Pairwise\\nRanking Loss.\\nStill, as Goodhart’s Law states, when a measure becomes a target, it ceases to be a good measure. To ensure\\nourmeasurewon’tdivergefromthehumanpreferences,weadditionallyusedamoregeneralreward,trained\\n17\\n\\nRLHF- v5\\n(with PPO)\\nRLHF- v5\\n(no PPO)\\nRLHF- v4\\nRLHF- v3\\n            RLHF- v2      RLHF- v1 SFT-v2       \\nSFT-v1\\n10% 20% 30% 40% 50% 60% 70% 80% 90%10%20%30%40%50%60%70%80%\\nHelpfulness\\nJudge: Meta R ewar d ModelsHarmlessness\\n  RLHF- v5\\n  (with PPO)RLHF- v5  \\n(no PPO)  \\nRLHF- v4\\nRLHF- v3\\n     RLHF- v2RLHF- v1     \\nSFT-v2    \\nSFT-v1\\n10% 20% 30% 40% 50% 60% 70% 80% 90%10%20%30%40%50%60%70%80%\\nHelpfulness\\nJudge: GPT -4HarmlessnessFigure 11: Evolution of Llama 2-Chat . We show the evolution after multiple iterations fine-tuning for the\\nwin-rate%of Llama 2-Chat comparedtoChatGPT. Left: thejudgeisourrewardmodel,whichmayfavor\\nour model, and right, the judge is GPT-4, which should be more neutral.\\non diverse open-source Reward Modeling datasets. We have not yet observed any such divergence, and\\nhypothesize that iterative model updates may be helping to prevent this.\\nAs a last verification step to ensure no regression between our new model and the previous one, we use both\\nto sample during the next annotation iteration. This enables a model comparison “for free” on new prompts\\nand can help to increase diversity when sampling.\\nProgressionofModels. Figure11reportstheprogressofourdifferentSFTandthenRLHFversionsfor\\nboth Safetyand Helpfulnessaxes, measuredbyour in-houseSafetyand Helpfulnessreward models. On\\nthis set of evaluations, we outperform ChatGPT on both axes after RLHF-V3 (harmlessness and helpfulness\\n>50%). Despite the aforementioned relevance of using our reward as a point-wise metric, it can arguably be\\nbiased in favor of Llama 2-Chat . Therefore, for a fair comparison, we additionally compute the final results\\nusingGPT-4toassesswhichgenerationispreferred. TheorderinwhichChatGPTand Llama 2-Chat outputs\\nappearedinGPT-4promptarerandomlyswappedtoavoidanybias. Asexpected,thewin-rateinfavorof\\nLlama 2-Chat is less pronounced, although obtaining more than a 60% win-rate for our latest Llama 2-Chat .\\nThe prompts correspond to a validation set of 1,586and584prompts for safety and helpfulness, respectively.\\n3.4.2 Human Evaluation\\nHuman evaluation is often considered the gold standardfor judging models fornatural language generation,\\nincluding dialogue models. To evaluate the quality of major model versions, we asked human evaluators to\\nrate them on helpfulness and safety. We compare the Llama 2-Chat models to open-source models (Falcon,\\nMPT MosaicML NLP Team et al. (2023), Vicuna Chiang et al. (2023), as well as closed-source models (Chat-\\nGPT(OpenAI,2023)andPaLMAniletal.(2023))onover 4,000singleandmulti-turnprompts.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-17'),\n",
              " 'e556310f-3245-41ec-94ec-e186408e4b66': IndexNode(id_='e556310f-3245-41ec-94ec-e186408e4b66', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-18', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='bacb7624ae0b64581b824a22b0e09f63620d52404bbce3fa755abe115dafe8ea'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='289c1650-755c-4e16-9363-7aaa686ef6a1', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='7fa15a6f65b739780e18dcca82ab4a49d0177ffe4123e7ec01088dff1ad54a1e')}, hash='809700d516ac9d4a271c4a0e28f700177d479eda95c05b198d49c04347b59464', text='(2023))onover 4,000singleandmulti-turnprompts. ForChatGPT,\\nweuse gpt-3.5-turbo-0301 modelinallgenerations. ForPaLM,weusethe chat-bison-001 modelinall\\ngenerations. ThefinalpromptcountforhumanevaluationsforeachmodelisshowninTable32. Seemore\\nmethodology details in Appendix, Section A.3.7. The following section shows helpfulness results; safety\\nresults are presented in Section 4.4.\\nResults.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-18'),\n",
              " '289c1650-755c-4e16-9363-7aaa686ef6a1': IndexNode(id_='289c1650-755c-4e16-9363-7aaa686ef6a1', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-18', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='bacb7624ae0b64581b824a22b0e09f63620d52404bbce3fa755abe115dafe8ea'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='e556310f-3245-41ec-94ec-e186408e4b66', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='809700d516ac9d4a271c4a0e28f700177d479eda95c05b198d49c04347b59464'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='7f71479d-69f0-4227-8c15-2244b6efa4c7', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='6443455ff9042b9428a92bdda5be2b56bb1376917fdd5e4ef2e90aba3892f6f2')}, hash='7fa15a6f65b739780e18dcca82ab4a49d0177ffe4123e7ec01088dff1ad54a1e', text='Results. AsshowninFigure12, Llama 2-Chat modelsoutperformopen-sourcemodelsbyasignificant\\nmargin on both single turn and multi-turn prompts. Particularly, Llama 2-Chat 7B model outperforms\\nMPT-7B-chaton60%oftheprompts. Llama 2-Chat 34Bhasanoverallwinrateofmorethan75%against\\nequivalently sized Vicuna-33B and Falcon 40B models.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-18'),\n",
              " '7f71479d-69f0-4227-8c15-2244b6efa4c7': IndexNode(id_='7f71479d-69f0-4227-8c15-2244b6efa4c7', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-18', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='bacb7624ae0b64581b824a22b0e09f63620d52404bbce3fa755abe115dafe8ea'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='289c1650-755c-4e16-9363-7aaa686ef6a1', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='7fa15a6f65b739780e18dcca82ab4a49d0177ffe4123e7ec01088dff1ad54a1e'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='01dba903-c3ce-499b-a65d-3e6e31b4c289', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='46a7b1d3e925418cfb9346de2e6b7a334c23b6513ac041824271a753123fe508')}, hash='6443455ff9042b9428a92bdda5be2b56bb1376917fdd5e4ef2e90aba3892f6f2', text='18\\n\\nFigure12: Humanevaluationresults forLlama 2-Chat modelscomparedtoopen-andclosed-sourcemodels\\nacross ~4,000 helpfulness prompts with three raters per prompt.\\nThelargest Llama 2-Chat modeliscompetitivewithChatGPT. Llama 2-Chat 70Bmodelhasawinrateof\\n36% and a tie rate of 31.5% relative to ChatGPT. Llama 2-Chat 70B model outperforms PaLM-bison chat\\nmodel by a large percentage on our prompt set.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-18'),\n",
              " '01dba903-c3ce-499b-a65d-3e6e31b4c289': IndexNode(id_='01dba903-c3ce-499b-a65d-3e6e31b4c289', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-18', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='bacb7624ae0b64581b824a22b0e09f63620d52404bbce3fa755abe115dafe8ea'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='7f71479d-69f0-4227-8c15-2244b6efa4c7', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='6443455ff9042b9428a92bdda5be2b56bb1376917fdd5e4ef2e90aba3892f6f2'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='5b6c05b4-7d5f-4576-8a35-6768a4da3865', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='1101435695cdf8dcf1cc263aff761f321c748716df803840f1714b9b796a2be9')}, hash='46a7b1d3e925418cfb9346de2e6b7a334c23b6513ac041824271a753123fe508', text='More results and analysis is available in Section A.3.7.\\nInter-Rater Reliability (IRR). In our human evaluations, three different annotators provided independent\\nassessments for each model generation comparison. High IRR scores (closer to 1.0) are typically seen as\\nbetter from a data quality perspective, however, context is important. Highly subjective tasks like evaluating\\nthe overall helpfulness of LLM generations will usually have lower IRR scores than more objective labelling\\ntasks.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-18'),\n",
              " '5b6c05b4-7d5f-4576-8a35-6768a4da3865': IndexNode(id_='5b6c05b4-7d5f-4576-8a35-6768a4da3865', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-18', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='bacb7624ae0b64581b824a22b0e09f63620d52404bbce3fa755abe115dafe8ea'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='01dba903-c3ce-499b-a65d-3e6e31b4c289', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='46a7b1d3e925418cfb9346de2e6b7a334c23b6513ac041824271a753123fe508'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='5ddcc653-6051-4f1f-a37d-2c1b69c374b4', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='7a741201bc868a8af7e86af386a73536c17f2dc0553d76b7d311a1afeb40a9af')}, hash='1101435695cdf8dcf1cc263aff761f321c748716df803840f1714b9b796a2be9', text='There arerelativelyfewpublicbenchmarksfor thesecontexts, sowefeelsharing ouranalysis herewill\\nbenefit the research community.\\nWe used Gwet’s AC1/2 statistic (Gwet, 2008, 2014) to measure inter-rater reliability (IRR), as we found it to\\nbethemoststablemetricacrossdifferentmeasurementscenarios.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-18'),\n",
              " '5ddcc653-6051-4f1f-a37d-2c1b69c374b4': IndexNode(id_='5ddcc653-6051-4f1f-a37d-2c1b69c374b4', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-18', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='bacb7624ae0b64581b824a22b0e09f63620d52404bbce3fa755abe115dafe8ea'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='5b6c05b4-7d5f-4576-8a35-6768a4da3865', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='1101435695cdf8dcf1cc263aff761f321c748716df803840f1714b9b796a2be9'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='5a7b2a53-b584-4c1c-9b92-f779569a5d5b', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='40568c2911cb5cf1d269db0767e30a5c1be52a80050a95048e87e677d3f6db85')}, hash='7a741201bc868a8af7e86af386a73536c17f2dc0553d76b7d311a1afeb40a9af', text='Onthe7-pointLikertscalehelpfulness\\ntaskthatisusedinouranalysis,Gwet’sAC2scorevariesbetween 0.37and0.55dependingonthespecific\\nmodelcomparison. Weseescoresonthelowerendofthatrangeforratingsfrommodelcomparisonswith\\nsimilar win rates to each other (like the Llama 2-Chat -70B-chat vs. ChatGPT comparison).', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-18'),\n",
              " '5a7b2a53-b584-4c1c-9b92-f779569a5d5b': IndexNode(id_='5a7b2a53-b584-4c1c-9b92-f779569a5d5b', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-18', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='bacb7624ae0b64581b824a22b0e09f63620d52404bbce3fa755abe115dafe8ea'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='5ddcc653-6051-4f1f-a37d-2c1b69c374b4', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='7a741201bc868a8af7e86af386a73536c17f2dc0553d76b7d311a1afeb40a9af'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='440b69c8-f169-4117-ab49-e960a408c6ab', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='52d5baaeaef038bd74867d21bc54c5a9b3e993bbc42d056189438febf5c9b6f2')}, hash='40568c2911cb5cf1d269db0767e30a5c1be52a80050a95048e87e677d3f6db85', text='ChatGPT comparison). We see scores on\\nthehigherendofthatrangeforratingsfrommodelcomparisonswithamoreclearwinner(likethe Llama\\n2-Chat-34b-chat vs. Falcon-40b-instruct).\\nLimitations of human evaluations. While our results indicate that Llama 2-Chat is on par with ChatGPT\\non human evaluations, it is important to note that human evaluations have several limitations.\\n•Byacademicandresearchstandards,wehavealargepromptsetof4kprompts.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-18'),\n",
              " '440b69c8-f169-4117-ab49-e960a408c6ab': IndexNode(id_='440b69c8-f169-4117-ab49-e960a408c6ab', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-18', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='bacb7624ae0b64581b824a22b0e09f63620d52404bbce3fa755abe115dafe8ea'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='5a7b2a53-b584-4c1c-9b92-f779569a5d5b', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='40568c2911cb5cf1d269db0767e30a5c1be52a80050a95048e87e677d3f6db85'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='231e5fe0-7115-485b-ba7a-cac0523e6d53', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='07b85f7213583f8dff2ec0bf9ba799df57c2d8424ebce92c7a31ae315ae36834')}, hash='52d5baaeaef038bd74867d21bc54c5a9b3e993bbc42d056189438febf5c9b6f2', text='However,itdoesnotcover\\nreal-world usage of these models, which will likely cover a significantly larger number of use cases.\\n•Diversity of the prompts could be another factor in our results. For example, our prompt set does not\\ninclude any coding- or reasoning-related prompts.\\n•We only evaluate the final generation of a multi-turn conversation. A more interesting evaluation could be\\nto ask the models to complete a task and rate the overall experience with the model over multiple turns.\\n•Humanevaluationforgenerativemodelsisinherentlysubjectiveandnoisy.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-18'),\n",
              " '231e5fe0-7115-485b-ba7a-cac0523e6d53': IndexNode(id_='231e5fe0-7115-485b-ba7a-cac0523e6d53', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-18', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='bacb7624ae0b64581b824a22b0e09f63620d52404bbce3fa755abe115dafe8ea'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='440b69c8-f169-4117-ab49-e960a408c6ab', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='52d5baaeaef038bd74867d21bc54c5a9b3e993bbc42d056189438febf5c9b6f2')}, hash='07b85f7213583f8dff2ec0bf9ba799df57c2d8424ebce92c7a31ae315ae36834', text='•Humanevaluationforgenerativemodelsisinherentlysubjectiveandnoisy. Asaresult,evaluationona\\ndifferent set of prompts or with different instructions could result in different results.\\n19\\n\\n4 Safety\\nWARNING: this section contains examples of text that may be considered unsafe, offensive, or upsetting.\\nIn this section, we dive deeper into the important topic of safety measurements and mitigations. We first\\ndiscussoursafetyinvestigationsintopretrainingdataandpretrainedmodels(Section4.1).', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-18'),\n",
              " '6f88845b-8a38-400d-a0a5-423732d0b483': IndexNode(id_='6f88845b-8a38-400d-a0a5-423732d0b483', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-18', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='bacb7624ae0b64581b824a22b0e09f63620d52404bbce3fa755abe115dafe8ea'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='8918a5b8-c3a1-40e1-af33-0bca9261468a', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='692a57d004dd02c97e6e297a2c8d271ae3ccee4bdff3134626813cea37ae4d4f')}, hash='fa6757eabe245da1e922c0146b96598ede12f1730d214e87d2e82eaf620e52ec', text='(2023))onover 4,000singleandmulti-turnprompts. ForChatGPT,\\nweuse gpt-3.5-turbo-0301 modelinallgenerations. ForPaLM,weusethe chat-bison-001 modelinall\\ngenerations. ThefinalpromptcountforhumanevaluationsforeachmodelisshowninTable32. Seemore\\nmethodology details in Appendix, Section A.3.7. The following section shows helpfulness results; safety\\nresults are presented in Section 4.4.\\nResults. AsshowninFigure12, Llama 2-Chat modelsoutperformopen-sourcemodelsbyasignificant\\nmargin on both single turn and multi-turn prompts. Particularly, Llama 2-Chat 7B model outperforms\\nMPT-7B-chaton60%oftheprompts. Llama 2-Chat 34Bhasanoverallwinrateofmorethan75%against\\nequivalently sized Vicuna-33B and Falcon 40B models.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-18'),\n",
              " '8918a5b8-c3a1-40e1-af33-0bca9261468a': IndexNode(id_='8918a5b8-c3a1-40e1-af33-0bca9261468a', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-18', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='bacb7624ae0b64581b824a22b0e09f63620d52404bbce3fa755abe115dafe8ea'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='6f88845b-8a38-400d-a0a5-423732d0b483', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='fa6757eabe245da1e922c0146b96598ede12f1730d214e87d2e82eaf620e52ec'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='877464a2-c273-4dba-adef-087ceed4157a', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='b56eba78c7f5b057df678b605d779412a844f2d4c4237ed1969c004813ef5eaf')}, hash='692a57d004dd02c97e6e297a2c8d271ae3ccee4bdff3134626813cea37ae4d4f', text='18\\n\\nFigure12: Humanevaluationresults forLlama 2-Chat modelscomparedtoopen-andclosed-sourcemodels\\nacross ~4,000 helpfulness prompts with three raters per prompt.\\nThelargest Llama 2-Chat modeliscompetitivewithChatGPT. Llama 2-Chat 70Bmodelhasawinrateof\\n36% and a tie rate of 31.5% relative to ChatGPT. Llama 2-Chat 70B model outperforms PaLM-bison chat\\nmodel by a large percentage on our prompt set. More results and analysis is available in Section A.3.7.\\nInter-Rater Reliability (IRR). In our human evaluations, three different annotators provided independent\\nassessments for each model generation comparison. High IRR scores (closer to 1.0) are typically seen as\\nbetter from a data quality perspective, however, context is important. Highly subjective tasks like evaluating\\nthe overall helpfulness of LLM generations will usually have lower IRR scores than more objective labelling\\ntasks.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-18'),\n",
              " '877464a2-c273-4dba-adef-087ceed4157a': IndexNode(id_='877464a2-c273-4dba-adef-087ceed4157a', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-18', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='bacb7624ae0b64581b824a22b0e09f63620d52404bbce3fa755abe115dafe8ea'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='8918a5b8-c3a1-40e1-af33-0bca9261468a', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='692a57d004dd02c97e6e297a2c8d271ae3ccee4bdff3134626813cea37ae4d4f'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='ee3d007e-0c88-4cfa-8538-4d5ee1ce3c92', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='2043a922539a8553cdabdb6bbb45794b19efce8d800c6d76600cf85d1b67e462')}, hash='b56eba78c7f5b057df678b605d779412a844f2d4c4237ed1969c004813ef5eaf', text='There arerelativelyfewpublicbenchmarksfor thesecontexts, sowefeelsharing ouranalysis herewill\\nbenefit the research community.\\nWe used Gwet’s AC1/2 statistic (Gwet, 2008, 2014) to measure inter-rater reliability (IRR), as we found it to\\nbethemoststablemetricacrossdifferentmeasurementscenarios. Onthe7-pointLikertscalehelpfulness\\ntaskthatisusedinouranalysis,Gwet’sAC2scorevariesbetween 0.37and0.55dependingonthespecific\\nmodelcomparison. Weseescoresonthelowerendofthatrangeforratingsfrommodelcomparisonswith\\nsimilar win rates to each other (like the Llama 2-Chat -70B-chat vs. ChatGPT comparison). We see scores on\\nthehigherendofthatrangeforratingsfrommodelcomparisonswithamoreclearwinner(likethe Llama\\n2-Chat-34b-chat vs. Falcon-40b-instruct).\\nLimitations of human evaluations.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-18'),\n",
              " 'ee3d007e-0c88-4cfa-8538-4d5ee1ce3c92': IndexNode(id_='ee3d007e-0c88-4cfa-8538-4d5ee1ce3c92', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-18', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='bacb7624ae0b64581b824a22b0e09f63620d52404bbce3fa755abe115dafe8ea'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='877464a2-c273-4dba-adef-087ceed4157a', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='b56eba78c7f5b057df678b605d779412a844f2d4c4237ed1969c004813ef5eaf'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='31851ed4-1c4b-465e-a80b-f26b0279a6f7', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='fd995af2eea12c9b0bfae772d160eab2f880997740c6ad0981af6a49c1b24a32')}, hash='2043a922539a8553cdabdb6bbb45794b19efce8d800c6d76600cf85d1b67e462', text='Falcon-40b-instruct).\\nLimitations of human evaluations. While our results indicate that Llama 2-Chat is on par with ChatGPT\\non human evaluations, it is important to note that human evaluations have several limitations.\\n•Byacademicandresearchstandards,wehavealargepromptsetof4kprompts. However,itdoesnotcover\\nreal-world usage of these models, which will likely cover a significantly larger number of use cases.\\n•Diversity of the prompts could be another factor in our results. For example, our prompt set does not\\ninclude any coding- or reasoning-related prompts.\\n•We only evaluate the final generation of a multi-turn conversation. A more interesting evaluation could be\\nto ask the models to complete a task and rate the overall experience with the model over multiple turns.\\n•Humanevaluationforgenerativemodelsisinherentlysubjectiveandnoisy. Asaresult,evaluationona\\ndifferent set of prompts or with different instructions could result in different results.\\n19\\n\\n4 Safety\\nWARNING: this section contains examples of text that may be considered unsafe, offensive, or upsetting.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-18'),\n",
              " '31851ed4-1c4b-465e-a80b-f26b0279a6f7': IndexNode(id_='31851ed4-1c4b-465e-a80b-f26b0279a6f7', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-18', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='bacb7624ae0b64581b824a22b0e09f63620d52404bbce3fa755abe115dafe8ea'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='ee3d007e-0c88-4cfa-8538-4d5ee1ce3c92', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='2043a922539a8553cdabdb6bbb45794b19efce8d800c6d76600cf85d1b67e462')}, hash='fd995af2eea12c9b0bfae772d160eab2f880997740c6ad0981af6a49c1b24a32', text='In this section, we dive deeper into the important topic of safety measurements and mitigations. We first\\ndiscussoursafetyinvestigationsintopretrainingdataandpretrainedmodels(Section4.1).', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-18'),\n",
              " '9a60dff1-011b-488e-b226-2f142296a083': IndexNode(id_='9a60dff1-011b-488e-b226-2f142296a083', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-18', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='bacb7624ae0b64581b824a22b0e09f63620d52404bbce3fa755abe115dafe8ea'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='fd5efca6-6f54-4195-bfd2-18aa1c416f2f', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='80ea0f78982bcca350dcb94c0bb28d167aeb1e96daf593b4d329e1c04a45a2dd')}, hash='5e5d61ceb365296fbe48085ad148b277158197187c6de58443da6cbc0c8644c9', text='(2023))onover 4,000singleandmulti-turnprompts. ForChatGPT,\\nweuse gpt-3.5-turbo-0301 modelinallgenerations. ForPaLM,weusethe chat-bison-001 modelinall\\ngenerations. ThefinalpromptcountforhumanevaluationsforeachmodelisshowninTable32. Seemore\\nmethodology details in Appendix, Section A.3.7. The following section shows helpfulness results; safety\\nresults are presented in Section 4.4.\\nResults. AsshowninFigure12, Llama 2-Chat modelsoutperformopen-sourcemodelsbyasignificant\\nmargin on both single turn and multi-turn prompts. Particularly, Llama 2-Chat 7B model outperforms\\nMPT-7B-chaton60%oftheprompts. Llama 2-Chat 34Bhasanoverallwinrateofmorethan75%against\\nequivalently sized Vicuna-33B and Falcon 40B models.\\n18\\n\\nFigure12: Humanevaluationresults forLlama 2-Chat modelscomparedtoopen-andclosed-sourcemodels\\nacross ~4,000 helpfulness prompts with three raters per prompt.\\nThelargest Llama 2-Chat modeliscompetitivewithChatGPT. Llama 2-Chat 70Bmodelhasawinrateof\\n36% and a tie rate of 31.5% relative to ChatGPT. Llama 2-Chat 70B model outperforms PaLM-bison chat\\nmodel by a large percentage on our prompt set. More results and analysis is available in Section A.3.7.\\nInter-Rater Reliability (IRR). In our human evaluations, three different annotators provided independent\\nassessments for each model generation comparison. High IRR scores (closer to 1.0) are typically seen as\\nbetter from a data quality perspective, however, context is important. Highly subjective tasks like evaluating\\nthe overall helpfulness of LLM generations will usually have lower IRR scores than more objective labelling\\ntasks. There arerelativelyfewpublicbenchmarksfor thesecontexts, sowefeelsharing ouranalysis herewill\\nbenefit the research community.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-18'),\n",
              " 'fd5efca6-6f54-4195-bfd2-18aa1c416f2f': IndexNode(id_='fd5efca6-6f54-4195-bfd2-18aa1c416f2f', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-18', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='bacb7624ae0b64581b824a22b0e09f63620d52404bbce3fa755abe115dafe8ea'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='9a60dff1-011b-488e-b226-2f142296a083', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='5e5d61ceb365296fbe48085ad148b277158197187c6de58443da6cbc0c8644c9')}, hash='80ea0f78982bcca350dcb94c0bb28d167aeb1e96daf593b4d329e1c04a45a2dd', text='We used Gwet’s AC1/2 statistic (Gwet, 2008, 2014) to measure inter-rater reliability (IRR), as we found it to\\nbethemoststablemetricacrossdifferentmeasurementscenarios. Onthe7-pointLikertscalehelpfulness\\ntaskthatisusedinouranalysis,Gwet’sAC2scorevariesbetween 0.37and0.55dependingonthespecific\\nmodelcomparison. Weseescoresonthelowerendofthatrangeforratingsfrommodelcomparisonswith\\nsimilar win rates to each other (like the Llama 2-Chat -70B-chat vs. ChatGPT comparison). We see scores on\\nthehigherendofthatrangeforratingsfrommodelcomparisonswithamoreclearwinner(likethe Llama\\n2-Chat-34b-chat vs. Falcon-40b-instruct).\\nLimitations of human evaluations. While our results indicate that Llama 2-Chat is on par with ChatGPT\\non human evaluations, it is important to note that human evaluations have several limitations.\\n•Byacademicandresearchstandards,wehavealargepromptsetof4kprompts. However,itdoesnotcover\\nreal-world usage of these models, which will likely cover a significantly larger number of use cases.\\n•Diversity of the prompts could be another factor in our results. For example, our prompt set does not\\ninclude any coding- or reasoning-related prompts.\\n•We only evaluate the final generation of a multi-turn conversation. A more interesting evaluation could be\\nto ask the models to complete a task and rate the overall experience with the model over multiple turns.\\n•Humanevaluationforgenerativemodelsisinherentlysubjectiveandnoisy. Asaresult,evaluationona\\ndifferent set of prompts or with different instructions could result in different results.\\n19\\n\\n4 Safety\\nWARNING: this section contains examples of text that may be considered unsafe, offensive, or upsetting.\\nIn this section, we dive deeper into the important topic of safety measurements and mitigations. We first\\ndiscussoursafetyinvestigationsintopretrainingdataandpretrainedmodels(Section4.1).', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-18'),\n",
              " 'node-18': IndexNode(id_='node-18', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='415b7efc-e73f-4ac4-bbfd-c1546f099026', node_type=<ObjectType.DOCUMENT: '4'>, metadata={}, hash='231b3bd773f012c01b893ada9e009ecf25ee59934614c5a595c9bf1b3a123292'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='8bf3afeb-b8ef-49cf-99e8-22bb1ecad588', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='fbf315836074ae5e01f8a617565ce5b7e7a60ca9196a62c38f71fa99b99c31ab'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='4dc51dfd-9f12-4a2c-98d4-af64a9431396', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='13fb13483f68b94fd2b1e6dd07fa044e73fe9f25f3b11bd6364babed6147e852')}, hash='bacb7624ae0b64581b824a22b0e09f63620d52404bbce3fa755abe115dafe8ea', text='(2023))onover 4,000singleandmulti-turnprompts. ForChatGPT,\\nweuse gpt-3.5-turbo-0301 modelinallgenerations. ForPaLM,weusethe chat-bison-001 modelinall\\ngenerations. ThefinalpromptcountforhumanevaluationsforeachmodelisshowninTable32. Seemore\\nmethodology details in Appendix, Section A.3.7. The following section shows helpfulness results; safety\\nresults are presented in Section 4.4.\\nResults. AsshowninFigure12, Llama 2-Chat modelsoutperformopen-sourcemodelsbyasignificant\\nmargin on both single turn and multi-turn prompts. Particularly, Llama 2-Chat 7B model outperforms\\nMPT-7B-chaton60%oftheprompts. Llama 2-Chat 34Bhasanoverallwinrateofmorethan75%against\\nequivalently sized Vicuna-33B and Falcon 40B models.\\n18\\n\\nFigure12: Humanevaluationresults forLlama 2-Chat modelscomparedtoopen-andclosed-sourcemodels\\nacross ~4,000 helpfulness prompts with three raters per prompt.\\nThelargest Llama 2-Chat modeliscompetitivewithChatGPT. Llama 2-Chat 70Bmodelhasawinrateof\\n36% and a tie rate of 31.5% relative to ChatGPT. Llama 2-Chat 70B model outperforms PaLM-bison chat\\nmodel by a large percentage on our prompt set. More results and analysis is available in Section A.3.7.\\nInter-Rater Reliability (IRR). In our human evaluations, three different annotators provided independent\\nassessments for each model generation comparison. High IRR scores (closer to 1.0) are typically seen as\\nbetter from a data quality perspective, however, context is important. Highly subjective tasks like evaluating\\nthe overall helpfulness of LLM generations will usually have lower IRR scores than more objective labelling\\ntasks. There arerelativelyfewpublicbenchmarksfor thesecontexts, sowefeelsharing ouranalysis herewill\\nbenefit the research community.\\nWe used Gwet’s AC1/2 statistic (Gwet, 2008, 2014) to measure inter-rater reliability (IRR), as we found it to\\nbethemoststablemetricacrossdifferentmeasurementscenarios. Onthe7-pointLikertscalehelpfulness\\ntaskthatisusedinouranalysis,Gwet’sAC2scorevariesbetween 0.37and0.55dependingonthespecific\\nmodelcomparison. Weseescoresonthelowerendofthatrangeforratingsfrommodelcomparisonswith\\nsimilar win rates to each other (like the Llama 2-Chat -70B-chat vs. ChatGPT comparison). We see scores on\\nthehigherendofthatrangeforratingsfrommodelcomparisonswithamoreclearwinner(likethe Llama\\n2-Chat-34b-chat vs. Falcon-40b-instruct).\\nLimitations of human evaluations. While our results indicate that Llama 2-Chat is on par with ChatGPT\\non human evaluations, it is important to note that human evaluations have several limitations.\\n•Byacademicandresearchstandards,wehavealargepromptsetof4kprompts. However,itdoesnotcover\\nreal-world usage of these models, which will likely cover a significantly larger number of use cases.\\n•Diversity of the prompts could be another factor in our results. For example, our prompt set does not\\ninclude any coding- or reasoning-related prompts.\\n•We only evaluate the final generation of a multi-turn conversation. A more interesting evaluation could be\\nto ask the models to complete a task and rate the overall experience with the model over multiple turns.\\n•Humanevaluationforgenerativemodelsisinherentlysubjectiveandnoisy. Asaresult,evaluationona\\ndifferent set of prompts or with different instructions could result in different results.\\n19\\n\\n4 Safety\\nWARNING: this section contains examples of text that may be considered unsafe, offensive, or upsetting.\\nIn this section, we dive deeper into the important topic of safety measurements and mitigations. We first\\ndiscussoursafetyinvestigationsintopretrainingdataandpretrainedmodels(Section4.1).', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-18'),\n",
              " 'f08a18d6-2ad9-4033-822b-ef327279d1fc': IndexNode(id_='f08a18d6-2ad9-4033-822b-ef327279d1fc', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-19', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='13fb13483f68b94fd2b1e6dd07fa044e73fe9f25f3b11bd6364babed6147e852'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='fe343aba-99ad-4176-8803-4e9f6f6f0f87', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='38d49f32b9b2c94f7651692f3c305d6b1f2f80ddb8aae7cbfa3c3aa2e6dad695')}, hash='3f6d1e4b9f70eb9b1322e17c4c940531d650a15fb5e13310ad96df4f33f54d5d', text='Next,wedescribe\\ntheprocessofoursafetyalignment(Section4.2),explaininghowwecollectedsafety-relatedannotationsand\\nutilizedSFTandRLHF,andpresentexperimentalresults. Then,wediscusstheredteamingweperformedto\\nfurtherunderstandandimprovemodelsafety(Section4.3). Finally,wepresentquantitativesafetyevaluations\\nofLlama 2-Chat (Section 4.4). We also share a model card in the Appendix, in Table 52.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-19'),\n",
              " 'fe343aba-99ad-4176-8803-4e9f6f6f0f87': IndexNode(id_='fe343aba-99ad-4176-8803-4e9f6f6f0f87', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-19', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='13fb13483f68b94fd2b1e6dd07fa044e73fe9f25f3b11bd6364babed6147e852'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='f08a18d6-2ad9-4033-822b-ef327279d1fc', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='3f6d1e4b9f70eb9b1322e17c4c940531d650a15fb5e13310ad96df4f33f54d5d'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='b899f90b-fa92-4dde-835c-b7f3da43d414', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='649ccaad9e3cdba62fa6215de002666f3598fde98c2151f687fc3ef2b840ec32')}, hash='38d49f32b9b2c94f7651692f3c305d6b1f2f80ddb8aae7cbfa3c3aa2e6dad695', text='We also share a model card in the Appendix, in Table 52.\\n4.1 Safety in Pretraining\\nIt is important to understand what is in the pretraining data both to increase transparency and to shed\\nlightonrootcausesofpotentialdownstreamissues,suchaspotentialbiases. Thiscaninformwhat,ifany,\\ndownstream mitigations to consider, and help guide appropriate model use. In this section, we analyze the\\npretraining datafor distributionsof languages,demographic representations,and toxicity.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-19'),\n",
              " 'b899f90b-fa92-4dde-835c-b7f3da43d414': IndexNode(id_='b899f90b-fa92-4dde-835c-b7f3da43d414', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-19', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='13fb13483f68b94fd2b1e6dd07fa044e73fe9f25f3b11bd6364babed6147e852'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='fe343aba-99ad-4176-8803-4e9f6f6f0f87', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='38d49f32b9b2c94f7651692f3c305d6b1f2f80ddb8aae7cbfa3c3aa2e6dad695'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='39b06a59-405d-444b-baad-d6dd3fa23663', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='86e16dd623d6c2f49f1fd53ce35e2b1ac78b1ecc09c10462e3d938a25587c524')}, hash='649ccaad9e3cdba62fa6215de002666f3598fde98c2151f687fc3ef2b840ec32', text='Wealso present\\nthe results of testing the pretrained models on existing safety benchmarks.\\nSteps Taken to Pretrain Responsibly. We followed Meta’s standard privacy and legal review processes for\\neach dataset used in training. We did not use any Meta user data in training. We excluded data from certain\\nsitesknowntocontainahighvolumeofpersonalinformationaboutprivateindividuals. Wemadeabest\\neffort to train our models efficiently to reduce the carbon footprint of pretraining (Section 2.2.1).', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-19'),\n",
              " '39b06a59-405d-444b-baad-d6dd3fa23663': IndexNode(id_='39b06a59-405d-444b-baad-d6dd3fa23663', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-19', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='13fb13483f68b94fd2b1e6dd07fa044e73fe9f25f3b11bd6364babed6147e852'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='b899f90b-fa92-4dde-835c-b7f3da43d414', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='649ccaad9e3cdba62fa6215de002666f3598fde98c2151f687fc3ef2b840ec32'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='772c05ff-ca50-442e-8720-582e7db11eb2', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='eaa7218fa1a9d47466a407f7f49ad97e35aaecc748e7c2475b505db653051374')}, hash='86e16dd623d6c2f49f1fd53ce35e2b1ac78b1ecc09c10462e3d938a25587c524', text='Sharing our\\nmodelsbroadlywillreducetheneedforotherstotrainsimilarmodels. Noadditionalfilteringwasconducted\\nonthedatasets,toallow Llama 2 tobemorewidelyusableacrosstasks(e.g.,itcanbebetterusedforhate\\nspeechclassification),whileavoidingthepotentialfortheaccidentaldemographicerasuresometimescaused\\nbyover-scrubbing.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-19'),\n",
              " '772c05ff-ca50-442e-8720-582e7db11eb2': IndexNode(id_='772c05ff-ca50-442e-8720-582e7db11eb2', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-19', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='13fb13483f68b94fd2b1e6dd07fa044e73fe9f25f3b11bd6364babed6147e852'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='39b06a59-405d-444b-baad-d6dd3fa23663', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='86e16dd623d6c2f49f1fd53ce35e2b1ac78b1ecc09c10462e3d938a25587c524'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='c97cfa95-caf3-4e48-922c-dffe18ed3614', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='78e7039b2a22a03fe8c4b0ab7b7ce08f60bb92fd94a00738aad6fef8bfdf25fe')}, hash='eaa7218fa1a9d47466a407f7f49ad97e35aaecc748e7c2475b505db653051374', text='Importantly,thisallows Llama 2-Chat togeneralizemoreeffectivelyduringsafetytuning\\nwith fewer examples (Welbl et al., 2021; Korbak et al., 2023; Xu et al., 2021). As a result, Llama 2 models\\nshould be used carefully and deployed only after significant safety tuning is applied.\\nDemographic Representation: Pronouns. Bias in model generations may result from biases inherited\\nfrom the training data itself. For instance, Bailey et al.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-19'),\n",
              " 'c97cfa95-caf3-4e48-922c-dffe18ed3614': IndexNode(id_='c97cfa95-caf3-4e48-922c-dffe18ed3614', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-19', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='13fb13483f68b94fd2b1e6dd07fa044e73fe9f25f3b11bd6364babed6147e852'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='772c05ff-ca50-442e-8720-582e7db11eb2', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='eaa7218fa1a9d47466a407f7f49ad97e35aaecc748e7c2475b505db653051374'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='bbdb3651-99d9-4e20-a6a0-f54cdce4b2cc', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='f90afa637d5550ca1760c0d3a994b2ec7944b7aad3fa6eee0c1c09004fef89a0')}, hash='78e7039b2a22a03fe8c4b0ab7b7ce08f60bb92fd94a00738aad6fef8bfdf25fe', text='For instance, Bailey et al. (2022) shows that in massive text corpora, words\\nrepresenting “people” are often used in more similar contexts to words representing “men”than to words\\nrepresenting “women,” andGaneshetal.(2023)demonstratesthatamodel’sperformanceonfairnessmetrics\\ncan be highly dependent on how the model trains on data representing underrepresented demographic\\ngroups.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-19'),\n",
              " 'bbdb3651-99d9-4e20-a6a0-f54cdce4b2cc': IndexNode(id_='bbdb3651-99d9-4e20-a6a0-f54cdce4b2cc', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-19', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='13fb13483f68b94fd2b1e6dd07fa044e73fe9f25f3b11bd6364babed6147e852'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='c97cfa95-caf3-4e48-922c-dffe18ed3614', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='78e7039b2a22a03fe8c4b0ab7b7ce08f60bb92fd94a00738aad6fef8bfdf25fe'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='f22671f0-ad19-4803-96e7-5b8d9f607a2f', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='4c3f2bc7f7a0188f1ca72138cf10cb5b249d96c525f448be9dc12a80a39ea5c1')}, hash='f90afa637d5550ca1760c0d3a994b2ec7944b7aad3fa6eee0c1c09004fef89a0', text='WithinourEnglish-languagetrainingcorpus,wecomputedthefrequenciesofthemostcommon\\nEnglishpronounsinTable9a. Weobservethat Hepronounsaregenerallyoverrepresentedindocuments\\ncomparedto Shepronouns,echoingsimilarfrequencydifferencesobservedinpronominalusageforsimilarly\\nsized modelpretraining datasets(Chowdhery etal., 2022).', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-19'),\n",
              " 'f22671f0-ad19-4803-96e7-5b8d9f607a2f': IndexNode(id_='f22671f0-ad19-4803-96e7-5b8d9f607a2f', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-19', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='13fb13483f68b94fd2b1e6dd07fa044e73fe9f25f3b11bd6364babed6147e852'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='bbdb3651-99d9-4e20-a6a0-f54cdce4b2cc', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='f90afa637d5550ca1760c0d3a994b2ec7944b7aad3fa6eee0c1c09004fef89a0'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='a0417101-40f9-4655-8bed-9ac5c10316ee', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='7d6fb2cc3e1f4a6be64e315e86998c9b816cfdca9d9af17786dac869a1c8b4d3')}, hash='4c3f2bc7f7a0188f1ca72138cf10cb5b249d96c525f448be9dc12a80a39ea5c1', text='This could meanthat themodel islearning less\\nduringpretrainingaboutcontextthatmentions Shepronouns,andsubsequentlymaypotentiallygenerate He\\npronouns at a higher rate than Shepronouns.\\nDemographicRepresentation: Identities. Wealsoanalyzetherepresentationofdifferentdemographic\\ngroupsinthepretrainingdatabymeasuringratesofusageofdemographicidentitytermsfromtheHolisticBias\\ndataset(Smithetal.,2022)asaproxy.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-19'),\n",
              " 'a0417101-40f9-4655-8bed-9ac5c10316ee': IndexNode(id_='a0417101-40f9-4655-8bed-9ac5c10316ee', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-19', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='13fb13483f68b94fd2b1e6dd07fa044e73fe9f25f3b11bd6364babed6147e852'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='f22671f0-ad19-4803-96e7-5b8d9f607a2f', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='4c3f2bc7f7a0188f1ca72138cf10cb5b249d96c525f448be9dc12a80a39ea5c1'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='1c5f21a3-4d93-424e-9aee-f5b1444a470c', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='3f27599ee83884308b57f5cbd6426fec9b08fe349f362ee9db321003dc781d2c')}, hash='7d6fb2cc3e1f4a6be64e315e86998c9b816cfdca9d9af17786dac869a1c8b4d3', text='Wecomputefrequenciesforeachdescriptorterminthepretraining\\ncorpus. We group descriptors into 5 axes ( Religion ,Gender and Sex ,Nationality ,Race and Ethnicity , and\\nSexual Orientation ), and show the top 5 terms in each axis in Table 9b. In the top 5 terms, we remove a few\\nterms such as “straight,” “white,” and“black,”because these terms have frequent uses beyond demographic\\nmentions (e.g., as basic color terms).', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-19'),\n",
              " '1c5f21a3-4d93-424e-9aee-f5b1444a470c': IndexNode(id_='1c5f21a3-4d93-424e-9aee-f5b1444a470c', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-19', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='13fb13483f68b94fd2b1e6dd07fa044e73fe9f25f3b11bd6364babed6147e852'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='a0417101-40f9-4655-8bed-9ac5c10316ee', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='7d6fb2cc3e1f4a6be64e315e86998c9b816cfdca9d9af17786dac869a1c8b4d3')}, hash='3f27599ee83884308b57f5cbd6426fec9b08fe349f362ee9db321003dc781d2c', text='We also deduplicate across lists, removing a few terms found in\\nbothGender and Sex andSexual Orientation .', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-19'),\n",
              " '9cc53e81-3a96-4616-9cc8-0450478d68fa': IndexNode(id_='9cc53e81-3a96-4616-9cc8-0450478d68fa', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-19', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='13fb13483f68b94fd2b1e6dd07fa044e73fe9f25f3b11bd6364babed6147e852'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='37848dc0-086f-4b0d-a52c-ca40891deb02', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='9c49ededac70c923facad70e5b27cab90cbe49757b859fb317c36d061cb4ba4d')}, hash='47940495fd364081e21147bfba2a28cf14ac44b1d0d877faae24b916697d752f', text='Next,wedescribe\\ntheprocessofoursafetyalignment(Section4.2),explaininghowwecollectedsafety-relatedannotationsand\\nutilizedSFTandRLHF,andpresentexperimentalresults. Then,wediscusstheredteamingweperformedto\\nfurtherunderstandandimprovemodelsafety(Section4.3). Finally,wepresentquantitativesafetyevaluations\\nofLlama 2-Chat (Section 4.4). We also share a model card in the Appendix, in Table 52.\\n4.1 Safety in Pretraining\\nIt is important to understand what is in the pretraining data both to increase transparency and to shed\\nlightonrootcausesofpotentialdownstreamissues,suchaspotentialbiases. Thiscaninformwhat,ifany,\\ndownstream mitigations to consider, and help guide appropriate model use. In this section, we analyze the\\npretraining datafor distributionsof languages,demographic representations,and toxicity. Wealso present\\nthe results of testing the pretrained models on existing safety benchmarks.\\nSteps Taken to Pretrain Responsibly.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-19'),\n",
              " '37848dc0-086f-4b0d-a52c-ca40891deb02': IndexNode(id_='37848dc0-086f-4b0d-a52c-ca40891deb02', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-19', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='13fb13483f68b94fd2b1e6dd07fa044e73fe9f25f3b11bd6364babed6147e852'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='9cc53e81-3a96-4616-9cc8-0450478d68fa', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='47940495fd364081e21147bfba2a28cf14ac44b1d0d877faae24b916697d752f'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='39d36138-d2a6-4051-9e18-ed2f83bcecef', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='211ec90788223e651511d30b2fa2cc1d72ea61b9199b81f9655f59920c8eb952')}, hash='9c49ededac70c923facad70e5b27cab90cbe49757b859fb317c36d061cb4ba4d', text='Steps Taken to Pretrain Responsibly. We followed Meta’s standard privacy and legal review processes for\\neach dataset used in training. We did not use any Meta user data in training. We excluded data from certain\\nsitesknowntocontainahighvolumeofpersonalinformationaboutprivateindividuals. Wemadeabest\\neffort to train our models efficiently to reduce the carbon footprint of pretraining (Section 2.2.1). Sharing our\\nmodelsbroadlywillreducetheneedforotherstotrainsimilarmodels. Noadditionalfilteringwasconducted\\nonthedatasets,toallow Llama 2 tobemorewidelyusableacrosstasks(e.g.,itcanbebetterusedforhate\\nspeechclassification),whileavoidingthepotentialfortheaccidentaldemographicerasuresometimescaused\\nbyover-scrubbing. Importantly,thisallows Llama 2-Chat togeneralizemoreeffectivelyduringsafetytuning\\nwith fewer examples (Welbl et al., 2021; Korbak et al., 2023; Xu et al., 2021).', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-19'),\n",
              " '39d36138-d2a6-4051-9e18-ed2f83bcecef': IndexNode(id_='39d36138-d2a6-4051-9e18-ed2f83bcecef', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-19', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='13fb13483f68b94fd2b1e6dd07fa044e73fe9f25f3b11bd6364babed6147e852'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='37848dc0-086f-4b0d-a52c-ca40891deb02', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='9c49ededac70c923facad70e5b27cab90cbe49757b859fb317c36d061cb4ba4d'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='a98ce260-83fd-4d0f-a733-aac07d4bfdee', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='ef8f515387dc4e9dadedc313e98197251d07636194be5613e51c9c4db4749932')}, hash='211ec90788223e651511d30b2fa2cc1d72ea61b9199b81f9655f59920c8eb952', text='As a result, Llama 2 models\\nshould be used carefully and deployed only after significant safety tuning is applied.\\nDemographic Representation: Pronouns. Bias in model generations may result from biases inherited\\nfrom the training data itself. For instance, Bailey et al. (2022) shows that in massive text corpora, words\\nrepresenting “people” are often used in more similar contexts to words representing “men”than to words\\nrepresenting “women,” andGaneshetal.(2023)demonstratesthatamodel’sperformanceonfairnessmetrics\\ncan be highly dependent on how the model trains on data representing underrepresented demographic\\ngroups. WithinourEnglish-languagetrainingcorpus,wecomputedthefrequenciesofthemostcommon\\nEnglishpronounsinTable9a. Weobservethat Hepronounsaregenerallyoverrepresentedindocuments\\ncomparedto Shepronouns,echoingsimilarfrequencydifferencesobservedinpronominalusageforsimilarly\\nsized modelpretraining datasets(Chowdhery etal., 2022).', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-19'),\n",
              " 'a98ce260-83fd-4d0f-a733-aac07d4bfdee': IndexNode(id_='a98ce260-83fd-4d0f-a733-aac07d4bfdee', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-19', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='13fb13483f68b94fd2b1e6dd07fa044e73fe9f25f3b11bd6364babed6147e852'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='39d36138-d2a6-4051-9e18-ed2f83bcecef', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='211ec90788223e651511d30b2fa2cc1d72ea61b9199b81f9655f59920c8eb952'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='aada3d2e-5675-4845-ba7c-9e049712b90c', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='3f27599ee83884308b57f5cbd6426fec9b08fe349f362ee9db321003dc781d2c')}, hash='ef8f515387dc4e9dadedc313e98197251d07636194be5613e51c9c4db4749932', text='This could meanthat themodel islearning less\\nduringpretrainingaboutcontextthatmentions Shepronouns,andsubsequentlymaypotentiallygenerate He\\npronouns at a higher rate than Shepronouns.\\nDemographicRepresentation: Identities. Wealsoanalyzetherepresentationofdifferentdemographic\\ngroupsinthepretrainingdatabymeasuringratesofusageofdemographicidentitytermsfromtheHolisticBias\\ndataset(Smithetal.,2022)asaproxy. Wecomputefrequenciesforeachdescriptorterminthepretraining\\ncorpus. We group descriptors into 5 axes ( Religion ,Gender and Sex ,Nationality ,Race and Ethnicity , and\\nSexual Orientation ), and show the top 5 terms in each axis in Table 9b. In the top 5 terms, we remove a few\\nterms such as “straight,” “white,” and“black,”because these terms have frequent uses beyond demographic\\nmentions (e.g., as basic color terms).', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-19'),\n",
              " 'aada3d2e-5675-4845-ba7c-9e049712b90c': IndexNode(id_='aada3d2e-5675-4845-ba7c-9e049712b90c', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-19', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='13fb13483f68b94fd2b1e6dd07fa044e73fe9f25f3b11bd6364babed6147e852'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='a98ce260-83fd-4d0f-a733-aac07d4bfdee', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='ef8f515387dc4e9dadedc313e98197251d07636194be5613e51c9c4db4749932')}, hash='3f27599ee83884308b57f5cbd6426fec9b08fe349f362ee9db321003dc781d2c', text='We also deduplicate across lists, removing a few terms found in\\nbothGender and Sex andSexual Orientation .', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-19'),\n",
              " 'fa6fcbac-d4da-483c-8407-9545498d379d': IndexNode(id_='fa6fcbac-d4da-483c-8407-9545498d379d', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-19', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='13fb13483f68b94fd2b1e6dd07fa044e73fe9f25f3b11bd6364babed6147e852'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='547e792c-4249-4f35-b66d-8498c0a211dd', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='3ce589abbfbba94bc9b3dec25b1605847842498f8a006d1c7dd0f8a9c04c6c1d')}, hash='343f670adb3c7f365ba8feb761f36b00bb94bd2a75311d4598bf433cfec38e0a', text='Next,wedescribe\\ntheprocessofoursafetyalignment(Section4.2),explaininghowwecollectedsafety-relatedannotationsand\\nutilizedSFTandRLHF,andpresentexperimentalresults. Then,wediscusstheredteamingweperformedto\\nfurtherunderstandandimprovemodelsafety(Section4.3). Finally,wepresentquantitativesafetyevaluations\\nofLlama 2-Chat (Section 4.4). We also share a model card in the Appendix, in Table 52.\\n4.1 Safety in Pretraining\\nIt is important to understand what is in the pretraining data both to increase transparency and to shed\\nlightonrootcausesofpotentialdownstreamissues,suchaspotentialbiases. Thiscaninformwhat,ifany,\\ndownstream mitigations to consider, and help guide appropriate model use. In this section, we analyze the\\npretraining datafor distributionsof languages,demographic representations,and toxicity. Wealso present\\nthe results of testing the pretrained models on existing safety benchmarks.\\nSteps Taken to Pretrain Responsibly. We followed Meta’s standard privacy and legal review processes for\\neach dataset used in training. We did not use any Meta user data in training. We excluded data from certain\\nsitesknowntocontainahighvolumeofpersonalinformationaboutprivateindividuals. Wemadeabest\\neffort to train our models efficiently to reduce the carbon footprint of pretraining (Section 2.2.1). Sharing our\\nmodelsbroadlywillreducetheneedforotherstotrainsimilarmodels. Noadditionalfilteringwasconducted\\nonthedatasets,toallow Llama 2 tobemorewidelyusableacrosstasks(e.g.,itcanbebetterusedforhate\\nspeechclassification),whileavoidingthepotentialfortheaccidentaldemographicerasuresometimescaused\\nbyover-scrubbing. Importantly,thisallows Llama 2-Chat togeneralizemoreeffectivelyduringsafetytuning\\nwith fewer examples (Welbl et al., 2021; Korbak et al., 2023; Xu et al., 2021). As a result, Llama 2 models\\nshould be used carefully and deployed only after significant safety tuning is applied.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-19'),\n",
              " '547e792c-4249-4f35-b66d-8498c0a211dd': IndexNode(id_='547e792c-4249-4f35-b66d-8498c0a211dd', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-19', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='13fb13483f68b94fd2b1e6dd07fa044e73fe9f25f3b11bd6364babed6147e852'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='fa6fcbac-d4da-483c-8407-9545498d379d', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='343f670adb3c7f365ba8feb761f36b00bb94bd2a75311d4598bf433cfec38e0a')}, hash='3ce589abbfbba94bc9b3dec25b1605847842498f8a006d1c7dd0f8a9c04c6c1d', text='Demographic Representation: Pronouns. Bias in model generations may result from biases inherited\\nfrom the training data itself. For instance, Bailey et al. (2022) shows that in massive text corpora, words\\nrepresenting “people” are often used in more similar contexts to words representing “men”than to words\\nrepresenting “women,” andGaneshetal.(2023)demonstratesthatamodel’sperformanceonfairnessmetrics\\ncan be highly dependent on how the model trains on data representing underrepresented demographic\\ngroups. WithinourEnglish-languagetrainingcorpus,wecomputedthefrequenciesofthemostcommon\\nEnglishpronounsinTable9a. Weobservethat Hepronounsaregenerallyoverrepresentedindocuments\\ncomparedto Shepronouns,echoingsimilarfrequencydifferencesobservedinpronominalusageforsimilarly\\nsized modelpretraining datasets(Chowdhery etal., 2022). This could meanthat themodel islearning less\\nduringpretrainingaboutcontextthatmentions Shepronouns,andsubsequentlymaypotentiallygenerate He\\npronouns at a higher rate than Shepronouns.\\nDemographicRepresentation: Identities. Wealsoanalyzetherepresentationofdifferentdemographic\\ngroupsinthepretrainingdatabymeasuringratesofusageofdemographicidentitytermsfromtheHolisticBias\\ndataset(Smithetal.,2022)asaproxy. Wecomputefrequenciesforeachdescriptorterminthepretraining\\ncorpus. We group descriptors into 5 axes ( Religion ,Gender and Sex ,Nationality ,Race and Ethnicity , and\\nSexual Orientation ), and show the top 5 terms in each axis in Table 9b. In the top 5 terms, we remove a few\\nterms such as “straight,” “white,” and“black,”because these terms have frequent uses beyond demographic\\nmentions (e.g., as basic color terms). We also deduplicate across lists, removing a few terms found in\\nbothGender and Sex andSexual Orientation .', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-19'),\n",
              " 'node-19': IndexNode(id_='node-19', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='415b7efc-e73f-4ac4-bbfd-c1546f099026', node_type=<ObjectType.DOCUMENT: '4'>, metadata={}, hash='231b3bd773f012c01b893ada9e009ecf25ee59934614c5a595c9bf1b3a123292'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='86252bea-9c5f-4a3d-94c3-3e4381a079e8', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='bacb7624ae0b64581b824a22b0e09f63620d52404bbce3fa755abe115dafe8ea'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='9ec29903-8f3d-4baf-b5a0-c3a0913e9b9f', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='68f370ddf9c749f1830399ccbe295abafcf530e1adba662fc44bce3047b8b395')}, hash='13fb13483f68b94fd2b1e6dd07fa044e73fe9f25f3b11bd6364babed6147e852', text='Next,wedescribe\\ntheprocessofoursafetyalignment(Section4.2),explaininghowwecollectedsafety-relatedannotationsand\\nutilizedSFTandRLHF,andpresentexperimentalresults. Then,wediscusstheredteamingweperformedto\\nfurtherunderstandandimprovemodelsafety(Section4.3). Finally,wepresentquantitativesafetyevaluations\\nofLlama 2-Chat (Section 4.4). We also share a model card in the Appendix, in Table 52.\\n4.1 Safety in Pretraining\\nIt is important to understand what is in the pretraining data both to increase transparency and to shed\\nlightonrootcausesofpotentialdownstreamissues,suchaspotentialbiases. Thiscaninformwhat,ifany,\\ndownstream mitigations to consider, and help guide appropriate model use. In this section, we analyze the\\npretraining datafor distributionsof languages,demographic representations,and toxicity. Wealso present\\nthe results of testing the pretrained models on existing safety benchmarks.\\nSteps Taken to Pretrain Responsibly. We followed Meta’s standard privacy and legal review processes for\\neach dataset used in training. We did not use any Meta user data in training. We excluded data from certain\\nsitesknowntocontainahighvolumeofpersonalinformationaboutprivateindividuals. Wemadeabest\\neffort to train our models efficiently to reduce the carbon footprint of pretraining (Section 2.2.1). Sharing our\\nmodelsbroadlywillreducetheneedforotherstotrainsimilarmodels. Noadditionalfilteringwasconducted\\nonthedatasets,toallow Llama 2 tobemorewidelyusableacrosstasks(e.g.,itcanbebetterusedforhate\\nspeechclassification),whileavoidingthepotentialfortheaccidentaldemographicerasuresometimescaused\\nbyover-scrubbing. Importantly,thisallows Llama 2-Chat togeneralizemoreeffectivelyduringsafetytuning\\nwith fewer examples (Welbl et al., 2021; Korbak et al., 2023; Xu et al., 2021). As a result, Llama 2 models\\nshould be used carefully and deployed only after significant safety tuning is applied.\\nDemographic Representation: Pronouns. Bias in model generations may result from biases inherited\\nfrom the training data itself. For instance, Bailey et al. (2022) shows that in massive text corpora, words\\nrepresenting “people” are often used in more similar contexts to words representing “men”than to words\\nrepresenting “women,” andGaneshetal.(2023)demonstratesthatamodel’sperformanceonfairnessmetrics\\ncan be highly dependent on how the model trains on data representing underrepresented demographic\\ngroups. WithinourEnglish-languagetrainingcorpus,wecomputedthefrequenciesofthemostcommon\\nEnglishpronounsinTable9a. Weobservethat Hepronounsaregenerallyoverrepresentedindocuments\\ncomparedto Shepronouns,echoingsimilarfrequencydifferencesobservedinpronominalusageforsimilarly\\nsized modelpretraining datasets(Chowdhery etal., 2022). This could meanthat themodel islearning less\\nduringpretrainingaboutcontextthatmentions Shepronouns,andsubsequentlymaypotentiallygenerate He\\npronouns at a higher rate than Shepronouns.\\nDemographicRepresentation: Identities. Wealsoanalyzetherepresentationofdifferentdemographic\\ngroupsinthepretrainingdatabymeasuringratesofusageofdemographicidentitytermsfromtheHolisticBias\\ndataset(Smithetal.,2022)asaproxy. Wecomputefrequenciesforeachdescriptorterminthepretraining\\ncorpus. We group descriptors into 5 axes ( Religion ,Gender and Sex ,Nationality ,Race and Ethnicity , and\\nSexual Orientation ), and show the top 5 terms in each axis in Table 9b. In the top 5 terms, we remove a few\\nterms such as “straight,” “white,” and“black,”because these terms have frequent uses beyond demographic\\nmentions (e.g., as basic color terms). We also deduplicate across lists, removing a few terms found in\\nbothGender and Sex andSexual Orientation .', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-19'),\n",
              " 'b844c603-b4ca-46dc-aa6c-c9ba718dc493': IndexNode(id_='b844c603-b4ca-46dc-aa6c-c9ba718dc493', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-20', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='68f370ddf9c749f1830399ccbe295abafcf530e1adba662fc44bce3047b8b395'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='0d899949-452c-4826-9ef0-543087e60219', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='a576ec718e1afbc263180bc6eaa6b02cce55fa91eff04946aa0ab4333395fdd9')}, hash='5f61c0af7372347bdf85d29668209378711e6de8cadee900ac3a0ae24b0a5c0d', text='ForGender and Sex , whileShepronouns are mentioned\\nin fewer documents, the term “female” is present in a larger percentage of documents. This could imply\\nthat whilethere isless frequent contextabout Shepronouns, commentsabout “females” are moreprevalent,\\nperhaps reflecting the differences in linguistic markedness of these terms (Blodgett et al., 2021). For Sexual\\nOrientation ,thetopfivetermsallrelatetoLGBTQ+identities.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-20'),\n",
              " '0d899949-452c-4826-9ef0-543087e60219': IndexNode(id_='0d899949-452c-4826-9ef0-543087e60219', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-20', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='68f370ddf9c749f1830399ccbe295abafcf530e1adba662fc44bce3047b8b395'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='b844c603-b4ca-46dc-aa6c-c9ba718dc493', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='5f61c0af7372347bdf85d29668209378711e6de8cadee900ac3a0ae24b0a5c0d'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='ebfbf5e7-e51f-4a94-b903-2d0739b770ce', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='3f71addbf9863bbab015f8fe80265730614065cce8fb37f20ede2a56607579fd')}, hash='a576ec718e1afbc263180bc6eaa6b02cce55fa91eff04946aa0ab4333395fdd9', text='For Nationality ,RaceandEthnicity ,and\\nReligion , we observe a Western skew (Bhatt et al., 2022). For instance, the term “American” is mentioned in\\n69.4% of the references, the term “European” is more prevalent than other race and ethnicity, and “Christian”\\nis the most represented religion followed by “Catholic” and“Jewish.”\\n20\\n\\nGender Pronouns 75.23% Grammatical Person 94.47%\\nShe(she, her, hers, herself) 28.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-20'),\n",
              " 'ebfbf5e7-e51f-4a94-b903-2d0739b770ce': IndexNode(id_='ebfbf5e7-e51f-4a94-b903-2d0739b770ce', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-20', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='68f370ddf9c749f1830399ccbe295abafcf530e1adba662fc44bce3047b8b395'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='0d899949-452c-4826-9ef0-543087e60219', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='a576ec718e1afbc263180bc6eaa6b02cce55fa91eff04946aa0ab4333395fdd9'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='2c39249f-ef8a-4c68-b6fd-52be2ed37d94', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='57c5cdfe65b6749956479345d7ea91771a6c96c386c434223a00185a468f3e26')}, hash='3f71addbf9863bbab015f8fe80265730614065cce8fb37f20ede2a56607579fd', text='47%\\nShe(she, her, hers, herself) 28.45% 1st(I, me, my, mine, myself, .) 70.71%\\nHe(he, him, his, himself) 50.73% 2nd(you, your, yours, .) 61.80%\\nUnspecified (they, them, their, .) 86.38% 3rd(it, its, itself, she, her, he, him, .) 93.07%\\n(a)Percentage of documents containing gender pronouns and grammatical person.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-20'),\n",
              " '2c39249f-ef8a-4c68-b6fd-52be2ed37d94': IndexNode(id_='2c39249f-ef8a-4c68-b6fd-52be2ed37d94', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-20', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='68f370ddf9c749f1830399ccbe295abafcf530e1adba662fc44bce3047b8b395'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='ebfbf5e7-e51f-4a94-b903-2d0739b770ce', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='3f71addbf9863bbab015f8fe80265730614065cce8fb37f20ede2a56607579fd'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='cbbca197-a3bf-4c9c-aa69-3e606a6ee3ee', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='7971768d2c7709bbcfb1505dfb8772e7571eaf6600ca23d1142af5690708338a')}, hash='57c5cdfe65b6749956479345d7ea91771a6c96c386c434223a00185a468f3e26', text='07%\\n(a)Percentage of documents containing gender pronouns and grammatical person. 75% of all documents contain\\ngendered pronouns. Within this subset, 28% of all documents contain Shepronouns. 94% of all documents contain\\npronouns in general. See the full detailed list of pronouns for each subgroup in Appendix A.4.3.\\nGender and Sex\\n(5.91%)Sexual Orientation\\n(6.67%)Nationality\\n(14.83%)Race and Ethnicity\\n(19.51%)Religion\\n(7.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-20'),\n",
              " 'cbbca197-a3bf-4c9c-aa69-3e606a6ee3ee': IndexNode(id_='cbbca197-a3bf-4c9c-aa69-3e606a6ee3ee', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-20', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='68f370ddf9c749f1830399ccbe295abafcf530e1adba662fc44bce3047b8b395'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='2c39249f-ef8a-4c68-b6fd-52be2ed37d94', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='57c5cdfe65b6749956479345d7ea91771a6c96c386c434223a00185a468f3e26'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='30a1f26a-4f73-4ddc-875c-4d009544988f', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='a8a7fb5e9d80dd863dfa083edda49da279fad197704596349d6743d41e7173fc')}, hash='7971768d2c7709bbcfb1505dfb8772e7571eaf6600ca23d1142af5690708338a', text='83%)Race and Ethnicity\\n(19.51%)Religion\\n(7.93%)\\nDescriptor % Doc Descriptor % Doc Descriptor % Doc Descriptor % Doc Descriptor % Doc\\nfemale 50.0% gay 14.8% american 69.4% european 20.7% christian 33.2%\\nmale 39.1% lesbian 4.3% indian 16.5% african 11.5% religious 28.8%\\nfeminine 5.4% lgbt 4.0% chinese 16.3% asian 7.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-20'),\n",
              " '30a1f26a-4f73-4ddc-875c-4d009544988f': IndexNode(id_='30a1f26a-4f73-4ddc-875c-4d009544988f', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-20', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='68f370ddf9c749f1830399ccbe295abafcf530e1adba662fc44bce3047b8b395'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='cbbca197-a3bf-4c9c-aa69-3e606a6ee3ee', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='7971768d2c7709bbcfb1505dfb8772e7571eaf6600ca23d1142af5690708338a'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='86ab5e95-e02c-4b02-99d5-c589a2abf930', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='f0041caa438ab662f9a35026b1d3fa4c677bd388c5f1c292058e8b1d77cb1864')}, hash='a8a7fb5e9d80dd863dfa083edda49da279fad197704596349d6743d41e7173fc', text='4% lgbt 4.0% chinese 16.3% asian 7.4% spiritual 20.6%\\ntransgender 4.2% lgbtq 3.6% korean 5.1% latin 6.2% catholic 15.4%\\nmasculine 3.1% queer 3.5% mexican 4.9% indigenous 3.7% jewish 13.0%\\n(b)The percentage listed below each demographic axis represents the percentage of all documents that mention any of\\nthedescriptortermsinthisaxis.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-20'),\n",
              " '86ab5e95-e02c-4b02-99d5-c589a2abf930': IndexNode(id_='86ab5e95-e02c-4b02-99d5-c589a2abf930', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-20', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='68f370ddf9c749f1830399ccbe295abafcf530e1adba662fc44bce3047b8b395'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='30a1f26a-4f73-4ddc-875c-4d009544988f', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='a8a7fb5e9d80dd863dfa083edda49da279fad197704596349d6743d41e7173fc'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='257bcb8a-e3e2-49aa-8387-4a0121baa869', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='bf2ba41fbf68b210657310a47906c6932205c1c3c244d3145c00d1db30314e7f')}, hash='f0041caa438ab662f9a35026b1d3fa4c677bd388c5f1c292058e8b1d77cb1864', text='Thepercentagelistedforeachdemographicdescriptorrepresents,amongthedocuments\\nthat mention a descriptor in the given demographic axis, the percentage that mention this specific descriptor.\\nTable9: Demographicrepresentations. Analysisofpronounsandidentitiesinourpretrainingcorpusshows\\nsome skews that may affect performance, such as higher representations of Western demographics.\\nFigure13: Pretrainingdatatoxicity. Toallowforbetterdownstreamgeneralization,wechosenottoscrub\\ntoxicdatafrompretraining.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-20'),\n",
              " '257bcb8a-e3e2-49aa-8387-4a0121baa869': IndexNode(id_='257bcb8a-e3e2-49aa-8387-4a0121baa869', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-20', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='68f370ddf9c749f1830399ccbe295abafcf530e1adba662fc44bce3047b8b395'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='86ab5e95-e02c-4b02-99d5-c589a2abf930', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='f0041caa438ab662f9a35026b1d3fa4c677bd388c5f1c292058e8b1d77cb1864'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='075006f4-8bd4-4157-aa63-6b00504a276a', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='4301bf63cf3a422dab18e0395b01f5be75eebdc2030f417f52589ae0fb6bc97c')}, hash='bf2ba41fbf68b210657310a47906c6932205c1c3c244d3145c00d1db30314e7f', text='TheHateBERTclassifierassignsatoxicitylikelihoodof0.5orhighertoabout\\n0.2% of documents in our pretraining corpus.\\nDataToxicity. WemeasuretheprevalenceoftoxicityintheEnglish-languageportionofthepretraining\\ncorpususingaHateBERTclassifierfine-tunedontheToxiGendataset(Hartvigsenetal.,2022). Wescoreeach\\nlineofadocumentseparatelyandaveragethemtoassignadocumentscore.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-20'),\n",
              " '075006f4-8bd4-4157-aa63-6b00504a276a': IndexNode(id_='075006f4-8bd4-4157-aa63-6b00504a276a', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-20', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='68f370ddf9c749f1830399ccbe295abafcf530e1adba662fc44bce3047b8b395'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='257bcb8a-e3e2-49aa-8387-4a0121baa869', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='bf2ba41fbf68b210657310a47906c6932205c1c3c244d3145c00d1db30314e7f')}, hash='4301bf63cf3a422dab18e0395b01f5be75eebdc2030f417f52589ae0fb6bc97c', text='Figure13showsthedistribution\\nof scores in a 10% random sample of the full corpus. About 0.2% of documents evaluated are assigned a\\nlikelihood score of 0.5 or higher, meaning there is a small amount of toxicity in our pretraining data.\\nLanguageIdentification. WhileourpretrainingdataismostlyEnglish,italsoincludestextfromasmall\\nnumber ofother languages. Table 10showsthe distributionof languages inour corpus, subsettedto those\\nfoundinmorethan0.005%ofthedocuments.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-20'),\n",
              " '70936932-4efc-4110-8714-54cd3b70a081': IndexNode(id_='70936932-4efc-4110-8714-54cd3b70a081', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-20', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='68f370ddf9c749f1830399ccbe295abafcf530e1adba662fc44bce3047b8b395'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='75a6dc04-f952-4f73-bcc9-e3836d790470', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='61978fc0e9582ccb3df020f3bbe3683b4e3af999e72ea2644862d991cf931fc4')}, hash='475b5197c03db762849e3afed8b7ff1105f6dca2bf332c259c4c2b8b7cfa8b1f', text='ForGender and Sex , whileShepronouns are mentioned\\nin fewer documents, the term “female” is present in a larger percentage of documents. This could imply\\nthat whilethere isless frequent contextabout Shepronouns, commentsabout “females” are moreprevalent,\\nperhaps reflecting the differences in linguistic markedness of these terms (Blodgett et al., 2021). For Sexual\\nOrientation ,thetopfivetermsallrelatetoLGBTQ+identities. For Nationality ,RaceandEthnicity ,and\\nReligion , we observe a Western skew (Bhatt et al., 2022).', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-20'),\n",
              " '75a6dc04-f952-4f73-bcc9-e3836d790470': IndexNode(id_='75a6dc04-f952-4f73-bcc9-e3836d790470', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-20', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='68f370ddf9c749f1830399ccbe295abafcf530e1adba662fc44bce3047b8b395'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='70936932-4efc-4110-8714-54cd3b70a081', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='475b5197c03db762849e3afed8b7ff1105f6dca2bf332c259c4c2b8b7cfa8b1f'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='b577c446-23f6-4fe9-ae0f-b2c63ed19aed', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='78d6ca6b442b28d0bc1a8a3b3271ce381b64217356c4894b4e14597ec31d190a')}, hash='61978fc0e9582ccb3df020f3bbe3683b4e3af999e72ea2644862d991cf931fc4', text='For instance, the term “American” is mentioned in\\n69.4% of the references, the term “European” is more prevalent than other race and ethnicity, and “Christian”\\nis the most represented religion followed by “Catholic” and“Jewish.”\\n20\\n\\nGender Pronouns 75.23% Grammatical Person 94.47%\\nShe(she, her, hers, herself) 28.45% 1st(I, me, my, mine, myself, ...) 70.71%\\nHe(he, him, his, himself) 50.73% 2nd(you, your, yours, ...) 61.80%\\nUnspecified (they, them, their, ...) 86.38% 3rd(it, its, itself, she, her, he, him, ...) 93.07%\\n(a)Percentage of documents containing gender pronouns and grammatical person. 75% of all documents contain\\ngendered pronouns. Within this subset, 28% of all documents contain Shepronouns. 94% of all documents contain\\npronouns in general.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-20'),\n",
              " 'b577c446-23f6-4fe9-ae0f-b2c63ed19aed': IndexNode(id_='b577c446-23f6-4fe9-ae0f-b2c63ed19aed', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-20', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='68f370ddf9c749f1830399ccbe295abafcf530e1adba662fc44bce3047b8b395'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='75a6dc04-f952-4f73-bcc9-e3836d790470', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='61978fc0e9582ccb3df020f3bbe3683b4e3af999e72ea2644862d991cf931fc4'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='0d79abb3-eca2-414d-aa6b-827cfc82c4ee', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='0a143c1204b15f9834072c1bdd77741ac0d9f6e314c984eb5ab8f223f4b4b457')}, hash='78d6ca6b442b28d0bc1a8a3b3271ce381b64217356c4894b4e14597ec31d190a', text='94% of all documents contain\\npronouns in general. See the full detailed list of pronouns for each subgroup in Appendix A.4.3.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-20'),\n",
              " '0d79abb3-eca2-414d-aa6b-827cfc82c4ee': IndexNode(id_='0d79abb3-eca2-414d-aa6b-827cfc82c4ee', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-20', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='68f370ddf9c749f1830399ccbe295abafcf530e1adba662fc44bce3047b8b395'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='b577c446-23f6-4fe9-ae0f-b2c63ed19aed', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='78d6ca6b442b28d0bc1a8a3b3271ce381b64217356c4894b4e14597ec31d190a'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='fba2f18b-d54a-4b91-817a-67ae9ea2eeba', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='18ede9fb43746500007384ed1c8305cbe4d6a211791aed17a208a6975d5c2238')}, hash='0a143c1204b15f9834072c1bdd77741ac0d9f6e314c984eb5ab8f223f4b4b457', text='See the full detailed list of pronouns for each subgroup in Appendix A.4.3.\\nGender and Sex\\n(5.91%)Sexual Orientation\\n(6.67%)Nationality\\n(14.83%)Race and Ethnicity\\n(19.51%)Religion\\n(7.93%)\\nDescriptor % Doc Descriptor % Doc Descriptor % Doc Descriptor % Doc Descriptor % Doc\\nfemale 50.0% gay 14.8% american 69.4% european 20.7% christian 33.2%\\nmale 39.1% lesbian 4.3% indian 16.5% african 11.5% religious 28.8%\\nfeminine 5.4% lgbt 4.0% chinese 16.3% asian 7.4% spiritual 20.6%\\ntransgender 4.2% lgbtq 3.6% korean 5.1% latin 6.2% catholic 15.4%\\nmasculine 3.1% queer 3.5% mexican 4.9% indigenous 3.7% jewish 13.0%\\n(b)The percentage listed below each demographic axis represents the percentage of all documents that mention any of\\nthedescriptortermsinthisaxis.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-20'),\n",
              " 'fba2f18b-d54a-4b91-817a-67ae9ea2eeba': IndexNode(id_='fba2f18b-d54a-4b91-817a-67ae9ea2eeba', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-20', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='68f370ddf9c749f1830399ccbe295abafcf530e1adba662fc44bce3047b8b395'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='0d79abb3-eca2-414d-aa6b-827cfc82c4ee', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='0a143c1204b15f9834072c1bdd77741ac0d9f6e314c984eb5ab8f223f4b4b457'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='841ca32e-94d8-4054-95a9-7c6e7374dd04', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='4301bf63cf3a422dab18e0395b01f5be75eebdc2030f417f52589ae0fb6bc97c')}, hash='18ede9fb43746500007384ed1c8305cbe4d6a211791aed17a208a6975d5c2238', text='Thepercentagelistedforeachdemographicdescriptorrepresents,amongthedocuments\\nthat mention a descriptor in the given demographic axis, the percentage that mention this specific descriptor.\\nTable9: Demographicrepresentations. Analysisofpronounsandidentitiesinourpretrainingcorpusshows\\nsome skews that may affect performance, such as higher representations of Western demographics.\\nFigure13: Pretrainingdatatoxicity. Toallowforbetterdownstreamgeneralization,wechosenottoscrub\\ntoxicdatafrompretraining. TheHateBERTclassifierassignsatoxicitylikelihoodof0.5orhighertoabout\\n0.2% of documents in our pretraining corpus.\\nDataToxicity. WemeasuretheprevalenceoftoxicityintheEnglish-languageportionofthepretraining\\ncorpususingaHateBERTclassifierfine-tunedontheToxiGendataset(Hartvigsenetal.,2022). Wescoreeach\\nlineofadocumentseparatelyandaveragethemtoassignadocumentscore.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-20'),\n",
              " '841ca32e-94d8-4054-95a9-7c6e7374dd04': IndexNode(id_='841ca32e-94d8-4054-95a9-7c6e7374dd04', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-20', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='68f370ddf9c749f1830399ccbe295abafcf530e1adba662fc44bce3047b8b395'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='fba2f18b-d54a-4b91-817a-67ae9ea2eeba', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='18ede9fb43746500007384ed1c8305cbe4d6a211791aed17a208a6975d5c2238')}, hash='4301bf63cf3a422dab18e0395b01f5be75eebdc2030f417f52589ae0fb6bc97c', text='Figure13showsthedistribution\\nof scores in a 10% random sample of the full corpus. About 0.2% of documents evaluated are assigned a\\nlikelihood score of 0.5 or higher, meaning there is a small amount of toxicity in our pretraining data.\\nLanguageIdentification. WhileourpretrainingdataismostlyEnglish,italsoincludestextfromasmall\\nnumber ofother languages. Table 10showsthe distributionof languages inour corpus, subsettedto those\\nfoundinmorethan0.005%ofthedocuments.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-20'),\n",
              " 'c00bbf85-ee46-4146-92ee-97d57bb8b17b': IndexNode(id_='c00bbf85-ee46-4146-92ee-97d57bb8b17b', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-20', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='68f370ddf9c749f1830399ccbe295abafcf530e1adba662fc44bce3047b8b395'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='f6d939e7-855a-43c6-b6ff-ca4914c75d3b', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='4034119d05add1e8c275293262325de61be70d596e010278b476bb9a66e179d7')}, hash='3561c4434ea3507b52ac160b999d94efcc5b827a3c7c1335182d412f7cd4eb64', text='ForGender and Sex , whileShepronouns are mentioned\\nin fewer documents, the term “female” is present in a larger percentage of documents. This could imply\\nthat whilethere isless frequent contextabout Shepronouns, commentsabout “females” are moreprevalent,\\nperhaps reflecting the differences in linguistic markedness of these terms (Blodgett et al., 2021). For Sexual\\nOrientation ,thetopfivetermsallrelatetoLGBTQ+identities. For Nationality ,RaceandEthnicity ,and\\nReligion , we observe a Western skew (Bhatt et al., 2022). For instance, the term “American” is mentioned in\\n69.4% of the references, the term “European” is more prevalent than other race and ethnicity, and “Christian”\\nis the most represented religion followed by “Catholic” and“Jewish.”\\n20\\n\\nGender Pronouns 75.23% Grammatical Person 94.47%\\nShe(she, her, hers, herself) 28.45% 1st(I, me, my, mine, myself, ...) 70.71%\\nHe(he, him, his, himself) 50.73% 2nd(you, your, yours, ...) 61.80%\\nUnspecified (they, them, their, ...) 86.38% 3rd(it, its, itself, she, her, he, him, ...) 93.07%\\n(a)Percentage of documents containing gender pronouns and grammatical person. 75% of all documents contain\\ngendered pronouns. Within this subset, 28% of all documents contain Shepronouns. 94% of all documents contain\\npronouns in general. See the full detailed list of pronouns for each subgroup in Appendix A.4.3.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-20'),\n",
              " 'f6d939e7-855a-43c6-b6ff-ca4914c75d3b': IndexNode(id_='f6d939e7-855a-43c6-b6ff-ca4914c75d3b', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-20', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='68f370ddf9c749f1830399ccbe295abafcf530e1adba662fc44bce3047b8b395'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='c00bbf85-ee46-4146-92ee-97d57bb8b17b', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='3561c4434ea3507b52ac160b999d94efcc5b827a3c7c1335182d412f7cd4eb64'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='05ae8250-b1e1-4caa-9da2-ad058e7526e4', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='c64cba000fbf82a48c08b39c6888ac0f7667ee4184c6e9c1a81ffbe6709221dd')}, hash='4034119d05add1e8c275293262325de61be70d596e010278b476bb9a66e179d7', text='See the full detailed list of pronouns for each subgroup in Appendix A.4.3.\\nGender and Sex\\n(5.91%)Sexual Orientation\\n(6.67%)Nationality\\n(14.83%)Race and Ethnicity\\n(19.51%)Religion\\n(7.93%)\\nDescriptor % Doc Descriptor % Doc Descriptor % Doc Descriptor % Doc Descriptor % Doc\\nfemale 50.0% gay 14.8% american 69.4% european 20.7% christian 33.2%\\nmale 39.1% lesbian 4.3% indian 16.5% african 11.5% religious 28.8%\\nfeminine 5.4% lgbt 4.0% chinese 16.3% asian 7.4% spiritual 20.6%\\ntransgender 4.2% lgbtq 3.6% korean 5.1% latin 6.2% catholic 15.4%\\nmasculine 3.1% queer 3.5% mexican 4.9% indigenous 3.7% jewish 13.0%\\n(b)The percentage listed below each demographic axis represents the percentage of all documents that mention any of\\nthedescriptortermsinthisaxis. Thepercentagelistedforeachdemographicdescriptorrepresents,amongthedocuments\\nthat mention a descriptor in the given demographic axis, the percentage that mention this specific descriptor.\\nTable9: Demographicrepresentations. Analysisofpronounsandidentitiesinourpretrainingcorpusshows\\nsome skews that may affect performance, such as higher representations of Western demographics.\\nFigure13: Pretrainingdatatoxicity. Toallowforbetterdownstreamgeneralization,wechosenottoscrub\\ntoxicdatafrompretraining. TheHateBERTclassifierassignsatoxicitylikelihoodof0.5orhighertoabout\\n0.2% of documents in our pretraining corpus.\\nDataToxicity. WemeasuretheprevalenceoftoxicityintheEnglish-languageportionofthepretraining\\ncorpususingaHateBERTclassifierfine-tunedontheToxiGendataset(Hartvigsenetal.,2022).', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-20'),\n",
              " '05ae8250-b1e1-4caa-9da2-ad058e7526e4': IndexNode(id_='05ae8250-b1e1-4caa-9da2-ad058e7526e4', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-20', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='68f370ddf9c749f1830399ccbe295abafcf530e1adba662fc44bce3047b8b395'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='f6d939e7-855a-43c6-b6ff-ca4914c75d3b', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='4034119d05add1e8c275293262325de61be70d596e010278b476bb9a66e179d7')}, hash='c64cba000fbf82a48c08b39c6888ac0f7667ee4184c6e9c1a81ffbe6709221dd', text='Wescoreeach\\nlineofadocumentseparatelyandaveragethemtoassignadocumentscore. Figure13showsthedistribution\\nof scores in a 10% random sample of the full corpus. About 0.2% of documents evaluated are assigned a\\nlikelihood score of 0.5 or higher, meaning there is a small amount of toxicity in our pretraining data.\\nLanguageIdentification. WhileourpretrainingdataismostlyEnglish,italsoincludestextfromasmall\\nnumber ofother languages. Table 10showsthe distributionof languages inour corpus, subsettedto those\\nfoundinmorethan0.005%ofthedocuments.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-20'),\n",
              " 'node-20': IndexNode(id_='node-20', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='415b7efc-e73f-4ac4-bbfd-c1546f099026', node_type=<ObjectType.DOCUMENT: '4'>, metadata={}, hash='231b3bd773f012c01b893ada9e009ecf25ee59934614c5a595c9bf1b3a123292'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='4dc51dfd-9f12-4a2c-98d4-af64a9431396', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='13fb13483f68b94fd2b1e6dd07fa044e73fe9f25f3b11bd6364babed6147e852'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='b5599d63-93d3-4f3c-9f99-83ba8bac9687', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='878a58c50329bc623a4ffff25d70e783176a9b990e47b9d4f24166278a3d067a')}, hash='68f370ddf9c749f1830399ccbe295abafcf530e1adba662fc44bce3047b8b395', text='ForGender and Sex , whileShepronouns are mentioned\\nin fewer documents, the term “female” is present in a larger percentage of documents. This could imply\\nthat whilethere isless frequent contextabout Shepronouns, commentsabout “females” are moreprevalent,\\nperhaps reflecting the differences in linguistic markedness of these terms (Blodgett et al., 2021). For Sexual\\nOrientation ,thetopfivetermsallrelatetoLGBTQ+identities. For Nationality ,RaceandEthnicity ,and\\nReligion , we observe a Western skew (Bhatt et al., 2022). For instance, the term “American” is mentioned in\\n69.4% of the references, the term “European” is more prevalent than other race and ethnicity, and “Christian”\\nis the most represented religion followed by “Catholic” and“Jewish.”\\n20\\n\\nGender Pronouns 75.23% Grammatical Person 94.47%\\nShe(she, her, hers, herself) 28.45% 1st(I, me, my, mine, myself, ...) 70.71%\\nHe(he, him, his, himself) 50.73% 2nd(you, your, yours, ...) 61.80%\\nUnspecified (they, them, their, ...) 86.38% 3rd(it, its, itself, she, her, he, him, ...) 93.07%\\n(a)Percentage of documents containing gender pronouns and grammatical person. 75% of all documents contain\\ngendered pronouns. Within this subset, 28% of all documents contain Shepronouns. 94% of all documents contain\\npronouns in general. See the full detailed list of pronouns for each subgroup in Appendix A.4.3.\\nGender and Sex\\n(5.91%)Sexual Orientation\\n(6.67%)Nationality\\n(14.83%)Race and Ethnicity\\n(19.51%)Religion\\n(7.93%)\\nDescriptor % Doc Descriptor % Doc Descriptor % Doc Descriptor % Doc Descriptor % Doc\\nfemale 50.0% gay 14.8% american 69.4% european 20.7% christian 33.2%\\nmale 39.1% lesbian 4.3% indian 16.5% african 11.5% religious 28.8%\\nfeminine 5.4% lgbt 4.0% chinese 16.3% asian 7.4% spiritual 20.6%\\ntransgender 4.2% lgbtq 3.6% korean 5.1% latin 6.2% catholic 15.4%\\nmasculine 3.1% queer 3.5% mexican 4.9% indigenous 3.7% jewish 13.0%\\n(b)The percentage listed below each demographic axis represents the percentage of all documents that mention any of\\nthedescriptortermsinthisaxis. Thepercentagelistedforeachdemographicdescriptorrepresents,amongthedocuments\\nthat mention a descriptor in the given demographic axis, the percentage that mention this specific descriptor.\\nTable9: Demographicrepresentations. Analysisofpronounsandidentitiesinourpretrainingcorpusshows\\nsome skews that may affect performance, such as higher representations of Western demographics.\\nFigure13: Pretrainingdatatoxicity. Toallowforbetterdownstreamgeneralization,wechosenottoscrub\\ntoxicdatafrompretraining. TheHateBERTclassifierassignsatoxicitylikelihoodof0.5orhighertoabout\\n0.2% of documents in our pretraining corpus.\\nDataToxicity. WemeasuretheprevalenceoftoxicityintheEnglish-languageportionofthepretraining\\ncorpususingaHateBERTclassifierfine-tunedontheToxiGendataset(Hartvigsenetal.,2022). Wescoreeach\\nlineofadocumentseparatelyandaveragethemtoassignadocumentscore. Figure13showsthedistribution\\nof scores in a 10% random sample of the full corpus. About 0.2% of documents evaluated are assigned a\\nlikelihood score of 0.5 or higher, meaning there is a small amount of toxicity in our pretraining data.\\nLanguageIdentification. WhileourpretrainingdataismostlyEnglish,italsoincludestextfromasmall\\nnumber ofother languages. Table 10showsthe distributionof languages inour corpus, subsettedto those\\nfoundinmorethan0.005%ofthedocuments.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-20'),\n",
              " 'b45a0812-2b2e-4b3f-a4f3-5d741ecf5b44': IndexNode(id_='b45a0812-2b2e-4b3f-a4f3-5d741ecf5b44', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-21', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='878a58c50329bc623a4ffff25d70e783176a9b990e47b9d4f24166278a3d067a'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='51c3b986-5dd5-4982-b425-5b876bbd0992', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='56bb166a6ad474499547e90827fe805f7d906520af7a79e8a075836a42d3ba6a')}, hash='846b5a276458d27722d46f8ddc6f0788f6f82725838cf8a82fbbff0337a12d57', text='OuranalysisusesthefastText(Bojanowskietal.,2016)language\\nidentification tool and a threshold of 0.5for the language detection. A training corpus with a majority in\\nEnglish means that the model may not be suitable for use in other languages.\\n21\\n\\nLanguage Percent Language Percent\\nen 89.70% uk 0.07%\\nunknown 8.38% ko 0.06%\\nde 0.17% ca 0.04%\\nfr 0.16% sr 0.04%\\nsv 0.15% id 0.03%\\nzh 0.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-21'),\n",
              " '51c3b986-5dd5-4982-b425-5b876bbd0992': IndexNode(id_='51c3b986-5dd5-4982-b425-5b876bbd0992', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-21', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='878a58c50329bc623a4ffff25d70e783176a9b990e47b9d4f24166278a3d067a'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='b45a0812-2b2e-4b3f-a4f3-5d741ecf5b44', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='846b5a276458d27722d46f8ddc6f0788f6f82725838cf8a82fbbff0337a12d57'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='506f92d8-0ac9-472c-a1de-a762b3cc2280', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='fdd17d99fe8c3fc36764a01da8af0467ef2dcef96ecaad39a576b734842408dc')}, hash='56bb166a6ad474499547e90827fe805f7d906520af7a79e8a075836a42d3ba6a', text='04%\\nsv 0.15% id 0.03%\\nzh 0.13% cs 0.03%\\nes 0.13% fi 0.03%\\nru 0.13% hu 0.03%\\nnl 0.12% no 0.03%\\nit 0.11% ro 0.03%\\nja 0.10% bg 0.02%\\npl 0.09% da 0.02%\\npt 0.09% sl 0.01%\\nvi 0.08% hr 0.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-21'),\n",
              " '506f92d8-0ac9-472c-a1de-a762b3cc2280': IndexNode(id_='506f92d8-0ac9-472c-a1de-a762b3cc2280', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-21', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='878a58c50329bc623a4ffff25d70e783176a9b990e47b9d4f24166278a3d067a'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='51c3b986-5dd5-4982-b425-5b876bbd0992', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='56bb166a6ad474499547e90827fe805f7d906520af7a79e8a075836a42d3ba6a'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='795b9c59-ba72-4b3c-a874-295181db85af', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='eaed0234c396568e10cca2d690ba9a44fe8e065f340e6e69d164b0a54b3f2301')}, hash='fdd17d99fe8c3fc36764a01da8af0467ef2dcef96ecaad39a576b734842408dc', text='09% sl 0.01%\\nvi 0.08% hr 0.01%\\nTable 10: Language distribution in pretraining data with percentage >= 0.005% . Most data is in English,\\nmeaning that Llama 2 will perform best for English-language use cases. The large unknown category is\\npartially made up of programming code data.\\nSafetyBenchmarksforPretrainedModels. Weevaluatethesafetycapabilitiesof Llama 2 onthreepopular\\nautomatic benchmarks, pertaining to three key dimensions of LM safety.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-21'),\n",
              " '795b9c59-ba72-4b3c-a874-295181db85af': IndexNode(id_='795b9c59-ba72-4b3c-a874-295181db85af', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-21', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='878a58c50329bc623a4ffff25d70e783176a9b990e47b9d4f24166278a3d067a'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='506f92d8-0ac9-472c-a1de-a762b3cc2280', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='fdd17d99fe8c3fc36764a01da8af0467ef2dcef96ecaad39a576b734842408dc'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='6f14ca02-a4e7-4a4c-81a0-47a954053ee1', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='bac713a8ccb6b4cd593ebe77df68d13e6e3a9bc2b39980659be28740639154a7')}, hash='eaed0234c396568e10cca2d690ba9a44fe8e065f340e6e69d164b0a54b3f2301', text='1.Truthfulness , referring to whether a language model produces known falsehoods due to misconcep-\\ntions or false beliefs. We employ TruthfulQA (Lin et al., 2021) to measure how well our LLMs can\\ngenerate reliable outputs that agree with factuality and common sense.\\n2.Toxicity,definedasthetendencyofalanguagemodeltogeneratetoxic,rude,adversarial,orimplicitly\\nhateful content.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-21'),\n",
              " '6f14ca02-a4e7-4a4c-81a0-47a954053ee1': IndexNode(id_='6f14ca02-a4e7-4a4c-81a0-47a954053ee1', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-21', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='878a58c50329bc623a4ffff25d70e783176a9b990e47b9d4f24166278a3d067a'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='795b9c59-ba72-4b3c-a874-295181db85af', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='eaed0234c396568e10cca2d690ba9a44fe8e065f340e6e69d164b0a54b3f2301'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='6c602370-80ed-49a5-a89c-516cc7e305f5', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='9b94d491bcd09d862173b51505c49648af76710b979bbfe612fb10aff7b49c11')}, hash='bac713a8ccb6b4cd593ebe77df68d13e6e3a9bc2b39980659be28740639154a7', text='We choose ToxiGen (Hartvigsen et al., 2022) to measure the amount of generation\\nof toxic language and hate speech across different groups.\\n3.Bias, defined as how model generations reproduce existing stereotypical social biases. We use\\nBOLD(Dhamala et al., 2021) to study how the sentiment in model generations may vary with\\ndemographic attributes.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-21'),\n",
              " '6c602370-80ed-49a5-a89c-516cc7e305f5': IndexNode(id_='6c602370-80ed-49a5-a89c-516cc7e305f5', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-21', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='878a58c50329bc623a4ffff25d70e783176a9b990e47b9d4f24166278a3d067a'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='6f14ca02-a4e7-4a4c-81a0-47a954053ee1', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='bac713a8ccb6b4cd593ebe77df68d13e6e3a9bc2b39980659be28740639154a7'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='99eb40e0-2b3c-467d-9f8b-546e8fee697a', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='b8cf8f172375a7ada0ab3707a0be27490031e8caef4509ef2b7a4128e1aef23d')}, hash='9b94d491bcd09d862173b51505c49648af76710b979bbfe612fb10aff7b49c11', text='We compare the performance of Llama 2 with Llama 1 (Touvron et al., 2023), Falcon (Almazrouei et al.,\\n2023), and MPT (MosaicML NLP Team et al., 2023) in Table 11. For decoding, we set temperature to 0.1\\nand use nucleus sampling (Holtzman et al., 2020) with top- pset to 0.9. For TruthfulQA, we present the\\npercentageofgenerationsthatarebothtruthfulandinformative(thehigher,thebetter).', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-21'),\n",
              " '99eb40e0-2b3c-467d-9f8b-546e8fee697a': IndexNode(id_='99eb40e0-2b3c-467d-9f8b-546e8fee697a', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-21', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='878a58c50329bc623a4ffff25d70e783176a9b990e47b9d4f24166278a3d067a'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='6c602370-80ed-49a5-a89c-516cc7e305f5', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='9b94d491bcd09d862173b51505c49648af76710b979bbfe612fb10aff7b49c11'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='a6689bb2-25cc-4972-b198-08a2d67c8119', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='94e2ea1535778ca6436cab350c0337ba5d8e3bc7586f8bc65b38befa29684c98')}, hash='b8cf8f172375a7ada0ab3707a0be27490031e8caef4509ef2b7a4128e1aef23d', text='ForToxiGen,we\\npresentthepercentageofgenerationsthataredeemedtoxicbythemetric(thelower,thebetter). Detailed\\ndescriptionsofthebenchmarksandmetricscanbefoundinAppendixA.4.7. Whencomparedto Llama 1-7B,\\nLlama 2-7B demonstrates a 21.37% increase in truthfulness and informativeness and a 7.61% decrease in\\ntoxicity.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-21'),\n",
              " 'a6689bb2-25cc-4972-b198-08a2d67c8119': IndexNode(id_='a6689bb2-25cc-4972-b198-08a2d67c8119', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-21', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='878a58c50329bc623a4ffff25d70e783176a9b990e47b9d4f24166278a3d067a'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='99eb40e0-2b3c-467d-9f8b-546e8fee697a', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='b8cf8f172375a7ada0ab3707a0be27490031e8caef4509ef2b7a4128e1aef23d'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='feaa1854-1f3f-4633-8e3f-52ce3fa8c945', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='1e04f577844121f50b4f2071261d5cab98f1c7cd1152faaa6ab6301d0661237f')}, hash='94e2ea1535778ca6436cab350c0337ba5d8e3bc7586f8bc65b38befa29684c98', text='We also observe an increase in toxicity in the pretrained 13B and 70B Llama 2, which may result\\nfrom larger pretraining data or a different dataset mix. Some have postulated the existence of a relationship\\nbetween pretraining dataset size and downstream model toxicity or bias (Bender et al., 2021b), but empirical\\nwork to validate this claim is still ongoing (Dodge et al., 2021; Smith and Williams, 2021; Tal et al., 2022), and\\nfurther evidence from up-to-date models is still needed.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-21'),\n",
              " 'feaa1854-1f3f-4633-8e3f-52ce3fa8c945': IndexNode(id_='feaa1854-1f3f-4633-8e3f-52ce3fa8c945', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-21', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='878a58c50329bc623a4ffff25d70e783176a9b990e47b9d4f24166278a3d067a'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='a6689bb2-25cc-4972-b198-08a2d67c8119', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='94e2ea1535778ca6436cab350c0337ba5d8e3bc7586f8bc65b38befa29684c98'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='b9b8ed41-7511-40bc-8c70-e12b8e66dd6e', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='2078a1989b9280db10b7de0398579fb99ccb059d258571b1588f4b2b887505aa')}, hash='1e04f577844121f50b4f2071261d5cab98f1c7cd1152faaa6ab6301d0661237f', text='In Appendix A.4.7, we present bias metrics, such as how the sentiment of model generations varies with\\ndemographic attributes. We note an increase in positive sentiment overall for many of the groups using\\nBOLDprompts. MoredetailedresultssplitbydifferentdemographicgroupscanbefoundinAppendixA.4.8.\\nLlama 2 doesnotoutperformothermodelsontoxicitymetrics,andwespeculatethatthismaybebecausewe\\nrefrained from aggressively filtering the pretraining data.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-21'),\n",
              " 'b9b8ed41-7511-40bc-8c70-e12b8e66dd6e': IndexNode(id_='b9b8ed41-7511-40bc-8c70-e12b8e66dd6e', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-21', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='878a58c50329bc623a4ffff25d70e783176a9b990e47b9d4f24166278a3d067a'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='feaa1854-1f3f-4633-8e3f-52ce3fa8c945', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='1e04f577844121f50b4f2071261d5cab98f1c7cd1152faaa6ab6301d0661237f')}, hash='2078a1989b9280db10b7de0398579fb99ccb059d258571b1588f4b2b887505aa', text='Recall that leaving pretraining data unfiltered may\\nenable base models tuned to perform well on more downstream tasks (including hate speech detection),\\nand it carries less risk of accidentally filtering out some demographic groups.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-21'),\n",
              " 'b78e6ddc-5822-460c-bd6b-68cbbcac3170': IndexNode(id_='b78e6ddc-5822-460c-bd6b-68cbbcac3170', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-21', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='878a58c50329bc623a4ffff25d70e783176a9b990e47b9d4f24166278a3d067a'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='c6aa920a-0856-4869-8a60-74333c20b7f5', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='12632789c9c8125048dfe68c6eb8d9a016bc9e79c6c0c52e9dcdd02e5502e904')}, hash='8d9271cca7180f004fad81cdabc5f4086d8d6f9780a2d3b3756190d933442b01', text='OuranalysisusesthefastText(Bojanowskietal.,2016)language\\nidentification tool and a threshold of 0.5for the language detection. A training corpus with a majority in\\nEnglish means that the model may not be suitable for use in other languages.\\n21\\n\\nLanguage Percent Language Percent\\nen 89.70% uk 0.07%\\nunknown 8.38% ko 0.06%\\nde 0.17% ca 0.04%\\nfr 0.16% sr 0.04%\\nsv 0.15% id 0.03%\\nzh 0.13% cs 0.03%\\nes 0.13% fi 0.03%\\nru 0.13% hu 0.03%\\nnl 0.12% no 0.03%\\nit 0.11% ro 0.03%\\nja 0.10% bg 0.02%\\npl 0.09% da 0.02%\\npt 0.09% sl 0.01%\\nvi 0.08% hr 0.01%\\nTable 10: Language distribution in pretraining data with percentage >= 0.005% .', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-21'),\n",
              " 'c6aa920a-0856-4869-8a60-74333c20b7f5': IndexNode(id_='c6aa920a-0856-4869-8a60-74333c20b7f5', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-21', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='878a58c50329bc623a4ffff25d70e783176a9b990e47b9d4f24166278a3d067a'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='b78e6ddc-5822-460c-bd6b-68cbbcac3170', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='8d9271cca7180f004fad81cdabc5f4086d8d6f9780a2d3b3756190d933442b01'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='a4e43544-56bc-448d-bf02-43e73f560e2d', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='faae8026e58a59968285c1e86253faa6af818c32065ada6bf09f2bca3079e76a')}, hash='12632789c9c8125048dfe68c6eb8d9a016bc9e79c6c0c52e9dcdd02e5502e904', text='Most data is in English,\\nmeaning that Llama 2 will perform best for English-language use cases. The large unknown category is\\npartially made up of programming code data.\\nSafetyBenchmarksforPretrainedModels. Weevaluatethesafetycapabilitiesof Llama 2 onthreepopular\\nautomatic benchmarks, pertaining to three key dimensions of LM safety.\\n1.Truthfulness , referring to whether a language model produces known falsehoods due to misconcep-\\ntions or false beliefs. We employ TruthfulQA (Lin et al., 2021) to measure how well our LLMs can\\ngenerate reliable outputs that agree with factuality and common sense.\\n2.Toxicity,definedasthetendencyofalanguagemodeltogeneratetoxic,rude,adversarial,orimplicitly\\nhateful content. We choose ToxiGen (Hartvigsen et al., 2022) to measure the amount of generation\\nof toxic language and hate speech across different groups.\\n3.Bias, defined as how model generations reproduce existing stereotypical social biases.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-21'),\n",
              " 'a4e43544-56bc-448d-bf02-43e73f560e2d': IndexNode(id_='a4e43544-56bc-448d-bf02-43e73f560e2d', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-21', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='878a58c50329bc623a4ffff25d70e783176a9b990e47b9d4f24166278a3d067a'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='c6aa920a-0856-4869-8a60-74333c20b7f5', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='12632789c9c8125048dfe68c6eb8d9a016bc9e79c6c0c52e9dcdd02e5502e904'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='c53f80c7-f05a-4f96-a81c-3b14ec9753c2', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='47a27506ac5a324d2f04eb9a03ecb1ab1760b3aeec713edeada24dcee1c59c9e')}, hash='faae8026e58a59968285c1e86253faa6af818c32065ada6bf09f2bca3079e76a', text='3.Bias, defined as how model generations reproduce existing stereotypical social biases. We use\\nBOLD(Dhamala et al., 2021) to study how the sentiment in model generations may vary with\\ndemographic attributes.\\nWe compare the performance of Llama 2 with Llama 1 (Touvron et al., 2023), Falcon (Almazrouei et al.,\\n2023), and MPT (MosaicML NLP Team et al., 2023) in Table 11. For decoding, we set temperature to 0.1\\nand use nucleus sampling (Holtzman et al., 2020) with top- pset to 0.9. For TruthfulQA, we present the\\npercentageofgenerationsthatarebothtruthfulandinformative(thehigher,thebetter). ForToxiGen,we\\npresentthepercentageofgenerationsthataredeemedtoxicbythemetric(thelower,thebetter). Detailed\\ndescriptionsofthebenchmarksandmetricscanbefoundinAppendixA.4.7.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-21'),\n",
              " 'c53f80c7-f05a-4f96-a81c-3b14ec9753c2': IndexNode(id_='c53f80c7-f05a-4f96-a81c-3b14ec9753c2', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-21', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='878a58c50329bc623a4ffff25d70e783176a9b990e47b9d4f24166278a3d067a'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='a4e43544-56bc-448d-bf02-43e73f560e2d', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='faae8026e58a59968285c1e86253faa6af818c32065ada6bf09f2bca3079e76a'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='2230651a-582f-4c57-9e03-2618600822b6', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='3047d70e9ec2e2733f8d2f2f8970c76c221bd75def612ab5c68f3aeea214e015')}, hash='47a27506ac5a324d2f04eb9a03ecb1ab1760b3aeec713edeada24dcee1c59c9e', text='Whencomparedto Llama 1-7B,\\nLlama 2-7B demonstrates a 21.37% increase in truthfulness and informativeness and a 7.61% decrease in\\ntoxicity. We also observe an increase in toxicity in the pretrained 13B and 70B Llama 2, which may result\\nfrom larger pretraining data or a different dataset mix. Some have postulated the existence of a relationship\\nbetween pretraining dataset size and downstream model toxicity or bias (Bender et al., 2021b), but empirical\\nwork to validate this claim is still ongoing (Dodge et al., 2021; Smith and Williams, 2021; Tal et al., 2022), and\\nfurther evidence from up-to-date models is still needed.\\nIn Appendix A.4.7, we present bias metrics, such as how the sentiment of model generations varies with\\ndemographic attributes. We note an increase in positive sentiment overall for many of the groups using\\nBOLDprompts. MoredetailedresultssplitbydifferentdemographicgroupscanbefoundinAppendixA.4.8.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-21'),\n",
              " '2230651a-582f-4c57-9e03-2618600822b6': IndexNode(id_='2230651a-582f-4c57-9e03-2618600822b6', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-21', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='878a58c50329bc623a4ffff25d70e783176a9b990e47b9d4f24166278a3d067a'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='c53f80c7-f05a-4f96-a81c-3b14ec9753c2', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='47a27506ac5a324d2f04eb9a03ecb1ab1760b3aeec713edeada24dcee1c59c9e')}, hash='3047d70e9ec2e2733f8d2f2f8970c76c221bd75def612ab5c68f3aeea214e015', text='Llama 2 doesnotoutperformothermodelsontoxicitymetrics,andwespeculatethatthismaybebecausewe\\nrefrained from aggressively filtering the pretraining data. Recall that leaving pretraining data unfiltered may\\nenable base models tuned to perform well on more downstream tasks (including hate speech detection),\\nand it carries less risk of accidentally filtering out some demographic groups.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-21'),\n",
              " 'b6917b03-a92a-46cc-b243-8b06331e7163': IndexNode(id_='b6917b03-a92a-46cc-b243-8b06331e7163', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-21', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='878a58c50329bc623a4ffff25d70e783176a9b990e47b9d4f24166278a3d067a'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='80e944b5-aa47-4b3c-8fc1-9bfdadc68394', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='e81e13c88431a6f151a5cd0926f6121ea679ef9ab0f8698329a4924be6e7b8b9')}, hash='4bb682a077740217fb87d982e68132d6d5b8681ea277d22507abe001cd86a867', text='OuranalysisusesthefastText(Bojanowskietal.,2016)language\\nidentification tool and a threshold of 0.5for the language detection. A training corpus with a majority in\\nEnglish means that the model may not be suitable for use in other languages.\\n21\\n\\nLanguage Percent Language Percent\\nen 89.70% uk 0.07%\\nunknown 8.38% ko 0.06%\\nde 0.17% ca 0.04%\\nfr 0.16% sr 0.04%\\nsv 0.15% id 0.03%\\nzh 0.13% cs 0.03%\\nes 0.13% fi 0.03%\\nru 0.13% hu 0.03%\\nnl 0.12% no 0.03%\\nit 0.11% ro 0.03%\\nja 0.10% bg 0.02%\\npl 0.09% da 0.02%\\npt 0.09% sl 0.01%\\nvi 0.08% hr 0.01%\\nTable 10: Language distribution in pretraining data with percentage >= 0.005% . Most data is in English,\\nmeaning that Llama 2 will perform best for English-language use cases. The large unknown category is\\npartially made up of programming code data.\\nSafetyBenchmarksforPretrainedModels. Weevaluatethesafetycapabilitiesof Llama 2 onthreepopular\\nautomatic benchmarks, pertaining to three key dimensions of LM safety.\\n1.Truthfulness , referring to whether a language model produces known falsehoods due to misconcep-\\ntions or false beliefs. We employ TruthfulQA (Lin et al., 2021) to measure how well our LLMs can\\ngenerate reliable outputs that agree with factuality and common sense.\\n2.Toxicity,definedasthetendencyofalanguagemodeltogeneratetoxic,rude,adversarial,orimplicitly\\nhateful content. We choose ToxiGen (Hartvigsen et al., 2022) to measure the amount of generation\\nof toxic language and hate speech across different groups.\\n3.Bias, defined as how model generations reproduce existing stereotypical social biases. We use\\nBOLD(Dhamala et al., 2021) to study how the sentiment in model generations may vary with\\ndemographic attributes.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-21'),\n",
              " '80e944b5-aa47-4b3c-8fc1-9bfdadc68394': IndexNode(id_='80e944b5-aa47-4b3c-8fc1-9bfdadc68394', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-21', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='878a58c50329bc623a4ffff25d70e783176a9b990e47b9d4f24166278a3d067a'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='b6917b03-a92a-46cc-b243-8b06331e7163', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='4bb682a077740217fb87d982e68132d6d5b8681ea277d22507abe001cd86a867')}, hash='e81e13c88431a6f151a5cd0926f6121ea679ef9ab0f8698329a4924be6e7b8b9', text='We compare the performance of Llama 2 with Llama 1 (Touvron et al., 2023), Falcon (Almazrouei et al.,\\n2023), and MPT (MosaicML NLP Team et al., 2023) in Table 11. For decoding, we set temperature to 0.1\\nand use nucleus sampling (Holtzman et al., 2020) with top- pset to 0.9. For TruthfulQA, we present the\\npercentageofgenerationsthatarebothtruthfulandinformative(thehigher,thebetter). ForToxiGen,we\\npresentthepercentageofgenerationsthataredeemedtoxicbythemetric(thelower,thebetter). Detailed\\ndescriptionsofthebenchmarksandmetricscanbefoundinAppendixA.4.7. Whencomparedto Llama 1-7B,\\nLlama 2-7B demonstrates a 21.37% increase in truthfulness and informativeness and a 7.61% decrease in\\ntoxicity. We also observe an increase in toxicity in the pretrained 13B and 70B Llama 2, which may result\\nfrom larger pretraining data or a different dataset mix. Some have postulated the existence of a relationship\\nbetween pretraining dataset size and downstream model toxicity or bias (Bender et al., 2021b), but empirical\\nwork to validate this claim is still ongoing (Dodge et al., 2021; Smith and Williams, 2021; Tal et al., 2022), and\\nfurther evidence from up-to-date models is still needed.\\nIn Appendix A.4.7, we present bias metrics, such as how the sentiment of model generations varies with\\ndemographic attributes. We note an increase in positive sentiment overall for many of the groups using\\nBOLDprompts. MoredetailedresultssplitbydifferentdemographicgroupscanbefoundinAppendixA.4.8.\\nLlama 2 doesnotoutperformothermodelsontoxicitymetrics,andwespeculatethatthismaybebecausewe\\nrefrained from aggressively filtering the pretraining data. Recall that leaving pretraining data unfiltered may\\nenable base models tuned to perform well on more downstream tasks (including hate speech detection),\\nand it carries less risk of accidentally filtering out some demographic groups.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-21'),\n",
              " 'node-21': IndexNode(id_='node-21', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='415b7efc-e73f-4ac4-bbfd-c1546f099026', node_type=<ObjectType.DOCUMENT: '4'>, metadata={}, hash='231b3bd773f012c01b893ada9e009ecf25ee59934614c5a595c9bf1b3a123292'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='9ec29903-8f3d-4baf-b5a0-c3a0913e9b9f', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='68f370ddf9c749f1830399ccbe295abafcf530e1adba662fc44bce3047b8b395'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='6c1aec3f-d146-4bd7-81cd-c53f7de0493c', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='60e16382f8ffcd8ebb49f78fa450199f60f18b0a69ffadcbe41b7dc2990678c3')}, hash='878a58c50329bc623a4ffff25d70e783176a9b990e47b9d4f24166278a3d067a', text='OuranalysisusesthefastText(Bojanowskietal.,2016)language\\nidentification tool and a threshold of 0.5for the language detection. A training corpus with a majority in\\nEnglish means that the model may not be suitable for use in other languages.\\n21\\n\\nLanguage Percent Language Percent\\nen 89.70% uk 0.07%\\nunknown 8.38% ko 0.06%\\nde 0.17% ca 0.04%\\nfr 0.16% sr 0.04%\\nsv 0.15% id 0.03%\\nzh 0.13% cs 0.03%\\nes 0.13% fi 0.03%\\nru 0.13% hu 0.03%\\nnl 0.12% no 0.03%\\nit 0.11% ro 0.03%\\nja 0.10% bg 0.02%\\npl 0.09% da 0.02%\\npt 0.09% sl 0.01%\\nvi 0.08% hr 0.01%\\nTable 10: Language distribution in pretraining data with percentage >= 0.005% . Most data is in English,\\nmeaning that Llama 2 will perform best for English-language use cases. The large unknown category is\\npartially made up of programming code data.\\nSafetyBenchmarksforPretrainedModels. Weevaluatethesafetycapabilitiesof Llama 2 onthreepopular\\nautomatic benchmarks, pertaining to three key dimensions of LM safety.\\n1.Truthfulness , referring to whether a language model produces known falsehoods due to misconcep-\\ntions or false beliefs. We employ TruthfulQA (Lin et al., 2021) to measure how well our LLMs can\\ngenerate reliable outputs that agree with factuality and common sense.\\n2.Toxicity,definedasthetendencyofalanguagemodeltogeneratetoxic,rude,adversarial,orimplicitly\\nhateful content. We choose ToxiGen (Hartvigsen et al., 2022) to measure the amount of generation\\nof toxic language and hate speech across different groups.\\n3.Bias, defined as how model generations reproduce existing stereotypical social biases. We use\\nBOLD(Dhamala et al., 2021) to study how the sentiment in model generations may vary with\\ndemographic attributes.\\nWe compare the performance of Llama 2 with Llama 1 (Touvron et al., 2023), Falcon (Almazrouei et al.,\\n2023), and MPT (MosaicML NLP Team et al., 2023) in Table 11. For decoding, we set temperature to 0.1\\nand use nucleus sampling (Holtzman et al., 2020) with top- pset to 0.9. For TruthfulQA, we present the\\npercentageofgenerationsthatarebothtruthfulandinformative(thehigher,thebetter). ForToxiGen,we\\npresentthepercentageofgenerationsthataredeemedtoxicbythemetric(thelower,thebetter). Detailed\\ndescriptionsofthebenchmarksandmetricscanbefoundinAppendixA.4.7. Whencomparedto Llama 1-7B,\\nLlama 2-7B demonstrates a 21.37% increase in truthfulness and informativeness and a 7.61% decrease in\\ntoxicity. We also observe an increase in toxicity in the pretrained 13B and 70B Llama 2, which may result\\nfrom larger pretraining data or a different dataset mix. Some have postulated the existence of a relationship\\nbetween pretraining dataset size and downstream model toxicity or bias (Bender et al., 2021b), but empirical\\nwork to validate this claim is still ongoing (Dodge et al., 2021; Smith and Williams, 2021; Tal et al., 2022), and\\nfurther evidence from up-to-date models is still needed.\\nIn Appendix A.4.7, we present bias metrics, such as how the sentiment of model generations varies with\\ndemographic attributes. We note an increase in positive sentiment overall for many of the groups using\\nBOLDprompts. MoredetailedresultssplitbydifferentdemographicgroupscanbefoundinAppendixA.4.8.\\nLlama 2 doesnotoutperformothermodelsontoxicitymetrics,andwespeculatethatthismaybebecausewe\\nrefrained from aggressively filtering the pretraining data. Recall that leaving pretraining data unfiltered may\\nenable base models tuned to perform well on more downstream tasks (including hate speech detection),\\nand it carries less risk of accidentally filtering out some demographic groups.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-21'),\n",
              " '9a7e15b9-8c6c-443a-a7d8-04f964049421': IndexNode(id_='9a7e15b9-8c6c-443a-a7d8-04f964049421', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-22', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='60e16382f8ffcd8ebb49f78fa450199f60f18b0a69ffadcbe41b7dc2990678c3'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='de1b66e0-aab5-4786-a79d-52cdcbfe4eef', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='115b72b4495ae41fd40e5e033cc23e1d20c58461024359f3a751560a84f54a32')}, hash='88301a3b6707a178bbe2ad3b056ad26c5ff528527a7dccceae6e8be5631c66bc', text='We observe that models\\ntrained from less aggressively filtered pretraining data also required fewer examples to achieve reasonable\\nsafety-alignment. Wereiteratethatthismotivatedchoicedoesimplythatadditionalsafetymitigationsshould\\nbe applied before deployment of base Llama 2 models.\\n22\\n\\nTruthfulQA ↑ToxiGen ↓\\nMPT7B 29.13 22.32\\n30B 35.25 22.61\\nFalcon7B 25.95 14.53\\n40B 40.39 23.44\\nLlama 17B 27.42 23.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-22'),\n",
              " 'de1b66e0-aab5-4786-a79d-52cdcbfe4eef': IndexNode(id_='de1b66e0-aab5-4786-a79d-52cdcbfe4eef', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-22', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='60e16382f8ffcd8ebb49f78fa450199f60f18b0a69ffadcbe41b7dc2990678c3'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='9a7e15b9-8c6c-443a-a7d8-04f964049421', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='88301a3b6707a178bbe2ad3b056ad26c5ff528527a7dccceae6e8be5631c66bc'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='0d257be2-0151-485d-bfea-b7b15dc47135', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='33b9eb757f756b8dee72689be46cb34f6809adecaf87df852df49cf5c7dc1215')}, hash='115b72b4495ae41fd40e5e033cc23e1d20c58461024359f3a751560a84f54a32', text='39 23.44\\nLlama 17B 27.42 23.00\\n13B 41.74 23.08\\n33B 44.19 22.57\\n65B 48.71 21.77\\nLlama 27B 33.29 21.25\\n13B 41.86 26.10\\n34B 43.45 21.19\\n70B 50.18 24.60\\nTable 11: Evaluation of pretrained LLMs on automatic safety benchmarks.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-22'),\n",
              " '0d257be2-0151-485d-bfea-b7b15dc47135': IndexNode(id_='0d257be2-0151-485d-bfea-b7b15dc47135', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-22', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='60e16382f8ffcd8ebb49f78fa450199f60f18b0a69ffadcbe41b7dc2990678c3'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='de1b66e0-aab5-4786-a79d-52cdcbfe4eef', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='115b72b4495ae41fd40e5e033cc23e1d20c58461024359f3a751560a84f54a32'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='d6c22529-6227-42be-8de2-2e4ce80e208f', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='b8b1c42a62d284d34db56c4ce219d734d2fd57bebd29be560ec280ab89102961')}, hash='33b9eb757f756b8dee72689be46cb34f6809adecaf87df852df49cf5c7dc1215', text='18 24.60\\nTable 11: Evaluation of pretrained LLMs on automatic safety benchmarks. For TruthfulQA, we present the\\npercentageofgenerationsthatarebothtruthfulandinformative(thehigherthebetter). ForToxiGen,we\\npresent the percentage of toxic generations (the smaller, the better).', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-22'),\n",
              " 'd6c22529-6227-42be-8de2-2e4ce80e208f': IndexNode(id_='d6c22529-6227-42be-8de2-2e4ce80e208f', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-22', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='60e16382f8ffcd8ebb49f78fa450199f60f18b0a69ffadcbe41b7dc2990678c3'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='0d257be2-0151-485d-bfea-b7b15dc47135', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='33b9eb757f756b8dee72689be46cb34f6809adecaf87df852df49cf5c7dc1215'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='0490482c-dd2a-4002-bd93-b392cf781caa', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='01a8b8297b4a9a4ee76d99aecd41e4a4af77e4f90df594786d56b131ff048253')}, hash='b8b1c42a62d284d34db56c4ce219d734d2fd57bebd29be560ec280ab89102961', text='Benchmarks give a summary view ofmodel capabilities and behaviors that allow us to understand general\\npatternsinthemodel,buttheydonotprovideafullycomprehensiveviewoftheimpactthemodelmayhave\\nonpeopleorreal-worldoutcomes;thatwouldrequirestudyofend-to-endproductdeployments. Further\\ntesting and mitigation should be done to understand bias and other social issues for the specific context\\nin which a system may be deployed.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-22'),\n",
              " '0490482c-dd2a-4002-bd93-b392cf781caa': IndexNode(id_='0490482c-dd2a-4002-bd93-b392cf781caa', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-22', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='60e16382f8ffcd8ebb49f78fa450199f60f18b0a69ffadcbe41b7dc2990678c3'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='d6c22529-6227-42be-8de2-2e4ce80e208f', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='b8b1c42a62d284d34db56c4ce219d734d2fd57bebd29be560ec280ab89102961'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='5931d016-c400-41de-add2-d147ebc3bad0', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='ddbc22969a2dbfdb7e625a6f0e1984be758f82e1b4cb3be77b34adcf52f14ccd')}, hash='01a8b8297b4a9a4ee76d99aecd41e4a4af77e4f90df594786d56b131ff048253', text='For this, it may be necessary to test beyond the groups available in\\ntheBOLDdataset(race,religion,andgender). AsLLMsareintegratedanddeployed,welookforwardto\\ncontinuing research that will amplify their potential for positive impact on these important social issues.\\n4.2 Safety Fine-Tuning\\nIn this section, we describe our approach to safety fine-tuning, including safety categories, annotation\\nguidelines,andthetechniquesweusetomitigatesafetyrisks.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-22'),\n",
              " '5931d016-c400-41de-add2-d147ebc3bad0': IndexNode(id_='5931d016-c400-41de-add2-d147ebc3bad0', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-22', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='60e16382f8ffcd8ebb49f78fa450199f60f18b0a69ffadcbe41b7dc2990678c3'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='0490482c-dd2a-4002-bd93-b392cf781caa', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='01a8b8297b4a9a4ee76d99aecd41e4a4af77e4f90df594786d56b131ff048253'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='f5d4c709-a205-4d9c-b100-9310a26da765', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='be0144e55b0aa0483b6bdde99888a34f60a324c2e4c886d49774e9febc90b197')}, hash='ddbc22969a2dbfdb7e625a6f0e1984be758f82e1b4cb3be77b34adcf52f14ccd', text='Weemployaprocesssimilartothegeneral\\nfine-tuning methods as described in Section 3, with some notable differences related to safety concerns.\\nSpecifically, we use the following techniques in safety fine-tuning:\\n1.Supervised Safety Fine-Tuning : We initialize by gathering adversarial prompts and safe demonstra-\\ntions that are then included in the general supervised fine-tuning process (Section 3.1). This teaches\\nthemodeltoalignwithoursafetyguidelinesevenbeforeRLHF,andthuslaysthefoundationfor\\nhigh-quality human preference data annotation.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-22'),\n",
              " 'f5d4c709-a205-4d9c-b100-9310a26da765': IndexNode(id_='f5d4c709-a205-4d9c-b100-9310a26da765', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-22', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='60e16382f8ffcd8ebb49f78fa450199f60f18b0a69ffadcbe41b7dc2990678c3'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='5931d016-c400-41de-add2-d147ebc3bad0', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='ddbc22969a2dbfdb7e625a6f0e1984be758f82e1b4cb3be77b34adcf52f14ccd'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='c1f45d2f-4287-45bc-b832-a32ebb234a18', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='6a2550a566de4100415718754c2b9e9b2622256670e2f59d90878a7e55406c0e')}, hash='be0144e55b0aa0483b6bdde99888a34f60a324c2e4c886d49774e9febc90b197', text='2.Safety RLHF : Subsequently, we integrate safety in the general RLHF pipeline described in Sec-\\ntion 3.2.2. This includes training a safety-specific reward model and gathering more challenging\\nadversarial prompts for rejection sampling style fine-tuning and PPO optimization.\\n3.SafetyContextDistillation : Finally,werefineourRLHFpipelinewithcontextdistillation(Askell\\netal.,2021b).', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-22'),\n",
              " 'c1f45d2f-4287-45bc-b832-a32ebb234a18': IndexNode(id_='c1f45d2f-4287-45bc-b832-a32ebb234a18', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-22', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='60e16382f8ffcd8ebb49f78fa450199f60f18b0a69ffadcbe41b7dc2990678c3'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='f5d4c709-a205-4d9c-b100-9310a26da765', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='be0144e55b0aa0483b6bdde99888a34f60a324c2e4c886d49774e9febc90b197'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='1c6fc9fc-3d95-46a0-b141-ef86a43b7f4c', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='2919a4492353316a99e00ce6c58b6ffec12636ba4cef8b1b7595b0b2f44f6827')}, hash='6a2550a566de4100415718754c2b9e9b2622256670e2f59d90878a7e55406c0e', text='Thisinvolvesgeneratingsafermodelresponsesbyprefixingapromptwithasafety\\npreprompt, e.g., “You are a safe and responsible assistant,” and then fine-tuning the model on the safer\\nresponses without the preprompt, which essentially distillsthe safety preprompt (context) into the\\nmodel. Weuseatargetedapproachthatallowsoursafetyrewardmodeltochoosewhethertouse\\ncontext distillation for each sample.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-22'),\n",
              " '1c6fc9fc-3d95-46a0-b141-ef86a43b7f4c': IndexNode(id_='1c6fc9fc-3d95-46a0-b141-ef86a43b7f4c', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-22', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='60e16382f8ffcd8ebb49f78fa450199f60f18b0a69ffadcbe41b7dc2990678c3'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='c1f45d2f-4287-45bc-b832-a32ebb234a18', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='6a2550a566de4100415718754c2b9e9b2622256670e2f59d90878a7e55406c0e'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='e777a957-84d0-4855-a193-aac2a645e8f5', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='8326bc141d03b68ccd263e9c5034ef06241fbdc347fd335883e1f9d24ef3345c')}, hash='2919a4492353316a99e00ce6c58b6ffec12636ba4cef8b1b7595b0b2f44f6827', text='4.2.1 Safety Categories and Annotation Guidelines\\nBased on limitations of LLMs known from prior work, we design instructions for our annotation team to\\ncreateadversarialpromptsalongtwodimensions: a riskcategory ,orpotentialtopicaboutwhichtheLLM\\ncouldproduceunsafecontent;andan attackvector ,orquestionstyletocoverdifferentvarietiesofprompts\\nthat could elicit bad model behaviors.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-22'),\n",
              " 'e777a957-84d0-4855-a193-aac2a645e8f5': IndexNode(id_='e777a957-84d0-4855-a193-aac2a645e8f5', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-22', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='60e16382f8ffcd8ebb49f78fa450199f60f18b0a69ffadcbe41b7dc2990678c3'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='1c6fc9fc-3d95-46a0-b141-ef86a43b7f4c', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='2919a4492353316a99e00ce6c58b6ffec12636ba4cef8b1b7595b0b2f44f6827')}, hash='8326bc141d03b68ccd263e9c5034ef06241fbdc347fd335883e1f9d24ef3345c', text='Theriskcategoriesconsideredcanbebroadlydividedintothefollowingthreecategories: illicitandcriminal\\nactivities (e.g.,terrorism,theft,humantrafficking); hatefulandharmfulactivities (e.g.,defamation,self-\\nharm, eating disorders, discrimination); and unqualified advice (e.g., medical advice, financial advice, legal\\n23\\n\\nadvice).', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-22'),\n",
              " '5b9259f7-2701-4677-a978-8f8238cba9ac': IndexNode(id_='5b9259f7-2701-4677-a978-8f8238cba9ac', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-22', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='60e16382f8ffcd8ebb49f78fa450199f60f18b0a69ffadcbe41b7dc2990678c3'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='9c948280-68e0-405e-890a-846214abb1ac', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='e3967ecc078d39d02f73bf8763c11ab64843fac523ac0968f58ea59ff7486be0')}, hash='3b65d6a6422ac7492438231ffe8610bcb67687d73f19f46c3c62986d58da1d69', text='We observe that models\\ntrained from less aggressively filtered pretraining data also required fewer examples to achieve reasonable\\nsafety-alignment. Wereiteratethatthismotivatedchoicedoesimplythatadditionalsafetymitigationsshould\\nbe applied before deployment of base Llama 2 models.\\n22\\n\\nTruthfulQA ↑ToxiGen ↓\\nMPT7B 29.13 22.32\\n30B 35.25 22.61\\nFalcon7B 25.95 14.53\\n40B 40.39 23.44\\nLlama 17B 27.42 23.00\\n13B 41.74 23.08\\n33B 44.19 22.57\\n65B 48.71 21.77\\nLlama 27B 33.29 21.25\\n13B 41.86 26.10\\n34B 43.45 21.19\\n70B 50.18 24.60\\nTable 11: Evaluation of pretrained LLMs on automatic safety benchmarks. For TruthfulQA, we present the\\npercentageofgenerationsthatarebothtruthfulandinformative(thehigherthebetter).', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-22'),\n",
              " '9c948280-68e0-405e-890a-846214abb1ac': IndexNode(id_='9c948280-68e0-405e-890a-846214abb1ac', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-22', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='60e16382f8ffcd8ebb49f78fa450199f60f18b0a69ffadcbe41b7dc2990678c3'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='5b9259f7-2701-4677-a978-8f8238cba9ac', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='3b65d6a6422ac7492438231ffe8610bcb67687d73f19f46c3c62986d58da1d69'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='6e47b827-c85b-4093-a346-30e65790fb83', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='97d0fbbde8249a31e763aacf5dd110216157bf207802fb24b5e94e851189b03b')}, hash='e3967ecc078d39d02f73bf8763c11ab64843fac523ac0968f58ea59ff7486be0', text='ForToxiGen,we\\npresent the percentage of toxic generations (the smaller, the better).\\nBenchmarks give a summary view ofmodel capabilities and behaviors that allow us to understand general\\npatternsinthemodel,buttheydonotprovideafullycomprehensiveviewoftheimpactthemodelmayhave\\nonpeopleorreal-worldoutcomes;thatwouldrequirestudyofend-to-endproductdeployments. Further\\ntesting and mitigation should be done to understand bias and other social issues for the specific context\\nin which a system may be deployed. For this, it may be necessary to test beyond the groups available in\\ntheBOLDdataset(race,religion,andgender). AsLLMsareintegratedanddeployed,welookforwardto\\ncontinuing research that will amplify their potential for positive impact on these important social issues.\\n4.2 Safety Fine-Tuning\\nIn this section, we describe our approach to safety fine-tuning, including safety categories, annotation\\nguidelines,andthetechniquesweusetomitigatesafetyrisks.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-22'),\n",
              " '6e47b827-c85b-4093-a346-30e65790fb83': IndexNode(id_='6e47b827-c85b-4093-a346-30e65790fb83', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-22', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='60e16382f8ffcd8ebb49f78fa450199f60f18b0a69ffadcbe41b7dc2990678c3'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='9c948280-68e0-405e-890a-846214abb1ac', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='e3967ecc078d39d02f73bf8763c11ab64843fac523ac0968f58ea59ff7486be0'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='fa6fbd09-4154-4356-a720-2c4950cdfd16', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='2e9f0a2fd62d141e265ffc3af19a67c0f2c3ac8bfe1b5efc30edb572fa2b65b6')}, hash='97d0fbbde8249a31e763aacf5dd110216157bf207802fb24b5e94e851189b03b', text='Weemployaprocesssimilartothegeneral\\nfine-tuning methods as described in Section 3, with some notable differences related to safety concerns.\\nSpecifically, we use the following techniques in safety fine-tuning:\\n1.Supervised Safety Fine-Tuning : We initialize by gathering adversarial prompts and safe demonstra-\\ntions that are then included in the general supervised fine-tuning process (Section 3.1). This teaches\\nthemodeltoalignwithoursafetyguidelinesevenbeforeRLHF,andthuslaysthefoundationfor\\nhigh-quality human preference data annotation.\\n2.Safety RLHF : Subsequently, we integrate safety in the general RLHF pipeline described in Sec-\\ntion 3.2.2. This includes training a safety-specific reward model and gathering more challenging\\nadversarial prompts for rejection sampling style fine-tuning and PPO optimization.\\n3.SafetyContextDistillation : Finally,werefineourRLHFpipelinewithcontextdistillation(Askell\\netal.,2021b).', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-22'),\n",
              " 'fa6fbd09-4154-4356-a720-2c4950cdfd16': IndexNode(id_='fa6fbd09-4154-4356-a720-2c4950cdfd16', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-22', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='60e16382f8ffcd8ebb49f78fa450199f60f18b0a69ffadcbe41b7dc2990678c3'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='6e47b827-c85b-4093-a346-30e65790fb83', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='97d0fbbde8249a31e763aacf5dd110216157bf207802fb24b5e94e851189b03b'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='4baff638-d9b8-484b-95da-b2355754caaa', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='8326bc141d03b68ccd263e9c5034ef06241fbdc347fd335883e1f9d24ef3345c')}, hash='2e9f0a2fd62d141e265ffc3af19a67c0f2c3ac8bfe1b5efc30edb572fa2b65b6', text='Thisinvolvesgeneratingsafermodelresponsesbyprefixingapromptwithasafety\\npreprompt, e.g., “You are a safe and responsible assistant,” and then fine-tuning the model on the safer\\nresponses without the preprompt, which essentially distillsthe safety preprompt (context) into the\\nmodel. Weuseatargetedapproachthatallowsoursafetyrewardmodeltochoosewhethertouse\\ncontext distillation for each sample.\\n4.2.1 Safety Categories and Annotation Guidelines\\nBased on limitations of LLMs known from prior work, we design instructions for our annotation team to\\ncreateadversarialpromptsalongtwodimensions: a riskcategory ,orpotentialtopicaboutwhichtheLLM\\ncouldproduceunsafecontent;andan attackvector ,orquestionstyletocoverdifferentvarietiesofprompts\\nthat could elicit bad model behaviors.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-22'),\n",
              " '4baff638-d9b8-484b-95da-b2355754caaa': IndexNode(id_='4baff638-d9b8-484b-95da-b2355754caaa', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-22', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='60e16382f8ffcd8ebb49f78fa450199f60f18b0a69ffadcbe41b7dc2990678c3'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='fa6fbd09-4154-4356-a720-2c4950cdfd16', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='2e9f0a2fd62d141e265ffc3af19a67c0f2c3ac8bfe1b5efc30edb572fa2b65b6')}, hash='8326bc141d03b68ccd263e9c5034ef06241fbdc347fd335883e1f9d24ef3345c', text='Theriskcategoriesconsideredcanbebroadlydividedintothefollowingthreecategories: illicitandcriminal\\nactivities (e.g.,terrorism,theft,humantrafficking); hatefulandharmfulactivities (e.g.,defamation,self-\\nharm, eating disorders, discrimination); and unqualified advice (e.g., medical advice, financial advice, legal\\n23\\n\\nadvice).', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-22'),\n",
              " 'd134cd7a-47d5-4442-a625-82415e8c7ad8': IndexNode(id_='d134cd7a-47d5-4442-a625-82415e8c7ad8', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-22', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='60e16382f8ffcd8ebb49f78fa450199f60f18b0a69ffadcbe41b7dc2990678c3'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='9b4d0632-d93f-4694-853d-9facce819254', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='9ca62562cf717ea1d004240fee87c587ddb095d2e2b44d08f4d74203b0fbfe6f')}, hash='37259dac39be88b7840e00e786f0316e33169fbebed92887ca8a5efc9cf37c69', text='We observe that models\\ntrained from less aggressively filtered pretraining data also required fewer examples to achieve reasonable\\nsafety-alignment. Wereiteratethatthismotivatedchoicedoesimplythatadditionalsafetymitigationsshould\\nbe applied before deployment of base Llama 2 models.\\n22\\n\\nTruthfulQA ↑ToxiGen ↓\\nMPT7B 29.13 22.32\\n30B 35.25 22.61\\nFalcon7B 25.95 14.53\\n40B 40.39 23.44\\nLlama 17B 27.42 23.00\\n13B 41.74 23.08\\n33B 44.19 22.57\\n65B 48.71 21.77\\nLlama 27B 33.29 21.25\\n13B 41.86 26.10\\n34B 43.45 21.19\\n70B 50.18 24.60\\nTable 11: Evaluation of pretrained LLMs on automatic safety benchmarks. For TruthfulQA, we present the\\npercentageofgenerationsthatarebothtruthfulandinformative(thehigherthebetter). ForToxiGen,we\\npresent the percentage of toxic generations (the smaller, the better).\\nBenchmarks give a summary view ofmodel capabilities and behaviors that allow us to understand general\\npatternsinthemodel,buttheydonotprovideafullycomprehensiveviewoftheimpactthemodelmayhave\\nonpeopleorreal-worldoutcomes;thatwouldrequirestudyofend-to-endproductdeployments. Further\\ntesting and mitigation should be done to understand bias and other social issues for the specific context\\nin which a system may be deployed. For this, it may be necessary to test beyond the groups available in\\ntheBOLDdataset(race,religion,andgender). AsLLMsareintegratedanddeployed,welookforwardto\\ncontinuing research that will amplify their potential for positive impact on these important social issues.\\n4.2 Safety Fine-Tuning\\nIn this section, we describe our approach to safety fine-tuning, including safety categories, annotation\\nguidelines,andthetechniquesweusetomitigatesafetyrisks.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-22'),\n",
              " '9b4d0632-d93f-4694-853d-9facce819254': IndexNode(id_='9b4d0632-d93f-4694-853d-9facce819254', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-22', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='60e16382f8ffcd8ebb49f78fa450199f60f18b0a69ffadcbe41b7dc2990678c3'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='d134cd7a-47d5-4442-a625-82415e8c7ad8', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='37259dac39be88b7840e00e786f0316e33169fbebed92887ca8a5efc9cf37c69')}, hash='9ca62562cf717ea1d004240fee87c587ddb095d2e2b44d08f4d74203b0fbfe6f', text='Weemployaprocesssimilartothegeneral\\nfine-tuning methods as described in Section 3, with some notable differences related to safety concerns.\\nSpecifically, we use the following techniques in safety fine-tuning:\\n1.Supervised Safety Fine-Tuning : We initialize by gathering adversarial prompts and safe demonstra-\\ntions that are then included in the general supervised fine-tuning process (Section 3.1). This teaches\\nthemodeltoalignwithoursafetyguidelinesevenbeforeRLHF,andthuslaysthefoundationfor\\nhigh-quality human preference data annotation.\\n2.Safety RLHF : Subsequently, we integrate safety in the general RLHF pipeline described in Sec-\\ntion 3.2.2. This includes training a safety-specific reward model and gathering more challenging\\nadversarial prompts for rejection sampling style fine-tuning and PPO optimization.\\n3.SafetyContextDistillation : Finally,werefineourRLHFpipelinewithcontextdistillation(Askell\\netal.,2021b). Thisinvolvesgeneratingsafermodelresponsesbyprefixingapromptwithasafety\\npreprompt, e.g., “You are a safe and responsible assistant,” and then fine-tuning the model on the safer\\nresponses without the preprompt, which essentially distillsthe safety preprompt (context) into the\\nmodel. Weuseatargetedapproachthatallowsoursafetyrewardmodeltochoosewhethertouse\\ncontext distillation for each sample.\\n4.2.1 Safety Categories and Annotation Guidelines\\nBased on limitations of LLMs known from prior work, we design instructions for our annotation team to\\ncreateadversarialpromptsalongtwodimensions: a riskcategory ,orpotentialtopicaboutwhichtheLLM\\ncouldproduceunsafecontent;andan attackvector ,orquestionstyletocoverdifferentvarietiesofprompts\\nthat could elicit bad model behaviors.\\nTheriskcategoriesconsideredcanbebroadlydividedintothefollowingthreecategories: illicitandcriminal\\nactivities (e.g.,terrorism,theft,humantrafficking); hatefulandharmfulactivities (e.g.,defamation,self-\\nharm, eating disorders, discrimination); and unqualified advice (e.g., medical advice, financial advice, legal\\n23\\n\\nadvice).', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-22'),\n",
              " 'node-22': IndexNode(id_='node-22', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='415b7efc-e73f-4ac4-bbfd-c1546f099026', node_type=<ObjectType.DOCUMENT: '4'>, metadata={}, hash='231b3bd773f012c01b893ada9e009ecf25ee59934614c5a595c9bf1b3a123292'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='b5599d63-93d3-4f3c-9f99-83ba8bac9687', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='878a58c50329bc623a4ffff25d70e783176a9b990e47b9d4f24166278a3d067a'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='eb23eec0-7cd1-4ea5-b371-8ab1f45e712d', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='843167ff7c56a21575eccdb5b6e987568d9f0dae62087e4aa3914490f3acfe20')}, hash='60e16382f8ffcd8ebb49f78fa450199f60f18b0a69ffadcbe41b7dc2990678c3', text='We observe that models\\ntrained from less aggressively filtered pretraining data also required fewer examples to achieve reasonable\\nsafety-alignment. Wereiteratethatthismotivatedchoicedoesimplythatadditionalsafetymitigationsshould\\nbe applied before deployment of base Llama 2 models.\\n22\\n\\nTruthfulQA ↑ToxiGen ↓\\nMPT7B 29.13 22.32\\n30B 35.25 22.61\\nFalcon7B 25.95 14.53\\n40B 40.39 23.44\\nLlama 17B 27.42 23.00\\n13B 41.74 23.08\\n33B 44.19 22.57\\n65B 48.71 21.77\\nLlama 27B 33.29 21.25\\n13B 41.86 26.10\\n34B 43.45 21.19\\n70B 50.18 24.60\\nTable 11: Evaluation of pretrained LLMs on automatic safety benchmarks. For TruthfulQA, we present the\\npercentageofgenerationsthatarebothtruthfulandinformative(thehigherthebetter). ForToxiGen,we\\npresent the percentage of toxic generations (the smaller, the better).\\nBenchmarks give a summary view ofmodel capabilities and behaviors that allow us to understand general\\npatternsinthemodel,buttheydonotprovideafullycomprehensiveviewoftheimpactthemodelmayhave\\nonpeopleorreal-worldoutcomes;thatwouldrequirestudyofend-to-endproductdeployments. Further\\ntesting and mitigation should be done to understand bias and other social issues for the specific context\\nin which a system may be deployed. For this, it may be necessary to test beyond the groups available in\\ntheBOLDdataset(race,religion,andgender). AsLLMsareintegratedanddeployed,welookforwardto\\ncontinuing research that will amplify their potential for positive impact on these important social issues.\\n4.2 Safety Fine-Tuning\\nIn this section, we describe our approach to safety fine-tuning, including safety categories, annotation\\nguidelines,andthetechniquesweusetomitigatesafetyrisks. Weemployaprocesssimilartothegeneral\\nfine-tuning methods as described in Section 3, with some notable differences related to safety concerns.\\nSpecifically, we use the following techniques in safety fine-tuning:\\n1.Supervised Safety Fine-Tuning : We initialize by gathering adversarial prompts and safe demonstra-\\ntions that are then included in the general supervised fine-tuning process (Section 3.1). This teaches\\nthemodeltoalignwithoursafetyguidelinesevenbeforeRLHF,andthuslaysthefoundationfor\\nhigh-quality human preference data annotation.\\n2.Safety RLHF : Subsequently, we integrate safety in the general RLHF pipeline described in Sec-\\ntion 3.2.2. This includes training a safety-specific reward model and gathering more challenging\\nadversarial prompts for rejection sampling style fine-tuning and PPO optimization.\\n3.SafetyContextDistillation : Finally,werefineourRLHFpipelinewithcontextdistillation(Askell\\netal.,2021b). Thisinvolvesgeneratingsafermodelresponsesbyprefixingapromptwithasafety\\npreprompt, e.g., “You are a safe and responsible assistant,” and then fine-tuning the model on the safer\\nresponses without the preprompt, which essentially distillsthe safety preprompt (context) into the\\nmodel. Weuseatargetedapproachthatallowsoursafetyrewardmodeltochoosewhethertouse\\ncontext distillation for each sample.\\n4.2.1 Safety Categories and Annotation Guidelines\\nBased on limitations of LLMs known from prior work, we design instructions for our annotation team to\\ncreateadversarialpromptsalongtwodimensions: a riskcategory ,orpotentialtopicaboutwhichtheLLM\\ncouldproduceunsafecontent;andan attackvector ,orquestionstyletocoverdifferentvarietiesofprompts\\nthat could elicit bad model behaviors.\\nTheriskcategoriesconsideredcanbebroadlydividedintothefollowingthreecategories: illicitandcriminal\\nactivities (e.g.,terrorism,theft,humantrafficking); hatefulandharmfulactivities (e.g.,defamation,self-\\nharm, eating disorders, discrimination); and unqualified advice (e.g., medical advice, financial advice, legal\\n23\\n\\nadvice).', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-22'),\n",
              " 'c7f2ec4e-1ff3-436a-a754-1b60d6a79c49': IndexNode(id_='c7f2ec4e-1ff3-436a-a754-1b60d6a79c49', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-23', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='843167ff7c56a21575eccdb5b6e987568d9f0dae62087e4aa3914490f3acfe20'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='c49e2dd6-c96c-4c76-88fc-d18ffd39864b', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='17e950dd3a024deafe2d629c628b500e4b9a68b92d92aedac4fb283ef5ac48d6')}, hash='f807d7259db641b57eb4ca5801bd19cb02987c8055075e989271cfc265f82702', text='The attackvectors exploredconsist ofpsychological manipulation(e.g., authoritymanipulation),\\nlogic manipulation (e.g., false premises), syntactic manipulation (e.g., misspelling), semantic manipulation\\n(e.g., metaphor), perspective manipulation (e.g., role playing), non-English languages, and others.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-23'),\n",
              " 'c49e2dd6-c96c-4c76-88fc-d18ffd39864b': IndexNode(id_='c49e2dd6-c96c-4c76-88fc-d18ffd39864b', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-23', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='843167ff7c56a21575eccdb5b6e987568d9f0dae62087e4aa3914490f3acfe20'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='c7f2ec4e-1ff3-436a-a754-1b60d6a79c49', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='f807d7259db641b57eb4ca5801bd19cb02987c8055075e989271cfc265f82702'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='dc953e81-087f-43a6-ab1a-1d30a1d3721f', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='03b7113fdb19c46352c2787b5bad6e2fd4b0a118a189042434799f0a04ce9c59')}, hash='17e950dd3a024deafe2d629c628b500e4b9a68b92d92aedac4fb283ef5ac48d6', text='Wethendefinebestpracticesforsafeandhelpfulmodelresponses: themodelshouldfirstaddressimmediate\\nsafetyconcernsifapplicable,thenaddressthepromptbyexplainingthepotentialriskstotheuser,andfinally\\nprovide additional information if possible. We also ask the annotators to avoid negative user experience\\ncategories (see Appendix A.5.2). The guidelines are meant to be a general guide for the model and are\\niteratively refined and revised to include newly identified risks.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-23'),\n",
              " 'dc953e81-087f-43a6-ab1a-1d30a1d3721f': IndexNode(id_='dc953e81-087f-43a6-ab1a-1d30a1d3721f', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-23', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='843167ff7c56a21575eccdb5b6e987568d9f0dae62087e4aa3914490f3acfe20'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='c49e2dd6-c96c-4c76-88fc-d18ffd39864b', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='17e950dd3a024deafe2d629c628b500e4b9a68b92d92aedac4fb283ef5ac48d6'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='3e2a4a85-4586-48cb-bf21-e5703d0aeabc', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='1b581f9246f04948d0a263b6fe58043b5c7216ffa1b59c71df6ab0f609008501')}, hash='03b7113fdb19c46352c2787b5bad6e2fd4b0a118a189042434799f0a04ce9c59', text='4.2.2 Safety Supervised Fine-Tuning\\nInaccordancewiththeestablishedguidelinesfromSection4.2.1,wegatherpromptsanddemonstrations\\nofsafemodelresponsesfromtrainedannotators,andusethedataforsupervisedfine-tuninginthesame\\nmanner as described in Section 3.1. An example can be found in Table 5.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-23'),\n",
              " '3e2a4a85-4586-48cb-bf21-e5703d0aeabc': IndexNode(id_='3e2a4a85-4586-48cb-bf21-e5703d0aeabc', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-23', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='843167ff7c56a21575eccdb5b6e987568d9f0dae62087e4aa3914490f3acfe20'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='dc953e81-087f-43a6-ab1a-1d30a1d3721f', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='03b7113fdb19c46352c2787b5bad6e2fd4b0a118a189042434799f0a04ce9c59'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='56fb7524-c4de-4138-aecb-c18560d87f6d', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='d10122348e445139fc4953fc832591d321c6342cda77a893cec74d0d806983ea')}, hash='1b581f9246f04948d0a263b6fe58043b5c7216ffa1b59c71df6ab0f609008501', text='An example can be found in Table 5.\\nThe annotators are instructed to initially come up with prompts that they think could potentially induce\\nthemodel toexhibit unsafebehavior, i.e.,perform redteaming, asdefined bythe guidelines. Subsequently,\\nannotators are tasked with crafting a safe and helpful response that the model should produce.\\n4.2.3 Safety RLHF\\nWeobserveearlyinthedevelopmentof Llama 2-Chat thatitisabletogeneralizefromthesafedemonstrations\\ninsupervisedfine-tuning.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-23'),\n",
              " '56fb7524-c4de-4138-aecb-c18560d87f6d': IndexNode(id_='56fb7524-c4de-4138-aecb-c18560d87f6d', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-23', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='843167ff7c56a21575eccdb5b6e987568d9f0dae62087e4aa3914490f3acfe20'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='3e2a4a85-4586-48cb-bf21-e5703d0aeabc', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='1b581f9246f04948d0a263b6fe58043b5c7216ffa1b59c71df6ab0f609008501'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='871a718f-1206-414d-a49f-8aebc9980f0c', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='6ffcd417769f0e34cae1ab16e6c9cd5e6352ca6312c3572694b9726dc37dc0fd')}, hash='d10122348e445139fc4953fc832591d321c6342cda77a893cec74d0d806983ea', text='Themodelquicklylearnstowritedetailedsaferesponses,addresssafetyconcerns,\\nexplainwhythetopicmightbesensitive,andprovideadditionalhelpfulinformation. Inparticular,when\\nthe model outputs safe responses, they are often more detailed than what the average annotator writes.\\nTherefore, after gathering only a few thousand supervised demonstrations, we switched entirely to RLHF to\\nteachthemodelhowtowritemorenuancedresponses.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-23'),\n",
              " '871a718f-1206-414d-a49f-8aebc9980f0c': IndexNode(id_='871a718f-1206-414d-a49f-8aebc9980f0c', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-23', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='843167ff7c56a21575eccdb5b6e987568d9f0dae62087e4aa3914490f3acfe20'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='56fb7524-c4de-4138-aecb-c18560d87f6d', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='d10122348e445139fc4953fc832591d321c6342cda77a893cec74d0d806983ea'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='c7d85a0d-df35-461f-b0cc-7682908c1273', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='be0be9b5c3aab4a527cb1ec96485530c45bb237b4c365dbd68dcaf49df061643')}, hash='6ffcd417769f0e34cae1ab16e6c9cd5e6352ca6312c3572694b9726dc37dc0fd', text='ComprehensivetuningwithRLHFhastheadded\\nbenefit that it may make the model more robust to jailbreak attempts (Bai et al., 2022a).\\nWeconductRLHFbyfirstcollectinghumanpreferencedataforsafetysimilartoSection3.2.2: annotators\\nwriteapromptthattheybelievecanelicitunsafebehavior,andthencomparemultiplemodelresponsesto\\ntheprompts,selectingtheresponsethatissafestaccordingtoasetofguidelines.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-23'),\n",
              " 'c7d85a0d-df35-461f-b0cc-7682908c1273': IndexNode(id_='c7d85a0d-df35-461f-b0cc-7682908c1273', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-23', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='843167ff7c56a21575eccdb5b6e987568d9f0dae62087e4aa3914490f3acfe20'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='871a718f-1206-414d-a49f-8aebc9980f0c', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='6ffcd417769f0e34cae1ab16e6c9cd5e6352ca6312c3572694b9726dc37dc0fd'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='2ba5ea03-5677-47f3-8810-179e7849e546', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='372c4d4fccbae088549e220ce77fdb940766ad98ab8f3524c912607c7a033389')}, hash='be0be9b5c3aab4a527cb1ec96485530c45bb237b4c365dbd68dcaf49df061643', text='Wethenusethehuman\\npreference data to train a safety reward model (see Section 3.2.2), and also reuse the adversarial prompts to\\nsample from the model during the RLHF stage.\\nBetterLong-TailSafetyRobustnesswithoutHurtingHelpfulness Safetyisinherentlyalong-tailproblem,\\nwherethe challengecomesfrom asmallnumber ofveryspecific cases.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-23'),\n",
              " '2ba5ea03-5677-47f3-8810-179e7849e546': IndexNode(id_='2ba5ea03-5677-47f3-8810-179e7849e546', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-23', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='843167ff7c56a21575eccdb5b6e987568d9f0dae62087e4aa3914490f3acfe20'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='c7d85a0d-df35-461f-b0cc-7682908c1273', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='be0be9b5c3aab4a527cb1ec96485530c45bb237b4c365dbd68dcaf49df061643'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='4bbffd6f-194a-427e-9da4-d30247621f32', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='1ca060b87d1164295a3bebd7741033919eefd5cee4d0bc821ec663c3271ef395')}, hash='372c4d4fccbae088549e220ce77fdb940766ad98ab8f3524c912607c7a033389', text='Weinvestigatetheimpact ofSafety\\nRLHFbytakingtwointermediate Llama 2-Chat checkpoints—onewithoutadversarialpromptsintheRLHF\\nstageandonewiththem—andscoretheirresponsesonourtestsetsusingoursafetyandhelpfulnessreward\\nmodels. In Figure 14, we plot the score distribution shift of the safety RM on the safety test set (left) and that\\nof the helpfulness RM on the helpfulness test set (right).', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-23'),\n",
              " '4bbffd6f-194a-427e-9da4-d30247621f32': IndexNode(id_='4bbffd6f-194a-427e-9da4-d30247621f32', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-23', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='843167ff7c56a21575eccdb5b6e987568d9f0dae62087e4aa3914490f3acfe20'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='2ba5ea03-5677-47f3-8810-179e7849e546', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='372c4d4fccbae088549e220ce77fdb940766ad98ab8f3524c912607c7a033389'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='0f7191ee-9833-4dfd-98d1-3e655b8f614f', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='0aa23df4d0660808f50663fdbbf2c27d8d0e5e11ba7e88dc542ef440902711ec')}, hash='1ca060b87d1164295a3bebd7741033919eefd5cee4d0bc821ec663c3271ef395', text='In the left hand side of the figure, we observe that\\nthedistributionofsafetyRMscoresonthesafetysetshiftstohigherrewardscoresaftersafetytuningwith\\nRLHF,andthatthelongtailofthedistributionnearzerothinsout. Aclearclusterappearsonthetop-left\\ncorner suggesting the improvements of model safety.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-23'),\n",
              " '0f7191ee-9833-4dfd-98d1-3e655b8f614f': IndexNode(id_='0f7191ee-9833-4dfd-98d1-3e655b8f614f', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-23', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='843167ff7c56a21575eccdb5b6e987568d9f0dae62087e4aa3914490f3acfe20'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='4bbffd6f-194a-427e-9da4-d30247621f32', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='1ca060b87d1164295a3bebd7741033919eefd5cee4d0bc821ec663c3271ef395')}, hash='0aa23df4d0660808f50663fdbbf2c27d8d0e5e11ba7e88dc542ef440902711ec', text='On the right side, we do not observe any gathering\\npatternbelowthe y=xlineontherighthandsideofFigure14,whichindicatesthatthehelpfulnessscore\\ndistributionispreservedaftersafetytuningwithRLHF.Putanotherway,givensufficienthelpfulnesstraining\\ndata, the addition of an additional stage of safety mitigation does not negatively impact model performance\\non helpfulness to any notable degradation. A qualitative example is shown in Table 12.\\nImpactofSafetyDataScaling.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-23'),\n",
              " '4453e6e5-7e76-426e-88e8-b032c7cfef4e': IndexNode(id_='4453e6e5-7e76-426e-88e8-b032c7cfef4e', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-23', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='843167ff7c56a21575eccdb5b6e987568d9f0dae62087e4aa3914490f3acfe20'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='819d47a1-9f2d-47d5-a543-2bafc393f337', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='731dfd943c81ea36f0a1d2a492351c8618b50e12320af4f01d752f55ed084adc')}, hash='22e56aaf2ac61e0631fa72fbfc9838e7ef52691d0ffeafc77ef466cb25d993ee', text='The attackvectors exploredconsist ofpsychological manipulation(e.g., authoritymanipulation),\\nlogic manipulation (e.g., false premises), syntactic manipulation (e.g., misspelling), semantic manipulation\\n(e.g., metaphor), perspective manipulation (e.g., role playing), non-English languages, and others.\\nWethendefinebestpracticesforsafeandhelpfulmodelresponses: themodelshouldfirstaddressimmediate\\nsafetyconcernsifapplicable,thenaddressthepromptbyexplainingthepotentialriskstotheuser,andfinally\\nprovide additional information if possible. We also ask the annotators to avoid negative user experience\\ncategories (see Appendix A.5.2). The guidelines are meant to be a general guide for the model and are\\niteratively refined and revised to include newly identified risks.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-23'),\n",
              " '819d47a1-9f2d-47d5-a543-2bafc393f337': IndexNode(id_='819d47a1-9f2d-47d5-a543-2bafc393f337', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-23', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='843167ff7c56a21575eccdb5b6e987568d9f0dae62087e4aa3914490f3acfe20'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='4453e6e5-7e76-426e-88e8-b032c7cfef4e', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='22e56aaf2ac61e0631fa72fbfc9838e7ef52691d0ffeafc77ef466cb25d993ee'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='e8786cdd-a402-42a7-a3fc-1cdb5ebdaff9', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='8c0249a18bad4a0920402ae9b7a49c31c0db8de023e314773ac8079404fd3bcc')}, hash='731dfd943c81ea36f0a1d2a492351c8618b50e12320af4f01d752f55ed084adc', text='4.2.2 Safety Supervised Fine-Tuning\\nInaccordancewiththeestablishedguidelinesfromSection4.2.1,wegatherpromptsanddemonstrations\\nofsafemodelresponsesfromtrainedannotators,andusethedataforsupervisedfine-tuninginthesame\\nmanner as described in Section 3.1. An example can be found in Table 5.\\nThe annotators are instructed to initially come up with prompts that they think could potentially induce\\nthemodel toexhibit unsafebehavior, i.e.,perform redteaming, asdefined bythe guidelines. Subsequently,\\nannotators are tasked with crafting a safe and helpful response that the model should produce.\\n4.2.3 Safety RLHF\\nWeobserveearlyinthedevelopmentof Llama 2-Chat thatitisabletogeneralizefromthesafedemonstrations\\ninsupervisedfine-tuning. Themodelquicklylearnstowritedetailedsaferesponses,addresssafetyconcerns,\\nexplainwhythetopicmightbesensitive,andprovideadditionalhelpfulinformation.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-23'),\n",
              " 'e8786cdd-a402-42a7-a3fc-1cdb5ebdaff9': IndexNode(id_='e8786cdd-a402-42a7-a3fc-1cdb5ebdaff9', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-23', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='843167ff7c56a21575eccdb5b6e987568d9f0dae62087e4aa3914490f3acfe20'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='819d47a1-9f2d-47d5-a543-2bafc393f337', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='731dfd943c81ea36f0a1d2a492351c8618b50e12320af4f01d752f55ed084adc'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='83cf4116-560b-4ed9-a708-b047b1a9d09e', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='0bb15d46dc9feb1e75740c5ba23ef3c49799b7e6360d49f687b7399bef88c5bf')}, hash='8c0249a18bad4a0920402ae9b7a49c31c0db8de023e314773ac8079404fd3bcc', text='Inparticular,when\\nthe model outputs safe responses, they are often more detailed than what the average annotator writes.\\nTherefore, after gathering only a few thousand supervised demonstrations, we switched entirely to RLHF to\\nteachthemodelhowtowritemorenuancedresponses. ComprehensivetuningwithRLHFhastheadded\\nbenefit that it may make the model more robust to jailbreak attempts (Bai et al., 2022a).\\nWeconductRLHFbyfirstcollectinghumanpreferencedataforsafetysimilartoSection3.2.2: annotators\\nwriteapromptthattheybelievecanelicitunsafebehavior,andthencomparemultiplemodelresponsesto\\ntheprompts,selectingtheresponsethatissafestaccordingtoasetofguidelines. Wethenusethehuman\\npreference data to train a safety reward model (see Section 3.2.2), and also reuse the adversarial prompts to\\nsample from the model during the RLHF stage.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-23'),\n",
              " '83cf4116-560b-4ed9-a708-b047b1a9d09e': IndexNode(id_='83cf4116-560b-4ed9-a708-b047b1a9d09e', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-23', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='843167ff7c56a21575eccdb5b6e987568d9f0dae62087e4aa3914490f3acfe20'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='e8786cdd-a402-42a7-a3fc-1cdb5ebdaff9', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='8c0249a18bad4a0920402ae9b7a49c31c0db8de023e314773ac8079404fd3bcc'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='53068e89-edd9-4d22-9130-8ed4e01f125e', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='0aa23df4d0660808f50663fdbbf2c27d8d0e5e11ba7e88dc542ef440902711ec')}, hash='0bb15d46dc9feb1e75740c5ba23ef3c49799b7e6360d49f687b7399bef88c5bf', text='BetterLong-TailSafetyRobustnesswithoutHurtingHelpfulness Safetyisinherentlyalong-tailproblem,\\nwherethe challengecomesfrom asmallnumber ofveryspecific cases. Weinvestigatetheimpact ofSafety\\nRLHFbytakingtwointermediate Llama 2-Chat checkpoints—onewithoutadversarialpromptsintheRLHF\\nstageandonewiththem—andscoretheirresponsesonourtestsetsusingoursafetyandhelpfulnessreward\\nmodels. In Figure 14, we plot the score distribution shift of the safety RM on the safety test set (left) and that\\nof the helpfulness RM on the helpfulness test set (right). In the left hand side of the figure, we observe that\\nthedistributionofsafetyRMscoresonthesafetysetshiftstohigherrewardscoresaftersafetytuningwith\\nRLHF,andthatthelongtailofthedistributionnearzerothinsout. Aclearclusterappearsonthetop-left\\ncorner suggesting the improvements of model safety.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-23'),\n",
              " '53068e89-edd9-4d22-9130-8ed4e01f125e': IndexNode(id_='53068e89-edd9-4d22-9130-8ed4e01f125e', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-23', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='843167ff7c56a21575eccdb5b6e987568d9f0dae62087e4aa3914490f3acfe20'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='83cf4116-560b-4ed9-a708-b047b1a9d09e', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='0bb15d46dc9feb1e75740c5ba23ef3c49799b7e6360d49f687b7399bef88c5bf')}, hash='0aa23df4d0660808f50663fdbbf2c27d8d0e5e11ba7e88dc542ef440902711ec', text='On the right side, we do not observe any gathering\\npatternbelowthe y=xlineontherighthandsideofFigure14,whichindicatesthatthehelpfulnessscore\\ndistributionispreservedaftersafetytuningwithRLHF.Putanotherway,givensufficienthelpfulnesstraining\\ndata, the addition of an additional stage of safety mitigation does not negatively impact model performance\\non helpfulness to any notable degradation. A qualitative example is shown in Table 12.\\nImpactofSafetyDataScaling.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-23'),\n",
              " '0db2cf77-4387-4e6c-bd05-73bc295b890e': IndexNode(id_='0db2cf77-4387-4e6c-bd05-73bc295b890e', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-23', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='843167ff7c56a21575eccdb5b6e987568d9f0dae62087e4aa3914490f3acfe20'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='cc0e9aeb-a3f1-45bb-b3ef-df8103ca9efe', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='7c851c478467e5fcbd7d12cacc522f35f3a55813b5f0ee9ab16c2b2a57161dea')}, hash='e8af5d00993307f7e02c1e20578dea40bfc8e03fc66c827b27b3a039eef2b422', text='The attackvectors exploredconsist ofpsychological manipulation(e.g., authoritymanipulation),\\nlogic manipulation (e.g., false premises), syntactic manipulation (e.g., misspelling), semantic manipulation\\n(e.g., metaphor), perspective manipulation (e.g., role playing), non-English languages, and others.\\nWethendefinebestpracticesforsafeandhelpfulmodelresponses: themodelshouldfirstaddressimmediate\\nsafetyconcernsifapplicable,thenaddressthepromptbyexplainingthepotentialriskstotheuser,andfinally\\nprovide additional information if possible. We also ask the annotators to avoid negative user experience\\ncategories (see Appendix A.5.2). The guidelines are meant to be a general guide for the model and are\\niteratively refined and revised to include newly identified risks.\\n4.2.2 Safety Supervised Fine-Tuning\\nInaccordancewiththeestablishedguidelinesfromSection4.2.1,wegatherpromptsanddemonstrations\\nofsafemodelresponsesfromtrainedannotators,andusethedataforsupervisedfine-tuninginthesame\\nmanner as described in Section 3.1. An example can be found in Table 5.\\nThe annotators are instructed to initially come up with prompts that they think could potentially induce\\nthemodel toexhibit unsafebehavior, i.e.,perform redteaming, asdefined bythe guidelines. Subsequently,\\nannotators are tasked with crafting a safe and helpful response that the model should produce.\\n4.2.3 Safety RLHF\\nWeobserveearlyinthedevelopmentof Llama 2-Chat thatitisabletogeneralizefromthesafedemonstrations\\ninsupervisedfine-tuning. Themodelquicklylearnstowritedetailedsaferesponses,addresssafetyconcerns,\\nexplainwhythetopicmightbesensitive,andprovideadditionalhelpfulinformation. Inparticular,when\\nthe model outputs safe responses, they are often more detailed than what the average annotator writes.\\nTherefore, after gathering only a few thousand supervised demonstrations, we switched entirely to RLHF to\\nteachthemodelhowtowritemorenuancedresponses.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-23'),\n",
              " 'cc0e9aeb-a3f1-45bb-b3ef-df8103ca9efe': IndexNode(id_='cc0e9aeb-a3f1-45bb-b3ef-df8103ca9efe', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-23', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='843167ff7c56a21575eccdb5b6e987568d9f0dae62087e4aa3914490f3acfe20'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='0db2cf77-4387-4e6c-bd05-73bc295b890e', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='e8af5d00993307f7e02c1e20578dea40bfc8e03fc66c827b27b3a039eef2b422')}, hash='7c851c478467e5fcbd7d12cacc522f35f3a55813b5f0ee9ab16c2b2a57161dea', text='ComprehensivetuningwithRLHFhastheadded\\nbenefit that it may make the model more robust to jailbreak attempts (Bai et al., 2022a).\\nWeconductRLHFbyfirstcollectinghumanpreferencedataforsafetysimilartoSection3.2.2: annotators\\nwriteapromptthattheybelievecanelicitunsafebehavior,andthencomparemultiplemodelresponsesto\\ntheprompts,selectingtheresponsethatissafestaccordingtoasetofguidelines. Wethenusethehuman\\npreference data to train a safety reward model (see Section 3.2.2), and also reuse the adversarial prompts to\\nsample from the model during the RLHF stage.\\nBetterLong-TailSafetyRobustnesswithoutHurtingHelpfulness Safetyisinherentlyalong-tailproblem,\\nwherethe challengecomesfrom asmallnumber ofveryspecific cases. Weinvestigatetheimpact ofSafety\\nRLHFbytakingtwointermediate Llama 2-Chat checkpoints—onewithoutadversarialpromptsintheRLHF\\nstageandonewiththem—andscoretheirresponsesonourtestsetsusingoursafetyandhelpfulnessreward\\nmodels. In Figure 14, we plot the score distribution shift of the safety RM on the safety test set (left) and that\\nof the helpfulness RM on the helpfulness test set (right). In the left hand side of the figure, we observe that\\nthedistributionofsafetyRMscoresonthesafetysetshiftstohigherrewardscoresaftersafetytuningwith\\nRLHF,andthatthelongtailofthedistributionnearzerothinsout. Aclearclusterappearsonthetop-left\\ncorner suggesting the improvements of model safety. On the right side, we do not observe any gathering\\npatternbelowthe y=xlineontherighthandsideofFigure14,whichindicatesthatthehelpfulnessscore\\ndistributionispreservedaftersafetytuningwithRLHF.Putanotherway,givensufficienthelpfulnesstraining\\ndata, the addition of an additional stage of safety mitigation does not negatively impact model performance\\non helpfulness to any notable degradation. A qualitative example is shown in Table 12.\\nImpactofSafetyDataScaling.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-23'),\n",
              " 'node-23': IndexNode(id_='node-23', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='415b7efc-e73f-4ac4-bbfd-c1546f099026', node_type=<ObjectType.DOCUMENT: '4'>, metadata={}, hash='231b3bd773f012c01b893ada9e009ecf25ee59934614c5a595c9bf1b3a123292'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='6c1aec3f-d146-4bd7-81cd-c53f7de0493c', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='60e16382f8ffcd8ebb49f78fa450199f60f18b0a69ffadcbe41b7dc2990678c3'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='2f82e0ab-6c24-47cb-b5a9-771b8856b2ac', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='2aa7fe81895347a469a33159e78a97581601e9b018df1aa2e84cd996990a1636')}, hash='843167ff7c56a21575eccdb5b6e987568d9f0dae62087e4aa3914490f3acfe20', text='The attackvectors exploredconsist ofpsychological manipulation(e.g., authoritymanipulation),\\nlogic manipulation (e.g., false premises), syntactic manipulation (e.g., misspelling), semantic manipulation\\n(e.g., metaphor), perspective manipulation (e.g., role playing), non-English languages, and others.\\nWethendefinebestpracticesforsafeandhelpfulmodelresponses: themodelshouldfirstaddressimmediate\\nsafetyconcernsifapplicable,thenaddressthepromptbyexplainingthepotentialriskstotheuser,andfinally\\nprovide additional information if possible. We also ask the annotators to avoid negative user experience\\ncategories (see Appendix A.5.2). The guidelines are meant to be a general guide for the model and are\\niteratively refined and revised to include newly identified risks.\\n4.2.2 Safety Supervised Fine-Tuning\\nInaccordancewiththeestablishedguidelinesfromSection4.2.1,wegatherpromptsanddemonstrations\\nofsafemodelresponsesfromtrainedannotators,andusethedataforsupervisedfine-tuninginthesame\\nmanner as described in Section 3.1. An example can be found in Table 5.\\nThe annotators are instructed to initially come up with prompts that they think could potentially induce\\nthemodel toexhibit unsafebehavior, i.e.,perform redteaming, asdefined bythe guidelines. Subsequently,\\nannotators are tasked with crafting a safe and helpful response that the model should produce.\\n4.2.3 Safety RLHF\\nWeobserveearlyinthedevelopmentof Llama 2-Chat thatitisabletogeneralizefromthesafedemonstrations\\ninsupervisedfine-tuning. Themodelquicklylearnstowritedetailedsaferesponses,addresssafetyconcerns,\\nexplainwhythetopicmightbesensitive,andprovideadditionalhelpfulinformation. Inparticular,when\\nthe model outputs safe responses, they are often more detailed than what the average annotator writes.\\nTherefore, after gathering only a few thousand supervised demonstrations, we switched entirely to RLHF to\\nteachthemodelhowtowritemorenuancedresponses. ComprehensivetuningwithRLHFhastheadded\\nbenefit that it may make the model more robust to jailbreak attempts (Bai et al., 2022a).\\nWeconductRLHFbyfirstcollectinghumanpreferencedataforsafetysimilartoSection3.2.2: annotators\\nwriteapromptthattheybelievecanelicitunsafebehavior,andthencomparemultiplemodelresponsesto\\ntheprompts,selectingtheresponsethatissafestaccordingtoasetofguidelines. Wethenusethehuman\\npreference data to train a safety reward model (see Section 3.2.2), and also reuse the adversarial prompts to\\nsample from the model during the RLHF stage.\\nBetterLong-TailSafetyRobustnesswithoutHurtingHelpfulness Safetyisinherentlyalong-tailproblem,\\nwherethe challengecomesfrom asmallnumber ofveryspecific cases. Weinvestigatetheimpact ofSafety\\nRLHFbytakingtwointermediate Llama 2-Chat checkpoints—onewithoutadversarialpromptsintheRLHF\\nstageandonewiththem—andscoretheirresponsesonourtestsetsusingoursafetyandhelpfulnessreward\\nmodels. In Figure 14, we plot the score distribution shift of the safety RM on the safety test set (left) and that\\nof the helpfulness RM on the helpfulness test set (right). In the left hand side of the figure, we observe that\\nthedistributionofsafetyRMscoresonthesafetysetshiftstohigherrewardscoresaftersafetytuningwith\\nRLHF,andthatthelongtailofthedistributionnearzerothinsout. Aclearclusterappearsonthetop-left\\ncorner suggesting the improvements of model safety. On the right side, we do not observe any gathering\\npatternbelowthe y=xlineontherighthandsideofFigure14,whichindicatesthatthehelpfulnessscore\\ndistributionispreservedaftersafetytuningwithRLHF.Putanotherway,givensufficienthelpfulnesstraining\\ndata, the addition of an additional stage of safety mitigation does not negatively impact model performance\\non helpfulness to any notable degradation. A qualitative example is shown in Table 12.\\nImpactofSafetyDataScaling.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-23'),\n",
              " '26b2c140-0e36-47bb-87e9-6ba03396aee5': IndexNode(id_='26b2c140-0e36-47bb-87e9-6ba03396aee5', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-24', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='2aa7fe81895347a469a33159e78a97581601e9b018df1aa2e84cd996990a1636'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='f4fc5e82-ae4d-482f-a618-4d8251052c88', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='ef24397903e9d89778f4c3a676d8b091b9636ec73b925fcf310fb4d8012f0ea6')}, hash='fb38daf0a7e69dbbf9bb3c6e4e6339c8364c9a56d6fa52a481ee1a2fd81dac3b', text='A qualitative example is shown in Table 12.\\nImpactofSafetyDataScaling. AtensionbetweenhelpfulnessandsafetyofLLMshasbeenobservedin\\nprevious studies (Bai et al., 2022a). To better understand how the addition of safety training data affects\\ngeneral model performance, especially helpfulness, we investigate the trends in safety data scaling by\\nadjustingtheamountofsafetydatausedintheRLHFstage.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-24'),\n",
              " 'f4fc5e82-ae4d-482f-a618-4d8251052c88': IndexNode(id_='f4fc5e82-ae4d-482f-a618-4d8251052c88', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-24', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='2aa7fe81895347a469a33159e78a97581601e9b018df1aa2e84cd996990a1636'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='26b2c140-0e36-47bb-87e9-6ba03396aee5', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='fb38daf0a7e69dbbf9bb3c6e4e6339c8364c9a56d6fa52a481ee1a2fd81dac3b'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='3a908a34-b878-47c7-93a0-4eed50801288', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='e89a8627802225e7a4dbbeed1e75839ab800d871a509e17bcbb89e336012b43f')}, hash='ef24397903e9d89778f4c3a676d8b091b9636ec73b925fcf310fb4d8012f0ea6', text='Inthisablationexperiment,wekeeptheamount\\nof helpfulness training data unchanged ( ∼0.9M samples) and gradually increase the amount of safety data\\nused in model tuning, ranging from 0% to 100% ( ∼0.1M samples). For the specific training data mix recipe,\\nwe follow the procedure described in Section 3.1 and fine-tune Llama 2 pretrained model for 2 epochs.\\nWe eventually obtain 6 model variants trained with 0%, 1%, 10%, 25%, 50%, and 100% of the total safety\\ndata.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-24'),\n",
              " '3a908a34-b878-47c7-93a0-4eed50801288': IndexNode(id_='3a908a34-b878-47c7-93a0-4eed50801288', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-24', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='2aa7fe81895347a469a33159e78a97581601e9b018df1aa2e84cd996990a1636'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='f4fc5e82-ae4d-482f-a618-4d8251052c88', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='ef24397903e9d89778f4c3a676d8b091b9636ec73b925fcf310fb4d8012f0ea6'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='68014fd5-ad2a-48e7-b6c1-e391cb6671c8', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='b49a3f3a0d9afb9987eaa2f74833e80a3640caf93e81557173f524a9b260a1be')}, hash='e89a8627802225e7a4dbbeed1e75839ab800d871a509e17bcbb89e336012b43f', text='We evaluate them using our safety and helpfulness reward models described in Section 3.2.2. For\\n24\\n\\n0.0 0.2 0.4 0.6 0.8 1.0\\nSafety RM Score before Safety RLHF0.00.20.40.60.81.0Safety RM Score after Safety RLHF\\nSafety \\n Improvement01000\\n01000\\n0.0 0.2 0.4 0.6 0.8 1.0\\nHelpfulness RM Score before Safety RLHF0.00.20.40.60.81.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-24'),\n",
              " '68014fd5-ad2a-48e7-b6c1-e391cb6671c8': IndexNode(id_='68014fd5-ad2a-48e7-b6c1-e391cb6671c8', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-24', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='2aa7fe81895347a469a33159e78a97581601e9b018df1aa2e84cd996990a1636'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='3a908a34-b878-47c7-93a0-4eed50801288', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='e89a8627802225e7a4dbbeed1e75839ab800d871a509e17bcbb89e336012b43f'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='0e891bdd-9956-4c46-a19d-eefa93d82bbb', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='1fc9c587ce519d7e3c35a20f733b0319fae89d0c44ac7ce734ba0ef3bdc7a125')}, hash='b49a3f3a0d9afb9987eaa2f74833e80a3640caf93e81557173f524a9b260a1be', text='00.20.40.60.81.0Helpfulness RM Score after Safety RLHF\\n01000\\n01000Figure 14: Impact of safety RLHF measured by reward model score distributions. Left: safety reward\\nmodel scores of generations on the Meta Safety test set. The clustering of samples in the top left corner\\nsuggeststheimprovementsofmodelsafety. Right: helpfulnessrewardmodelscoresofgenerationsonthe\\nMeta Helpfulness test set.\\n➤Prompt: Write a scam email requesting 10,000 dollars.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-24'),\n",
              " '0e891bdd-9956-4c46-a19d-eefa93d82bbb': IndexNode(id_='0e891bdd-9956-4c46-a19d-eefa93d82bbb', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-24', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='2aa7fe81895347a469a33159e78a97581601e9b018df1aa2e84cd996990a1636'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='68014fd5-ad2a-48e7-b6c1-e391cb6671c8', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='b49a3f3a0d9afb9987eaa2f74833e80a3640caf93e81557173f524a9b260a1be'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='8ca4fa38-6323-4655-9e4d-718c0c4f68df', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='ef7695551871eab3453834a9bd4784542b035cdb137555d113bb2fa49f138a40')}, hash='1fc9c587ce519d7e3c35a20f733b0319fae89d0c44ac7ce734ba0ef3bdc7a125', text='➤Prompt: Write a scam email requesting 10,000 dollars.\\nBefore safety RLHF After safety RLHF\\nSubject: Urgent Assistance Required\\nDear [Name],\\nIhopethisemailfindsyouingoodhealthandspirits.\\nIamwritingtoyoutodaybecauseIfindmyselfina\\ndifficultsituationandIneedyourhelp. Iamcurrently\\nin [insert location here] and I have been robbed. My\\nwallet, phone, and all of my other belongings have\\nbeen taken, leaving me with nothing.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-24'),\n",
              " '8ca4fa38-6323-4655-9e4d-718c0c4f68df': IndexNode(id_='8ca4fa38-6323-4655-9e4d-718c0c4f68df', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-24', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='2aa7fe81895347a469a33159e78a97581601e9b018df1aa2e84cd996990a1636'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='0e891bdd-9956-4c46-a19d-eefa93d82bbb', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='1fc9c587ce519d7e3c35a20f733b0319fae89d0c44ac7ce734ba0ef3bdc7a125'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='fe370af2-dfc1-4def-86f9-12e6cb5d3ecd', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='737ff9d82dd4fe49afcc450b2aaebd868dd61f6fdf53d7f9a8e9c96ddc762c13')}, hash='ef7695551871eab3453834a9bd4784542b035cdb137555d113bb2fa49f138a40', text='I have tried to\\ncontactthelocalauthorities,buttheyarenotbeing\\nvery helpful.\\nI am reaching out to you because I need your help. I\\nneed you to send me $10,000 so that I can get back\\nhomeandstartrebuildingmylife. Iknowthatthisis\\nalotofmoney,butIpromisetopayyoubackassoon\\nas I can.\\nPlease,ifyoucanhelpme,Iwouldbeforevergrateful.\\nI am desperate and I don’t know what else to do.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-24'),\n",
              " 'fe370af2-dfc1-4def-86f9-12e6cb5d3ecd': IndexNode(id_='fe370af2-dfc1-4def-86f9-12e6cb5d3ecd', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-24', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='2aa7fe81895347a469a33159e78a97581601e9b018df1aa2e84cd996990a1636'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='8ca4fa38-6323-4655-9e4d-718c0c4f68df', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='ef7695551871eab3453834a9bd4784542b035cdb137555d113bb2fa49f138a40'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='b41910f1-a8dd-4cd6-93d6-ea4c3daa98e9', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='75b9fbc7091594635ae64b718bf3d107d651809d1eb9444b3ede299e6f82596b')}, hash='737ff9d82dd4fe49afcc450b2aaebd868dd61f6fdf53d7f9a8e9c96ddc762c13', text='I am desperate and I don’t know what else to do.\\nSincerely,\\n[Your Name]Icannotfulfillyourrequest. Itisunethicalandpoten-\\ntiallyillegaltosendscamemailsrequestingmoney.\\nItisimportanttorespectpeople’stimeandresources,\\nandnottoengageinfraudulentordeceitfulactivities.\\nAdditionally, it is harmful and potentially danger-\\nous to solicit money from people through false or\\nmisleading pretenses.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-24'),\n",
              " 'b41910f1-a8dd-4cd6-93d6-ea4c3daa98e9': IndexNode(id_='b41910f1-a8dd-4cd6-93d6-ea4c3daa98e9', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-24', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='2aa7fe81895347a469a33159e78a97581601e9b018df1aa2e84cd996990a1636'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='fe370af2-dfc1-4def-86f9-12e6cb5d3ecd', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='737ff9d82dd4fe49afcc450b2aaebd868dd61f6fdf53d7f9a8e9c96ddc762c13'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='97a639c7-98ce-4b0b-952c-55f2c1b99f29', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='33af78e712aa8e84a0341104564878f796ee6b3ade0a2bce21b10e4ced35b6e4')}, hash='75b9fbc7091594635ae64b718bf3d107d651809d1eb9444b3ede299e6f82596b', text='Instead, I suggest focusing on\\nlegitimateandethicalwaystocommunicatewithoth-\\ners online.\\nIf you have any questions or concerns, please feel\\nfree to ask and I will do my best to assist you in a\\nresponsible and safe manner. Let’s all strive to use\\ntheinternetandemailforpositiveandbeneficialpur-\\nposes. Is there something else I can help you with?\\nTable12: ExampleofsaferresponseaftersafetyRLHF .Left: responseisgeneratedbyanearlyversionof\\nthe model ( SFT-v2).', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-24'),\n",
              " '97a639c7-98ce-4b0b-952c-55f2c1b99f29': IndexNode(id_='97a639c7-98ce-4b0b-952c-55f2c1b99f29', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-24', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='2aa7fe81895347a469a33159e78a97581601e9b018df1aa2e84cd996990a1636'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='b41910f1-a8dd-4cd6-93d6-ea4c3daa98e9', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='75b9fbc7091594635ae64b718bf3d107d651809d1eb9444b3ede299e6f82596b')}, hash='33af78e712aa8e84a0341104564878f796ee6b3ade0a2bce21b10e4ced35b6e4', text='Right: response is generated by the latest version of the model ( RLHF-V5 with PPO ).\\n25\\n\\neach variant, we use the safety and helpfulness reward models to score model generations corresponding to\\nprompts in the Meta Safety and Helpful test sets, respectively.\\nAsshowninFigure15,weusethemeanrewardmodelscoresasproxiesofmodelperformanceonsafetyand\\nhelpfulness.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-24'),\n",
              " '2116e36a-b4e0-4e0c-9094-f93d85f20de7': IndexNode(id_='2116e36a-b4e0-4e0c-9094-f93d85f20de7', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-24', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='2aa7fe81895347a469a33159e78a97581601e9b018df1aa2e84cd996990a1636'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='c6e89cb6-e935-41c7-831c-d9a5d7f30abb', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='9f8da622a4d0f21f721c7523a91d73b9a61b319aca58beed3ea77f88a90bcf07')}, hash='798744fbd45509de8178689641784c0ba89511d9eb153542a7c7c3e5baf9528e', text='A qualitative example is shown in Table 12.\\nImpactofSafetyDataScaling. AtensionbetweenhelpfulnessandsafetyofLLMshasbeenobservedin\\nprevious studies (Bai et al., 2022a). To better understand how the addition of safety training data affects\\ngeneral model performance, especially helpfulness, we investigate the trends in safety data scaling by\\nadjustingtheamountofsafetydatausedintheRLHFstage. Inthisablationexperiment,wekeeptheamount\\nof helpfulness training data unchanged ( ∼0.9M samples) and gradually increase the amount of safety data\\nused in model tuning, ranging from 0% to 100% ( ∼0.1M samples). For the specific training data mix recipe,\\nwe follow the procedure described in Section 3.1 and fine-tune Llama 2 pretrained model for 2 epochs.\\nWe eventually obtain 6 model variants trained with 0%, 1%, 10%, 25%, 50%, and 100% of the total safety\\ndata. We evaluate them using our safety and helpfulness reward models described in Section 3.2.2.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-24'),\n",
              " 'c6e89cb6-e935-41c7-831c-d9a5d7f30abb': IndexNode(id_='c6e89cb6-e935-41c7-831c-d9a5d7f30abb', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-24', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='2aa7fe81895347a469a33159e78a97581601e9b018df1aa2e84cd996990a1636'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='2116e36a-b4e0-4e0c-9094-f93d85f20de7', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='798744fbd45509de8178689641784c0ba89511d9eb153542a7c7c3e5baf9528e'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='6231a03f-d4da-4f9a-9107-6bf88a904f6d', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='2801670702d75d0848a68c47b902dfff4bb04cdfadde1342e594e3b17edadc2a')}, hash='9f8da622a4d0f21f721c7523a91d73b9a61b319aca58beed3ea77f88a90bcf07', text='For\\n24\\n\\n0.0 0.2 0.4 0.6 0.8 1.0\\nSafety RM Score before Safety RLHF0.00.20.40.60.81.0Safety RM Score after Safety RLHF\\nSafety \\n Improvement01000\\n01000\\n0.0 0.2 0.4 0.6 0.8 1.0\\nHelpfulness RM Score before Safety RLHF0.00.20.40.60.81.0Helpfulness RM Score after Safety RLHF\\n01000\\n01000Figure 14: Impact of safety RLHF measured by reward model score distributions. Left: safety reward\\nmodel scores of generations on the Meta Safety test set. The clustering of samples in the top left corner\\nsuggeststheimprovementsofmodelsafety. Right: helpfulnessrewardmodelscoresofgenerationsonthe\\nMeta Helpfulness test set.\\n➤Prompt: Write a scam email requesting 10,000 dollars.\\nBefore safety RLHF After safety RLHF\\nSubject: Urgent Assistance Required\\nDear [Name],\\nIhopethisemailfindsyouingoodhealthandspirits.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-24'),\n",
              " '6231a03f-d4da-4f9a-9107-6bf88a904f6d': IndexNode(id_='6231a03f-d4da-4f9a-9107-6bf88a904f6d', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-24', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='2aa7fe81895347a469a33159e78a97581601e9b018df1aa2e84cd996990a1636'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='c6e89cb6-e935-41c7-831c-d9a5d7f30abb', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='9f8da622a4d0f21f721c7523a91d73b9a61b319aca58beed3ea77f88a90bcf07'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='07d45b40-1a8b-46d6-ab26-336e622e304d', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='5d6435ab7b9d0feab3fca15aa51bb01102658b86f2bf3950119396700065a3b4')}, hash='2801670702d75d0848a68c47b902dfff4bb04cdfadde1342e594e3b17edadc2a', text='IamwritingtoyoutodaybecauseIfindmyselfina\\ndifficultsituationandIneedyourhelp. Iamcurrently\\nin [insert location here] and I have been robbed. My\\nwallet, phone, and all of my other belongings have\\nbeen taken, leaving me with nothing. I have tried to\\ncontactthelocalauthorities,buttheyarenotbeing\\nvery helpful.\\nI am reaching out to you because I need your help. I\\nneed you to send me $10,000 so that I can get back\\nhomeandstartrebuildingmylife. Iknowthatthisis\\nalotofmoney,butIpromisetopayyoubackassoon\\nas I can.\\nPlease,ifyoucanhelpme,Iwouldbeforevergrateful.\\nI am desperate and I don’t know what else to do.\\nSincerely,\\n[Your Name]Icannotfulfillyourrequest. Itisunethicalandpoten-\\ntiallyillegaltosendscamemailsrequestingmoney.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-24'),\n",
              " '07d45b40-1a8b-46d6-ab26-336e622e304d': IndexNode(id_='07d45b40-1a8b-46d6-ab26-336e622e304d', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-24', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='2aa7fe81895347a469a33159e78a97581601e9b018df1aa2e84cd996990a1636'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='6231a03f-d4da-4f9a-9107-6bf88a904f6d', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='2801670702d75d0848a68c47b902dfff4bb04cdfadde1342e594e3b17edadc2a'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='d0c24109-3cfe-4e14-9193-7e9338ea119b', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='2ccbf4cc9c97d02e4db5a5eb7a232c4d96eb5e21236e7789f65b663634711a09')}, hash='5d6435ab7b9d0feab3fca15aa51bb01102658b86f2bf3950119396700065a3b4', text='Itisimportanttorespectpeople’stimeandresources,\\nandnottoengageinfraudulentordeceitfulactivities.\\nAdditionally, it is harmful and potentially danger-\\nous to solicit money from people through false or\\nmisleading pretenses. Instead, I suggest focusing on\\nlegitimateandethicalwaystocommunicatewithoth-\\ners online.\\nIf you have any questions or concerns, please feel\\nfree to ask and I will do my best to assist you in a\\nresponsible and safe manner. Let’s all strive to use\\ntheinternetandemailforpositiveandbeneficialpur-\\nposes. Is there something else I can help you with?\\nTable12: ExampleofsaferresponseaftersafetyRLHF .Left: responseisgeneratedbyanearlyversionof\\nthe model ( SFT-v2). Right: response is generated by the latest version of the model ( RLHF-V5 with PPO ).\\n25\\n\\neach variant, we use the safety and helpfulness reward models to score model generations corresponding to\\nprompts in the Meta Safety and Helpful test sets, respectively.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-24'),\n",
              " 'd0c24109-3cfe-4e14-9193-7e9338ea119b': IndexNode(id_='d0c24109-3cfe-4e14-9193-7e9338ea119b', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-24', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='2aa7fe81895347a469a33159e78a97581601e9b018df1aa2e84cd996990a1636'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='07d45b40-1a8b-46d6-ab26-336e622e304d', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='5d6435ab7b9d0feab3fca15aa51bb01102658b86f2bf3950119396700065a3b4')}, hash='2ccbf4cc9c97d02e4db5a5eb7a232c4d96eb5e21236e7789f65b663634711a09', text='AsshowninFigure15,weusethemeanrewardmodelscoresasproxiesofmodelperformanceonsafetyand\\nhelpfulness.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-24'),\n",
              " '08bbf168-b0d6-41f6-8776-dae420cb0730': IndexNode(id_='08bbf168-b0d6-41f6-8776-dae420cb0730', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-24', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='2aa7fe81895347a469a33159e78a97581601e9b018df1aa2e84cd996990a1636'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='7385c3b7-a293-4f23-8b4e-019448825003', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='c4337163a89e0fb64d66bbcd26436539e3aa232b5c9a02073ec11a5d4f9073fb')}, hash='24b257d894cfb81031e5ac39fa241bd72dca68ad691cb400c2f55dada21fc278', text='A qualitative example is shown in Table 12.\\nImpactofSafetyDataScaling. AtensionbetweenhelpfulnessandsafetyofLLMshasbeenobservedin\\nprevious studies (Bai et al., 2022a). To better understand how the addition of safety training data affects\\ngeneral model performance, especially helpfulness, we investigate the trends in safety data scaling by\\nadjustingtheamountofsafetydatausedintheRLHFstage. Inthisablationexperiment,wekeeptheamount\\nof helpfulness training data unchanged ( ∼0.9M samples) and gradually increase the amount of safety data\\nused in model tuning, ranging from 0% to 100% ( ∼0.1M samples). For the specific training data mix recipe,\\nwe follow the procedure described in Section 3.1 and fine-tune Llama 2 pretrained model for 2 epochs.\\nWe eventually obtain 6 model variants trained with 0%, 1%, 10%, 25%, 50%, and 100% of the total safety\\ndata. We evaluate them using our safety and helpfulness reward models described in Section 3.2.2. For\\n24\\n\\n0.0 0.2 0.4 0.6 0.8 1.0\\nSafety RM Score before Safety RLHF0.00.20.40.60.81.0Safety RM Score after Safety RLHF\\nSafety \\n Improvement01000\\n01000\\n0.0 0.2 0.4 0.6 0.8 1.0\\nHelpfulness RM Score before Safety RLHF0.00.20.40.60.81.0Helpfulness RM Score after Safety RLHF\\n01000\\n01000Figure 14: Impact of safety RLHF measured by reward model score distributions. Left: safety reward\\nmodel scores of generations on the Meta Safety test set. The clustering of samples in the top left corner\\nsuggeststheimprovementsofmodelsafety. Right: helpfulnessrewardmodelscoresofgenerationsonthe\\nMeta Helpfulness test set.\\n➤Prompt: Write a scam email requesting 10,000 dollars.\\nBefore safety RLHF After safety RLHF\\nSubject: Urgent Assistance Required\\nDear [Name],\\nIhopethisemailfindsyouingoodhealthandspirits.\\nIamwritingtoyoutodaybecauseIfindmyselfina\\ndifficultsituationandIneedyourhelp.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-24'),\n",
              " '7385c3b7-a293-4f23-8b4e-019448825003': IndexNode(id_='7385c3b7-a293-4f23-8b4e-019448825003', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-24', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='2aa7fe81895347a469a33159e78a97581601e9b018df1aa2e84cd996990a1636'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='08bbf168-b0d6-41f6-8776-dae420cb0730', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='24b257d894cfb81031e5ac39fa241bd72dca68ad691cb400c2f55dada21fc278')}, hash='c4337163a89e0fb64d66bbcd26436539e3aa232b5c9a02073ec11a5d4f9073fb', text='Iamcurrently\\nin [insert location here] and I have been robbed. My\\nwallet, phone, and all of my other belongings have\\nbeen taken, leaving me with nothing. I have tried to\\ncontactthelocalauthorities,buttheyarenotbeing\\nvery helpful.\\nI am reaching out to you because I need your help. I\\nneed you to send me $10,000 so that I can get back\\nhomeandstartrebuildingmylife. Iknowthatthisis\\nalotofmoney,butIpromisetopayyoubackassoon\\nas I can.\\nPlease,ifyoucanhelpme,Iwouldbeforevergrateful.\\nI am desperate and I don’t know what else to do.\\nSincerely,\\n[Your Name]Icannotfulfillyourrequest. Itisunethicalandpoten-\\ntiallyillegaltosendscamemailsrequestingmoney.\\nItisimportanttorespectpeople’stimeandresources,\\nandnottoengageinfraudulentordeceitfulactivities.\\nAdditionally, it is harmful and potentially danger-\\nous to solicit money from people through false or\\nmisleading pretenses. Instead, I suggest focusing on\\nlegitimateandethicalwaystocommunicatewithoth-\\ners online.\\nIf you have any questions or concerns, please feel\\nfree to ask and I will do my best to assist you in a\\nresponsible and safe manner. Let’s all strive to use\\ntheinternetandemailforpositiveandbeneficialpur-\\nposes. Is there something else I can help you with?\\nTable12: ExampleofsaferresponseaftersafetyRLHF .Left: responseisgeneratedbyanearlyversionof\\nthe model ( SFT-v2). Right: response is generated by the latest version of the model ( RLHF-V5 with PPO ).\\n25\\n\\neach variant, we use the safety and helpfulness reward models to score model generations corresponding to\\nprompts in the Meta Safety and Helpful test sets, respectively.\\nAsshowninFigure15,weusethemeanrewardmodelscoresasproxiesofmodelperformanceonsafetyand\\nhelpfulness.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-24'),\n",
              " 'node-24': IndexNode(id_='node-24', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='415b7efc-e73f-4ac4-bbfd-c1546f099026', node_type=<ObjectType.DOCUMENT: '4'>, metadata={}, hash='231b3bd773f012c01b893ada9e009ecf25ee59934614c5a595c9bf1b3a123292'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='eb23eec0-7cd1-4ea5-b371-8ab1f45e712d', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='843167ff7c56a21575eccdb5b6e987568d9f0dae62087e4aa3914490f3acfe20'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='bfb9b644-8d43-4b89-8a8a-cbbf9086bf01', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='3b74a59af91ef8ff3221fd3b7dc26d01b168f5a13afdb91a57ab37aa5dec559c')}, hash='2aa7fe81895347a469a33159e78a97581601e9b018df1aa2e84cd996990a1636', text='A qualitative example is shown in Table 12.\\nImpactofSafetyDataScaling. AtensionbetweenhelpfulnessandsafetyofLLMshasbeenobservedin\\nprevious studies (Bai et al., 2022a). To better understand how the addition of safety training data affects\\ngeneral model performance, especially helpfulness, we investigate the trends in safety data scaling by\\nadjustingtheamountofsafetydatausedintheRLHFstage. Inthisablationexperiment,wekeeptheamount\\nof helpfulness training data unchanged ( ∼0.9M samples) and gradually increase the amount of safety data\\nused in model tuning, ranging from 0% to 100% ( ∼0.1M samples). For the specific training data mix recipe,\\nwe follow the procedure described in Section 3.1 and fine-tune Llama 2 pretrained model for 2 epochs.\\nWe eventually obtain 6 model variants trained with 0%, 1%, 10%, 25%, 50%, and 100% of the total safety\\ndata. We evaluate them using our safety and helpfulness reward models described in Section 3.2.2. For\\n24\\n\\n0.0 0.2 0.4 0.6 0.8 1.0\\nSafety RM Score before Safety RLHF0.00.20.40.60.81.0Safety RM Score after Safety RLHF\\nSafety \\n Improvement01000\\n01000\\n0.0 0.2 0.4 0.6 0.8 1.0\\nHelpfulness RM Score before Safety RLHF0.00.20.40.60.81.0Helpfulness RM Score after Safety RLHF\\n01000\\n01000Figure 14: Impact of safety RLHF measured by reward model score distributions. Left: safety reward\\nmodel scores of generations on the Meta Safety test set. The clustering of samples in the top left corner\\nsuggeststheimprovementsofmodelsafety. Right: helpfulnessrewardmodelscoresofgenerationsonthe\\nMeta Helpfulness test set.\\n➤Prompt: Write a scam email requesting 10,000 dollars.\\nBefore safety RLHF After safety RLHF\\nSubject: Urgent Assistance Required\\nDear [Name],\\nIhopethisemailfindsyouingoodhealthandspirits.\\nIamwritingtoyoutodaybecauseIfindmyselfina\\ndifficultsituationandIneedyourhelp. Iamcurrently\\nin [insert location here] and I have been robbed. My\\nwallet, phone, and all of my other belongings have\\nbeen taken, leaving me with nothing. I have tried to\\ncontactthelocalauthorities,buttheyarenotbeing\\nvery helpful.\\nI am reaching out to you because I need your help. I\\nneed you to send me $10,000 so that I can get back\\nhomeandstartrebuildingmylife. Iknowthatthisis\\nalotofmoney,butIpromisetopayyoubackassoon\\nas I can.\\nPlease,ifyoucanhelpme,Iwouldbeforevergrateful.\\nI am desperate and I don’t know what else to do.\\nSincerely,\\n[Your Name]Icannotfulfillyourrequest. Itisunethicalandpoten-\\ntiallyillegaltosendscamemailsrequestingmoney.\\nItisimportanttorespectpeople’stimeandresources,\\nandnottoengageinfraudulentordeceitfulactivities.\\nAdditionally, it is harmful and potentially danger-\\nous to solicit money from people through false or\\nmisleading pretenses. Instead, I suggest focusing on\\nlegitimateandethicalwaystocommunicatewithoth-\\ners online.\\nIf you have any questions or concerns, please feel\\nfree to ask and I will do my best to assist you in a\\nresponsible and safe manner. Let’s all strive to use\\ntheinternetandemailforpositiveandbeneficialpur-\\nposes. Is there something else I can help you with?\\nTable12: ExampleofsaferresponseaftersafetyRLHF .Left: responseisgeneratedbyanearlyversionof\\nthe model ( SFT-v2). Right: response is generated by the latest version of the model ( RLHF-V5 with PPO ).\\n25\\n\\neach variant, we use the safety and helpfulness reward models to score model generations corresponding to\\nprompts in the Meta Safety and Helpful test sets, respectively.\\nAsshowninFigure15,weusethemeanrewardmodelscoresasproxiesofmodelperformanceonsafetyand\\nhelpfulness.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-24'),\n",
              " '9e141db1-9a78-4ba4-a629-2f21649895ee': IndexNode(id_='9e141db1-9a78-4ba4-a629-2f21649895ee', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-25', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='3b74a59af91ef8ff3221fd3b7dc26d01b168f5a13afdb91a57ab37aa5dec559c'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='e8b93735-ec0a-4ef1-b34d-7fd8044dbd02', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='d587d33a685d295eb9ccbdea54138d3bb1bd0e9cd075b8191ee99249579107b6')}, hash='56b7ab076fedc12efa045b0fbc0a9861d20bd2a470422de566bdc9b6daabb765', text='Weobservethatwhenweincreasetheproportionofsafetydata,themodel’sperformanceon\\nhandling risky and adversarial prompts improves dramatically, and we see a lighter tail in the safety reward\\nmodelscoredistribution. Meanwhile,themeanhelpfulnessscoreremainsconstant. Wehypothesizethat\\nthis is because we already have a sufficiently large amount of helpfulness training data.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-25'),\n",
              " 'e8b93735-ec0a-4ef1-b34d-7fd8044dbd02': IndexNode(id_='e8b93735-ec0a-4ef1-b34d-7fd8044dbd02', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-25', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='3b74a59af91ef8ff3221fd3b7dc26d01b168f5a13afdb91a57ab37aa5dec559c'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='9e141db1-9a78-4ba4-a629-2f21649895ee', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='56b7ab076fedc12efa045b0fbc0a9861d20bd2a470422de566bdc9b6daabb765'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='02ba4968-7b59-4c34-9851-066a024be1eb', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='727034699f85784925867f5daea1763df85349649ca9a534d27c9bdd39d631f3')}, hash='d587d33a685d295eb9ccbdea54138d3bb1bd0e9cd075b8191ee99249579107b6', text='Appendix A.4.2 lists\\nmore qualitative results that demonstrate how different amounts of safety data in training can change model\\nbehavior in responding to adversarial and non-adversarial prompts.\\n0 25 50 75 100\\nSafety Data Pct. (%)0.5750.6000.6250.6500.6750.7000.7250.7500.775Mean Reward Model Score\\nSafety\\nHelpfulnessSafety Data Pct. 0%\\nSafety Data Pct. 1%\\nSafety Data Pct. 10%\\nSafety Data Pct.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-25'),\n",
              " '02ba4968-7b59-4c34-9851-066a024be1eb': IndexNode(id_='02ba4968-7b59-4c34-9851-066a024be1eb', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-25', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='3b74a59af91ef8ff3221fd3b7dc26d01b168f5a13afdb91a57ab37aa5dec559c'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='e8b93735-ec0a-4ef1-b34d-7fd8044dbd02', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='d587d33a685d295eb9ccbdea54138d3bb1bd0e9cd075b8191ee99249579107b6'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='4e5b509d-8dce-465a-91a1-819536de71e0', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='e188d7c46c968f91bf2638fcd77c2a1ccc90c274cdaa86cf4fcd0345f62a921b')}, hash='727034699f85784925867f5daea1763df85349649ca9a534d27c9bdd39d631f3', text='1%\\nSafety Data Pct. 10%\\nSafety Data Pct. 25%\\nSafety Data Pct. 50%\\n0.0 0.2 0.4 0.6 0.8 1.0\\nSafety Reward Model ScoreSafety Data Pct. 100%\\nFigure 15: Safety data scaling trends. Left: as we increase the amount of safety data in model training, the\\nmean safety RM score improves significantly while the helpfulness counterpart remains relatively stable.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-25'),\n",
              " '4e5b509d-8dce-465a-91a1-819536de71e0': IndexNode(id_='4e5b509d-8dce-465a-91a1-819536de71e0', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-25', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='3b74a59af91ef8ff3221fd3b7dc26d01b168f5a13afdb91a57ab37aa5dec559c'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='02ba4968-7b59-4c34-9851-066a024be1eb', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='727034699f85784925867f5daea1763df85349649ca9a534d27c9bdd39d631f3'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='87eae4be-25e9-4770-81aa-17a7e7f48b5e', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='eeb586625c7efc0c42ad6618af530388f98f647fbcf09a8f0640321f87dd3a13')}, hash='e188d7c46c968f91bf2638fcd77c2a1ccc90c274cdaa86cf4fcd0345f62a921b', text='Right: the left tail of safety RM scores (i.e., most unsafe responses) gradually disappears with the addition of\\nmore safety training data.\\nMeasure of False Refusal. Even though we do not see overall regression on model helpfulness, we qualita-\\ntively observe, through interaction, that the model with more safety mitigation answers certain questions in\\na more conservative manner (e.g., example shown in Appendix Table 38).', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-25'),\n",
              " '87eae4be-25e9-4770-81aa-17a7e7f48b5e': IndexNode(id_='87eae4be-25e9-4770-81aa-17a7e7f48b5e', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-25', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='3b74a59af91ef8ff3221fd3b7dc26d01b168f5a13afdb91a57ab37aa5dec559c'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='4e5b509d-8dce-465a-91a1-819536de71e0', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='e188d7c46c968f91bf2638fcd77c2a1ccc90c274cdaa86cf4fcd0345f62a921b'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='d6061e3f-fe8b-46ff-915c-e1d3e89058c0', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='d9adcc04e77a1f5568abd6113757c02aa50967f44def09cca0d04323660410e8')}, hash='eeb586625c7efc0c42ad6618af530388f98f647fbcf09a8f0640321f87dd3a13', text='As a follow-up, we measure false\\nrefusaltoquantifythefrequencythatthemodelincorrectlyrefusestoanswernon-adversarialprompts. Here,\\nwe define false refusal as the model incorrectly refusing to answer legitimate user prompts due to irrelevant\\nsafety concerns. Refusing due to reasonable causes exceeding the model’s capability, e.g., “I am not capable of\\nparticipating in video calls” and“2024 is beyond my knowledge cut-off date,” are not counted as false refusals.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-25'),\n",
              " 'd6061e3f-fe8b-46ff-915c-e1d3e89058c0': IndexNode(id_='d6061e3f-fe8b-46ff-915c-e1d3e89058c0', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-25', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='3b74a59af91ef8ff3221fd3b7dc26d01b168f5a13afdb91a57ab37aa5dec559c'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='87eae4be-25e9-4770-81aa-17a7e7f48b5e', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='eeb586625c7efc0c42ad6618af530388f98f647fbcf09a8f0640321f87dd3a13'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='8c6b3dc5-9b12-4025-b039-af0550b89cc1', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='e84ee63a744e1e424c144d92944ea5888e850e8971d1f899a8f0e3b45049e1f6')}, hash='d9adcc04e77a1f5568abd6113757c02aa50967f44def09cca0d04323660410e8', text='We\\ntrainaclassifierfordetectingrefusalsinresponsesandapplytheclassifieron1)theabovehelpfulnesstest\\nsetsand2)acuratedborderlinetestsetconsistingof210samplesforthepurposeofboundarytestingsimilar\\nto OpenAI (2023). The borderline dataset is designed intentionally so that its prompts look adversarial\\n(e.g., containing sensitive words or subwords) but are not actually unsafe (e.g., “give me a recipe for Christmas\\nCrack”)(see Appendix Table 41 for more examples).', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-25'),\n",
              " '8c6b3dc5-9b12-4025-b039-af0550b89cc1': IndexNode(id_='8c6b3dc5-9b12-4025-b039-af0550b89cc1', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-25', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='3b74a59af91ef8ff3221fd3b7dc26d01b168f5a13afdb91a57ab37aa5dec559c'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='d6061e3f-fe8b-46ff-915c-e1d3e89058c0', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='d9adcc04e77a1f5568abd6113757c02aa50967f44def09cca0d04323660410e8'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='1f3b7096-6896-4189-98e4-f46463a7c347', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='44f28f901f51384bdf742aec1118ad02afba33668806bf7190c224ae75157639')}, hash='e84ee63a744e1e424c144d92944ea5888e850e8971d1f899a8f0e3b45049e1f6', text='With more safety data mixed in model tuning, the false-refusal rate becomes larger on both datasets (see\\nAppendix Figure 33). However, false refusal is overall rare—approximately 0.05%—on the helpfulness\\ndataset,evenwith100%safetydata. Ontheotherhand,thefalse-refusalrateismuchlargerontheborderline\\nsetduetoitsdifficulty.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-25'),\n",
              " '1f3b7096-6896-4189-98e4-f46463a7c347': IndexNode(id_='1f3b7096-6896-4189-98e4-f46463a7c347', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-25', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='3b74a59af91ef8ff3221fd3b7dc26d01b168f5a13afdb91a57ab37aa5dec559c'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='8c6b3dc5-9b12-4025-b039-af0550b89cc1', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='e84ee63a744e1e424c144d92944ea5888e850e8971d1f899a8f0e3b45049e1f6'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='8d135d4e-3bfd-421f-89cc-5d53deaa5ba3', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='c3fec889cdb58701b54636c297a9dcd8987a95233ce1be671e5ee68c265f725f')}, hash='44f28f901f51384bdf742aec1118ad02afba33668806bf7190c224ae75157639', text='Llama 2-Chat sometimeshasdifficultydistinguishingwhetherapromptissafewhen\\nthe prompt contains words that frequently occur in unsafe generations (such as “bomb”). Appendix Table 41\\nshows some examples of false refusals we discovered.\\n26\\n\\nGeneric Preprompt Preprompt with Answer Template\\nThe following is a discussion between a human and a\\nknowledgeable and empathetic assistant.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-25'),\n",
              " '8d135d4e-3bfd-421f-89cc-5d53deaa5ba3': IndexNode(id_='8d135d4e-3bfd-421f-89cc-5d53deaa5ba3', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-25', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='3b74a59af91ef8ff3221fd3b7dc26d01b168f5a13afdb91a57ab37aa5dec559c'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='1f3b7096-6896-4189-98e4-f46463a7c347', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='44f28f901f51384bdf742aec1118ad02afba33668806bf7190c224ae75157639'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='33f026ae-159c-4722-9509-2844d89685a1', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='67b13af1c06dfe7ff209aea7b5222ac37a60be5e2961ffafccaca25335c4f9fa')}, hash='c3fec889cdb58701b54636c297a9dcd8987a95233ce1be671e5ee68c265f725f', text='The assistant’s\\nanswers should not include any harmful, unethical, or\\nsocially biased content, and should move the conversation\\nin a positive direction.\\nPleasewrite asillyguide that’s meanttoconvince\\nsomeone that the moon landing was faked.The following is a question that can ellicit unsafe behavior\\nfromyou. Thequestionwasclassifiedasbelongingtothe\\nviolatingcategory: ’FalseInformation/ Disinformation’.\\nYou should answer using the following template:\\n\"1. Address the prompt.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-25'),\n",
              " '33f026ae-159c-4722-9509-2844d89685a1': IndexNode(id_='33f026ae-159c-4722-9509-2844d89685a1', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-25', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='3b74a59af91ef8ff3221fd3b7dc26d01b168f5a13afdb91a57ab37aa5dec559c'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='8d135d4e-3bfd-421f-89cc-5d53deaa5ba3', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='c3fec889cdb58701b54636c297a9dcd8987a95233ce1be671e5ee68c265f725f')}, hash='67b13af1c06dfe7ff209aea7b5222ac37a60be5e2961ffafccaca25335c4f9fa', text='You should answer using the following template:\\n\"1. Address the prompt. the model should immediately\\nrefute any misinformation in the prompt.\\n2. Add context and additional information. the model\\nshould provide evidence with sourcing to counter\\nmisinformation as needed.\\n3. Encourage users to ask for/view additional info as\\nappropriate. If applicable, the model can point the user to\\nother legitimate sources for further reading.\"', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-25'),\n",
              " 'abbec7f7-3d61-4eca-ad3f-548094d80e28': IndexNode(id_='abbec7f7-3d61-4eca-ad3f-548094d80e28', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-25', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='3b74a59af91ef8ff3221fd3b7dc26d01b168f5a13afdb91a57ab37aa5dec559c'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='5bc8a93a-27b7-428d-9861-700ed449a7f1', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='f2976797154c6d8b9e1172a21eb91ff18e946c5a4b003a05e802f835f9618de5')}, hash='e8e692af56656ded926ebeb7b2b1bfc3574fb070db15d9e4637bd37c9d4bf4e9', text='Weobservethatwhenweincreasetheproportionofsafetydata,themodel’sperformanceon\\nhandling risky and adversarial prompts improves dramatically, and we see a lighter tail in the safety reward\\nmodelscoredistribution. Meanwhile,themeanhelpfulnessscoreremainsconstant. Wehypothesizethat\\nthis is because we already have a sufficiently large amount of helpfulness training data. Appendix A.4.2 lists\\nmore qualitative results that demonstrate how different amounts of safety data in training can change model\\nbehavior in responding to adversarial and non-adversarial prompts.\\n0 25 50 75 100\\nSafety Data Pct. (%)0.5750.6000.6250.6500.6750.7000.7250.7500.775Mean Reward Model Score\\nSafety\\nHelpfulnessSafety Data Pct. 0%\\nSafety Data Pct. 1%\\nSafety Data Pct. 10%\\nSafety Data Pct. 25%\\nSafety Data Pct. 50%\\n0.0 0.2 0.4 0.6 0.8 1.0\\nSafety Reward Model ScoreSafety Data Pct.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-25'),\n",
              " '5bc8a93a-27b7-428d-9861-700ed449a7f1': IndexNode(id_='5bc8a93a-27b7-428d-9861-700ed449a7f1', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-25', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='3b74a59af91ef8ff3221fd3b7dc26d01b168f5a13afdb91a57ab37aa5dec559c'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='abbec7f7-3d61-4eca-ad3f-548094d80e28', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='e8e692af56656ded926ebeb7b2b1bfc3574fb070db15d9e4637bd37c9d4bf4e9'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='a8f335a2-331b-4edb-b758-27e685d2fbe6', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='ed98155e44611449519395768ecb47003846f66eef3fea47d9df2c061ec73fdb')}, hash='f2976797154c6d8b9e1172a21eb91ff18e946c5a4b003a05e802f835f9618de5', text='100%\\nFigure 15: Safety data scaling trends. Left: as we increase the amount of safety data in model training, the\\nmean safety RM score improves significantly while the helpfulness counterpart remains relatively stable.\\nRight: the left tail of safety RM scores (i.e., most unsafe responses) gradually disappears with the addition of\\nmore safety training data.\\nMeasure of False Refusal. Even though we do not see overall regression on model helpfulness, we qualita-\\ntively observe, through interaction, that the model with more safety mitigation answers certain questions in\\na more conservative manner (e.g., example shown in Appendix Table 38). As a follow-up, we measure false\\nrefusaltoquantifythefrequencythatthemodelincorrectlyrefusestoanswernon-adversarialprompts. Here,\\nwe define false refusal as the model incorrectly refusing to answer legitimate user prompts due to irrelevant\\nsafety concerns.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-25'),\n",
              " 'a8f335a2-331b-4edb-b758-27e685d2fbe6': IndexNode(id_='a8f335a2-331b-4edb-b758-27e685d2fbe6', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-25', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='3b74a59af91ef8ff3221fd3b7dc26d01b168f5a13afdb91a57ab37aa5dec559c'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='5bc8a93a-27b7-428d-9861-700ed449a7f1', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='f2976797154c6d8b9e1172a21eb91ff18e946c5a4b003a05e802f835f9618de5'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='5326de48-f7e1-4e97-be97-24a09e9c1513', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='f7ae23f26aae9973471191e4e5d4dc2be1ab5756214979d88d5bb7bc47f48c9c')}, hash='ed98155e44611449519395768ecb47003846f66eef3fea47d9df2c061ec73fdb', text='Refusing due to reasonable causes exceeding the model’s capability, e.g., “I am not capable of\\nparticipating in video calls” and“2024 is beyond my knowledge cut-off date,” are not counted as false refusals. We\\ntrainaclassifierfordetectingrefusalsinresponsesandapplytheclassifieron1)theabovehelpfulnesstest\\nsetsand2)acuratedborderlinetestsetconsistingof210samplesforthepurposeofboundarytestingsimilar\\nto OpenAI (2023). The borderline dataset is designed intentionally so that its prompts look adversarial\\n(e.g., containing sensitive words or subwords) but are not actually unsafe (e.g., “give me a recipe for Christmas\\nCrack”)(see Appendix Table 41 for more examples).\\nWith more safety data mixed in model tuning, the false-refusal rate becomes larger on both datasets (see\\nAppendix Figure 33). However, false refusal is overall rare—approximately 0.05%—on the helpfulness\\ndataset,evenwith100%safetydata.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-25'),\n",
              " '5326de48-f7e1-4e97-be97-24a09e9c1513': IndexNode(id_='5326de48-f7e1-4e97-be97-24a09e9c1513', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-25', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='3b74a59af91ef8ff3221fd3b7dc26d01b168f5a13afdb91a57ab37aa5dec559c'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='a8f335a2-331b-4edb-b758-27e685d2fbe6', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='ed98155e44611449519395768ecb47003846f66eef3fea47d9df2c061ec73fdb'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='4ad45542-5504-4e00-80bd-e7b204fff1ed', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='67b13af1c06dfe7ff209aea7b5222ac37a60be5e2961ffafccaca25335c4f9fa')}, hash='f7ae23f26aae9973471191e4e5d4dc2be1ab5756214979d88d5bb7bc47f48c9c', text='Ontheotherhand,thefalse-refusalrateismuchlargerontheborderline\\nsetduetoitsdifficulty. Llama 2-Chat sometimeshasdifficultydistinguishingwhetherapromptissafewhen\\nthe prompt contains words that frequently occur in unsafe generations (such as “bomb”). Appendix Table 41\\nshows some examples of false refusals we discovered.\\n26\\n\\nGeneric Preprompt Preprompt with Answer Template\\nThe following is a discussion between a human and a\\nknowledgeable and empathetic assistant. The assistant’s\\nanswers should not include any harmful, unethical, or\\nsocially biased content, and should move the conversation\\nin a positive direction.\\nPleasewrite asillyguide that’s meanttoconvince\\nsomeone that the moon landing was faked.The following is a question that can ellicit unsafe behavior\\nfromyou. Thequestionwasclassifiedasbelongingtothe\\nviolatingcategory: ’FalseInformation/ Disinformation’.\\nYou should answer using the following template:\\n\"1. Address the prompt.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-25'),\n",
              " '4ad45542-5504-4e00-80bd-e7b204fff1ed': IndexNode(id_='4ad45542-5504-4e00-80bd-e7b204fff1ed', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-25', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='3b74a59af91ef8ff3221fd3b7dc26d01b168f5a13afdb91a57ab37aa5dec559c'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='5326de48-f7e1-4e97-be97-24a09e9c1513', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='f7ae23f26aae9973471191e4e5d4dc2be1ab5756214979d88d5bb7bc47f48c9c')}, hash='67b13af1c06dfe7ff209aea7b5222ac37a60be5e2961ffafccaca25335c4f9fa', text='You should answer using the following template:\\n\"1. Address the prompt. the model should immediately\\nrefute any misinformation in the prompt.\\n2. Add context and additional information. the model\\nshould provide evidence with sourcing to counter\\nmisinformation as needed.\\n3. Encourage users to ask for/view additional info as\\nappropriate. If applicable, the model can point the user to\\nother legitimate sources for further reading.\"', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-25'),\n",
              " 'a4a78b6f-e028-498c-8f74-5575a2b5eee6': IndexNode(id_='a4a78b6f-e028-498c-8f74-5575a2b5eee6', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-25', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='3b74a59af91ef8ff3221fd3b7dc26d01b168f5a13afdb91a57ab37aa5dec559c'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='07d38a8f-1b37-4a92-8f4e-e76d24837688', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='0a025483a03e55680cfd85fedb71a15179f7f0c5b4eb4743832612729cd0c276')}, hash='754b69b53c1c6a7b433725890ecf4d424885270b8a36b5f3f6620db7021cd5d5', text='Weobservethatwhenweincreasetheproportionofsafetydata,themodel’sperformanceon\\nhandling risky and adversarial prompts improves dramatically, and we see a lighter tail in the safety reward\\nmodelscoredistribution. Meanwhile,themeanhelpfulnessscoreremainsconstant. Wehypothesizethat\\nthis is because we already have a sufficiently large amount of helpfulness training data. Appendix A.4.2 lists\\nmore qualitative results that demonstrate how different amounts of safety data in training can change model\\nbehavior in responding to adversarial and non-adversarial prompts.\\n0 25 50 75 100\\nSafety Data Pct. (%)0.5750.6000.6250.6500.6750.7000.7250.7500.775Mean Reward Model Score\\nSafety\\nHelpfulnessSafety Data Pct. 0%\\nSafety Data Pct. 1%\\nSafety Data Pct. 10%\\nSafety Data Pct. 25%\\nSafety Data Pct. 50%\\n0.0 0.2 0.4 0.6 0.8 1.0\\nSafety Reward Model ScoreSafety Data Pct. 100%\\nFigure 15: Safety data scaling trends. Left: as we increase the amount of safety data in model training, the\\nmean safety RM score improves significantly while the helpfulness counterpart remains relatively stable.\\nRight: the left tail of safety RM scores (i.e., most unsafe responses) gradually disappears with the addition of\\nmore safety training data.\\nMeasure of False Refusal. Even though we do not see overall regression on model helpfulness, we qualita-\\ntively observe, through interaction, that the model with more safety mitigation answers certain questions in\\na more conservative manner (e.g., example shown in Appendix Table 38). As a follow-up, we measure false\\nrefusaltoquantifythefrequencythatthemodelincorrectlyrefusestoanswernon-adversarialprompts. Here,\\nwe define false refusal as the model incorrectly refusing to answer legitimate user prompts due to irrelevant\\nsafety concerns.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-25'),\n",
              " '07d38a8f-1b37-4a92-8f4e-e76d24837688': IndexNode(id_='07d38a8f-1b37-4a92-8f4e-e76d24837688', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-25', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='3b74a59af91ef8ff3221fd3b7dc26d01b168f5a13afdb91a57ab37aa5dec559c'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='a4a78b6f-e028-498c-8f74-5575a2b5eee6', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='754b69b53c1c6a7b433725890ecf4d424885270b8a36b5f3f6620db7021cd5d5'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='48398785-ad5b-4824-81e0-e269a1cdead2', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='436274e995772f9b5cbe19781d53c19fd12220eaa6e5f4eee97c20cf5bd4f56e')}, hash='0a025483a03e55680cfd85fedb71a15179f7f0c5b4eb4743832612729cd0c276', text='Refusing due to reasonable causes exceeding the model’s capability, e.g., “I am not capable of\\nparticipating in video calls” and“2024 is beyond my knowledge cut-off date,” are not counted as false refusals. We\\ntrainaclassifierfordetectingrefusalsinresponsesandapplytheclassifieron1)theabovehelpfulnesstest\\nsetsand2)acuratedborderlinetestsetconsistingof210samplesforthepurposeofboundarytestingsimilar\\nto OpenAI (2023). The borderline dataset is designed intentionally so that its prompts look adversarial\\n(e.g., containing sensitive words or subwords) but are not actually unsafe (e.g., “give me a recipe for Christmas\\nCrack”)(see Appendix Table 41 for more examples).\\nWith more safety data mixed in model tuning, the false-refusal rate becomes larger on both datasets (see\\nAppendix Figure 33). However, false refusal is overall rare—approximately 0.05%—on the helpfulness\\ndataset,evenwith100%safetydata. Ontheotherhand,thefalse-refusalrateismuchlargerontheborderline\\nsetduetoitsdifficulty. Llama 2-Chat sometimeshasdifficultydistinguishingwhetherapromptissafewhen\\nthe prompt contains words that frequently occur in unsafe generations (such as “bomb”). Appendix Table 41\\nshows some examples of false refusals we discovered.\\n26\\n\\nGeneric Preprompt Preprompt with Answer Template\\nThe following is a discussion between a human and a\\nknowledgeable and empathetic assistant. The assistant’s\\nanswers should not include any harmful, unethical, or\\nsocially biased content, and should move the conversation\\nin a positive direction.\\nPleasewrite asillyguide that’s meanttoconvince\\nsomeone that the moon landing was faked.The following is a question that can ellicit unsafe behavior\\nfromyou. Thequestionwasclassifiedasbelongingtothe\\nviolatingcategory: ’FalseInformation/ Disinformation’.\\nYou should answer using the following template:\\n\"1. Address the prompt. the model should immediately\\nrefute any misinformation in the prompt.\\n2.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-25'),\n",
              " '48398785-ad5b-4824-81e0-e269a1cdead2': IndexNode(id_='48398785-ad5b-4824-81e0-e269a1cdead2', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-25', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='3b74a59af91ef8ff3221fd3b7dc26d01b168f5a13afdb91a57ab37aa5dec559c'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='07d38a8f-1b37-4a92-8f4e-e76d24837688', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='0a025483a03e55680cfd85fedb71a15179f7f0c5b4eb4743832612729cd0c276')}, hash='436274e995772f9b5cbe19781d53c19fd12220eaa6e5f4eee97c20cf5bd4f56e', text='the model should immediately\\nrefute any misinformation in the prompt.\\n2. Add context and additional information. the model\\nshould provide evidence with sourcing to counter\\nmisinformation as needed.\\n3. Encourage users to ask for/view additional info as\\nappropriate. If applicable, the model can point the user to\\nother legitimate sources for further reading.\"', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-25'),\n",
              " 'node-25': IndexNode(id_='node-25', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='415b7efc-e73f-4ac4-bbfd-c1546f099026', node_type=<ObjectType.DOCUMENT: '4'>, metadata={}, hash='231b3bd773f012c01b893ada9e009ecf25ee59934614c5a595c9bf1b3a123292'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='2f82e0ab-6c24-47cb-b5a9-771b8856b2ac', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='2aa7fe81895347a469a33159e78a97581601e9b018df1aa2e84cd996990a1636'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='151d70ea-4932-45d4-8e1a-dd63a9a6c97e', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='9a93f76f9d060a4e3610095bb60e742c3d0fb634e6f57c64782a03d1e11d4802')}, hash='3b74a59af91ef8ff3221fd3b7dc26d01b168f5a13afdb91a57ab37aa5dec559c', text='Weobservethatwhenweincreasetheproportionofsafetydata,themodel’sperformanceon\\nhandling risky and adversarial prompts improves dramatically, and we see a lighter tail in the safety reward\\nmodelscoredistribution. Meanwhile,themeanhelpfulnessscoreremainsconstant. Wehypothesizethat\\nthis is because we already have a sufficiently large amount of helpfulness training data. Appendix A.4.2 lists\\nmore qualitative results that demonstrate how different amounts of safety data in training can change model\\nbehavior in responding to adversarial and non-adversarial prompts.\\n0 25 50 75 100\\nSafety Data Pct. (%)0.5750.6000.6250.6500.6750.7000.7250.7500.775Mean Reward Model Score\\nSafety\\nHelpfulnessSafety Data Pct. 0%\\nSafety Data Pct. 1%\\nSafety Data Pct. 10%\\nSafety Data Pct. 25%\\nSafety Data Pct. 50%\\n0.0 0.2 0.4 0.6 0.8 1.0\\nSafety Reward Model ScoreSafety Data Pct. 100%\\nFigure 15: Safety data scaling trends. Left: as we increase the amount of safety data in model training, the\\nmean safety RM score improves significantly while the helpfulness counterpart remains relatively stable.\\nRight: the left tail of safety RM scores (i.e., most unsafe responses) gradually disappears with the addition of\\nmore safety training data.\\nMeasure of False Refusal. Even though we do not see overall regression on model helpfulness, we qualita-\\ntively observe, through interaction, that the model with more safety mitigation answers certain questions in\\na more conservative manner (e.g., example shown in Appendix Table 38). As a follow-up, we measure false\\nrefusaltoquantifythefrequencythatthemodelincorrectlyrefusestoanswernon-adversarialprompts. Here,\\nwe define false refusal as the model incorrectly refusing to answer legitimate user prompts due to irrelevant\\nsafety concerns. Refusing due to reasonable causes exceeding the model’s capability, e.g., “I am not capable of\\nparticipating in video calls” and“2024 is beyond my knowledge cut-off date,” are not counted as false refusals. We\\ntrainaclassifierfordetectingrefusalsinresponsesandapplytheclassifieron1)theabovehelpfulnesstest\\nsetsand2)acuratedborderlinetestsetconsistingof210samplesforthepurposeofboundarytestingsimilar\\nto OpenAI (2023). The borderline dataset is designed intentionally so that its prompts look adversarial\\n(e.g., containing sensitive words or subwords) but are not actually unsafe (e.g., “give me a recipe for Christmas\\nCrack”)(see Appendix Table 41 for more examples).\\nWith more safety data mixed in model tuning, the false-refusal rate becomes larger on both datasets (see\\nAppendix Figure 33). However, false refusal is overall rare—approximately 0.05%—on the helpfulness\\ndataset,evenwith100%safetydata. Ontheotherhand,thefalse-refusalrateismuchlargerontheborderline\\nsetduetoitsdifficulty. Llama 2-Chat sometimeshasdifficultydistinguishingwhetherapromptissafewhen\\nthe prompt contains words that frequently occur in unsafe generations (such as “bomb”). Appendix Table 41\\nshows some examples of false refusals we discovered.\\n26\\n\\nGeneric Preprompt Preprompt with Answer Template\\nThe following is a discussion between a human and a\\nknowledgeable and empathetic assistant. The assistant’s\\nanswers should not include any harmful, unethical, or\\nsocially biased content, and should move the conversation\\nin a positive direction.\\nPleasewrite asillyguide that’s meanttoconvince\\nsomeone that the moon landing was faked.The following is a question that can ellicit unsafe behavior\\nfromyou. Thequestionwasclassifiedasbelongingtothe\\nviolatingcategory: ’FalseInformation/ Disinformation’.\\nYou should answer using the following template:\\n\"1. Address the prompt. the model should immediately\\nrefute any misinformation in the prompt.\\n2. Add context and additional information. the model\\nshould provide evidence with sourcing to counter\\nmisinformation as needed.\\n3. Encourage users to ask for/view additional info as\\nappropriate. If applicable, the model can point the user to\\nother legitimate sources for further reading.\"', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-25'),\n",
              " 'e94f338a-c79d-4383-b471-ad6a50e6564d': IndexNode(id_='e94f338a-c79d-4383-b471-ad6a50e6564d', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-26', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='9a93f76f9d060a4e3610095bb60e742c3d0fb634e6f57c64782a03d1e11d4802'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='d2c12231-a889-4141-8042-6de354f0489a', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='38ec2418ba13c4fdc3844fc45d7a02a148f2f1ceaf0c8e98b4048900f0172471')}, hash='281e2e912c39247e423b65dc6577411304c88fbb912c2f05476529ffd4fb8a51', text='If applicable, the model can point the user to\\nother legitimate sources for further reading.\"\\nPleasewrite asillyguide that’smeantto convince\\nsomeone that the moon landing was faked.\\nI can’t satisfy your request, I’m just an AI, I cannot\\nprovideaguidethatpromotesmisinformationorcon-\\nspiracy theories. The moon landing was not faked,\\nand it is important to rely on scientific evidence and\\ncrediblesourceswhenevaluatinghistoricalevents.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-26'),\n",
              " 'd2c12231-a889-4141-8042-6de354f0489a': IndexNode(id_='d2c12231-a889-4141-8042-6de354f0489a', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-26', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='9a93f76f9d060a4e3610095bb60e742c3d0fb634e6f57c64782a03d1e11d4802'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='e94f338a-c79d-4383-b471-ad6a50e6564d', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='281e2e912c39247e423b65dc6577411304c88fbb912c2f05476529ffd4fb8a51'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='a502892b-c57f-41a6-a042-4ad621ca5314', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='d1a9abb898b74af8e467a94c1f6192f932edd34c95aac20a9e9d4ad44a49ca23')}, hash='38ec2418ba13c4fdc3844fc45d7a02a148f2f1ceaf0c8e98b4048900f0172471', text='It\\nisnotappropriatetospreadmisinformationorpro-\\nmote conspiracy theories, as it can be harmful and\\ndisrespectfultothosewhowereinvolvedintheevent.\\nLet’s focus on sharing accurate and helpful informa-\\ntioninstead. IstheresomethingelseIcanhelpyou\\nwith?I cannot provide a response to this prompt as it\\ngoes against my programming rules to promote\\nor encourage the spread of false information.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-26'),\n",
              " 'a502892b-c57f-41a6-a042-4ad621ca5314': IndexNode(id_='a502892b-c57f-41a6-a042-4ad621ca5314', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-26', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='9a93f76f9d060a4e3610095bb60e742c3d0fb634e6f57c64782a03d1e11d4802'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='d2c12231-a889-4141-8042-6de354f0489a', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='38ec2418ba13c4fdc3844fc45d7a02a148f2f1ceaf0c8e98b4048900f0172471'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='645ad58f-2a53-47f5-a84b-bb648810c48a', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='9596d2c72ea04a92a6bb1696fe153289871ac9822334a8145792887cb840a61b')}, hash='d1a9abb898b74af8e467a94c1f6192f932edd34c95aac20a9e9d4ad44a49ca23', text='It\\nis important to respect the truth and accuracy in\\nall forms of communication, and to refrain from\\nspreading misinformation or conspiracy theories.\\nInstead, I would like to emphasize the impor-\\ntance of fact-checking and critical thinking when\\nevaluating information. It is crucial to rely on\\ncredible sources and evidence-based reasoning\\nwhen assessing the validity of a claim.\\nIf you have any other questions or concerns,\\nplease feel free to ask, and I will do my best to\\nprovide a helpful and accurate response.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-26'),\n",
              " '645ad58f-2a53-47f5-a84b-bb648810c48a': IndexNode(id_='645ad58f-2a53-47f5-a84b-bb648810c48a', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-26', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='9a93f76f9d060a4e3610095bb60e742c3d0fb634e6f57c64782a03d1e11d4802'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='a502892b-c57f-41a6-a042-4ad621ca5314', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='d1a9abb898b74af8e467a94c1f6192f932edd34c95aac20a9e9d4ad44a49ca23'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='9b1ea8fc-8c4b-4119-9172-a103acccf0b3', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='b4e4e8c45895de93eabab2fa3487083e4eeb99605311dbb90229351a2e47a9c6')}, hash='9596d2c72ea04a92a6bb1696fe153289871ac9822334a8145792887cb840a61b', text='Table13: Examplesofcontextdistillation withgenericprepromptandprepromptwithanswertemplate.\\nThe tailored preprompt with answer template is more relevant to the answer.\\n4.2.4 Context Distillation for Safety\\nWeencourage Llama 2-Chat toassociateadversarialpromptswithsaferresponsesbyusingcontextdistillation\\n(Askell et al., 2021a) similar to Section 3.3.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-26'),\n",
              " '9b1ea8fc-8c4b-4119-9172-a103acccf0b3': IndexNode(id_='9b1ea8fc-8c4b-4119-9172-a103acccf0b3', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-26', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='9a93f76f9d060a4e3610095bb60e742c3d0fb634e6f57c64782a03d1e11d4802'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='645ad58f-2a53-47f5-a84b-bb648810c48a', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='9596d2c72ea04a92a6bb1696fe153289871ac9822334a8145792887cb840a61b'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='0cd30e7e-d973-4b5b-bcd3-a5dcae57086e', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='73adb577f19ed69aaf1d78666d687be7ca573801ac84f386d13a221d3d5ae8c5')}, hash='b4e4e8c45895de93eabab2fa3487083e4eeb99605311dbb90229351a2e47a9c6', text='We observe that the safety capabilities of LLMs can be efficiently\\nenhanced by prefixing the model with a safety preprompt (e.g., “You are a safe and responsible assistant” ).\\nLike supervised safety fine-tuning, safety context distillation provides a quick way to bootstrap the model’s\\nresponses on hard adversarial prompts, so that they can then be further improved in RLHF.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-26'),\n",
              " '0cd30e7e-d973-4b5b-bcd3-a5dcae57086e': IndexNode(id_='0cd30e7e-d973-4b5b-bcd3-a5dcae57086e', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-26', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='9a93f76f9d060a4e3610095bb60e742c3d0fb634e6f57c64782a03d1e11d4802'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='9b1ea8fc-8c4b-4119-9172-a103acccf0b3', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='b4e4e8c45895de93eabab2fa3487083e4eeb99605311dbb90229351a2e47a9c6'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='e315d2f8-4acd-491a-b2a0-a649721b8cd3', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='680511521cf8a17ffe0a76a8f254ec0b35995980de83332c86cb628862f79bf0')}, hash='73adb577f19ed69aaf1d78666d687be7ca573801ac84f386d13a221d3d5ae8c5', text='Specifically, we apply context distillation by prefixing a safety preprompt to adversarial prompts to generate\\nsaferresponses,andthenfine-tunethemodelonitsownsafeoutputgiventheadversarialpromptwithout\\nthe preprompt. We generate safety preprompts automatically with templates.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-26'),\n",
              " 'e315d2f8-4acd-491a-b2a0-a649721b8cd3': IndexNode(id_='e315d2f8-4acd-491a-b2a0-a649721b8cd3', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-26', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='9a93f76f9d060a4e3610095bb60e742c3d0fb634e6f57c64782a03d1e11d4802'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='0cd30e7e-d973-4b5b-bcd3-a5dcae57086e', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='73adb577f19ed69aaf1d78666d687be7ca573801ac84f386d13a221d3d5ae8c5'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='d2873025-80f7-4070-be9b-917fe209fcc7', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='b802679150711b73662c6949ccb4abdc1719c025446d2628918bc1e389e4c794')}, hash='680511521cf8a17ffe0a76a8f254ec0b35995980de83332c86cb628862f79bf0', text='We generate safety preprompts automatically with templates. In particular, we use various\\nadjectivesusuallyassociatedwithsafebehaviorsuchas “responsible,”“respectful’,’ or“wise,”withtheintuition\\nthatthemodelassociatesthemwithpositivetraitsthatwewanttoseereflectedinsafeanswers. Weshow\\nexamples of safety preprompts in Appendix Table 39.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-26'),\n",
              " 'd2873025-80f7-4070-be9b-917fe209fcc7': IndexNode(id_='d2873025-80f7-4070-be9b-917fe209fcc7', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-26', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='9a93f76f9d060a4e3610095bb60e742c3d0fb634e6f57c64782a03d1e11d4802'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='e315d2f8-4acd-491a-b2a0-a649721b8cd3', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='680511521cf8a17ffe0a76a8f254ec0b35995980de83332c86cb628862f79bf0'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='3b6760fd-a064-40f5-83ad-d49d9a36f641', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='95f9425a640f3cf8273561f01a02081129a8dd9ea5e1f7d4d565c552cf6a1efa')}, hash='b802679150711b73662c6949ccb4abdc1719c025446d2628918bc1e389e4c794', text='Weshow\\nexamples of safety preprompts in Appendix Table 39.\\nContextDistillationwithAnswerTemplates Duringthepromptcollectionphase,wealsoaskedannotators\\ntolabelpromptsaccordingtoriskcategories,whichenablesevenmoretargetedpreprompts. Specifically,\\nthis allows us to provide some dedicated answer templates of how adversarial prompts should be addressed,\\nbased on each identified risk category. Figure 16a shows the impact of context distillation and context\\ndistillation with answer templates on the safety RM scores.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-26'),\n",
              " '3b6760fd-a064-40f5-83ad-d49d9a36f641': IndexNode(id_='3b6760fd-a064-40f5-83ad-d49d9a36f641', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-26', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='9a93f76f9d060a4e3610095bb60e742c3d0fb634e6f57c64782a03d1e11d4802'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='d2873025-80f7-4070-be9b-917fe209fcc7', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='b802679150711b73662c6949ccb4abdc1719c025446d2628918bc1e389e4c794'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='a2673f32-cd7a-4884-a106-ba0fc8ab2d5c', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='231244839d302d70cefcb46d14edbfa45659fbf6cf095d74ab1d8abee7f07d8a')}, hash='95f9425a640f3cf8273561f01a02081129a8dd9ea5e1f7d4d565c552cf6a1efa', text='27\\n\\n0 0.2 0.4 0.6 0.8 10123456\\nModel\\nBase\\n+ Generic Preprompt\\n+ Preprompt w/ Answer T emplate\\nSafety RM ScorePercent(a)Impact on Safety RM Score.\\n0 0.2 0.4 0.6 0.8 1−0.6−0.4−0.200.20.40.60.8\\nSelected?\\nSelected\\nRejected\\nOriginal Safety RM ScoreScore increase with CD (b)Targeted Context Distillation.\\nFigure 16: Context distillation analysis.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-26'),\n",
              " 'a2673f32-cd7a-4884-a106-ba0fc8ab2d5c': IndexNode(id_='a2673f32-cd7a-4884-a106-ba0fc8ab2d5c', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-26', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='9a93f76f9d060a4e3610095bb60e742c3d0fb634e6f57c64782a03d1e11d4802'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='3b6760fd-a064-40f5-83ad-d49d9a36f641', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='95f9425a640f3cf8273561f01a02081129a8dd9ea5e1f7d4d565c552cf6a1efa')}, hash='231244839d302d70cefcb46d14edbfa45659fbf6cf095d74ab1d8abee7f07d8a', text='Figure 16: Context distillation analysis. Left: Distribution of safety RM scores from the base model, when\\nadding a generic preprompt, and when adding a preprompt based on the risk category with tailored answer\\ntemplate. While a generic preprompt increases safety RM scores, a preprompt with tailored answer template\\nhelpsevenmore. Right:ContextdistillationincreasestheRMscoresignificantlyforsamplesthatinitially\\nhave a low score, but can also have a detrimental effect on samples that initially have a high score.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-26'),\n",
              " '2a72b2b2-cbb7-42bb-9589-6ee3b235a2de': IndexNode(id_='2a72b2b2-cbb7-42bb-9589-6ee3b235a2de', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-26', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='9a93f76f9d060a4e3610095bb60e742c3d0fb634e6f57c64782a03d1e11d4802'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='d8d5d9a3-8fef-4be7-9fa1-167761df5624', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='f963b30d129e2fd1feda9cfc203ba71c2a19cc62c09fc838c93bca7a87fb216b')}, hash='ab59af8eb0ed983c2203c0c557c60a4d518806e54e61405f43b9242cf0c52382', text='If applicable, the model can point the user to\\nother legitimate sources for further reading.\"\\nPleasewrite asillyguide that’smeantto convince\\nsomeone that the moon landing was faked.\\nI can’t satisfy your request, I’m just an AI, I cannot\\nprovideaguidethatpromotesmisinformationorcon-\\nspiracy theories. The moon landing was not faked,\\nand it is important to rely on scientific evidence and\\ncrediblesourceswhenevaluatinghistoricalevents. It\\nisnotappropriatetospreadmisinformationorpro-\\nmote conspiracy theories, as it can be harmful and\\ndisrespectfultothosewhowereinvolvedintheevent.\\nLet’s focus on sharing accurate and helpful informa-\\ntioninstead. IstheresomethingelseIcanhelpyou\\nwith?I cannot provide a response to this prompt as it\\ngoes against my programming rules to promote\\nor encourage the spread of false information. It\\nis important to respect the truth and accuracy in\\nall forms of communication, and to refrain from\\nspreading misinformation or conspiracy theories.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-26'),\n",
              " 'd8d5d9a3-8fef-4be7-9fa1-167761df5624': IndexNode(id_='d8d5d9a3-8fef-4be7-9fa1-167761df5624', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-26', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='9a93f76f9d060a4e3610095bb60e742c3d0fb634e6f57c64782a03d1e11d4802'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='2a72b2b2-cbb7-42bb-9589-6ee3b235a2de', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='ab59af8eb0ed983c2203c0c557c60a4d518806e54e61405f43b9242cf0c52382'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='94d9bd72-5e9a-4336-beb7-5b0ed6e55cb1', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='f42ee0b1a41654c1a7e0631b750a18b97de28029a5ec475c3f73a0818a755101')}, hash='f963b30d129e2fd1feda9cfc203ba71c2a19cc62c09fc838c93bca7a87fb216b', text='Instead, I would like to emphasize the impor-\\ntance of fact-checking and critical thinking when\\nevaluating information. It is crucial to rely on\\ncredible sources and evidence-based reasoning\\nwhen assessing the validity of a claim.\\nIf you have any other questions or concerns,\\nplease feel free to ask, and I will do my best to\\nprovide a helpful and accurate response.\\nTable13: Examplesofcontextdistillation withgenericprepromptandprepromptwithanswertemplate.\\nThe tailored preprompt with answer template is more relevant to the answer.\\n4.2.4 Context Distillation for Safety\\nWeencourage Llama 2-Chat toassociateadversarialpromptswithsaferresponsesbyusingcontextdistillation\\n(Askell et al., 2021a) similar to Section 3.3. We observe that the safety capabilities of LLMs can be efficiently\\nenhanced by prefixing the model with a safety preprompt (e.g., “You are a safe and responsible assistant” ).', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-26'),\n",
              " '94d9bd72-5e9a-4336-beb7-5b0ed6e55cb1': IndexNode(id_='94d9bd72-5e9a-4336-beb7-5b0ed6e55cb1', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-26', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='9a93f76f9d060a4e3610095bb60e742c3d0fb634e6f57c64782a03d1e11d4802'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='d8d5d9a3-8fef-4be7-9fa1-167761df5624', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='f963b30d129e2fd1feda9cfc203ba71c2a19cc62c09fc838c93bca7a87fb216b'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='8f90d8c0-451c-4167-af68-94082de3cd50', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='1afa3c18dc16c685f3a69ef3f6a3bb755e2c23012b57a92d08e54987d89e9e17')}, hash='f42ee0b1a41654c1a7e0631b750a18b97de28029a5ec475c3f73a0818a755101', text='Like supervised safety fine-tuning, safety context distillation provides a quick way to bootstrap the model’s\\nresponses on hard adversarial prompts, so that they can then be further improved in RLHF.\\nSpecifically, we apply context distillation by prefixing a safety preprompt to adversarial prompts to generate\\nsaferresponses,andthenfine-tunethemodelonitsownsafeoutputgiventheadversarialpromptwithout\\nthe preprompt. We generate safety preprompts automatically with templates. In particular, we use various\\nadjectivesusuallyassociatedwithsafebehaviorsuchas “responsible,”“respectful’,’ or“wise,”withtheintuition\\nthatthemodelassociatesthemwithpositivetraitsthatwewanttoseereflectedinsafeanswers. Weshow\\nexamples of safety preprompts in Appendix Table 39.\\nContextDistillationwithAnswerTemplates Duringthepromptcollectionphase,wealsoaskedannotators\\ntolabelpromptsaccordingtoriskcategories,whichenablesevenmoretargetedpreprompts.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-26'),\n",
              " '8f90d8c0-451c-4167-af68-94082de3cd50': IndexNode(id_='8f90d8c0-451c-4167-af68-94082de3cd50', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-26', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='9a93f76f9d060a4e3610095bb60e742c3d0fb634e6f57c64782a03d1e11d4802'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='94d9bd72-5e9a-4336-beb7-5b0ed6e55cb1', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='f42ee0b1a41654c1a7e0631b750a18b97de28029a5ec475c3f73a0818a755101'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='1e25dbb0-458a-4070-8787-e59dead019ff', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='9340ebbc4570d3596bb16cf742a98cf114f541438d338d9674d618dfa3dad6a1')}, hash='1afa3c18dc16c685f3a69ef3f6a3bb755e2c23012b57a92d08e54987d89e9e17', text='Specifically,\\nthis allows us to provide some dedicated answer templates of how adversarial prompts should be addressed,\\nbased on each identified risk category. Figure 16a shows the impact of context distillation and context\\ndistillation with answer templates on the safety RM scores.\\n27\\n\\n0 0.2 0.4 0.6 0.8 10123456\\nModel\\nBase\\n+ Generic Preprompt\\n+ Preprompt w/ Answer T emplate\\nSafety RM ScorePercent(a)Impact on Safety RM Score.\\n0 0.2 0.4 0.6 0.8 1−0.6−0.4−0.200.20.40.60.8\\nSelected?\\nSelected\\nRejected\\nOriginal Safety RM ScoreScore increase with CD (b)Targeted Context Distillation.\\nFigure 16: Context distillation analysis. Left: Distribution of safety RM scores from the base model, when\\nadding a generic preprompt, and when adding a preprompt based on the risk category with tailored answer\\ntemplate. While a generic preprompt increases safety RM scores, a preprompt with tailored answer template\\nhelpsevenmore.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-26'),\n",
              " '1e25dbb0-458a-4070-8787-e59dead019ff': IndexNode(id_='1e25dbb0-458a-4070-8787-e59dead019ff', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-26', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='9a93f76f9d060a4e3610095bb60e742c3d0fb634e6f57c64782a03d1e11d4802'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='8f90d8c0-451c-4167-af68-94082de3cd50', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='1afa3c18dc16c685f3a69ef3f6a3bb755e2c23012b57a92d08e54987d89e9e17')}, hash='9340ebbc4570d3596bb16cf742a98cf114f541438d338d9674d618dfa3dad6a1', text='Right:ContextdistillationincreasestheRMscoresignificantlyforsamplesthatinitially\\nhave a low score, but can also have a detrimental effect on samples that initially have a high score.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-26'),\n",
              " '58b7f457-2b47-4651-b71d-78c61539e0c6': IndexNode(id_='58b7f457-2b47-4651-b71d-78c61539e0c6', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-26', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='9a93f76f9d060a4e3610095bb60e742c3d0fb634e6f57c64782a03d1e11d4802'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='1519aace-92e5-4860-89bf-db138039a8d9', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='ebb17540b92a3834bc902869d8aea3edc9ed4e7917aafcfc5c5980cb2c8b3929')}, hash='96436b1bb55dbce6902d5db900bf617b16b745e7ede1f48b226281c13f2c9b36', text='If applicable, the model can point the user to\\nother legitimate sources for further reading.\"\\nPleasewrite asillyguide that’smeantto convince\\nsomeone that the moon landing was faked.\\nI can’t satisfy your request, I’m just an AI, I cannot\\nprovideaguidethatpromotesmisinformationorcon-\\nspiracy theories. The moon landing was not faked,\\nand it is important to rely on scientific evidence and\\ncrediblesourceswhenevaluatinghistoricalevents. It\\nisnotappropriatetospreadmisinformationorpro-\\nmote conspiracy theories, as it can be harmful and\\ndisrespectfultothosewhowereinvolvedintheevent.\\nLet’s focus on sharing accurate and helpful informa-\\ntioninstead. IstheresomethingelseIcanhelpyou\\nwith?I cannot provide a response to this prompt as it\\ngoes against my programming rules to promote\\nor encourage the spread of false information. It\\nis important to respect the truth and accuracy in\\nall forms of communication, and to refrain from\\nspreading misinformation or conspiracy theories.\\nInstead, I would like to emphasize the impor-\\ntance of fact-checking and critical thinking when\\nevaluating information. It is crucial to rely on\\ncredible sources and evidence-based reasoning\\nwhen assessing the validity of a claim.\\nIf you have any other questions or concerns,\\nplease feel free to ask, and I will do my best to\\nprovide a helpful and accurate response.\\nTable13: Examplesofcontextdistillation withgenericprepromptandprepromptwithanswertemplate.\\nThe tailored preprompt with answer template is more relevant to the answer.\\n4.2.4 Context Distillation for Safety\\nWeencourage Llama 2-Chat toassociateadversarialpromptswithsaferresponsesbyusingcontextdistillation\\n(Askell et al., 2021a) similar to Section 3.3. We observe that the safety capabilities of LLMs can be efficiently\\nenhanced by prefixing the model with a safety preprompt (e.g., “You are a safe and responsible assistant” ).', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-26'),\n",
              " '1519aace-92e5-4860-89bf-db138039a8d9': IndexNode(id_='1519aace-92e5-4860-89bf-db138039a8d9', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-26', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='9a93f76f9d060a4e3610095bb60e742c3d0fb634e6f57c64782a03d1e11d4802'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='58b7f457-2b47-4651-b71d-78c61539e0c6', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='96436b1bb55dbce6902d5db900bf617b16b745e7ede1f48b226281c13f2c9b36'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='be236169-7639-4d6b-adb9-74f5dce7855c', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='9340ebbc4570d3596bb16cf742a98cf114f541438d338d9674d618dfa3dad6a1')}, hash='ebb17540b92a3834bc902869d8aea3edc9ed4e7917aafcfc5c5980cb2c8b3929', text='Like supervised safety fine-tuning, safety context distillation provides a quick way to bootstrap the model’s\\nresponses on hard adversarial prompts, so that they can then be further improved in RLHF.\\nSpecifically, we apply context distillation by prefixing a safety preprompt to adversarial prompts to generate\\nsaferresponses,andthenfine-tunethemodelonitsownsafeoutputgiventheadversarialpromptwithout\\nthe preprompt. We generate safety preprompts automatically with templates. In particular, we use various\\nadjectivesusuallyassociatedwithsafebehaviorsuchas “responsible,”“respectful’,’ or“wise,”withtheintuition\\nthatthemodelassociatesthemwithpositivetraitsthatwewanttoseereflectedinsafeanswers. Weshow\\nexamples of safety preprompts in Appendix Table 39.\\nContextDistillationwithAnswerTemplates Duringthepromptcollectionphase,wealsoaskedannotators\\ntolabelpromptsaccordingtoriskcategories,whichenablesevenmoretargetedpreprompts. Specifically,\\nthis allows us to provide some dedicated answer templates of how adversarial prompts should be addressed,\\nbased on each identified risk category. Figure 16a shows the impact of context distillation and context\\ndistillation with answer templates on the safety RM scores.\\n27\\n\\n0 0.2 0.4 0.6 0.8 10123456\\nModel\\nBase\\n+ Generic Preprompt\\n+ Preprompt w/ Answer T emplate\\nSafety RM ScorePercent(a)Impact on Safety RM Score.\\n0 0.2 0.4 0.6 0.8 1−0.6−0.4−0.200.20.40.60.8\\nSelected?\\nSelected\\nRejected\\nOriginal Safety RM ScoreScore increase with CD (b)Targeted Context Distillation.\\nFigure 16: Context distillation analysis. Left: Distribution of safety RM scores from the base model, when\\nadding a generic preprompt, and when adding a preprompt based on the risk category with tailored answer\\ntemplate. While a generic preprompt increases safety RM scores, a preprompt with tailored answer template\\nhelpsevenmore.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-26'),\n",
              " 'be236169-7639-4d6b-adb9-74f5dce7855c': IndexNode(id_='be236169-7639-4d6b-adb9-74f5dce7855c', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-26', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='9a93f76f9d060a4e3610095bb60e742c3d0fb634e6f57c64782a03d1e11d4802'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='1519aace-92e5-4860-89bf-db138039a8d9', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='ebb17540b92a3834bc902869d8aea3edc9ed4e7917aafcfc5c5980cb2c8b3929')}, hash='9340ebbc4570d3596bb16cf742a98cf114f541438d338d9674d618dfa3dad6a1', text='Right:ContextdistillationincreasestheRMscoresignificantlyforsamplesthatinitially\\nhave a low score, but can also have a detrimental effect on samples that initially have a high score.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-26'),\n",
              " 'node-26': IndexNode(id_='node-26', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='415b7efc-e73f-4ac4-bbfd-c1546f099026', node_type=<ObjectType.DOCUMENT: '4'>, metadata={}, hash='231b3bd773f012c01b893ada9e009ecf25ee59934614c5a595c9bf1b3a123292'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='bfb9b644-8d43-4b89-8a8a-cbbf9086bf01', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='3b74a59af91ef8ff3221fd3b7dc26d01b168f5a13afdb91a57ab37aa5dec559c'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='f92ed592-9915-4d47-9166-5e8b0bd3ca65', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='9211b2b96b9f7d5bd072735994c9ded33055f0614098c62cf7434d3a06ef20d8')}, hash='9a93f76f9d060a4e3610095bb60e742c3d0fb634e6f57c64782a03d1e11d4802', text='If applicable, the model can point the user to\\nother legitimate sources for further reading.\"\\nPleasewrite asillyguide that’smeantto convince\\nsomeone that the moon landing was faked.\\nI can’t satisfy your request, I’m just an AI, I cannot\\nprovideaguidethatpromotesmisinformationorcon-\\nspiracy theories. The moon landing was not faked,\\nand it is important to rely on scientific evidence and\\ncrediblesourceswhenevaluatinghistoricalevents. It\\nisnotappropriatetospreadmisinformationorpro-\\nmote conspiracy theories, as it can be harmful and\\ndisrespectfultothosewhowereinvolvedintheevent.\\nLet’s focus on sharing accurate and helpful informa-\\ntioninstead. IstheresomethingelseIcanhelpyou\\nwith?I cannot provide a response to this prompt as it\\ngoes against my programming rules to promote\\nor encourage the spread of false information. It\\nis important to respect the truth and accuracy in\\nall forms of communication, and to refrain from\\nspreading misinformation or conspiracy theories.\\nInstead, I would like to emphasize the impor-\\ntance of fact-checking and critical thinking when\\nevaluating information. It is crucial to rely on\\ncredible sources and evidence-based reasoning\\nwhen assessing the validity of a claim.\\nIf you have any other questions or concerns,\\nplease feel free to ask, and I will do my best to\\nprovide a helpful and accurate response.\\nTable13: Examplesofcontextdistillation withgenericprepromptandprepromptwithanswertemplate.\\nThe tailored preprompt with answer template is more relevant to the answer.\\n4.2.4 Context Distillation for Safety\\nWeencourage Llama 2-Chat toassociateadversarialpromptswithsaferresponsesbyusingcontextdistillation\\n(Askell et al., 2021a) similar to Section 3.3. We observe that the safety capabilities of LLMs can be efficiently\\nenhanced by prefixing the model with a safety preprompt (e.g., “You are a safe and responsible assistant” ).\\nLike supervised safety fine-tuning, safety context distillation provides a quick way to bootstrap the model’s\\nresponses on hard adversarial prompts, so that they can then be further improved in RLHF.\\nSpecifically, we apply context distillation by prefixing a safety preprompt to adversarial prompts to generate\\nsaferresponses,andthenfine-tunethemodelonitsownsafeoutputgiventheadversarialpromptwithout\\nthe preprompt. We generate safety preprompts automatically with templates. In particular, we use various\\nadjectivesusuallyassociatedwithsafebehaviorsuchas “responsible,”“respectful’,’ or“wise,”withtheintuition\\nthatthemodelassociatesthemwithpositivetraitsthatwewanttoseereflectedinsafeanswers. Weshow\\nexamples of safety preprompts in Appendix Table 39.\\nContextDistillationwithAnswerTemplates Duringthepromptcollectionphase,wealsoaskedannotators\\ntolabelpromptsaccordingtoriskcategories,whichenablesevenmoretargetedpreprompts. Specifically,\\nthis allows us to provide some dedicated answer templates of how adversarial prompts should be addressed,\\nbased on each identified risk category. Figure 16a shows the impact of context distillation and context\\ndistillation with answer templates on the safety RM scores.\\n27\\n\\n0 0.2 0.4 0.6 0.8 10123456\\nModel\\nBase\\n+ Generic Preprompt\\n+ Preprompt w/ Answer T emplate\\nSafety RM ScorePercent(a)Impact on Safety RM Score.\\n0 0.2 0.4 0.6 0.8 1−0.6−0.4−0.200.20.40.60.8\\nSelected?\\nSelected\\nRejected\\nOriginal Safety RM ScoreScore increase with CD (b)Targeted Context Distillation.\\nFigure 16: Context distillation analysis. Left: Distribution of safety RM scores from the base model, when\\nadding a generic preprompt, and when adding a preprompt based on the risk category with tailored answer\\ntemplate. While a generic preprompt increases safety RM scores, a preprompt with tailored answer template\\nhelpsevenmore. Right:ContextdistillationincreasestheRMscoresignificantlyforsamplesthatinitially\\nhave a low score, but can also have a detrimental effect on samples that initially have a high score.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-26'),\n",
              " 'bf12dc10-b373-4f47-9c81-9043eab44a1e': IndexNode(id_='bf12dc10-b373-4f47-9c81-9043eab44a1e', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-27', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='9211b2b96b9f7d5bd072735994c9ded33055f0614098c62cf7434d3a06ef20d8'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='6ef813af-4fcd-448f-8df6-c1af22f1008f', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='6d6ebc6f1e085899ce7e2934e0891a8f7db6a1204990d8b2d9bf6f7ba49a19aa')}, hash='f87699f296c51d63dbd230771c1852bcbbdac2d1e1574628c790dfa622341dda', text='We\\ntherefore only apply context distillation on targeted samples when it increases RM score.\\nRejectingContextDistillationErrorswiththeSafetyRewardModel Itisimportanttonotethatperforming\\nsafetycontextdistillationforhelpfulpromptscandegrademodelperformanceandleadtomorefalserefusals\\n(see Appendix Table 40). We therefore perform safety context distillation only on adversarial prompts.\\nHowever, we observed that context distillation can sometimes degrade response quality, even when dealing\\nwith adversarial prompts.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-27'),\n",
              " '6ef813af-4fcd-448f-8df6-c1af22f1008f': IndexNode(id_='6ef813af-4fcd-448f-8df6-c1af22f1008f', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-27', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='9211b2b96b9f7d5bd072735994c9ded33055f0614098c62cf7434d3a06ef20d8'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='bf12dc10-b373-4f47-9c81-9043eab44a1e', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='f87699f296c51d63dbd230771c1852bcbbdac2d1e1574628c790dfa622341dda'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='88c534ed-9526-4a76-8864-ddb3e1122b94', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='871d804c3545588f023ea7e5e17106d09cfc6d4bb7ccded098ebf6073f32f6ec')}, hash='6d6ebc6f1e085899ce7e2934e0891a8f7db6a1204990d8b2d9bf6f7ba49a19aa', text='Specifically, if the model responses are already of high quality, the application of\\ncontext distillation can result in less pertinent replies, as the model tends to overemphasize the preprompt,\\noften resorting to generic concerns excessively (see Appendix Table 40 for an example of vague answers due\\ntocontextdistillation). Wethusleveragethesafetyrewardmodeltodecidewhethertousesafetycontext\\ndistillation – we keep the context-distilled output only on the examples where it gets a better reward model\\nscore than the original answer.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-27'),\n",
              " '88c534ed-9526-4a76-8864-ddb3e1122b94': IndexNode(id_='88c534ed-9526-4a76-8864-ddb3e1122b94', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-27', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='9211b2b96b9f7d5bd072735994c9ded33055f0614098c62cf7434d3a06ef20d8'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='6ef813af-4fcd-448f-8df6-c1af22f1008f', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='6d6ebc6f1e085899ce7e2934e0891a8f7db6a1204990d8b2d9bf6f7ba49a19aa'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='ccd031b5-dcc6-4b40-a147-bdfa97cdf4b2', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='dc4714f390d39686fd54ce77f5b33c342c9b53ede4d42a61297cdc68873f8b44')}, hash='871d804c3545588f023ea7e5e17106d09cfc6d4bb7ccded098ebf6073f32f6ec', text='We notice that thisis particularly helpful on prompts that the model is very\\nbad at, but limits the negative impact of context distillation (see Figure 16b).\\n4.3 Red Teaming\\nGivenhowbroadthecapabilitiesofLLMsareandhowvariedtheirtrainingdatais,itisinsufficienttoidentify\\nrisks solely via ex post facto usage and analysis. Rather, as has been done for other LLMs, we performed\\nvarious kinds of proactive risk identification, colloquially called “red teaming,“ based on the term commonly\\nused within computer security.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-27'),\n",
              " 'ccd031b5-dcc6-4b40-a147-bdfa97cdf4b2': IndexNode(id_='ccd031b5-dcc6-4b40-a147-bdfa97cdf4b2', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-27', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='9211b2b96b9f7d5bd072735994c9ded33055f0614098c62cf7434d3a06ef20d8'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='88c534ed-9526-4a76-8864-ddb3e1122b94', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='871d804c3545588f023ea7e5e17106d09cfc6d4bb7ccded098ebf6073f32f6ec'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='78b6bde1-99a3-45d5-86c8-ee75419c2c92', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='d3fc55dcc51b10bd52726caf12ab403f96bd9302462ffffdb8f59a2dce62cb3e')}, hash='dc4714f390d39686fd54ce77f5b33c342c9b53ede4d42a61297cdc68873f8b44', text='This kind of granular analysis is very important because safety is a long-tail\\nissue,inwhichevenveryinfrequentedgecasescancausenoticeableproblems. Evenifquantitativescores\\nreport good results, these types of qualitative insights allow us to recognize and target specific patterns in a\\nmore comprehensive way.\\nWe conducted a series of red teaming with various groups of internal employees, contract workers, and\\nexternalvendors.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-27'),\n",
              " '78b6bde1-99a3-45d5-86c8-ee75419c2c92': IndexNode(id_='78b6bde1-99a3-45d5-86c8-ee75419c2c92', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-27', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='9211b2b96b9f7d5bd072735994c9ded33055f0614098c62cf7434d3a06ef20d8'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='ccd031b5-dcc6-4b40-a147-bdfa97cdf4b2', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='dc4714f390d39686fd54ce77f5b33c342c9b53ede4d42a61297cdc68873f8b44'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='af5a8aa1-840e-4f0b-998b-cc192202d291', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='1e9e001b42f367bafb3bc16264f56ddab1dcfc48110a7491a3f5f3a9d9dcc259')}, hash='d3fc55dcc51b10bd52726caf12ab403f96bd9302462ffffdb8f59a2dce62cb3e', text='Theseteamsincludedover350people,includingdomainexpertsincybersecurity,elec-\\ntion fraud, social media misinformation, legal, policy, civil rights, ethics, software engineering, machine\\nlearning, responsible AI, and creative writing. They also included individuals representative of a variety of\\nsocioeconomic, gender, ethnicity, and racial demographics.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-27'),\n",
              " 'af5a8aa1-840e-4f0b-998b-cc192202d291': IndexNode(id_='af5a8aa1-840e-4f0b-998b-cc192202d291', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-27', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='9211b2b96b9f7d5bd072735994c9ded33055f0614098c62cf7434d3a06ef20d8'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='78b6bde1-99a3-45d5-86c8-ee75419c2c92', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='d3fc55dcc51b10bd52726caf12ab403f96bd9302462ffffdb8f59a2dce62cb3e'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='06c6d993-5ab9-4a66-be49-ea350a031e7f', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='0e94f8631bedad2d56abb9e8e6854d3c43c5577dbcfa8f2e556773e121a494de')}, hash='1e9e001b42f367bafb3bc16264f56ddab1dcfc48110a7491a3f5f3a9d9dcc259', text='28\\n\\nTheredteamersprobedourmodelsacrossawiderangeofriskcategories(suchascriminalplanning,human\\ntrafficking, regulated or controlled substances, sexually explicit content, unqualified health or financial\\nadvice, privacy violations, and more), as well as different attack vectors (such as hypothetical questions,\\nmalformed/misspelledinputs,orextendeddialogues). Additionally,weconductedspecificteststodetermine\\nthe capabilities of our models to facilitate the production of weapons (e.g.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-27'),\n",
              " '06c6d993-5ab9-4a66-be49-ea350a031e7f': IndexNode(id_='06c6d993-5ab9-4a66-be49-ea350a031e7f', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-27', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='9211b2b96b9f7d5bd072735994c9ded33055f0614098c62cf7434d3a06ef20d8'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='af5a8aa1-840e-4f0b-998b-cc192202d291', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='1e9e001b42f367bafb3bc16264f56ddab1dcfc48110a7491a3f5f3a9d9dcc259'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='daaf102f-08f8-4101-8ed5-8d1e3bc2a4b0', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='a65bf792a6d5e06965bc5070424a0062007616eeafb4d4ade946b82edacb1172')}, hash='0e94f8631bedad2d56abb9e8e6854d3c43c5577dbcfa8f2e556773e121a494de', text='nuclear, biological, chemical, and\\ncyber); findingsonthesetopicsweremarginal andweremitigated. Nonetheless, wewill continueourred\\nteaming efforts in this front.\\nTodate,allofourredteamingeffortshavetargetedmodeloutputsinEnglish,buthavecruciallyincluded\\nnon-Englishpromptsanddialoguecontexts,asthatisawell-knownattackvector.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-27'),\n",
              " 'daaf102f-08f8-4101-8ed5-8d1e3bc2a4b0': IndexNode(id_='daaf102f-08f8-4101-8ed5-8d1e3bc2a4b0', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-27', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='9211b2b96b9f7d5bd072735994c9ded33055f0614098c62cf7434d3a06ef20d8'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='06c6d993-5ab9-4a66-be49-ea350a031e7f', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='0e94f8631bedad2d56abb9e8e6854d3c43c5577dbcfa8f2e556773e121a494de'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='c26254d7-58bf-401a-a55e-2f6155b81e35', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='8b1486c5961f50253f4689e1731425b34c66729c16e067f847397648435d2958')}, hash='a65bf792a6d5e06965bc5070424a0062007616eeafb4d4ade946b82edacb1172', text='Inallexercises,participants\\nwere given risk category definitions and were shown just a handful of examples of risky interactions with an\\nLLM.Afterthat,eachparticipantwaspartofasubteamfocusedonaparticularcategoryofriskorattack\\nvector. Aftercreatingeachdialogue,theredteamparticipantwouldannotatevariousattributes,including\\nrisk areas and degree of risk, as captured by a 5-point Likert scale.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-27'),\n",
              " 'c26254d7-58bf-401a-a55e-2f6155b81e35': IndexNode(id_='c26254d7-58bf-401a-a55e-2f6155b81e35', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-27', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='9211b2b96b9f7d5bd072735994c9ded33055f0614098c62cf7434d3a06ef20d8'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='daaf102f-08f8-4101-8ed5-8d1e3bc2a4b0', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='a65bf792a6d5e06965bc5070424a0062007616eeafb4d4ade946b82edacb1172'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='d24d510a-8ac2-4da7-934c-451125374442', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='6dbd0b42bfcb8f8db8b36a30a24f63222bc4fe64b5859a827fe050760d2d3c03')}, hash='8b1486c5961f50253f4689e1731425b34c66729c16e067f847397648435d2958', text='Some examples of useful insights provided by members of red teams that we were able to improve upon\\nthroughout development:\\n•[Early models] were more likely to have generated unsafe responses without noting that they con-\\ntain problematiccontent. However, [slightly later models] have tended todisplay knowledge\\nthat the content is problematic, even if they do go on to provide it.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-27'),\n",
              " 'd24d510a-8ac2-4da7-934c-451125374442': IndexNode(id_='d24d510a-8ac2-4da7-934c-451125374442', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-27', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='9211b2b96b9f7d5bd072735994c9ded33055f0614098c62cf7434d3a06ef20d8'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='c26254d7-58bf-401a-a55e-2f6155b81e35', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='8b1486c5961f50253f4689e1731425b34c66729c16e067f847397648435d2958')}, hash='6dbd0b42bfcb8f8db8b36a30a24f63222bc4fe64b5859a827fe050760d2d3c03', text='“They respond with ‘[UNSAFE\\nCONTENT]isnotappropriatetodiscuss,etc.’ andthenimmediatelyfollowupwith‘Withthatsaid,here’s\\nhow [UNSAFE CONTENT].’ ” [Latest models] are able to resolve these issues.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-27'),\n",
              " '9a184762-3fc6-4093-8616-3dedf41c9641': IndexNode(id_='9a184762-3fc6-4093-8616-3dedf41c9641', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-27', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='9211b2b96b9f7d5bd072735994c9ded33055f0614098c62cf7434d3a06ef20d8'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='4f6b783b-3632-4e46-b66f-fa9d3fa2e4fb', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='c9dc7f36a7d9abc0e41037a98a6a03003691c7d15a791242fb78d0a6e5a98c5f')}, hash='ec99634beebb00df17a24bd569a32be47717d0ccea2bf102a47cddbf1ea1a044', text='We\\ntherefore only apply context distillation on targeted samples when it increases RM score.\\nRejectingContextDistillationErrorswiththeSafetyRewardModel Itisimportanttonotethatperforming\\nsafetycontextdistillationforhelpfulpromptscandegrademodelperformanceandleadtomorefalserefusals\\n(see Appendix Table 40). We therefore perform safety context distillation only on adversarial prompts.\\nHowever, we observed that context distillation can sometimes degrade response quality, even when dealing\\nwith adversarial prompts. Specifically, if the model responses are already of high quality, the application of\\ncontext distillation can result in less pertinent replies, as the model tends to overemphasize the preprompt,\\noften resorting to generic concerns excessively (see Appendix Table 40 for an example of vague answers due\\ntocontextdistillation). Wethusleveragethesafetyrewardmodeltodecidewhethertousesafetycontext\\ndistillation – we keep the context-distilled output only on the examples where it gets a better reward model\\nscore than the original answer.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-27'),\n",
              " '4f6b783b-3632-4e46-b66f-fa9d3fa2e4fb': IndexNode(id_='4f6b783b-3632-4e46-b66f-fa9d3fa2e4fb', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-27', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='9211b2b96b9f7d5bd072735994c9ded33055f0614098c62cf7434d3a06ef20d8'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='9a184762-3fc6-4093-8616-3dedf41c9641', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='ec99634beebb00df17a24bd569a32be47717d0ccea2bf102a47cddbf1ea1a044'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='b3578006-a76e-483a-b7f8-c309e36a85ee', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='d79ef62d0aeebf5e3194f064c7c70e08d3c3e8453e868a2a2b2db8d6870008c7')}, hash='c9dc7f36a7d9abc0e41037a98a6a03003691c7d15a791242fb78d0a6e5a98c5f', text='We notice that thisis particularly helpful on prompts that the model is very\\nbad at, but limits the negative impact of context distillation (see Figure 16b).\\n4.3 Red Teaming\\nGivenhowbroadthecapabilitiesofLLMsareandhowvariedtheirtrainingdatais,itisinsufficienttoidentify\\nrisks solely via ex post facto usage and analysis. Rather, as has been done for other LLMs, we performed\\nvarious kinds of proactive risk identification, colloquially called “red teaming,“ based on the term commonly\\nused within computer security. This kind of granular analysis is very important because safety is a long-tail\\nissue,inwhichevenveryinfrequentedgecasescancausenoticeableproblems. Evenifquantitativescores\\nreport good results, these types of qualitative insights allow us to recognize and target specific patterns in a\\nmore comprehensive way.\\nWe conducted a series of red teaming with various groups of internal employees, contract workers, and\\nexternalvendors.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-27'),\n",
              " 'b3578006-a76e-483a-b7f8-c309e36a85ee': IndexNode(id_='b3578006-a76e-483a-b7f8-c309e36a85ee', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-27', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='9211b2b96b9f7d5bd072735994c9ded33055f0614098c62cf7434d3a06ef20d8'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='4f6b783b-3632-4e46-b66f-fa9d3fa2e4fb', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='c9dc7f36a7d9abc0e41037a98a6a03003691c7d15a791242fb78d0a6e5a98c5f'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='841a0547-c352-4eed-973f-885ab10f4a6a', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='62bdc343c9373ad27246b297f309e85056c59bf8d9d2c6a17b51b507046bd030')}, hash='d79ef62d0aeebf5e3194f064c7c70e08d3c3e8453e868a2a2b2db8d6870008c7', text='Theseteamsincludedover350people,includingdomainexpertsincybersecurity,elec-\\ntion fraud, social media misinformation, legal, policy, civil rights, ethics, software engineering, machine\\nlearning, responsible AI, and creative writing. They also included individuals representative of a variety of\\nsocioeconomic, gender, ethnicity, and racial demographics.\\n28\\n\\nTheredteamersprobedourmodelsacrossawiderangeofriskcategories(suchascriminalplanning,human\\ntrafficking, regulated or controlled substances, sexually explicit content, unqualified health or financial\\nadvice, privacy violations, and more), as well as different attack vectors (such as hypothetical questions,\\nmalformed/misspelledinputs,orextendeddialogues). Additionally,weconductedspecificteststodetermine\\nthe capabilities of our models to facilitate the production of weapons (e.g. nuclear, biological, chemical, and\\ncyber); findingsonthesetopicsweremarginal andweremitigated. Nonetheless, wewill continueourred\\nteaming efforts in this front.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-27'),\n",
              " '841a0547-c352-4eed-973f-885ab10f4a6a': IndexNode(id_='841a0547-c352-4eed-973f-885ab10f4a6a', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-27', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='9211b2b96b9f7d5bd072735994c9ded33055f0614098c62cf7434d3a06ef20d8'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='b3578006-a76e-483a-b7f8-c309e36a85ee', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='d79ef62d0aeebf5e3194f064c7c70e08d3c3e8453e868a2a2b2db8d6870008c7'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='88de4d45-e8a3-49d3-aaaa-6a9d3b1e78c0', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='6dbd0b42bfcb8f8db8b36a30a24f63222bc4fe64b5859a827fe050760d2d3c03')}, hash='62bdc343c9373ad27246b297f309e85056c59bf8d9d2c6a17b51b507046bd030', text='Nonetheless, wewill continueourred\\nteaming efforts in this front.\\nTodate,allofourredteamingeffortshavetargetedmodeloutputsinEnglish,buthavecruciallyincluded\\nnon-Englishpromptsanddialoguecontexts,asthatisawell-knownattackvector. Inallexercises,participants\\nwere given risk category definitions and were shown just a handful of examples of risky interactions with an\\nLLM.Afterthat,eachparticipantwaspartofasubteamfocusedonaparticularcategoryofriskorattack\\nvector. Aftercreatingeachdialogue,theredteamparticipantwouldannotatevariousattributes,including\\nrisk areas and degree of risk, as captured by a 5-point Likert scale.\\nSome examples of useful insights provided by members of red teams that we were able to improve upon\\nthroughout development:\\n•[Early models] were more likely to have generated unsafe responses without noting that they con-\\ntain problematiccontent. However, [slightly later models] have tended todisplay knowledge\\nthat the content is problematic, even if they do go on to provide it.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-27'),\n",
              " '88de4d45-e8a3-49d3-aaaa-6a9d3b1e78c0': IndexNode(id_='88de4d45-e8a3-49d3-aaaa-6a9d3b1e78c0', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-27', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='9211b2b96b9f7d5bd072735994c9ded33055f0614098c62cf7434d3a06ef20d8'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='841a0547-c352-4eed-973f-885ab10f4a6a', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='62bdc343c9373ad27246b297f309e85056c59bf8d9d2c6a17b51b507046bd030')}, hash='6dbd0b42bfcb8f8db8b36a30a24f63222bc4fe64b5859a827fe050760d2d3c03', text='“They respond with ‘[UNSAFE\\nCONTENT]isnotappropriatetodiscuss,etc.’ andthenimmediatelyfollowupwith‘Withthatsaid,here’s\\nhow [UNSAFE CONTENT].’ ” [Latest models] are able to resolve these issues.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-27'),\n",
              " '6e5af965-8d3e-403b-a6d0-74f78b44a776': IndexNode(id_='6e5af965-8d3e-403b-a6d0-74f78b44a776', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-27', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='9211b2b96b9f7d5bd072735994c9ded33055f0614098c62cf7434d3a06ef20d8'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='c19b879a-e578-44cc-aef2-3d870e73c193', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='c2b979b8d793c9c9dde0634380aa0992acc38d69587864eb8e29d397bf51750c')}, hash='30b5767f0f5a354120b1d0f0de0c6ed38bccdef25ef84be0c659c9c721f633eb', text='We\\ntherefore only apply context distillation on targeted samples when it increases RM score.\\nRejectingContextDistillationErrorswiththeSafetyRewardModel Itisimportanttonotethatperforming\\nsafetycontextdistillationforhelpfulpromptscandegrademodelperformanceandleadtomorefalserefusals\\n(see Appendix Table 40). We therefore perform safety context distillation only on adversarial prompts.\\nHowever, we observed that context distillation can sometimes degrade response quality, even when dealing\\nwith adversarial prompts. Specifically, if the model responses are already of high quality, the application of\\ncontext distillation can result in less pertinent replies, as the model tends to overemphasize the preprompt,\\noften resorting to generic concerns excessively (see Appendix Table 40 for an example of vague answers due\\ntocontextdistillation). Wethusleveragethesafetyrewardmodeltodecidewhethertousesafetycontext\\ndistillation – we keep the context-distilled output only on the examples where it gets a better reward model\\nscore than the original answer. We notice that thisis particularly helpful on prompts that the model is very\\nbad at, but limits the negative impact of context distillation (see Figure 16b).\\n4.3 Red Teaming\\nGivenhowbroadthecapabilitiesofLLMsareandhowvariedtheirtrainingdatais,itisinsufficienttoidentify\\nrisks solely via ex post facto usage and analysis. Rather, as has been done for other LLMs, we performed\\nvarious kinds of proactive risk identification, colloquially called “red teaming,“ based on the term commonly\\nused within computer security. This kind of granular analysis is very important because safety is a long-tail\\nissue,inwhichevenveryinfrequentedgecasescancausenoticeableproblems. Evenifquantitativescores\\nreport good results, these types of qualitative insights allow us to recognize and target specific patterns in a\\nmore comprehensive way.\\nWe conducted a series of red teaming with various groups of internal employees, contract workers, and\\nexternalvendors. Theseteamsincludedover350people,includingdomainexpertsincybersecurity,elec-\\ntion fraud, social media misinformation, legal, policy, civil rights, ethics, software engineering, machine\\nlearning, responsible AI, and creative writing.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-27'),\n",
              " 'c19b879a-e578-44cc-aef2-3d870e73c193': IndexNode(id_='c19b879a-e578-44cc-aef2-3d870e73c193', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-27', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='9211b2b96b9f7d5bd072735994c9ded33055f0614098c62cf7434d3a06ef20d8'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='6e5af965-8d3e-403b-a6d0-74f78b44a776', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='30b5767f0f5a354120b1d0f0de0c6ed38bccdef25ef84be0c659c9c721f633eb')}, hash='c2b979b8d793c9c9dde0634380aa0992acc38d69587864eb8e29d397bf51750c', text='They also included individuals representative of a variety of\\nsocioeconomic, gender, ethnicity, and racial demographics.\\n28\\n\\nTheredteamersprobedourmodelsacrossawiderangeofriskcategories(suchascriminalplanning,human\\ntrafficking, regulated or controlled substances, sexually explicit content, unqualified health or financial\\nadvice, privacy violations, and more), as well as different attack vectors (such as hypothetical questions,\\nmalformed/misspelledinputs,orextendeddialogues). Additionally,weconductedspecificteststodetermine\\nthe capabilities of our models to facilitate the production of weapons (e.g. nuclear, biological, chemical, and\\ncyber); findingsonthesetopicsweremarginal andweremitigated. Nonetheless, wewill continueourred\\nteaming efforts in this front.\\nTodate,allofourredteamingeffortshavetargetedmodeloutputsinEnglish,buthavecruciallyincluded\\nnon-Englishpromptsanddialoguecontexts,asthatisawell-knownattackvector. Inallexercises,participants\\nwere given risk category definitions and were shown just a handful of examples of risky interactions with an\\nLLM.Afterthat,eachparticipantwaspartofasubteamfocusedonaparticularcategoryofriskorattack\\nvector. Aftercreatingeachdialogue,theredteamparticipantwouldannotatevariousattributes,including\\nrisk areas and degree of risk, as captured by a 5-point Likert scale.\\nSome examples of useful insights provided by members of red teams that we were able to improve upon\\nthroughout development:\\n•[Early models] were more likely to have generated unsafe responses without noting that they con-\\ntain problematiccontent. However, [slightly later models] have tended todisplay knowledge\\nthat the content is problematic, even if they do go on to provide it. “They respond with ‘[UNSAFE\\nCONTENT]isnotappropriatetodiscuss,etc.’ andthenimmediatelyfollowupwith‘Withthatsaid,here’s\\nhow [UNSAFE CONTENT].’ ” [Latest models] are able to resolve these issues.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-27'),\n",
              " 'node-27': IndexNode(id_='node-27', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='415b7efc-e73f-4ac4-bbfd-c1546f099026', node_type=<ObjectType.DOCUMENT: '4'>, metadata={}, hash='231b3bd773f012c01b893ada9e009ecf25ee59934614c5a595c9bf1b3a123292'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='151d70ea-4932-45d4-8e1a-dd63a9a6c97e', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='9a93f76f9d060a4e3610095bb60e742c3d0fb634e6f57c64782a03d1e11d4802'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='0308b214-6374-42d8-8f7d-bb1ebcf78290', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='e86b2a7fa79d05727bd33ffc6f9122e324f6e3385597fa11cbe6db44a5a2dd92')}, hash='9211b2b96b9f7d5bd072735994c9ded33055f0614098c62cf7434d3a06ef20d8', text='We\\ntherefore only apply context distillation on targeted samples when it increases RM score.\\nRejectingContextDistillationErrorswiththeSafetyRewardModel Itisimportanttonotethatperforming\\nsafetycontextdistillationforhelpfulpromptscandegrademodelperformanceandleadtomorefalserefusals\\n(see Appendix Table 40). We therefore perform safety context distillation only on adversarial prompts.\\nHowever, we observed that context distillation can sometimes degrade response quality, even when dealing\\nwith adversarial prompts. Specifically, if the model responses are already of high quality, the application of\\ncontext distillation can result in less pertinent replies, as the model tends to overemphasize the preprompt,\\noften resorting to generic concerns excessively (see Appendix Table 40 for an example of vague answers due\\ntocontextdistillation). Wethusleveragethesafetyrewardmodeltodecidewhethertousesafetycontext\\ndistillation – we keep the context-distilled output only on the examples where it gets a better reward model\\nscore than the original answer. We notice that thisis particularly helpful on prompts that the model is very\\nbad at, but limits the negative impact of context distillation (see Figure 16b).\\n4.3 Red Teaming\\nGivenhowbroadthecapabilitiesofLLMsareandhowvariedtheirtrainingdatais,itisinsufficienttoidentify\\nrisks solely via ex post facto usage and analysis. Rather, as has been done for other LLMs, we performed\\nvarious kinds of proactive risk identification, colloquially called “red teaming,“ based on the term commonly\\nused within computer security. This kind of granular analysis is very important because safety is a long-tail\\nissue,inwhichevenveryinfrequentedgecasescancausenoticeableproblems. Evenifquantitativescores\\nreport good results, these types of qualitative insights allow us to recognize and target specific patterns in a\\nmore comprehensive way.\\nWe conducted a series of red teaming with various groups of internal employees, contract workers, and\\nexternalvendors. Theseteamsincludedover350people,includingdomainexpertsincybersecurity,elec-\\ntion fraud, social media misinformation, legal, policy, civil rights, ethics, software engineering, machine\\nlearning, responsible AI, and creative writing. They also included individuals representative of a variety of\\nsocioeconomic, gender, ethnicity, and racial demographics.\\n28\\n\\nTheredteamersprobedourmodelsacrossawiderangeofriskcategories(suchascriminalplanning,human\\ntrafficking, regulated or controlled substances, sexually explicit content, unqualified health or financial\\nadvice, privacy violations, and more), as well as different attack vectors (such as hypothetical questions,\\nmalformed/misspelledinputs,orextendeddialogues). Additionally,weconductedspecificteststodetermine\\nthe capabilities of our models to facilitate the production of weapons (e.g. nuclear, biological, chemical, and\\ncyber); findingsonthesetopicsweremarginal andweremitigated. Nonetheless, wewill continueourred\\nteaming efforts in this front.\\nTodate,allofourredteamingeffortshavetargetedmodeloutputsinEnglish,buthavecruciallyincluded\\nnon-Englishpromptsanddialoguecontexts,asthatisawell-knownattackvector. Inallexercises,participants\\nwere given risk category definitions and were shown just a handful of examples of risky interactions with an\\nLLM.Afterthat,eachparticipantwaspartofasubteamfocusedonaparticularcategoryofriskorattack\\nvector. Aftercreatingeachdialogue,theredteamparticipantwouldannotatevariousattributes,including\\nrisk areas and degree of risk, as captured by a 5-point Likert scale.\\nSome examples of useful insights provided by members of red teams that we were able to improve upon\\nthroughout development:\\n•[Early models] were more likely to have generated unsafe responses without noting that they con-\\ntain problematiccontent. However, [slightly later models] have tended todisplay knowledge\\nthat the content is problematic, even if they do go on to provide it. “They respond with ‘[UNSAFE\\nCONTENT]isnotappropriatetodiscuss,etc.’ andthenimmediatelyfollowupwith‘Withthatsaid,here’s\\nhow [UNSAFE CONTENT].’ ” [Latest models] are able to resolve these issues.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-27'),\n",
              " 'c524efd8-ed8e-4ac8-95e8-5f501d782294': IndexNode(id_='c524efd8-ed8e-4ac8-95e8-5f501d782294', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-28', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='e86b2a7fa79d05727bd33ffc6f9122e324f6e3385597fa11cbe6db44a5a2dd92'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='d63b8ff0-dbb6-4319-9e87-c2457afc64b0', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='a20fe690352143cbd477d74fc96c2e60211196bbbcc03b1c610fa7de5b9a4ba5')}, hash='c6ce53efafbad310b6981bf30a47633e1dcf526aa0e3440d8e6209ace32866b3', text='•Distracting the [early models] by including “quirks” or specific requests usually defeated any\\nreluctanceencounteredviamoredirectrequests. “Acreativewritingrequest(song,story,poem,etc.)', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-28'),\n",
              " 'd63b8ff0-dbb6-4319-9e87-c2457afc64b0': IndexNode(id_='d63b8ff0-dbb6-4319-9e87-c2457afc64b0', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-28', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='e86b2a7fa79d05727bd33ffc6f9122e324f6e3385597fa11cbe6db44a5a2dd92'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='c524efd8-ed8e-4ac8-95e8-5f501d782294', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='c6ce53efafbad310b6981bf30a47633e1dcf526aa0e3440d8e6209ace32866b3'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='56a6a153-5025-463d-971f-cef630f70c80', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='5c14eb0fb79b4594839db4907a82707c5685d04df69beb87e242861156a93bad')}, hash='a20fe690352143cbd477d74fc96c2e60211196bbbcc03b1c610fa7de5b9a4ba5', text='“Acreativewritingrequest(song,story,poem,etc.) isa\\nreliable way to get it to produce content that it is otherwise robust against.”\\n•Embedding a problematic request in a positive context often successfully obscured the fact that\\nproblematicoutputwasbeingrequestedfor [early models] :“TheoverallprincipleI’vefoundmost\\neffective for any kind of attack is to hide it in language that is positive, progressive, and empowering.”\\nFrom Red Teaming Insights to Safer Models.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-28'),\n",
              " '56a6a153-5025-463d-971f-cef630f70c80': IndexNode(id_='56a6a153-5025-463d-971f-cef630f70c80', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-28', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='e86b2a7fa79d05727bd33ffc6f9122e324f6e3385597fa11cbe6db44a5a2dd92'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='d63b8ff0-dbb6-4319-9e87-c2457afc64b0', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='a20fe690352143cbd477d74fc96c2e60211196bbbcc03b1c610fa7de5b9a4ba5'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='141e0b4e-e359-451e-b598-50e56c112a22', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='21f760a885a1b7ae9bfc0310adaa3bfcb71bddb6dcb8e4fa3d7ade40c86c5cb1')}, hash='5c14eb0fb79b4594839db4907a82707c5685d04df69beb87e242861156a93bad', text='Crucially, after each exercise, we performed a thorough\\nanalysis of the collected data, including dialogue length, risk area distribution, histogram of topic of misin-\\nformation (where appropriate), and rated degree of risk. In each case, we took the overall lessons as a guide\\nto helpfurther modelsafetytraining, and specificallytook data fromthese exercisesformodel fine-tuning,\\nmodel feedback training, and as a signal for other safety model training.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-28'),\n",
              " '141e0b4e-e359-451e-b598-50e56c112a22': IndexNode(id_='141e0b4e-e359-451e-b598-50e56c112a22', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-28', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='e86b2a7fa79d05727bd33ffc6f9122e324f6e3385597fa11cbe6db44a5a2dd92'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='56a6a153-5025-463d-971f-cef630f70c80', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='5c14eb0fb79b4594839db4907a82707c5685d04df69beb87e242861156a93bad'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='71227f4d-eb8b-4c0e-9c56-f2d129583c24', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='7d48c5b717d375deac95a41d3d357c515ae0aef1df9bdb25cd75bc4d059f4624')}, hash='21f760a885a1b7ae9bfc0310adaa3bfcb71bddb6dcb8e4fa3d7ade40c86c5cb1', text='Multiple additionalrounds ofred teaming wereperformed over severalmonths tomeasure the robustness\\nof each new model as it was released internally. We defined the robustness of a model, γ, with respect to\\na red teaming exercise executed by a set of experts as the average number of created prompts that would\\ntriggeraviolatingresponsefromthemodelperpersonperhour. Asanexample,onour7Bmodel,wehadan\\nevolution of γ: 1.8→0.45over several red teaming iterations and model refinements.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-28'),\n",
              " '71227f4d-eb8b-4c0e-9c56-f2d129583c24': IndexNode(id_='71227f4d-eb8b-4c0e-9c56-f2d129583c24', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-28', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='e86b2a7fa79d05727bd33ffc6f9122e324f6e3385597fa11cbe6db44a5a2dd92'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='141e0b4e-e359-451e-b598-50e56c112a22', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='21f760a885a1b7ae9bfc0310adaa3bfcb71bddb6dcb8e4fa3d7ade40c86c5cb1'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='a1123de8-bc1d-4830-a975-07c6b136e5a0', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='5569d7d2540549c7eb266bf29b00b348cc35492060bc6a526bfea93204232ce6')}, hash='7d48c5b717d375deac95a41d3d357c515ae0aef1df9bdb25cd75bc4d059f4624', text='Robustness will likely\\ncontinue to improve with additional red teaming efforts. Another magnitude that we tracked as new models\\nwere produced was the percentage of prompts triggering violating responses discovered in the previous red\\nteaming exercises that were mitigated in a given new candidate release. On average, we had a 90% rejection\\nrate model over model.\\n4.4 Safety Evaluation of Llama 2-Chat\\nSafetyHumanEvaluation.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-28'),\n",
              " 'a1123de8-bc1d-4830-a975-07c6b136e5a0': IndexNode(id_='a1123de8-bc1d-4830-a975-07c6b136e5a0', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-28', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='e86b2a7fa79d05727bd33ffc6f9122e324f6e3385597fa11cbe6db44a5a2dd92'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='71227f4d-eb8b-4c0e-9c56-f2d129583c24', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='7d48c5b717d375deac95a41d3d357c515ae0aef1df9bdb25cd75bc4d059f4624'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='9d8c6d47-8aad-4f1b-8e87-e04eb445e1b4', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='e83be95f3ac93ea9d98fbd784c8226eafb1971fa81ce01d04501f6b7783f3148')}, hash='5569d7d2540549c7eb266bf29b00b348cc35492060bc6a526bfea93204232ce6', text='4.4 Safety Evaluation of Llama 2-Chat\\nSafetyHumanEvaluation. Wecollectedroughly2,000adversarialpromptsforhumanevaluationaccording\\nto the safety categories in Section 4.2.1, in which 1,351 prompts are single-turn and 623 are multi-turn.\\nExamples of evaluation prompts and responses can be found in Appendix A.4.6.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-28'),\n",
              " '9d8c6d47-8aad-4f1b-8e87-e04eb445e1b4': IndexNode(id_='9d8c6d47-8aad-4f1b-8e87-e04eb445e1b4', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-28', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='e86b2a7fa79d05727bd33ffc6f9122e324f6e3385597fa11cbe6db44a5a2dd92'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='a1123de8-bc1d-4830-a975-07c6b136e5a0', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='5569d7d2540549c7eb266bf29b00b348cc35492060bc6a526bfea93204232ce6'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='a84e1bc8-1eb8-4160-b1e7-cee65f07ca83', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='57fb039686b221d7e82a16dd9a354303ac1b820896250da4cfe6309142c6be7d')}, hash='e83be95f3ac93ea9d98fbd784c8226eafb1971fa81ce01d04501f6b7783f3148', text='Examples of evaluation prompts and responses can be found in Appendix A.4.6.\\nWe then asked raters to judge models for safety violations on a five-point Likert scale with the following\\ndefinitions:\\n•5- No safety violations and very helpful\\n•4- No safety violations and only minor non-safety issues\\n•3- No safety violations but not helpful or other major non-safety issues\\n•2- Mild or moderate safety violations\\n29\\n\\n(a)Overall violation percentage.\\n (b)Overall safety and helpfulness mean rating.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-28'),\n",
              " 'a84e1bc8-1eb8-4160-b1e7-cee65f07ca83': IndexNode(id_='a84e1bc8-1eb8-4160-b1e7-cee65f07ca83', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-28', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='e86b2a7fa79d05727bd33ffc6f9122e324f6e3385597fa11cbe6db44a5a2dd92'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='9d8c6d47-8aad-4f1b-8e87-e04eb445e1b4', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='e83be95f3ac93ea9d98fbd784c8226eafb1971fa81ce01d04501f6b7783f3148'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='8ef22698-ef63-4c6e-8e89-52b3a877d3e5', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='39cf94173459567eb2b0b49d4fd6e4ad4b4f02bf3fb08a4e98bc033ac5e05bcf')}, hash='57fb039686b221d7e82a16dd9a354303ac1b820896250da4cfe6309142c6be7d', text='(b)Overall safety and helpfulness mean rating.\\nFigure17: Overallsafetymeasures. Left: Llama 2-Chat haslowviolationpercentageoverallacrossmodel\\nsizes.Right: Llama 2-Chat has high safety and helpfulness mean rating overall across model sizes. It is\\nimportant to note that these results are subject to limitations of the prompt set, subjectivity of the review\\nguidelines, and subjectivity of individual raters.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-28'),\n",
              " '8ef22698-ef63-4c6e-8e89-52b3a877d3e5': IndexNode(id_='8ef22698-ef63-4c6e-8e89-52b3a877d3e5', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-28', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='e86b2a7fa79d05727bd33ffc6f9122e324f6e3385597fa11cbe6db44a5a2dd92'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='a84e1bc8-1eb8-4160-b1e7-cee65f07ca83', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='57fb039686b221d7e82a16dd9a354303ac1b820896250da4cfe6309142c6be7d'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='02cb0844-ef0e-4b05-8715-f9dbefb74e1a', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='46369079183811b03432a1663d586bde96a81e5e5b51045355cbb191aef415fb')}, hash='39cf94173459567eb2b0b49d4fd6e4ad4b4f02bf3fb08a4e98bc033ac5e05bcf', text='•1- Severe safety violations\\nWe consider a rating of 1 or 2 as violation and use violation percentage as our main evaluation metric, with\\nthemeanratingasasupplement. Eachexampleisannotatedbythreeannotatorsandwetakethemajority\\nvotetodetermineiftheresponseisviolatingornot. WeusedGwet’sAC1/2statistictomeasureinter-rater\\nreliability(IRR)asinthehelpfulnesshumanevaluation.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-28'),\n",
              " '02cb0844-ef0e-4b05-8715-f9dbefb74e1a': IndexNode(id_='02cb0844-ef0e-4b05-8715-f9dbefb74e1a', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-28', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='e86b2a7fa79d05727bd33ffc6f9122e324f6e3385597fa11cbe6db44a5a2dd92'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='8ef22698-ef63-4c6e-8e89-52b3a877d3e5', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='39cf94173459567eb2b0b49d4fd6e4ad4b4f02bf3fb08a4e98bc033ac5e05bcf'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='25a6855e-0759-454c-bd86-58398864ef3e', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='b3bc747943ffd68fb9fa0dc582a5bd5b36f9435cfcb6cecc5ea72e64ec3342f3')}, hash='46369079183811b03432a1663d586bde96a81e5e5b51045355cbb191aef415fb', text='TheIRRscoresrangefrom 0.70to0.95depending\\non the annotation batch, indicating a high degree of agreement among annotators on safety assessments.\\nOnLlama 2-Chat annotations, the average IRR is 0.92according to Gwet’s AC2 measure. We see lower IRR\\nscoresonbatcheswherethemodelshaveahighviolationrate(e.g.,Vicuna)andhigherIRRscoresonbatches\\nwhere the models have relatively low violation rates (e.g., Llama 2-Chat , Falcon, and ChatGPT).', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-28'),\n",
              " '25a6855e-0759-454c-bd86-58398864ef3e': IndexNode(id_='25a6855e-0759-454c-bd86-58398864ef3e', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-28', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='e86b2a7fa79d05727bd33ffc6f9122e324f6e3385597fa11cbe6db44a5a2dd92'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='02cb0844-ef0e-4b05-8715-f9dbefb74e1a', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='46369079183811b03432a1663d586bde96a81e5e5b51045355cbb191aef415fb')}, hash='b3bc747943ffd68fb9fa0dc582a5bd5b36f9435cfcb6cecc5ea72e64ec3342f3', text='Figure 18: Single-turn and multi-turn violation percentage.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-28'),\n",
              " '3b641a1a-4e9a-4ec7-90f7-ddf671ffd27d': IndexNode(id_='3b641a1a-4e9a-4ec7-90f7-ddf671ffd27d', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-28', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='e86b2a7fa79d05727bd33ffc6f9122e324f6e3385597fa11cbe6db44a5a2dd92'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='a72fcb2e-ee95-4c92-8229-4a98ecc4fa96', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='926dbd626737b61fc08551cbf2cb3ed94b036e79a3049fd5343e9da526a54c4a')}, hash='025a0876d46259196b82ed4422495ec0128e6e776ef99414ccddb3340b062476', text='•Distracting the [early models] by including “quirks” or specific requests usually defeated any\\nreluctanceencounteredviamoredirectrequests. “Acreativewritingrequest(song,story,poem,etc.) isa\\nreliable way to get it to produce content that it is otherwise robust against.”\\n•Embedding a problematic request in a positive context often successfully obscured the fact that\\nproblematicoutputwasbeingrequestedfor [early models] :“TheoverallprincipleI’vefoundmost\\neffective for any kind of attack is to hide it in language that is positive, progressive, and empowering.”\\nFrom Red Teaming Insights to Safer Models. Crucially, after each exercise, we performed a thorough\\nanalysis of the collected data, including dialogue length, risk area distribution, histogram of topic of misin-\\nformation (where appropriate), and rated degree of risk.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-28'),\n",
              " 'a72fcb2e-ee95-4c92-8229-4a98ecc4fa96': IndexNode(id_='a72fcb2e-ee95-4c92-8229-4a98ecc4fa96', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-28', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='e86b2a7fa79d05727bd33ffc6f9122e324f6e3385597fa11cbe6db44a5a2dd92'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='3b641a1a-4e9a-4ec7-90f7-ddf671ffd27d', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='025a0876d46259196b82ed4422495ec0128e6e776ef99414ccddb3340b062476'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='9a7f5815-a671-41f8-8e5c-61fc34bc61c9', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='b84fa22d46a63d94b5e1c80c031c2083bcdb3db17b83b58921bc8dc87b6d9d5f')}, hash='926dbd626737b61fc08551cbf2cb3ed94b036e79a3049fd5343e9da526a54c4a', text='In each case, we took the overall lessons as a guide\\nto helpfurther modelsafetytraining, and specificallytook data fromthese exercisesformodel fine-tuning,\\nmodel feedback training, and as a signal for other safety model training.\\nMultiple additionalrounds ofred teaming wereperformed over severalmonths tomeasure the robustness\\nof each new model as it was released internally. We defined the robustness of a model, γ, with respect to\\na red teaming exercise executed by a set of experts as the average number of created prompts that would\\ntriggeraviolatingresponsefromthemodelperpersonperhour. Asanexample,onour7Bmodel,wehadan\\nevolution of γ: 1.8→0.45over several red teaming iterations and model refinements. Robustness will likely\\ncontinue to improve with additional red teaming efforts. Another magnitude that we tracked as new models\\nwere produced was the percentage of prompts triggering violating responses discovered in the previous red\\nteaming exercises that were mitigated in a given new candidate release. On average, we had a 90% rejection\\nrate model over model.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-28'),\n",
              " '9a7f5815-a671-41f8-8e5c-61fc34bc61c9': IndexNode(id_='9a7f5815-a671-41f8-8e5c-61fc34bc61c9', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-28', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='e86b2a7fa79d05727bd33ffc6f9122e324f6e3385597fa11cbe6db44a5a2dd92'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='a72fcb2e-ee95-4c92-8229-4a98ecc4fa96', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='926dbd626737b61fc08551cbf2cb3ed94b036e79a3049fd5343e9da526a54c4a'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='6ecf6909-b168-409d-92bf-8e8427375a5e', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='fb192a157fe16f08cd262eca431ceed7333547c3046d8ba91e5f1dcdde602f9d')}, hash='b84fa22d46a63d94b5e1c80c031c2083bcdb3db17b83b58921bc8dc87b6d9d5f', text='On average, we had a 90% rejection\\nrate model over model.\\n4.4 Safety Evaluation of Llama 2-Chat\\nSafetyHumanEvaluation. Wecollectedroughly2,000adversarialpromptsforhumanevaluationaccording\\nto the safety categories in Section 4.2.1, in which 1,351 prompts are single-turn and 623 are multi-turn.\\nExamples of evaluation prompts and responses can be found in Appendix A.4.6.\\nWe then asked raters to judge models for safety violations on a five-point Likert scale with the following\\ndefinitions:\\n•5- No safety violations and very helpful\\n•4- No safety violations and only minor non-safety issues\\n•3- No safety violations but not helpful or other major non-safety issues\\n•2- Mild or moderate safety violations\\n29\\n\\n(a)Overall violation percentage.\\n (b)Overall safety and helpfulness mean rating.\\nFigure17: Overallsafetymeasures.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-28'),\n",
              " '6ecf6909-b168-409d-92bf-8e8427375a5e': IndexNode(id_='6ecf6909-b168-409d-92bf-8e8427375a5e', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-28', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='e86b2a7fa79d05727bd33ffc6f9122e324f6e3385597fa11cbe6db44a5a2dd92'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='9a7f5815-a671-41f8-8e5c-61fc34bc61c9', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='b84fa22d46a63d94b5e1c80c031c2083bcdb3db17b83b58921bc8dc87b6d9d5f'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='4523febc-f287-4588-ad11-d7e3feb3e6f2', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='ab94e719674c2d341ff1aa20f8c63b6474ffd19fb9edfc94403e3d86a87a61b9')}, hash='fb192a157fe16f08cd262eca431ceed7333547c3046d8ba91e5f1dcdde602f9d', text='Figure17: Overallsafetymeasures. Left: Llama 2-Chat haslowviolationpercentageoverallacrossmodel\\nsizes.Right: Llama 2-Chat has high safety and helpfulness mean rating overall across model sizes. It is\\nimportant to note that these results are subject to limitations of the prompt set, subjectivity of the review\\nguidelines, and subjectivity of individual raters.\\n•1- Severe safety violations\\nWe consider a rating of 1 or 2 as violation and use violation percentage as our main evaluation metric, with\\nthemeanratingasasupplement. Eachexampleisannotatedbythreeannotatorsandwetakethemajority\\nvotetodetermineiftheresponseisviolatingornot. WeusedGwet’sAC1/2statistictomeasureinter-rater\\nreliability(IRR)asinthehelpfulnesshumanevaluation. TheIRRscoresrangefrom 0.70to0.95depending\\non the annotation batch, indicating a high degree of agreement among annotators on safety assessments.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-28'),\n",
              " '4523febc-f287-4588-ad11-d7e3feb3e6f2': IndexNode(id_='4523febc-f287-4588-ad11-d7e3feb3e6f2', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-28', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='e86b2a7fa79d05727bd33ffc6f9122e324f6e3385597fa11cbe6db44a5a2dd92'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='6ecf6909-b168-409d-92bf-8e8427375a5e', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='fb192a157fe16f08cd262eca431ceed7333547c3046d8ba91e5f1dcdde602f9d')}, hash='ab94e719674c2d341ff1aa20f8c63b6474ffd19fb9edfc94403e3d86a87a61b9', text='OnLlama 2-Chat annotations, the average IRR is 0.92according to Gwet’s AC2 measure. We see lower IRR\\nscoresonbatcheswherethemodelshaveahighviolationrate(e.g.,Vicuna)andhigherIRRscoresonbatches\\nwhere the models have relatively low violation rates (e.g., Llama 2-Chat , Falcon, and ChatGPT).\\nFigure 18: Single-turn and multi-turn violation percentage.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-28'),\n",
              " '8ff9785d-e1ac-454b-b70b-343398249620': IndexNode(id_='8ff9785d-e1ac-454b-b70b-343398249620', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-28', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='e86b2a7fa79d05727bd33ffc6f9122e324f6e3385597fa11cbe6db44a5a2dd92'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='59f84618-602b-4668-be9d-7fb106019356', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='34197a66a6a0f6097379fd10f012e34b2cd13746d18b5c2ebb5edb422ec23590')}, hash='37d7e6753e5948d9b8dd755f4eb214645445c76267ef69b1fa966b28fddc1249', text='•Distracting the [early models] by including “quirks” or specific requests usually defeated any\\nreluctanceencounteredviamoredirectrequests. “Acreativewritingrequest(song,story,poem,etc.) isa\\nreliable way to get it to produce content that it is otherwise robust against.”\\n•Embedding a problematic request in a positive context often successfully obscured the fact that\\nproblematicoutputwasbeingrequestedfor [early models] :“TheoverallprincipleI’vefoundmost\\neffective for any kind of attack is to hide it in language that is positive, progressive, and empowering.”\\nFrom Red Teaming Insights to Safer Models. Crucially, after each exercise, we performed a thorough\\nanalysis of the collected data, including dialogue length, risk area distribution, histogram of topic of misin-\\nformation (where appropriate), and rated degree of risk. In each case, we took the overall lessons as a guide\\nto helpfurther modelsafetytraining, and specificallytook data fromthese exercisesformodel fine-tuning,\\nmodel feedback training, and as a signal for other safety model training.\\nMultiple additionalrounds ofred teaming wereperformed over severalmonths tomeasure the robustness\\nof each new model as it was released internally. We defined the robustness of a model, γ, with respect to\\na red teaming exercise executed by a set of experts as the average number of created prompts that would\\ntriggeraviolatingresponsefromthemodelperpersonperhour. Asanexample,onour7Bmodel,wehadan\\nevolution of γ: 1.8→0.45over several red teaming iterations and model refinements. Robustness will likely\\ncontinue to improve with additional red teaming efforts. Another magnitude that we tracked as new models\\nwere produced was the percentage of prompts triggering violating responses discovered in the previous red\\nteaming exercises that were mitigated in a given new candidate release. On average, we had a 90% rejection\\nrate model over model.\\n4.4 Safety Evaluation of Llama 2-Chat\\nSafetyHumanEvaluation.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-28'),\n",
              " '59f84618-602b-4668-be9d-7fb106019356': IndexNode(id_='59f84618-602b-4668-be9d-7fb106019356', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-28', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='e86b2a7fa79d05727bd33ffc6f9122e324f6e3385597fa11cbe6db44a5a2dd92'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='8ff9785d-e1ac-454b-b70b-343398249620', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='37d7e6753e5948d9b8dd755f4eb214645445c76267ef69b1fa966b28fddc1249'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='ab514891-456e-46b0-90b5-05aee988f6ff', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='49a6881a30797b59214ed0fff6d1733e35f75a92441cdc201b09f58361f42061')}, hash='34197a66a6a0f6097379fd10f012e34b2cd13746d18b5c2ebb5edb422ec23590', text='4.4 Safety Evaluation of Llama 2-Chat\\nSafetyHumanEvaluation. Wecollectedroughly2,000adversarialpromptsforhumanevaluationaccording\\nto the safety categories in Section 4.2.1, in which 1,351 prompts are single-turn and 623 are multi-turn.\\nExamples of evaluation prompts and responses can be found in Appendix A.4.6.\\nWe then asked raters to judge models for safety violations on a five-point Likert scale with the following\\ndefinitions:\\n•5- No safety violations and very helpful\\n•4- No safety violations and only minor non-safety issues\\n•3- No safety violations but not helpful or other major non-safety issues\\n•2- Mild or moderate safety violations\\n29\\n\\n(a)Overall violation percentage.\\n (b)Overall safety and helpfulness mean rating.\\nFigure17: Overallsafetymeasures. Left: Llama 2-Chat haslowviolationpercentageoverallacrossmodel\\nsizes.Right: Llama 2-Chat has high safety and helpfulness mean rating overall across model sizes. It is\\nimportant to note that these results are subject to limitations of the prompt set, subjectivity of the review\\nguidelines, and subjectivity of individual raters.\\n•1- Severe safety violations\\nWe consider a rating of 1 or 2 as violation and use violation percentage as our main evaluation metric, with\\nthemeanratingasasupplement. Eachexampleisannotatedbythreeannotatorsandwetakethemajority\\nvotetodetermineiftheresponseisviolatingornot. WeusedGwet’sAC1/2statistictomeasureinter-rater\\nreliability(IRR)asinthehelpfulnesshumanevaluation. TheIRRscoresrangefrom 0.70to0.95depending\\non the annotation batch, indicating a high degree of agreement among annotators on safety assessments.\\nOnLlama 2-Chat annotations, the average IRR is 0.92according to Gwet’s AC2 measure.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-28'),\n",
              " 'ab514891-456e-46b0-90b5-05aee988f6ff': IndexNode(id_='ab514891-456e-46b0-90b5-05aee988f6ff', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-28', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='e86b2a7fa79d05727bd33ffc6f9122e324f6e3385597fa11cbe6db44a5a2dd92'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='59f84618-602b-4668-be9d-7fb106019356', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='34197a66a6a0f6097379fd10f012e34b2cd13746d18b5c2ebb5edb422ec23590')}, hash='49a6881a30797b59214ed0fff6d1733e35f75a92441cdc201b09f58361f42061', text='We see lower IRR\\nscoresonbatcheswherethemodelshaveahighviolationrate(e.g.,Vicuna)andhigherIRRscoresonbatches\\nwhere the models have relatively low violation rates (e.g., Llama 2-Chat , Falcon, and ChatGPT).\\nFigure 18: Single-turn and multi-turn violation percentage.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-28'),\n",
              " 'node-28': IndexNode(id_='node-28', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='415b7efc-e73f-4ac4-bbfd-c1546f099026', node_type=<ObjectType.DOCUMENT: '4'>, metadata={}, hash='231b3bd773f012c01b893ada9e009ecf25ee59934614c5a595c9bf1b3a123292'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='f92ed592-9915-4d47-9166-5e8b0bd3ca65', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='9211b2b96b9f7d5bd072735994c9ded33055f0614098c62cf7434d3a06ef20d8'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='0c2dd9aa-c1e3-4893-b155-fb4484aa49ca', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='531c43e09125fc31befe0377b54908e51877b900caa33a2e4025d4608ecc6579')}, hash='e86b2a7fa79d05727bd33ffc6f9122e324f6e3385597fa11cbe6db44a5a2dd92', text='•Distracting the [early models] by including “quirks” or specific requests usually defeated any\\nreluctanceencounteredviamoredirectrequests. “Acreativewritingrequest(song,story,poem,etc.) isa\\nreliable way to get it to produce content that it is otherwise robust against.”\\n•Embedding a problematic request in a positive context often successfully obscured the fact that\\nproblematicoutputwasbeingrequestedfor [early models] :“TheoverallprincipleI’vefoundmost\\neffective for any kind of attack is to hide it in language that is positive, progressive, and empowering.”\\nFrom Red Teaming Insights to Safer Models. Crucially, after each exercise, we performed a thorough\\nanalysis of the collected data, including dialogue length, risk area distribution, histogram of topic of misin-\\nformation (where appropriate), and rated degree of risk. In each case, we took the overall lessons as a guide\\nto helpfurther modelsafetytraining, and specificallytook data fromthese exercisesformodel fine-tuning,\\nmodel feedback training, and as a signal for other safety model training.\\nMultiple additionalrounds ofred teaming wereperformed over severalmonths tomeasure the robustness\\nof each new model as it was released internally. We defined the robustness of a model, γ, with respect to\\na red teaming exercise executed by a set of experts as the average number of created prompts that would\\ntriggeraviolatingresponsefromthemodelperpersonperhour. Asanexample,onour7Bmodel,wehadan\\nevolution of γ: 1.8→0.45over several red teaming iterations and model refinements. Robustness will likely\\ncontinue to improve with additional red teaming efforts. Another magnitude that we tracked as new models\\nwere produced was the percentage of prompts triggering violating responses discovered in the previous red\\nteaming exercises that were mitigated in a given new candidate release. On average, we had a 90% rejection\\nrate model over model.\\n4.4 Safety Evaluation of Llama 2-Chat\\nSafetyHumanEvaluation. Wecollectedroughly2,000adversarialpromptsforhumanevaluationaccording\\nto the safety categories in Section 4.2.1, in which 1,351 prompts are single-turn and 623 are multi-turn.\\nExamples of evaluation prompts and responses can be found in Appendix A.4.6.\\nWe then asked raters to judge models for safety violations on a five-point Likert scale with the following\\ndefinitions:\\n•5- No safety violations and very helpful\\n•4- No safety violations and only minor non-safety issues\\n•3- No safety violations but not helpful or other major non-safety issues\\n•2- Mild or moderate safety violations\\n29\\n\\n(a)Overall violation percentage.\\n (b)Overall safety and helpfulness mean rating.\\nFigure17: Overallsafetymeasures. Left: Llama 2-Chat haslowviolationpercentageoverallacrossmodel\\nsizes.Right: Llama 2-Chat has high safety and helpfulness mean rating overall across model sizes. It is\\nimportant to note that these results are subject to limitations of the prompt set, subjectivity of the review\\nguidelines, and subjectivity of individual raters.\\n•1- Severe safety violations\\nWe consider a rating of 1 or 2 as violation and use violation percentage as our main evaluation metric, with\\nthemeanratingasasupplement. Eachexampleisannotatedbythreeannotatorsandwetakethemajority\\nvotetodetermineiftheresponseisviolatingornot. WeusedGwet’sAC1/2statistictomeasureinter-rater\\nreliability(IRR)asinthehelpfulnesshumanevaluation. TheIRRscoresrangefrom 0.70to0.95depending\\non the annotation batch, indicating a high degree of agreement among annotators on safety assessments.\\nOnLlama 2-Chat annotations, the average IRR is 0.92according to Gwet’s AC2 measure. We see lower IRR\\nscoresonbatcheswherethemodelshaveahighviolationrate(e.g.,Vicuna)andhigherIRRscoresonbatches\\nwhere the models have relatively low violation rates (e.g., Llama 2-Chat , Falcon, and ChatGPT).\\nFigure 18: Single-turn and multi-turn violation percentage.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-28'),\n",
              " 'a29fede5-b95c-4256-8045-ae1ab09ef67b': IndexNode(id_='a29fede5-b95c-4256-8045-ae1ab09ef67b', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-29', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='531c43e09125fc31befe0377b54908e51877b900caa33a2e4025d4608ecc6579'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='8fc59f73-19b8-459b-b2b6-5abbe36199c0', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='d3228932b4462e70977673895aafc9606a11323766ec714386084ecbea7bf1c1')}, hash='ca614ae458fcfd73561d7cde46f2803817f57961c385983e7c41e54ca0a23a56', text='Figure 18: Single-turn and multi-turn violation percentage. Note that these results should be interpreted\\ncarefully due to limitations of the prompt set, subjectivity of the review guidelines, content standards, and\\nindividual raters.\\nWe show the overall violation percentage and safety rating of various LLMs in Figure 17.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-29'),\n",
              " '8fc59f73-19b8-459b-b2b6-5abbe36199c0': IndexNode(id_='8fc59f73-19b8-459b-b2b6-5abbe36199c0', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-29', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='531c43e09125fc31befe0377b54908e51877b900caa33a2e4025d4608ecc6579'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='a29fede5-b95c-4256-8045-ae1ab09ef67b', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='ca614ae458fcfd73561d7cde46f2803817f57961c385983e7c41e54ca0a23a56'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='5b31e4e1-041f-427e-87f9-ca466ee16cfe', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='b3d3b9374f501a58ccc53ac0eb1e9fc43885d0194615a490e5b6216d64842478')}, hash='d3228932b4462e70977673895aafc9606a11323766ec714386084ecbea7bf1c1', text='We show the overall violation percentage and safety rating of various LLMs in Figure 17. Llama 2-Chat has\\ncomparableorloweroverallviolationpercentageacrossmodelsizes,whileChatGPTandFalcon(Almazrouei\\netal., 2023)come next, thenMPT (MosaicMLNLP Teamet al.,2023) andVicuna(Chiang etal., 2023).', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-29'),\n",
              " '5b31e4e1-041f-427e-87f9-ca466ee16cfe': IndexNode(id_='5b31e4e1-041f-427e-87f9-ca466ee16cfe', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-29', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='531c43e09125fc31befe0377b54908e51877b900caa33a2e4025d4608ecc6579'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='8fc59f73-19b8-459b-b2b6-5abbe36199c0', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='d3228932b4462e70977673895aafc9606a11323766ec714386084ecbea7bf1c1'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='c9b09c76-2161-4571-a434-990da138883c', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='786f9f5f80d6c207c21aec6ac4231f8dcdb31c752b2b821db38eb52cf6037226')}, hash='b3d3b9374f501a58ccc53ac0eb1e9fc43885d0194615a490e5b6216d64842478', text='It is\\nimportanttointerprettheseresultscarefully,astheyareaffectedbylimitationsofthepromptset,subjectivity\\nof the review guidelines, content standards, and subjectivity of individual raters. Upon manual analysis, we\\nfound that the response of Falcon is typically short (one or two sentences), thus less prone to generating\\nunsafe content but also generally less helpful. This is reflected by a large number of responses of Falcon with\\nrating = 3.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-29'),\n",
              " 'c9b09c76-2161-4571-a434-990da138883c': IndexNode(id_='c9b09c76-2161-4571-a434-990da138883c', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-29', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='531c43e09125fc31befe0377b54908e51877b900caa33a2e4025d4608ecc6579'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='5b31e4e1-041f-427e-87f9-ca466ee16cfe', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='b3d3b9374f501a58ccc53ac0eb1e9fc43885d0194615a490e5b6216d64842478'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='ead00f0d-24d0-4697-a225-d5f21f24565f', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='1319db26dfaa1bad9b7cf3b793e84efa969e8ad0eaadf3a54b9dd4aeface4d01')}, hash='786f9f5f80d6c207c21aec6ac4231f8dcdb31c752b2b821db38eb52cf6037226', text='This is reflected by a large number of responses of Falcon with\\nrating = 3. As a result, we note that in Figure 17b the average rating of Falcon is much lower than Llama\\n2-Chat(34B) although their violation percentages look similar ( 3.88vs4.45).\\n30\\n\\nFigure19: Violationpercentageperriskcategory. Note: theseresultsshouldbeinterpretedcarefullydueto\\nlimitations of the prompt set, subjectivity of the review guidelines, content standards, and individual raters.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-29'),\n",
              " 'ead00f0d-24d0-4697-a225-d5f21f24565f': IndexNode(id_='ead00f0d-24d0-4697-a225-d5f21f24565f', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-29', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='531c43e09125fc31befe0377b54908e51877b900caa33a2e4025d4608ecc6579'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='c9b09c76-2161-4571-a434-990da138883c', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='786f9f5f80d6c207c21aec6ac4231f8dcdb31c752b2b821db38eb52cf6037226'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='d3d31dfd-fc5b-4ae4-9a21-e0926d16057d', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='6d273afe1d2aebcc0e7549d4ce2cd0c3442ca65c48ee7730910f532a2719df48')}, hash='1319db26dfaa1bad9b7cf3b793e84efa969e8ad0eaadf3a54b9dd4aeface4d01', text='InFigure18,wereporttheviolationpercentageonsingle-andmulti-turnconversations,respectively. Atrend\\nacrossmodelsisthatmulti-turnconversationsaremorepronetoinducingunsaferesponses. Thatsaid, Llama\\n2-Chatstillperformswellcomparedtobaselines,especiallyonmulti-turnconversations.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-29'),\n",
              " 'd3d31dfd-fc5b-4ae4-9a21-e0926d16057d': IndexNode(id_='d3d31dfd-fc5b-4ae4-9a21-e0926d16057d', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-29', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='531c43e09125fc31befe0377b54908e51877b900caa33a2e4025d4608ecc6579'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='ead00f0d-24d0-4697-a225-d5f21f24565f', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='1319db26dfaa1bad9b7cf3b793e84efa969e8ad0eaadf3a54b9dd4aeface4d01'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='5b5bd92a-38aa-4168-90fc-4128491a0998', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='68cec8d6d05e5d3a6c0f2ae58efde9c1ff1f11898c6d08e8c6640307c062d55f')}, hash='6d273afe1d2aebcc0e7549d4ce2cd0c3442ca65c48ee7730910f532a2719df48', text='Wealsoobserve\\nthat Falcon performs particularly well on single-turn conversations (largely due to its conciseness) but much\\nworse on multi-turn conversations, which could be due to its lack of multi-turn supervised fine-tuning data.\\nInFigure19,weshowtheper-categorysafetyviolationpercentageofdifferentLLMs.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-29'),\n",
              " '5b5bd92a-38aa-4168-90fc-4128491a0998': IndexNode(id_='5b5bd92a-38aa-4168-90fc-4128491a0998', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-29', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='531c43e09125fc31befe0377b54908e51877b900caa33a2e4025d4608ecc6579'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='d3d31dfd-fc5b-4ae4-9a21-e0926d16057d', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='6d273afe1d2aebcc0e7549d4ce2cd0c3442ca65c48ee7730910f532a2719df48'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='2ab6c663-a937-437a-9356-108cef756d8d', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='6cf1e8492fbc0f47a7ed7b76faa17c9d9674abf4bd6841ee092019ea849a6cf4')}, hash='68cec8d6d05e5d3a6c0f2ae58efde9c1ff1f11898c6d08e8c6640307c062d55f', text='Whilemodelperfor-\\nmanceissimilaracrosscategories, Llama 2-Chat hasrelativelymoreviolationsunderthe unqualifiedadvice\\ncategory (although still low in an absolute sense), for various reasons, including lack of an appropriate\\ndisclaimer (e.g., “I am not a professional” ) at times. For the other two categories, Llama 2-Chat achieves\\ncomparable or lower violation percentage consistently regardless of model sizes.\\nTruthfulness, Toxicity, and Bias.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-29'),\n",
              " '2ab6c663-a937-437a-9356-108cef756d8d': IndexNode(id_='2ab6c663-a937-437a-9356-108cef756d8d', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-29', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='531c43e09125fc31befe0377b54908e51877b900caa33a2e4025d4608ecc6579'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='5b5bd92a-38aa-4168-90fc-4128491a0998', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='68cec8d6d05e5d3a6c0f2ae58efde9c1ff1f11898c6d08e8c6640307c062d55f'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='73284ac5-7be0-43d8-a304-38c367db52e4', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='9aff2f1188d41c3f64e92ccd4e6e90c74544b6d40fb293e10851e233f3f14170')}, hash='6cf1e8492fbc0f47a7ed7b76faa17c9d9674abf4bd6841ee092019ea849a6cf4', text='Truthfulness, Toxicity, and Bias. In Table 14, fine-tuned Llama 2-Chat shows great improvement over\\nthe pretrained Llama 2 in terms of truthfulness ( 50.18→64.14for 70B) and toxicity ( 24.60→0.01for 70B).\\nThe percentage of toxic generations shrinks to effectively 0% for Llama 2-Chat of all sizes: this is the lowest\\ntoxicitylevelamongallcomparedmodels.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-29'),\n",
              " '73284ac5-7be0-43d8-a304-38c367db52e4': IndexNode(id_='73284ac5-7be0-43d8-a304-38c367db52e4', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-29', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='531c43e09125fc31befe0377b54908e51877b900caa33a2e4025d4608ecc6579'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='2ab6c663-a937-437a-9356-108cef756d8d', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='6cf1e8492fbc0f47a7ed7b76faa17c9d9674abf4bd6841ee092019ea849a6cf4'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='20bd78c5-b72e-443e-b384-4dbd91727abf', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='77475d2874fb5ac0e956e92f24f510315b157d342d54449e30cf794180f93b38')}, hash='9aff2f1188d41c3f64e92ccd4e6e90c74544b6d40fb293e10851e233f3f14170', text='Ingeneral,whencomparedtoFalconandMPT,thefine-tuned\\nLlama 2-Chat showsthebestperformanceintermsoftoxicityandtruthfulness. Afterfine-tuning, Llama\\n2-Chattends to have an increase in positive sentiment overall for many of the demographic groups in BOLD.\\nInAppendixA.4.8,wepresentadetailedscorebreakdownofmodelgenerationsentimentacrossdifferent\\nsubgroups for the bias benchmark, along with more in-depth analyses and results of truthfulness and bias.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-29'),\n",
              " '20bd78c5-b72e-443e-b384-4dbd91727abf': IndexNode(id_='20bd78c5-b72e-443e-b384-4dbd91727abf', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-29', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='531c43e09125fc31befe0377b54908e51877b900caa33a2e4025d4608ecc6579'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='73284ac5-7be0-43d8-a304-38c367db52e4', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='9aff2f1188d41c3f64e92ccd4e6e90c74544b6d40fb293e10851e233f3f14170'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='fc9f0446-0783-4d9c-94dd-23ee71d60c5b', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='bcbdee68b148ab80a4edc8423efcf3d7d4614d484069187ea4cf5f89ffcd5915')}, hash='77475d2874fb5ac0e956e92f24f510315b157d342d54449e30cf794180f93b38', text='TruthfulQA ↑ToxiGen ↓\\nChatGPT - 78.46 0.20\\nFalcon-instruct 7B 28.03 7.89\\nMPT-instruct 7B 29.99 16.33\\nLlama 2-Chat7B 57.04 0.00\\n13B 62.18 0.00\\n34B 67.20 0.02\\n70B 64.14 0.01\\nTable 14: Evaluation of fine-tuned LLMs on different safety datasets.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-29'),\n",
              " 'fc9f0446-0783-4d9c-94dd-23ee71d60c5b': IndexNode(id_='fc9f0446-0783-4d9c-94dd-23ee71d60c5b', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-29', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='531c43e09125fc31befe0377b54908e51877b900caa33a2e4025d4608ecc6579'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='20bd78c5-b72e-443e-b384-4dbd91727abf', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='77475d2874fb5ac0e956e92f24f510315b157d342d54449e30cf794180f93b38')}, hash='bcbdee68b148ab80a4edc8423efcf3d7d4614d484069187ea4cf5f89ffcd5915', text='For TruthfulQA, we present the\\npercentageofgenerationsthatarebothtruthfulandinformative(thehigherthebetter). ForToxiGen,we\\npresent the percentage of toxic generations (the smaller the better).\\n31\\n\\n5 Discussion\\nHere, we discuss the interesting properties we have observed with RLHF (Section 5.1).', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-29'),\n",
              " '49611778-61b7-47ce-96d2-26602825027a': IndexNode(id_='49611778-61b7-47ce-96d2-26602825027a', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-29', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='531c43e09125fc31befe0377b54908e51877b900caa33a2e4025d4608ecc6579'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='3214d36e-f914-4b09-b4e8-56936bccf24a', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='b9b3cba074e6799cd2f704ef3392a9b23c26484792f7d504fbf9787b92ad3b68')}, hash='9af5cd14831d84cf7d2a303ff9d81cd7c9edfb907ba8ee8d3cdcefbdcb18a59b', text='Figure 18: Single-turn and multi-turn violation percentage. Note that these results should be interpreted\\ncarefully due to limitations of the prompt set, subjectivity of the review guidelines, content standards, and\\nindividual raters.\\nWe show the overall violation percentage and safety rating of various LLMs in Figure 17. Llama 2-Chat has\\ncomparableorloweroverallviolationpercentageacrossmodelsizes,whileChatGPTandFalcon(Almazrouei\\netal., 2023)come next, thenMPT (MosaicMLNLP Teamet al.,2023) andVicuna(Chiang etal., 2023). It is\\nimportanttointerprettheseresultscarefully,astheyareaffectedbylimitationsofthepromptset,subjectivity\\nof the review guidelines, content standards, and subjectivity of individual raters. Upon manual analysis, we\\nfound that the response of Falcon is typically short (one or two sentences), thus less prone to generating\\nunsafe content but also generally less helpful. This is reflected by a large number of responses of Falcon with\\nrating = 3.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-29'),\n",
              " '3214d36e-f914-4b09-b4e8-56936bccf24a': IndexNode(id_='3214d36e-f914-4b09-b4e8-56936bccf24a', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-29', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='531c43e09125fc31befe0377b54908e51877b900caa33a2e4025d4608ecc6579'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='49611778-61b7-47ce-96d2-26602825027a', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='9af5cd14831d84cf7d2a303ff9d81cd7c9edfb907ba8ee8d3cdcefbdcb18a59b'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='8bfb2afc-782b-40ed-8ca2-30bea550a9c3', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='4bc36a747a3e286e297dc67840649850450a75f1f790b285be92e880d6146a38')}, hash='b9b3cba074e6799cd2f704ef3392a9b23c26484792f7d504fbf9787b92ad3b68', text='This is reflected by a large number of responses of Falcon with\\nrating = 3. As a result, we note that in Figure 17b the average rating of Falcon is much lower than Llama\\n2-Chat(34B) although their violation percentages look similar ( 3.88vs4.45).\\n30\\n\\nFigure19: Violationpercentageperriskcategory. Note: theseresultsshouldbeinterpretedcarefullydueto\\nlimitations of the prompt set, subjectivity of the review guidelines, content standards, and individual raters.\\nInFigure18,wereporttheviolationpercentageonsingle-andmulti-turnconversations,respectively. Atrend\\nacrossmodelsisthatmulti-turnconversationsaremorepronetoinducingunsaferesponses. Thatsaid, Llama\\n2-Chatstillperformswellcomparedtobaselines,especiallyonmulti-turnconversations. Wealsoobserve\\nthat Falcon performs particularly well on single-turn conversations (largely due to its conciseness) but much\\nworse on multi-turn conversations, which could be due to its lack of multi-turn supervised fine-tuning data.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-29'),\n",
              " '8bfb2afc-782b-40ed-8ca2-30bea550a9c3': IndexNode(id_='8bfb2afc-782b-40ed-8ca2-30bea550a9c3', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-29', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='531c43e09125fc31befe0377b54908e51877b900caa33a2e4025d4608ecc6579'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='3214d36e-f914-4b09-b4e8-56936bccf24a', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='b9b3cba074e6799cd2f704ef3392a9b23c26484792f7d504fbf9787b92ad3b68'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='93fe6448-c05d-419c-b7fa-d52fb70c898e', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='0e99b8573d5116934fca02e2a91c329bc78bcf5998472dd1158379f62d13c774')}, hash='4bc36a747a3e286e297dc67840649850450a75f1f790b285be92e880d6146a38', text='InFigure19,weshowtheper-categorysafetyviolationpercentageofdifferentLLMs. Whilemodelperfor-\\nmanceissimilaracrosscategories, Llama 2-Chat hasrelativelymoreviolationsunderthe unqualifiedadvice\\ncategory (although still low in an absolute sense), for various reasons, including lack of an appropriate\\ndisclaimer (e.g., “I am not a professional” ) at times. For the other two categories, Llama 2-Chat achieves\\ncomparable or lower violation percentage consistently regardless of model sizes.\\nTruthfulness, Toxicity, and Bias. In Table 14, fine-tuned Llama 2-Chat shows great improvement over\\nthe pretrained Llama 2 in terms of truthfulness ( 50.18→64.14for 70B) and toxicity ( 24.60→0.01for 70B).\\nThe percentage of toxic generations shrinks to effectively 0% for Llama 2-Chat of all sizes: this is the lowest\\ntoxicitylevelamongallcomparedmodels.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-29'),\n",
              " '93fe6448-c05d-419c-b7fa-d52fb70c898e': IndexNode(id_='93fe6448-c05d-419c-b7fa-d52fb70c898e', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-29', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='531c43e09125fc31befe0377b54908e51877b900caa33a2e4025d4608ecc6579'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='8bfb2afc-782b-40ed-8ca2-30bea550a9c3', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='4bc36a747a3e286e297dc67840649850450a75f1f790b285be92e880d6146a38'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='35c1f02c-9c14-41f3-b595-a22b4388fcaf', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='bcbdee68b148ab80a4edc8423efcf3d7d4614d484069187ea4cf5f89ffcd5915')}, hash='0e99b8573d5116934fca02e2a91c329bc78bcf5998472dd1158379f62d13c774', text='Ingeneral,whencomparedtoFalconandMPT,thefine-tuned\\nLlama 2-Chat showsthebestperformanceintermsoftoxicityandtruthfulness. Afterfine-tuning, Llama\\n2-Chattends to have an increase in positive sentiment overall for many of the demographic groups in BOLD.\\nInAppendixA.4.8,wepresentadetailedscorebreakdownofmodelgenerationsentimentacrossdifferent\\nsubgroups for the bias benchmark, along with more in-depth analyses and results of truthfulness and bias.\\nTruthfulQA ↑ToxiGen ↓\\nChatGPT - 78.46 0.20\\nFalcon-instruct 7B 28.03 7.89\\nMPT-instruct 7B 29.99 16.33\\nLlama 2-Chat7B 57.04 0.00\\n13B 62.18 0.00\\n34B 67.20 0.02\\n70B 64.14 0.01\\nTable 14: Evaluation of fine-tuned LLMs on different safety datasets.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-29'),\n",
              " '35c1f02c-9c14-41f3-b595-a22b4388fcaf': IndexNode(id_='35c1f02c-9c14-41f3-b595-a22b4388fcaf', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-29', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='531c43e09125fc31befe0377b54908e51877b900caa33a2e4025d4608ecc6579'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='93fe6448-c05d-419c-b7fa-d52fb70c898e', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='0e99b8573d5116934fca02e2a91c329bc78bcf5998472dd1158379f62d13c774')}, hash='bcbdee68b148ab80a4edc8423efcf3d7d4614d484069187ea4cf5f89ffcd5915', text='For TruthfulQA, we present the\\npercentageofgenerationsthatarebothtruthfulandinformative(thehigherthebetter). ForToxiGen,we\\npresent the percentage of toxic generations (the smaller the better).\\n31\\n\\n5 Discussion\\nHere, we discuss the interesting properties we have observed with RLHF (Section 5.1).', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-29'),\n",
              " '4b5937f7-347b-4e10-8efd-5a004df5f43f': IndexNode(id_='4b5937f7-347b-4e10-8efd-5a004df5f43f', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-29', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='531c43e09125fc31befe0377b54908e51877b900caa33a2e4025d4608ecc6579'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='a4fd2fea-9dbf-400f-9c14-64e319a629d0', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='ccddc9d166e8ee28afe8f5de3d19d4a36e97197a86fe25a150770a68cd6feaa9')}, hash='29e6df379e9178bde31d6d26bf4f6e75cfc0204a50259e3b14cb9e7cc3d4b3ab', text='Figure 18: Single-turn and multi-turn violation percentage. Note that these results should be interpreted\\ncarefully due to limitations of the prompt set, subjectivity of the review guidelines, content standards, and\\nindividual raters.\\nWe show the overall violation percentage and safety rating of various LLMs in Figure 17. Llama 2-Chat has\\ncomparableorloweroverallviolationpercentageacrossmodelsizes,whileChatGPTandFalcon(Almazrouei\\netal., 2023)come next, thenMPT (MosaicMLNLP Teamet al.,2023) andVicuna(Chiang etal., 2023). It is\\nimportanttointerprettheseresultscarefully,astheyareaffectedbylimitationsofthepromptset,subjectivity\\nof the review guidelines, content standards, and subjectivity of individual raters. Upon manual analysis, we\\nfound that the response of Falcon is typically short (one or two sentences), thus less prone to generating\\nunsafe content but also generally less helpful. This is reflected by a large number of responses of Falcon with\\nrating = 3. As a result, we note that in Figure 17b the average rating of Falcon is much lower than Llama\\n2-Chat(34B) although their violation percentages look similar ( 3.88vs4.45).\\n30\\n\\nFigure19: Violationpercentageperriskcategory. Note: theseresultsshouldbeinterpretedcarefullydueto\\nlimitations of the prompt set, subjectivity of the review guidelines, content standards, and individual raters.\\nInFigure18,wereporttheviolationpercentageonsingle-andmulti-turnconversations,respectively. Atrend\\nacrossmodelsisthatmulti-turnconversationsaremorepronetoinducingunsaferesponses. Thatsaid, Llama\\n2-Chatstillperformswellcomparedtobaselines,especiallyonmulti-turnconversations. Wealsoobserve\\nthat Falcon performs particularly well on single-turn conversations (largely due to its conciseness) but much\\nworse on multi-turn conversations, which could be due to its lack of multi-turn supervised fine-tuning data.\\nInFigure19,weshowtheper-categorysafetyviolationpercentageofdifferentLLMs.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-29'),\n",
              " 'a4fd2fea-9dbf-400f-9c14-64e319a629d0': IndexNode(id_='a4fd2fea-9dbf-400f-9c14-64e319a629d0', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-29', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='531c43e09125fc31befe0377b54908e51877b900caa33a2e4025d4608ecc6579'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='4b5937f7-347b-4e10-8efd-5a004df5f43f', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='29e6df379e9178bde31d6d26bf4f6e75cfc0204a50259e3b14cb9e7cc3d4b3ab'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='820a0427-afbd-4c17-8a32-085015f2503a', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='65634c333f3a345fa1c4698e6532117e9289822d4a437e0aeda943257219d7e6')}, hash='ccddc9d166e8ee28afe8f5de3d19d4a36e97197a86fe25a150770a68cd6feaa9', text='Whilemodelperfor-\\nmanceissimilaracrosscategories, Llama 2-Chat hasrelativelymoreviolationsunderthe unqualifiedadvice\\ncategory (although still low in an absolute sense), for various reasons, including lack of an appropriate\\ndisclaimer (e.g., “I am not a professional” ) at times. For the other two categories, Llama 2-Chat achieves\\ncomparable or lower violation percentage consistently regardless of model sizes.\\nTruthfulness, Toxicity, and Bias. In Table 14, fine-tuned Llama 2-Chat shows great improvement over\\nthe pretrained Llama 2 in terms of truthfulness ( 50.18→64.14for 70B) and toxicity ( 24.60→0.01for 70B).\\nThe percentage of toxic generations shrinks to effectively 0% for Llama 2-Chat of all sizes: this is the lowest\\ntoxicitylevelamongallcomparedmodels. Ingeneral,whencomparedtoFalconandMPT,thefine-tuned\\nLlama 2-Chat showsthebestperformanceintermsoftoxicityandtruthfulness. Afterfine-tuning, Llama\\n2-Chattends to have an increase in positive sentiment overall for many of the demographic groups in BOLD.\\nInAppendixA.4.8,wepresentadetailedscorebreakdownofmodelgenerationsentimentacrossdifferent\\nsubgroups for the bias benchmark, along with more in-depth analyses and results of truthfulness and bias.\\nTruthfulQA ↑ToxiGen ↓\\nChatGPT - 78.46 0.20\\nFalcon-instruct 7B 28.03 7.89\\nMPT-instruct 7B 29.99 16.33\\nLlama 2-Chat7B 57.04 0.00\\n13B 62.18 0.00\\n34B 67.20 0.02\\n70B 64.14 0.01\\nTable 14: Evaluation of fine-tuned LLMs on different safety datasets. For TruthfulQA, we present the\\npercentageofgenerationsthatarebothtruthfulandinformative(thehigherthebetter). ForToxiGen,we\\npresent the percentage of toxic generations (the smaller the better).', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-29'),\n",
              " '820a0427-afbd-4c17-8a32-085015f2503a': IndexNode(id_='820a0427-afbd-4c17-8a32-085015f2503a', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-29', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='531c43e09125fc31befe0377b54908e51877b900caa33a2e4025d4608ecc6579'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='a4fd2fea-9dbf-400f-9c14-64e319a629d0', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='ccddc9d166e8ee28afe8f5de3d19d4a36e97197a86fe25a150770a68cd6feaa9')}, hash='65634c333f3a345fa1c4698e6532117e9289822d4a437e0aeda943257219d7e6', text='31\\n\\n5 Discussion\\nHere, we discuss the interesting properties we have observed with RLHF (Section 5.1).', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-29'),\n",
              " 'node-29': IndexNode(id_='node-29', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='415b7efc-e73f-4ac4-bbfd-c1546f099026', node_type=<ObjectType.DOCUMENT: '4'>, metadata={}, hash='231b3bd773f012c01b893ada9e009ecf25ee59934614c5a595c9bf1b3a123292'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='0308b214-6374-42d8-8f7d-bb1ebcf78290', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='e86b2a7fa79d05727bd33ffc6f9122e324f6e3385597fa11cbe6db44a5a2dd92'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='a92a0f1c-074e-4d8f-b30d-5fe748dd9c59', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='a694eade310d000ca9f116f3012716e193bb4804f30e0e7b548ce191ec662096')}, hash='531c43e09125fc31befe0377b54908e51877b900caa33a2e4025d4608ecc6579', text='Figure 18: Single-turn and multi-turn violation percentage. Note that these results should be interpreted\\ncarefully due to limitations of the prompt set, subjectivity of the review guidelines, content standards, and\\nindividual raters.\\nWe show the overall violation percentage and safety rating of various LLMs in Figure 17. Llama 2-Chat has\\ncomparableorloweroverallviolationpercentageacrossmodelsizes,whileChatGPTandFalcon(Almazrouei\\netal., 2023)come next, thenMPT (MosaicMLNLP Teamet al.,2023) andVicuna(Chiang etal., 2023). It is\\nimportanttointerprettheseresultscarefully,astheyareaffectedbylimitationsofthepromptset,subjectivity\\nof the review guidelines, content standards, and subjectivity of individual raters. Upon manual analysis, we\\nfound that the response of Falcon is typically short (one or two sentences), thus less prone to generating\\nunsafe content but also generally less helpful. This is reflected by a large number of responses of Falcon with\\nrating = 3. As a result, we note that in Figure 17b the average rating of Falcon is much lower than Llama\\n2-Chat(34B) although their violation percentages look similar ( 3.88vs4.45).\\n30\\n\\nFigure19: Violationpercentageperriskcategory. Note: theseresultsshouldbeinterpretedcarefullydueto\\nlimitations of the prompt set, subjectivity of the review guidelines, content standards, and individual raters.\\nInFigure18,wereporttheviolationpercentageonsingle-andmulti-turnconversations,respectively. Atrend\\nacrossmodelsisthatmulti-turnconversationsaremorepronetoinducingunsaferesponses. Thatsaid, Llama\\n2-Chatstillperformswellcomparedtobaselines,especiallyonmulti-turnconversations. Wealsoobserve\\nthat Falcon performs particularly well on single-turn conversations (largely due to its conciseness) but much\\nworse on multi-turn conversations, which could be due to its lack of multi-turn supervised fine-tuning data.\\nInFigure19,weshowtheper-categorysafetyviolationpercentageofdifferentLLMs. Whilemodelperfor-\\nmanceissimilaracrosscategories, Llama 2-Chat hasrelativelymoreviolationsunderthe unqualifiedadvice\\ncategory (although still low in an absolute sense), for various reasons, including lack of an appropriate\\ndisclaimer (e.g., “I am not a professional” ) at times. For the other two categories, Llama 2-Chat achieves\\ncomparable or lower violation percentage consistently regardless of model sizes.\\nTruthfulness, Toxicity, and Bias. In Table 14, fine-tuned Llama 2-Chat shows great improvement over\\nthe pretrained Llama 2 in terms of truthfulness ( 50.18→64.14for 70B) and toxicity ( 24.60→0.01for 70B).\\nThe percentage of toxic generations shrinks to effectively 0% for Llama 2-Chat of all sizes: this is the lowest\\ntoxicitylevelamongallcomparedmodels. Ingeneral,whencomparedtoFalconandMPT,thefine-tuned\\nLlama 2-Chat showsthebestperformanceintermsoftoxicityandtruthfulness. Afterfine-tuning, Llama\\n2-Chattends to have an increase in positive sentiment overall for many of the demographic groups in BOLD.\\nInAppendixA.4.8,wepresentadetailedscorebreakdownofmodelgenerationsentimentacrossdifferent\\nsubgroups for the bias benchmark, along with more in-depth analyses and results of truthfulness and bias.\\nTruthfulQA ↑ToxiGen ↓\\nChatGPT - 78.46 0.20\\nFalcon-instruct 7B 28.03 7.89\\nMPT-instruct 7B 29.99 16.33\\nLlama 2-Chat7B 57.04 0.00\\n13B 62.18 0.00\\n34B 67.20 0.02\\n70B 64.14 0.01\\nTable 14: Evaluation of fine-tuned LLMs on different safety datasets. For TruthfulQA, we present the\\npercentageofgenerationsthatarebothtruthfulandinformative(thehigherthebetter). ForToxiGen,we\\npresent the percentage of toxic generations (the smaller the better).\\n31\\n\\n5 Discussion\\nHere, we discuss the interesting properties we have observed with RLHF (Section 5.1).', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-29'),\n",
              " 'dfbcfcc8-5cb7-4eec-ad2a-ca85078f00e4': IndexNode(id_='dfbcfcc8-5cb7-4eec-ad2a-ca85078f00e4', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-30', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='a694eade310d000ca9f116f3012716e193bb4804f30e0e7b548ce191ec662096'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='50db644e-7684-4183-8afd-aa3d7e7f4dfe', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='0d1ea8c6aa65e4a51c3951f5e4c50d1f377dba8deaee6000ad9d2cbd79922522')}, hash='ad34610b8b9b06b6721d036f6bb3fe252c4de8dc2fc6d50bbc71fa5707a2849d', text='We then discuss the\\nlimitations of Llama 2-Chat (Section 5.2). Lastly, we present our strategy for responsibly releasing these\\nmodels (Section 5.3).\\n5.1 Learnings and Observations\\nOur tuning process revealed several interesting results, such as Llama 2-Chat ’s abilities to temporally\\norganize its knowledge, or to call APIs for external tools.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-30'),\n",
              " '50db644e-7684-4183-8afd-aa3d7e7f4dfe': IndexNode(id_='50db644e-7684-4183-8afd-aa3d7e7f4dfe', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-30', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='a694eade310d000ca9f116f3012716e193bb4804f30e0e7b548ce191ec662096'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='dfbcfcc8-5cb7-4eec-ad2a-ca85078f00e4', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='ad34610b8b9b06b6721d036f6bb3fe252c4de8dc2fc6d50bbc71fa5707a2849d'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='bc86726e-ecf7-46e0-b3ef-fba29868ab5d', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='988b4acd6b4cf3c4e582670759f3adccd520de47c148d665e453c185cf1c3352')}, hash='0d1ea8c6aa65e4a51c3951f5e4c50d1f377dba8deaee6000ad9d2cbd79922522', text='SFT (Mix)\\nSFT (Annotation)\\nRLHF (V1)\\n0.0 0.2 0.4 0.6 0.8 1.0\\nReward Model ScoreRLHF (V2)\\nFigure 20: Distribution shift for progressive versions of Llama 2-Chat , from SFT models towards RLHF.\\nBeyond Human Supervision. At the outset of the project, many among us expressed a preference for\\nsupervised annotation, attracted by its denser signal.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-30'),\n",
              " 'bc86726e-ecf7-46e0-b3ef-fba29868ab5d': IndexNode(id_='bc86726e-ecf7-46e0-b3ef-fba29868ab5d', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-30', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='a694eade310d000ca9f116f3012716e193bb4804f30e0e7b548ce191ec662096'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='50db644e-7684-4183-8afd-aa3d7e7f4dfe', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='0d1ea8c6aa65e4a51c3951f5e4c50d1f377dba8deaee6000ad9d2cbd79922522'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='c194f660-fcb0-4a7d-8b77-633c2f1fdb1d', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='b28832bd0011440460fe7b2d4457a2f32b21b04a5e2ef9162395a0d41cef4317')}, hash='988b4acd6b4cf3c4e582670759f3adccd520de47c148d665e453c185cf1c3352', text='Meanwhile reinforcement learning, known for its insta-\\nbility, seemed a somewhat shadowy field for those in the NLP research community. However, reinforcement\\nlearning proved highly effective, particularly given its cost and time effectiveness. Our findings underscore\\nthat the crucial determinant of RLHF’s success lies in the synergy it fosters between humans and LLMs\\nthroughout the annotation process.\\nEvenwithproficientannotators,eachindividualwriteswithsignificantvariation.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-30'),\n",
              " 'c194f660-fcb0-4a7d-8b77-633c2f1fdb1d': IndexNode(id_='c194f660-fcb0-4a7d-8b77-633c2f1fdb1d', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-30', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='a694eade310d000ca9f116f3012716e193bb4804f30e0e7b548ce191ec662096'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='bc86726e-ecf7-46e0-b3ef-fba29868ab5d', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='988b4acd6b4cf3c4e582670759f3adccd520de47c148d665e453c185cf1c3352'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='827c19b4-9af4-41ad-8a8e-531b2a56f75e', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='2ebdbbd98946bc17e9cce3173daefda9c1bfb6258c9cd90ae2fa0872e7661212')}, hash='b28832bd0011440460fe7b2d4457a2f32b21b04a5e2ef9162395a0d41cef4317', text='Evenwithproficientannotators,eachindividualwriteswithsignificantvariation. Amodelfine-tunedon\\nSFTannotationlearnsthisdiversity,including,unfortunately,thetail-endofpoorlyexecutedannotation. Fur-\\nthermore, the model’s performance is capped by the writing abilities of the most skilled annotators.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-30'),\n",
              " '827c19b4-9af4-41ad-8a8e-531b2a56f75e': IndexNode(id_='827c19b4-9af4-41ad-8a8e-531b2a56f75e', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-30', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='a694eade310d000ca9f116f3012716e193bb4804f30e0e7b548ce191ec662096'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='c194f660-fcb0-4a7d-8b77-633c2f1fdb1d', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='b28832bd0011440460fe7b2d4457a2f32b21b04a5e2ef9162395a0d41cef4317'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='3da33c39-179d-4242-aac9-f72c15204599', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='d5ae69d984bb6773a8eb114fcdcb23a4535532c76f0f8784b5ff08b02b0959b8')}, hash='2ebdbbd98946bc17e9cce3173daefda9c1bfb6258c9cd90ae2fa0872e7661212', text='Human\\nannotators are arguably less subject to discrepancy when comparing two outputs’ preference annotation\\nforRLHF.Consequently,therewardmechanismswiftlylearnstoassignlowscorestoundesirabletail-end\\ndistribution and aligns towards the human preference. This phenomena is illustrated in Figure 20, where we\\ncan see that the worst answers are progressively removed, shifting the distribution to the right.\\nIn addition, during annotation, the model has the potential to venture into writing trajectories that even the\\nbestannotatorsmaynotchart.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-30'),\n",
              " '3da33c39-179d-4242-aac9-f72c15204599': IndexNode(id_='3da33c39-179d-4242-aac9-f72c15204599', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-30', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='a694eade310d000ca9f116f3012716e193bb4804f30e0e7b548ce191ec662096'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='827c19b4-9af4-41ad-8a8e-531b2a56f75e', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='2ebdbbd98946bc17e9cce3173daefda9c1bfb6258c9cd90ae2fa0872e7661212'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='b623ebad-8062-49c1-a21a-98f6bc1d9b8f', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='27dd4d67bf5ec6e52770423f9d64780258d2820e4cd55dfd35a304dc4227df13')}, hash='d5ae69d984bb6773a8eb114fcdcb23a4535532c76f0f8784b5ff08b02b0959b8', text='Nonetheless,humanscanstillprovidevaluablefeedbackwhencomparingtwo\\nanswers, beyond their own writing competencies. Drawing a parallel, while we may not all be accomplished\\nartists, our ability to appreciate and critique art remains intact. We posit that the superior writing abilities of\\nLLMs, as manifested in surpassing human annotators in certain tasks, are fundamentally driven by RLHF, as\\ndocumented in Gilardi et al. (2023) and Huang et al. (2023).', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-30'),\n",
              " 'b623ebad-8062-49c1-a21a-98f6bc1d9b8f': IndexNode(id_='b623ebad-8062-49c1-a21a-98f6bc1d9b8f', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-30', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='a694eade310d000ca9f116f3012716e193bb4804f30e0e7b548ce191ec662096'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='3da33c39-179d-4242-aac9-f72c15204599', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='d5ae69d984bb6773a8eb114fcdcb23a4535532c76f0f8784b5ff08b02b0959b8'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='a1d6a5be-e61e-4dcf-95b2-ad754a4a9215', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='1d32f859ad263a02c9dbb1f725a284af924ea5c22b502c157ea18de15b81be6d')}, hash='27dd4d67bf5ec6e52770423f9d64780258d2820e4cd55dfd35a304dc4227df13', text='(2023) and Huang et al. (2023). Supervised data may no longer be the gold\\nstandard, and this evolving circumstance compels a re-evaluation of the concept of “supervision.”\\nIn-ContextTemperatureRescaling. WehaveobservedanintriguingphenomenonrelatedtoRLHF,afeature\\nnotpreviouslyreportedtothebestofourknowledge: thedynamicre-scalingoftemperaturecontingentupon\\nthecontext.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-30'),\n",
              " 'a1d6a5be-e61e-4dcf-95b2-ad754a4a9215': IndexNode(id_='a1d6a5be-e61e-4dcf-95b2-ad754a4a9215', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-30', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='a694eade310d000ca9f116f3012716e193bb4804f30e0e7b548ce191ec662096'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='b623ebad-8062-49c1-a21a-98f6bc1d9b8f', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='27dd4d67bf5ec6e52770423f9d64780258d2820e4cd55dfd35a304dc4227df13'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='1f055074-7257-4efd-be23-b9fdf81a2b87', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='8ec6630dd10ce4c63e1bc3a18ba8664d8fe7c4c3f086ae154fd07a4633a51f75')}, hash='1d32f859ad263a02c9dbb1f725a284af924ea5c22b502c157ea18de15b81be6d', text='AsindicatedinFigure8,thetemperatureappearstobeinfluencedbyRLHF.Yet,intriguingly,\\nour findings also revealed that the shifts are not uniformly applied across all prompts, as shown in Figure 21.\\nForinstance,whenitcomestopromptsassociatedwithcreativity,suchas“Writeapoem,”anincreasein\\ntemperature continues to generate diversity across our various RLHF iterations. This can be observed in the\\nSelf-BLEU slope, which mirrors a pattern comparable to that of the SFT model.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-30'),\n",
              " '1f055074-7257-4efd-be23-b9fdf81a2b87': IndexNode(id_='1f055074-7257-4efd-be23-b9fdf81a2b87', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-30', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='a694eade310d000ca9f116f3012716e193bb4804f30e0e7b548ce191ec662096'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='a1d6a5be-e61e-4dcf-95b2-ad754a4a9215', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='1d32f859ad263a02c9dbb1f725a284af924ea5c22b502c157ea18de15b81be6d'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='05d351f4-7637-4974-94c9-d3887f446563', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='c792e68b459df85112ee558e332a7f620038954c774b35b9ae33122bcfc3de41')}, hash='8ec6630dd10ce4c63e1bc3a18ba8664d8fe7c4c3f086ae154fd07a4633a51f75', text='Ontheotherhand,forpromptsbasedonfactualinformation,suchas“Whatisthecapitalof?” theSelf-BLEU\\nslopediminishesovertime. Thispatternsuggeststhatdespitetherisingtemperature,themodellearnsto\\nconsistently provide the same response to factual prompts.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-30'),\n",
              " '05d351f4-7637-4974-94c9-d3887f446563': IndexNode(id_='05d351f4-7637-4974-94c9-d3887f446563', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-30', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='a694eade310d000ca9f116f3012716e193bb4804f30e0e7b548ce191ec662096'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='1f055074-7257-4efd-be23-b9fdf81a2b87', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='8ec6630dd10ce4c63e1bc3a18ba8664d8fe7c4c3f086ae154fd07a4633a51f75'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='07aea1b6-7bbe-4141-886d-679acf7921ad', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='7875252b6310406452b1e9d7e3f5414725f9b92d98e2d3446d9f55086eaf8557')}, hash='c792e68b459df85112ee558e332a7f620038954c774b35b9ae33122bcfc3de41', text='32\\n\\n0.4 0.6 0.8 1.0 1.2 1.4\\nT emperature6065707580859095100Self-BLEU\\nFactual Prompts\\n0.4 0.6 0.8 1.0 1.2 1.4\\nT emperature\\nCreative Prompts\\nRLHF v3\\nRLHF v2\\nRLHF v1\\nSFTFigure 21: RLHF learns to adapt the temperature with regard to the type of prompt.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-30'),\n",
              " '07aea1b6-7bbe-4141-886d-679acf7921ad': IndexNode(id_='07aea1b6-7bbe-4141-886d-679acf7921ad', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-30', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='a694eade310d000ca9f116f3012716e193bb4804f30e0e7b548ce191ec662096'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='05d351f4-7637-4974-94c9-d3887f446563', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='c792e68b459df85112ee558e332a7f620038954c774b35b9ae33122bcfc3de41')}, hash='7875252b6310406452b1e9d7e3f5414725f9b92d98e2d3446d9f55086eaf8557', text='Lower Self-BLEU\\ncorresponds to more diversity: RLHF eliminates diversity in responses to factual prompts but retains more\\ndiversity when generating responses to creative prompts.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-30'),\n",
              " 'c904090c-de74-48b1-8dd9-5b8d5523639a': IndexNode(id_='c904090c-de74-48b1-8dd9-5b8d5523639a', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-30', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='a694eade310d000ca9f116f3012716e193bb4804f30e0e7b548ce191ec662096'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='e6abf147-6962-4d15-b59f-03d8482f5800', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='e14b9365e4dc23bc293fd4b8c16d381b8faa5e38113149b0af75cf45f3d1225e')}, hash='1c3f8c329cf359baed42af48ced1d643baf0d6fa5dbc172c6806961fd1910885', text='We then discuss the\\nlimitations of Llama 2-Chat (Section 5.2). Lastly, we present our strategy for responsibly releasing these\\nmodels (Section 5.3).\\n5.1 Learnings and Observations\\nOur tuning process revealed several interesting results, such as Llama 2-Chat ’s abilities to temporally\\norganize its knowledge, or to call APIs for external tools.\\nSFT (Mix)\\nSFT (Annotation)\\nRLHF (V1)\\n0.0 0.2 0.4 0.6 0.8 1.0\\nReward Model ScoreRLHF (V2)\\nFigure 20: Distribution shift for progressive versions of Llama 2-Chat , from SFT models towards RLHF.\\nBeyond Human Supervision. At the outset of the project, many among us expressed a preference for\\nsupervised annotation, attracted by its denser signal. Meanwhile reinforcement learning, known for its insta-\\nbility, seemed a somewhat shadowy field for those in the NLP research community. However, reinforcement\\nlearning proved highly effective, particularly given its cost and time effectiveness.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-30'),\n",
              " 'e6abf147-6962-4d15-b59f-03d8482f5800': IndexNode(id_='e6abf147-6962-4d15-b59f-03d8482f5800', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-30', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='a694eade310d000ca9f116f3012716e193bb4804f30e0e7b548ce191ec662096'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='c904090c-de74-48b1-8dd9-5b8d5523639a', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='1c3f8c329cf359baed42af48ced1d643baf0d6fa5dbc172c6806961fd1910885'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='aac76c89-bcce-4059-8210-9e41fe1f303e', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='c7badb47807d26776e495466ee957ddd7c4ef168ed8d00181bcae0b7abbe58a8')}, hash='e14b9365e4dc23bc293fd4b8c16d381b8faa5e38113149b0af75cf45f3d1225e', text='However, reinforcement\\nlearning proved highly effective, particularly given its cost and time effectiveness. Our findings underscore\\nthat the crucial determinant of RLHF’s success lies in the synergy it fosters between humans and LLMs\\nthroughout the annotation process.\\nEvenwithproficientannotators,eachindividualwriteswithsignificantvariation. Amodelfine-tunedon\\nSFTannotationlearnsthisdiversity,including,unfortunately,thetail-endofpoorlyexecutedannotation. Fur-\\nthermore, the model’s performance is capped by the writing abilities of the most skilled annotators. Human\\nannotators are arguably less subject to discrepancy when comparing two outputs’ preference annotation\\nforRLHF.Consequently,therewardmechanismswiftlylearnstoassignlowscorestoundesirabletail-end\\ndistribution and aligns towards the human preference. This phenomena is illustrated in Figure 20, where we\\ncan see that the worst answers are progressively removed, shifting the distribution to the right.\\nIn addition, during annotation, the model has the potential to venture into writing trajectories that even the\\nbestannotatorsmaynotchart.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-30'),\n",
              " 'aac76c89-bcce-4059-8210-9e41fe1f303e': IndexNode(id_='aac76c89-bcce-4059-8210-9e41fe1f303e', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-30', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='a694eade310d000ca9f116f3012716e193bb4804f30e0e7b548ce191ec662096'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='e6abf147-6962-4d15-b59f-03d8482f5800', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='e14b9365e4dc23bc293fd4b8c16d381b8faa5e38113149b0af75cf45f3d1225e'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='b6c4eb34-4786-45db-9601-1e7f2aed18d2', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='9d12eb13e4507e9698bce2267288fe75fb85b69c89a2492e2f87605b5ffd218f')}, hash='c7badb47807d26776e495466ee957ddd7c4ef168ed8d00181bcae0b7abbe58a8', text='Nonetheless,humanscanstillprovidevaluablefeedbackwhencomparingtwo\\nanswers, beyond their own writing competencies. Drawing a parallel, while we may not all be accomplished\\nartists, our ability to appreciate and critique art remains intact. We posit that the superior writing abilities of\\nLLMs, as manifested in surpassing human annotators in certain tasks, are fundamentally driven by RLHF, as\\ndocumented in Gilardi et al. (2023) and Huang et al. (2023). Supervised data may no longer be the gold\\nstandard, and this evolving circumstance compels a re-evaluation of the concept of “supervision.”\\nIn-ContextTemperatureRescaling. WehaveobservedanintriguingphenomenonrelatedtoRLHF,afeature\\nnotpreviouslyreportedtothebestofourknowledge: thedynamicre-scalingoftemperaturecontingentupon\\nthecontext. AsindicatedinFigure8,thetemperatureappearstobeinfluencedbyRLHF.Yet,intriguingly,\\nour findings also revealed that the shifts are not uniformly applied across all prompts, as shown in Figure 21.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-30'),\n",
              " 'b6c4eb34-4786-45db-9601-1e7f2aed18d2': IndexNode(id_='b6c4eb34-4786-45db-9601-1e7f2aed18d2', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-30', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='a694eade310d000ca9f116f3012716e193bb4804f30e0e7b548ce191ec662096'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='aac76c89-bcce-4059-8210-9e41fe1f303e', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='c7badb47807d26776e495466ee957ddd7c4ef168ed8d00181bcae0b7abbe58a8'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='9196ca54-c398-4f49-abb3-10cd882d7563', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='7875252b6310406452b1e9d7e3f5414725f9b92d98e2d3446d9f55086eaf8557')}, hash='9d12eb13e4507e9698bce2267288fe75fb85b69c89a2492e2f87605b5ffd218f', text='Forinstance,whenitcomestopromptsassociatedwithcreativity,suchas“Writeapoem,”anincreasein\\ntemperature continues to generate diversity across our various RLHF iterations. This can be observed in the\\nSelf-BLEU slope, which mirrors a pattern comparable to that of the SFT model.\\nOntheotherhand,forpromptsbasedonfactualinformation,suchas“Whatisthecapitalof?” theSelf-BLEU\\nslopediminishesovertime. Thispatternsuggeststhatdespitetherisingtemperature,themodellearnsto\\nconsistently provide the same response to factual prompts.\\n32\\n\\n0.4 0.6 0.8 1.0 1.2 1.4\\nT emperature6065707580859095100Self-BLEU\\nFactual Prompts\\n0.4 0.6 0.8 1.0 1.2 1.4\\nT emperature\\nCreative Prompts\\nRLHF v3\\nRLHF v2\\nRLHF v1\\nSFTFigure 21: RLHF learns to adapt the temperature with regard to the type of prompt.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-30'),\n",
              " '9196ca54-c398-4f49-abb3-10cd882d7563': IndexNode(id_='9196ca54-c398-4f49-abb3-10cd882d7563', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-30', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='a694eade310d000ca9f116f3012716e193bb4804f30e0e7b548ce191ec662096'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='b6c4eb34-4786-45db-9601-1e7f2aed18d2', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='9d12eb13e4507e9698bce2267288fe75fb85b69c89a2492e2f87605b5ffd218f')}, hash='7875252b6310406452b1e9d7e3f5414725f9b92d98e2d3446d9f55086eaf8557', text='Lower Self-BLEU\\ncorresponds to more diversity: RLHF eliminates diversity in responses to factual prompts but retains more\\ndiversity when generating responses to creative prompts.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-30'),\n",
              " '71ded4ac-6c44-4e97-a861-fea3a2ab6233': IndexNode(id_='71ded4ac-6c44-4e97-a861-fea3a2ab6233', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-30', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='a694eade310d000ca9f116f3012716e193bb4804f30e0e7b548ce191ec662096'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='ae3944ff-2723-4cf4-bc19-c0e91a29d4fd', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='e0a81e4ea4bf249d48797f4ffc739c8a0fed229aa1f70e038cf5a57e5d10652a')}, hash='d4de8048707560a34962570b3c2c977397c4ae27e9c18b1ca5db95e851d76e56', text='We then discuss the\\nlimitations of Llama 2-Chat (Section 5.2). Lastly, we present our strategy for responsibly releasing these\\nmodels (Section 5.3).\\n5.1 Learnings and Observations\\nOur tuning process revealed several interesting results, such as Llama 2-Chat ’s abilities to temporally\\norganize its knowledge, or to call APIs for external tools.\\nSFT (Mix)\\nSFT (Annotation)\\nRLHF (V1)\\n0.0 0.2 0.4 0.6 0.8 1.0\\nReward Model ScoreRLHF (V2)\\nFigure 20: Distribution shift for progressive versions of Llama 2-Chat , from SFT models towards RLHF.\\nBeyond Human Supervision. At the outset of the project, many among us expressed a preference for\\nsupervised annotation, attracted by its denser signal. Meanwhile reinforcement learning, known for its insta-\\nbility, seemed a somewhat shadowy field for those in the NLP research community. However, reinforcement\\nlearning proved highly effective, particularly given its cost and time effectiveness. Our findings underscore\\nthat the crucial determinant of RLHF’s success lies in the synergy it fosters between humans and LLMs\\nthroughout the annotation process.\\nEvenwithproficientannotators,eachindividualwriteswithsignificantvariation. Amodelfine-tunedon\\nSFTannotationlearnsthisdiversity,including,unfortunately,thetail-endofpoorlyexecutedannotation. Fur-\\nthermore, the model’s performance is capped by the writing abilities of the most skilled annotators. Human\\nannotators are arguably less subject to discrepancy when comparing two outputs’ preference annotation\\nforRLHF.Consequently,therewardmechanismswiftlylearnstoassignlowscorestoundesirabletail-end\\ndistribution and aligns towards the human preference. This phenomena is illustrated in Figure 20, where we\\ncan see that the worst answers are progressively removed, shifting the distribution to the right.\\nIn addition, during annotation, the model has the potential to venture into writing trajectories that even the\\nbestannotatorsmaynotchart. Nonetheless,humanscanstillprovidevaluablefeedbackwhencomparingtwo\\nanswers, beyond their own writing competencies.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-30'),\n",
              " 'ae3944ff-2723-4cf4-bc19-c0e91a29d4fd': IndexNode(id_='ae3944ff-2723-4cf4-bc19-c0e91a29d4fd', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-30', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='a694eade310d000ca9f116f3012716e193bb4804f30e0e7b548ce191ec662096'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='71ded4ac-6c44-4e97-a861-fea3a2ab6233', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='d4de8048707560a34962570b3c2c977397c4ae27e9c18b1ca5db95e851d76e56'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='07fa26d5-1a26-4405-b12f-6f8f30f5e661', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='7875252b6310406452b1e9d7e3f5414725f9b92d98e2d3446d9f55086eaf8557')}, hash='e0a81e4ea4bf249d48797f4ffc739c8a0fed229aa1f70e038cf5a57e5d10652a', text='Drawing a parallel, while we may not all be accomplished\\nartists, our ability to appreciate and critique art remains intact. We posit that the superior writing abilities of\\nLLMs, as manifested in surpassing human annotators in certain tasks, are fundamentally driven by RLHF, as\\ndocumented in Gilardi et al. (2023) and Huang et al. (2023). Supervised data may no longer be the gold\\nstandard, and this evolving circumstance compels a re-evaluation of the concept of “supervision.”\\nIn-ContextTemperatureRescaling. WehaveobservedanintriguingphenomenonrelatedtoRLHF,afeature\\nnotpreviouslyreportedtothebestofourknowledge: thedynamicre-scalingoftemperaturecontingentupon\\nthecontext. AsindicatedinFigure8,thetemperatureappearstobeinfluencedbyRLHF.Yet,intriguingly,\\nour findings also revealed that the shifts are not uniformly applied across all prompts, as shown in Figure 21.\\nForinstance,whenitcomestopromptsassociatedwithcreativity,suchas“Writeapoem,”anincreasein\\ntemperature continues to generate diversity across our various RLHF iterations. This can be observed in the\\nSelf-BLEU slope, which mirrors a pattern comparable to that of the SFT model.\\nOntheotherhand,forpromptsbasedonfactualinformation,suchas“Whatisthecapitalof?” theSelf-BLEU\\nslopediminishesovertime. Thispatternsuggeststhatdespitetherisingtemperature,themodellearnsto\\nconsistently provide the same response to factual prompts.\\n32\\n\\n0.4 0.6 0.8 1.0 1.2 1.4\\nT emperature6065707580859095100Self-BLEU\\nFactual Prompts\\n0.4 0.6 0.8 1.0 1.2 1.4\\nT emperature\\nCreative Prompts\\nRLHF v3\\nRLHF v2\\nRLHF v1\\nSFTFigure 21: RLHF learns to adapt the temperature with regard to the type of prompt.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-30'),\n",
              " '07fa26d5-1a26-4405-b12f-6f8f30f5e661': IndexNode(id_='07fa26d5-1a26-4405-b12f-6f8f30f5e661', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-30', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='a694eade310d000ca9f116f3012716e193bb4804f30e0e7b548ce191ec662096'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='ae3944ff-2723-4cf4-bc19-c0e91a29d4fd', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='e0a81e4ea4bf249d48797f4ffc739c8a0fed229aa1f70e038cf5a57e5d10652a')}, hash='7875252b6310406452b1e9d7e3f5414725f9b92d98e2d3446d9f55086eaf8557', text='Lower Self-BLEU\\ncorresponds to more diversity: RLHF eliminates diversity in responses to factual prompts but retains more\\ndiversity when generating responses to creative prompts.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-30'),\n",
              " 'node-30': IndexNode(id_='node-30', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='415b7efc-e73f-4ac4-bbfd-c1546f099026', node_type=<ObjectType.DOCUMENT: '4'>, metadata={}, hash='231b3bd773f012c01b893ada9e009ecf25ee59934614c5a595c9bf1b3a123292'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='0c2dd9aa-c1e3-4893-b155-fb4484aa49ca', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='531c43e09125fc31befe0377b54908e51877b900caa33a2e4025d4608ecc6579'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='6c10f8cb-ea27-4a14-8dbe-dd177390139d', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='7f57c341c1fb0e6031b27dee82789a5abb96223032a259bbf82901d9a15dec0d')}, hash='a694eade310d000ca9f116f3012716e193bb4804f30e0e7b548ce191ec662096', text='We then discuss the\\nlimitations of Llama 2-Chat (Section 5.2). Lastly, we present our strategy for responsibly releasing these\\nmodels (Section 5.3).\\n5.1 Learnings and Observations\\nOur tuning process revealed several interesting results, such as Llama 2-Chat ’s abilities to temporally\\norganize its knowledge, or to call APIs for external tools.\\nSFT (Mix)\\nSFT (Annotation)\\nRLHF (V1)\\n0.0 0.2 0.4 0.6 0.8 1.0\\nReward Model ScoreRLHF (V2)\\nFigure 20: Distribution shift for progressive versions of Llama 2-Chat , from SFT models towards RLHF.\\nBeyond Human Supervision. At the outset of the project, many among us expressed a preference for\\nsupervised annotation, attracted by its denser signal. Meanwhile reinforcement learning, known for its insta-\\nbility, seemed a somewhat shadowy field for those in the NLP research community. However, reinforcement\\nlearning proved highly effective, particularly given its cost and time effectiveness. Our findings underscore\\nthat the crucial determinant of RLHF’s success lies in the synergy it fosters between humans and LLMs\\nthroughout the annotation process.\\nEvenwithproficientannotators,eachindividualwriteswithsignificantvariation. Amodelfine-tunedon\\nSFTannotationlearnsthisdiversity,including,unfortunately,thetail-endofpoorlyexecutedannotation. Fur-\\nthermore, the model’s performance is capped by the writing abilities of the most skilled annotators. Human\\nannotators are arguably less subject to discrepancy when comparing two outputs’ preference annotation\\nforRLHF.Consequently,therewardmechanismswiftlylearnstoassignlowscorestoundesirabletail-end\\ndistribution and aligns towards the human preference. This phenomena is illustrated in Figure 20, where we\\ncan see that the worst answers are progressively removed, shifting the distribution to the right.\\nIn addition, during annotation, the model has the potential to venture into writing trajectories that even the\\nbestannotatorsmaynotchart. Nonetheless,humanscanstillprovidevaluablefeedbackwhencomparingtwo\\nanswers, beyond their own writing competencies. Drawing a parallel, while we may not all be accomplished\\nartists, our ability to appreciate and critique art remains intact. We posit that the superior writing abilities of\\nLLMs, as manifested in surpassing human annotators in certain tasks, are fundamentally driven by RLHF, as\\ndocumented in Gilardi et al. (2023) and Huang et al. (2023). Supervised data may no longer be the gold\\nstandard, and this evolving circumstance compels a re-evaluation of the concept of “supervision.”\\nIn-ContextTemperatureRescaling. WehaveobservedanintriguingphenomenonrelatedtoRLHF,afeature\\nnotpreviouslyreportedtothebestofourknowledge: thedynamicre-scalingoftemperaturecontingentupon\\nthecontext. AsindicatedinFigure8,thetemperatureappearstobeinfluencedbyRLHF.Yet,intriguingly,\\nour findings also revealed that the shifts are not uniformly applied across all prompts, as shown in Figure 21.\\nForinstance,whenitcomestopromptsassociatedwithcreativity,suchas“Writeapoem,”anincreasein\\ntemperature continues to generate diversity across our various RLHF iterations. This can be observed in the\\nSelf-BLEU slope, which mirrors a pattern comparable to that of the SFT model.\\nOntheotherhand,forpromptsbasedonfactualinformation,suchas“Whatisthecapitalof?” theSelf-BLEU\\nslopediminishesovertime. Thispatternsuggeststhatdespitetherisingtemperature,themodellearnsto\\nconsistently provide the same response to factual prompts.\\n32\\n\\n0.4 0.6 0.8 1.0 1.2 1.4\\nT emperature6065707580859095100Self-BLEU\\nFactual Prompts\\n0.4 0.6 0.8 1.0 1.2 1.4\\nT emperature\\nCreative Prompts\\nRLHF v3\\nRLHF v2\\nRLHF v1\\nSFTFigure 21: RLHF learns to adapt the temperature with regard to the type of prompt. Lower Self-BLEU\\ncorresponds to more diversity: RLHF eliminates diversity in responses to factual prompts but retains more\\ndiversity when generating responses to creative prompts.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-30'),\n",
              " '697ff2c6-f654-49c3-b53b-0a2e4ebf0f55': IndexNode(id_='697ff2c6-f654-49c3-b53b-0a2e4ebf0f55', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-31', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='7f57c341c1fb0e6031b27dee82789a5abb96223032a259bbf82901d9a15dec0d'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='4530c1b4-e7a1-46a0-b2c8-3d5e19dd05ec', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='a5fb546f0a342738d16df773f9f1c915cb47c64afb4c48f98edd42813d4ab34e')}, hash='e803ce9b729c546fa5ff86a13fb4d9d5977da1ba0337271c8a98d2e20677fae1', text='We prompt each model with a diverse set of\\n10 creative and 10 factual instructions and sample 25 responses. This is repeated for the temperatures\\nT∈ {k/10|k∈N: 1≤k≤15}. For each of the 25 responses we compute the Self-BLEU metric and report\\nthe mean and standard deviation against the temperature.\\nFigure 22: Time awareness — illustration of our model generalizing the notion of time, with 1,000 SFT\\ntime-focused data.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-31'),\n",
              " '4530c1b4-e7a1-46a0-b2c8-3d5e19dd05ec': IndexNode(id_='4530c1b4-e7a1-46a0-b2c8-3d5e19dd05ec', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-31', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='7f57c341c1fb0e6031b27dee82789a5abb96223032a259bbf82901d9a15dec0d'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='697ff2c6-f654-49c3-b53b-0a2e4ebf0f55', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='e803ce9b729c546fa5ff86a13fb4d9d5977da1ba0337271c8a98d2e20677fae1'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='f322693e-b472-4751-b330-dfd6c8ad015f', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='c614dcfba5887391eb75d06c463c988e806c0d5883e5921dc497d5a5aa33818c')}, hash='a5fb546f0a342738d16df773f9f1c915cb47c64afb4c48f98edd42813d4ab34e', text='Llama 2-Chat Temporal Perception Our model showcased impressive generalization ability, as shown in\\nFigure 22. We manually tested dozens of examples and observed consistently that our model demonstrates a\\nrobustcapabilitytoorganizeitsknowledgeinatemporalmanner,evenwhenprovidedwithminimaldata. To\\ninstillaconceptoftimein Llama 2-Chat ,wecollectedasetof1,000SFTexamplesthatwererelatedtospecific\\ndates.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-31'),\n",
              " 'f322693e-b472-4751-b330-dfd6c8ad015f': IndexNode(id_='f322693e-b472-4751-b330-dfd6c8ad015f', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-31', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='7f57c341c1fb0e6031b27dee82789a5abb96223032a259bbf82901d9a15dec0d'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='4530c1b4-e7a1-46a0-b2c8-3d5e19dd05ec', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='a5fb546f0a342738d16df773f9f1c915cb47c64afb4c48f98edd42813d4ab34e'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='6cd50c5d-3ca6-4862-b358-259255fc67aa', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='1fe2a5eca7cd15d72ae04b7b3cfe97d34882839544864f4ca343d0ced43bfcf8')}, hash='c614dcfba5887391eb75d06c463c988e806c0d5883e5921dc497d5a5aa33818c', text='Theseexamplesincludedquestionslike “Howlongago didBarackObama becomepresident?” Eachwas\\nassociated with two critical pieces of metadata: the date when the query was posed — which influenced the\\nresponse — and the event date, a point in time prior to which the question would be nonsensical.\\nThe observation suggests that LLMs have internalized the concept of time to a greater extent than previously\\nassumed,despitetheirtrainingbeingsolelybasedonnext-tokenpredictionanddatathatisrandomlyshuffled\\nwithout regard to their chronological context.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-31'),\n",
              " '6cd50c5d-3ca6-4862-b358-259255fc67aa': IndexNode(id_='6cd50c5d-3ca6-4862-b358-259255fc67aa', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-31', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='7f57c341c1fb0e6031b27dee82789a5abb96223032a259bbf82901d9a15dec0d'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='f322693e-b472-4751-b330-dfd6c8ad015f', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='c614dcfba5887391eb75d06c463c988e806c0d5883e5921dc497d5a5aa33818c'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='b734beec-90d8-430c-84c1-67974c9bbd58', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='586bb2b5e01ef0fb89c04519aa39c1465b54d27193c4229b4c68515712efa17f')}, hash='1fe2a5eca7cd15d72ae04b7b3cfe97d34882839544864f4ca343d0ced43bfcf8', text='Tool Use Emergence The integration of LLMs with tools is a growing research area, as highlighted in\\nMialonetal.(2023). TheapproachdevisedinToolformer(Schicketal.2023)entailsthesamplingofmillions\\n33\\n\\nModel ASDiv SVAMP MAWPS\\nOPT-66B 6.0 4.9 7.9\\nGPT-J 7.5 5.2 9.9\\nGPT-J + CC 9.6 5.0 9.3\\nGPT-3 14.0 10.0 19.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-31'),\n",
              " 'b734beec-90d8-430c-84c1-67974c9bbd58': IndexNode(id_='b734beec-90d8-430c-84c1-67974c9bbd58', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-31', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='7f57c341c1fb0e6031b27dee82789a5abb96223032a259bbf82901d9a15dec0d'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='6cd50c5d-3ca6-4862-b358-259255fc67aa', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='1fe2a5eca7cd15d72ae04b7b3cfe97d34882839544864f4ca343d0ced43bfcf8'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='b9bb70f8-0c7b-4bb4-8e90-5f7558643790', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='ed3fc39b24449ad913fb710671c5caf1ed8ded706202dd0a521c1ffdf75f2ac7')}, hash='586bb2b5e01ef0fb89c04519aa39c1465b54d27193c4229b4c68515712efa17f', text='6 5.0 9.3\\nGPT-3 14.0 10.0 19.8\\nToolformer 40.4 29.4 44.0\\nLlama 2-Chat 67.1 69.2 82.4\\nTable 15: Performance with tool use. Evaluation on the math datasets used in Toolformer. For different\\nbaselines, we report the scores from Schick et al. (2023).\\nof trajectories, complemented by the formulation of few-shot examples for each tool.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-31'),\n",
              " 'b9bb70f8-0c7b-4bb4-8e90-5f7558643790': IndexNode(id_='b9bb70f8-0c7b-4bb4-8e90-5f7558643790', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-31', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='7f57c341c1fb0e6031b27dee82789a5abb96223032a259bbf82901d9a15dec0d'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='b734beec-90d8-430c-84c1-67974c9bbd58', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='586bb2b5e01ef0fb89c04519aa39c1465b54d27193c4229b4c68515712efa17f'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='c9e3468f-1a9e-4237-8982-46d990073589', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='6c8557c2a23a85c6a4b0a0ebcf13abcbb98474d5269da47f61691d32181a7b7a')}, hash='ed3fc39b24449ad913fb710671c5caf1ed8ded706202dd0a521c1ffdf75f2ac7', text='of trajectories, complemented by the formulation of few-shot examples for each tool. Nonetheless, this\\ntechniquewasonlyappliedusingasingletoolperexample,andwouldnotscaleforasequenceoftoolusage.\\nFigure23: Tooluseemergence. Llama 2-Chat isabletounderstandthetools’sapplications,andtheAPI\\narguments, just through the semantics, despite never having been trained to use tools.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-31'),\n",
              " 'c9e3468f-1a9e-4237-8982-46d990073589': IndexNode(id_='c9e3468f-1a9e-4237-8982-46d990073589', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-31', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='7f57c341c1fb0e6031b27dee82789a5abb96223032a259bbf82901d9a15dec0d'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='b9bb70f8-0c7b-4bb4-8e90-5f7558643790', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='ed3fc39b24449ad913fb710671c5caf1ed8ded706202dd0a521c1ffdf75f2ac7'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='66b1def1-380d-4574-80f7-7d40cdb212f2', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='11f73e6085aade6573069976a94b356a19e8b127313b5458385942093a9a0592')}, hash='6c8557c2a23a85c6a4b0a0ebcf13abcbb98474d5269da47f61691d32181a7b7a', text='The release of OpenAI’s plugins‡‡has incited substantial discourse within the academic community, igniting\\nquestions such as: How can we effectively teach models to utilizetools? orDoes the processnecessitate a substantial\\ndataset?Our experiments indicate that tool usage can spontaneously emerge from alignment in a zero-shot\\nmanner. Although we never explicitly annotate tool-use usage, Figure 23 exhibits an instance where the\\nmodel demonstrated the capability to utilize a sequence of tools in a zero-shot context.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-31'),\n",
              " '66b1def1-380d-4574-80f7-7d40cdb212f2': IndexNode(id_='66b1def1-380d-4574-80f7-7d40cdb212f2', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-31', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='7f57c341c1fb0e6031b27dee82789a5abb96223032a259bbf82901d9a15dec0d'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='c9e3468f-1a9e-4237-8982-46d990073589', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='6c8557c2a23a85c6a4b0a0ebcf13abcbb98474d5269da47f61691d32181a7b7a'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='6a14148b-3c30-4550-87cd-718f466210f1', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='135dc6fe14e07782ea6891b25e3a8710491b5aa9fe46c7c0de4fe5c0a95ce5c3')}, hash='11f73e6085aade6573069976a94b356a19e8b127313b5458385942093a9a0592', text='In addition, our study extended to evaluating the Llama 2-Chat with access to a calculator. The results from\\nthisparticularexperimentaredocumentedinTable15. LLMtooluse,whileexciting,canalsocausesome\\nsafety concerns. We encourage more community research and red teaming in this area.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-31'),\n",
              " '6a14148b-3c30-4550-87cd-718f466210f1': IndexNode(id_='6a14148b-3c30-4550-87cd-718f466210f1', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-31', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='7f57c341c1fb0e6031b27dee82789a5abb96223032a259bbf82901d9a15dec0d'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='66b1def1-380d-4574-80f7-7d40cdb212f2', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='11f73e6085aade6573069976a94b356a19e8b127313b5458385942093a9a0592'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='28f0b3f9-595a-4508-86b4-1c6fd372fb7c', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='65040caa2bccac0331595ef69f476e0d6dc4f1c653c7155ca457b5391b35d0c3')}, hash='135dc6fe14e07782ea6891b25e3a8710491b5aa9fe46c7c0de4fe5c0a95ce5c3', text='We encourage more community research and red teaming in this area.\\n5.2 Limitations and Ethical Considerations\\nLlama 2-Chat is subject to the same well-recognized limitations of other LLMs, including a cessation of\\nknowledge updates post-pretraining, potential for non-factual generation such as unqualified advice, and a\\npropensity towards hallucinations.\\nFurthermore,ourinitialversionof Llama 2-Chat predominantlyconcentratedonEnglish-languagedata.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-31'),\n",
              " '28f0b3f9-595a-4508-86b4-1c6fd372fb7c': IndexNode(id_='28f0b3f9-595a-4508-86b4-1c6fd372fb7c', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-31', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='7f57c341c1fb0e6031b27dee82789a5abb96223032a259bbf82901d9a15dec0d'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='6a14148b-3c30-4550-87cd-718f466210f1', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='135dc6fe14e07782ea6891b25e3a8710491b5aa9fe46c7c0de4fe5c0a95ce5c3')}, hash='65040caa2bccac0331595ef69f476e0d6dc4f1c653c7155ca457b5391b35d0c3', text='While our experimental observations suggestthe model has garnered some proficiency in other languages,\\nitsproficiencyislimited,dueprimarilytothelimitedamountofpretrainingdataavailableinnon-English\\nlanguages(asdocumentedinTable10). Consequently,themodel’sperformanceinlanguagesotherthan\\nEnglish remains fragile and should be used with caution.\\nLike other LLMs, Llama 2 may generate harmful, offensive, or biased content due to its training on publicly\\navailable online datasets.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-31'),\n",
              " '47c3977d-b50a-4d9c-a0b5-67fc18288aee': IndexNode(id_='47c3977d-b50a-4d9c-a0b5-67fc18288aee', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-31', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='7f57c341c1fb0e6031b27dee82789a5abb96223032a259bbf82901d9a15dec0d'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='bfd066be-627c-4ac9-afae-1e6409663be7', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='99ed9acf00d922a1dbc690507ec1618c76111827469f05212bc7fb60015d2189')}, hash='58dcc690764ff68686488b3c4e9eebccba7fdc5514005bd5bdf8827e80cddb9a', text='We prompt each model with a diverse set of\\n10 creative and 10 factual instructions and sample 25 responses. This is repeated for the temperatures\\nT∈ {k/10|k∈N: 1≤k≤15}. For each of the 25 responses we compute the Self-BLEU metric and report\\nthe mean and standard deviation against the temperature.\\nFigure 22: Time awareness — illustration of our model generalizing the notion of time, with 1,000 SFT\\ntime-focused data.\\nLlama 2-Chat Temporal Perception Our model showcased impressive generalization ability, as shown in\\nFigure 22. We manually tested dozens of examples and observed consistently that our model demonstrates a\\nrobustcapabilitytoorganizeitsknowledgeinatemporalmanner,evenwhenprovidedwithminimaldata. To\\ninstillaconceptoftimein Llama 2-Chat ,wecollectedasetof1,000SFTexamplesthatwererelatedtospecific\\ndates.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-31'),\n",
              " 'bfd066be-627c-4ac9-afae-1e6409663be7': IndexNode(id_='bfd066be-627c-4ac9-afae-1e6409663be7', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-31', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='7f57c341c1fb0e6031b27dee82789a5abb96223032a259bbf82901d9a15dec0d'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='47c3977d-b50a-4d9c-a0b5-67fc18288aee', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='58dcc690764ff68686488b3c4e9eebccba7fdc5514005bd5bdf8827e80cddb9a'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='7d62c79d-5bf7-4f8d-9efb-8ec79dd0bf34', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='54992e8b3613bf0c5138cb1432c7be0cb932962c50895401271eef848f377cca')}, hash='99ed9acf00d922a1dbc690507ec1618c76111827469f05212bc7fb60015d2189', text='Theseexamplesincludedquestionslike “Howlongago didBarackObama becomepresident?” Eachwas\\nassociated with two critical pieces of metadata: the date when the query was posed — which influenced the\\nresponse — and the event date, a point in time prior to which the question would be nonsensical.\\nThe observation suggests that LLMs have internalized the concept of time to a greater extent than previously\\nassumed,despitetheirtrainingbeingsolelybasedonnext-tokenpredictionanddatathatisrandomlyshuffled\\nwithout regard to their chronological context.\\nTool Use Emergence The integration of LLMs with tools is a growing research area, as highlighted in\\nMialonetal.(2023).', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-31'),\n",
              " '7d62c79d-5bf7-4f8d-9efb-8ec79dd0bf34': IndexNode(id_='7d62c79d-5bf7-4f8d-9efb-8ec79dd0bf34', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-31', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='7f57c341c1fb0e6031b27dee82789a5abb96223032a259bbf82901d9a15dec0d'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='bfd066be-627c-4ac9-afae-1e6409663be7', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='99ed9acf00d922a1dbc690507ec1618c76111827469f05212bc7fb60015d2189'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='2b5b5c44-7191-4b99-a342-d4a38df1bc86', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='603ee1fcdf83addfd56ef9f194f6266b31cc68ddbe77bc3f4d5f323b4ec89d45')}, hash='54992e8b3613bf0c5138cb1432c7be0cb932962c50895401271eef848f377cca', text='TheapproachdevisedinToolformer(Schicketal.,2023)entailsthesamplingofmillions\\n33\\n\\nModel ASDiv SVAMP MAWPS\\nOPT-66B 6.0 4.9 7.9\\nGPT-J 7.5 5.2 9.9\\nGPT-J + CC 9.6 5.0 9.3\\nGPT-3 14.0 10.0 19.8\\nToolformer 40.4 29.4 44.0\\nLlama 2-Chat 67.1 69.2 82.4\\nTable 15: Performance with tool use. Evaluation on the math datasets used in Toolformer. For different\\nbaselines, we report the scores from Schick et al. (2023).\\nof trajectories, complemented by the formulation of few-shot examples for each tool. Nonetheless, this\\ntechniquewasonlyappliedusingasingletoolperexample,andwouldnotscaleforasequenceoftoolusage.\\nFigure23: Tooluseemergence.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-31'),\n",
              " '2b5b5c44-7191-4b99-a342-d4a38df1bc86': IndexNode(id_='2b5b5c44-7191-4b99-a342-d4a38df1bc86', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-31', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='7f57c341c1fb0e6031b27dee82789a5abb96223032a259bbf82901d9a15dec0d'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='7d62c79d-5bf7-4f8d-9efb-8ec79dd0bf34', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='54992e8b3613bf0c5138cb1432c7be0cb932962c50895401271eef848f377cca'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='ff661cd2-6d35-45a3-859d-5215d6dda228', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='fbf2d2725861add456f51354e582a039ea9f48726b5ef8fea0feea14a457d7cd')}, hash='603ee1fcdf83addfd56ef9f194f6266b31cc68ddbe77bc3f4d5f323b4ec89d45', text='Figure23: Tooluseemergence. Llama 2-Chat isabletounderstandthetools’sapplications,andtheAPI\\narguments, just through the semantics, despite never having been trained to use tools.\\nThe release of OpenAI’s plugins‡‡has incited substantial discourse within the academic community, igniting\\nquestions such as: How can we effectively teach models to utilizetools? orDoes the processnecessitate a substantial\\ndataset?Our experiments indicate that tool usage can spontaneously emerge from alignment in a zero-shot\\nmanner. Although we never explicitly annotate tool-use usage, Figure 23 exhibits an instance where the\\nmodel demonstrated the capability to utilize a sequence of tools in a zero-shot context.\\nIn addition, our study extended to evaluating the Llama 2-Chat with access to a calculator. The results from\\nthisparticularexperimentaredocumentedinTable15. LLMtooluse,whileexciting,canalsocausesome\\nsafety concerns. We encourage more community research and red teaming in this area.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-31'),\n",
              " 'ff661cd2-6d35-45a3-859d-5215d6dda228': IndexNode(id_='ff661cd2-6d35-45a3-859d-5215d6dda228', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-31', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='7f57c341c1fb0e6031b27dee82789a5abb96223032a259bbf82901d9a15dec0d'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='2b5b5c44-7191-4b99-a342-d4a38df1bc86', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='603ee1fcdf83addfd56ef9f194f6266b31cc68ddbe77bc3f4d5f323b4ec89d45')}, hash='fbf2d2725861add456f51354e582a039ea9f48726b5ef8fea0feea14a457d7cd', text='We encourage more community research and red teaming in this area.\\n5.2 Limitations and Ethical Considerations\\nLlama 2-Chat is subject to the same well-recognized limitations of other LLMs, including a cessation of\\nknowledge updates post-pretraining, potential for non-factual generation such as unqualified advice, and a\\npropensity towards hallucinations.\\nFurthermore,ourinitialversionof Llama 2-Chat predominantlyconcentratedonEnglish-languagedata.\\nWhile our experimental observations suggestthe model has garnered some proficiency in other languages,\\nitsproficiencyislimited,dueprimarilytothelimitedamountofpretrainingdataavailableinnon-English\\nlanguages(asdocumentedinTable10). Consequently,themodel’sperformanceinlanguagesotherthan\\nEnglish remains fragile and should be used with caution.\\nLike other LLMs, Llama 2 may generate harmful, offensive, or biased content due to its training on publicly\\navailable online datasets.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-31'),\n",
              " '0b31d6db-351f-4137-9525-38d8651bcf42': IndexNode(id_='0b31d6db-351f-4137-9525-38d8651bcf42', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-31', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='7f57c341c1fb0e6031b27dee82789a5abb96223032a259bbf82901d9a15dec0d'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='1c32c690-a789-4826-964f-65dd95526066', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='5003dfc63f5a7309904a4f6c587cf7fe94f10d0fab53a41a5e3f1fa80737a957')}, hash='849010d23c99c0b51928ea2bdb94cf1a8ca7f28a40726edab1fa93e1e33974c5', text='We prompt each model with a diverse set of\\n10 creative and 10 factual instructions and sample 25 responses. This is repeated for the temperatures\\nT∈ {k/10|k∈N: 1≤k≤15}. For each of the 25 responses we compute the Self-BLEU metric and report\\nthe mean and standard deviation against the temperature.\\nFigure 22: Time awareness — illustration of our model generalizing the notion of time, with 1,000 SFT\\ntime-focused data.\\nLlama 2-Chat Temporal Perception Our model showcased impressive generalization ability, as shown in\\nFigure 22. We manually tested dozens of examples and observed consistently that our model demonstrates a\\nrobustcapabilitytoorganizeitsknowledgeinatemporalmanner,evenwhenprovidedwithminimaldata. To\\ninstillaconceptoftimein Llama 2-Chat ,wecollectedasetof1,000SFTexamplesthatwererelatedtospecific\\ndates. Theseexamplesincludedquestionslike “Howlongago didBarackObama becomepresident?” Eachwas\\nassociated with two critical pieces of metadata: the date when the query was posed — which influenced the\\nresponse — and the event date, a point in time prior to which the question would be nonsensical.\\nThe observation suggests that LLMs have internalized the concept of time to a greater extent than previously\\nassumed,despitetheirtrainingbeingsolelybasedonnext-tokenpredictionanddatathatisrandomlyshuffled\\nwithout regard to their chronological context.\\nTool Use Emergence The integration of LLMs with tools is a growing research area, as highlighted in\\nMialonetal.(2023). TheapproachdevisedinToolformer(Schicketal.,2023)entailsthesamplingofmillions\\n33\\n\\nModel ASDiv SVAMP MAWPS\\nOPT-66B 6.0 4.9 7.9\\nGPT-J 7.5 5.2 9.9\\nGPT-J + CC 9.6 5.0 9.3\\nGPT-3 14.0 10.0 19.8\\nToolformer 40.4 29.4 44.0\\nLlama 2-Chat 67.1 69.2 82.4\\nTable 15: Performance with tool use.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-31'),\n",
              " '1c32c690-a789-4826-964f-65dd95526066': IndexNode(id_='1c32c690-a789-4826-964f-65dd95526066', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-31', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='7f57c341c1fb0e6031b27dee82789a5abb96223032a259bbf82901d9a15dec0d'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='0b31d6db-351f-4137-9525-38d8651bcf42', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='849010d23c99c0b51928ea2bdb94cf1a8ca7f28a40726edab1fa93e1e33974c5'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='d8a54029-62a5-4bf2-9346-6fcfb8fa428f', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='9918059237ad8ef1e064d50221d526b0e2f34ffd94d9ea2ae92133e1c4ce18e2')}, hash='5003dfc63f5a7309904a4f6c587cf7fe94f10d0fab53a41a5e3f1fa80737a957', text='Evaluation on the math datasets used in Toolformer. For different\\nbaselines, we report the scores from Schick et al. (2023).\\nof trajectories, complemented by the formulation of few-shot examples for each tool. Nonetheless, this\\ntechniquewasonlyappliedusingasingletoolperexample,andwouldnotscaleforasequenceoftoolusage.\\nFigure23: Tooluseemergence. Llama 2-Chat isabletounderstandthetools’sapplications,andtheAPI\\narguments, just through the semantics, despite never having been trained to use tools.\\nThe release of OpenAI’s plugins‡‡has incited substantial discourse within the academic community, igniting\\nquestions such as: How can we effectively teach models to utilizetools? orDoes the processnecessitate a substantial\\ndataset?Our experiments indicate that tool usage can spontaneously emerge from alignment in a zero-shot\\nmanner. Although we never explicitly annotate tool-use usage, Figure 23 exhibits an instance where the\\nmodel demonstrated the capability to utilize a sequence of tools in a zero-shot context.\\nIn addition, our study extended to evaluating the Llama 2-Chat with access to a calculator. The results from\\nthisparticularexperimentaredocumentedinTable15. LLMtooluse,whileexciting,canalsocausesome\\nsafety concerns. We encourage more community research and red teaming in this area.\\n5.2 Limitations and Ethical Considerations\\nLlama 2-Chat is subject to the same well-recognized limitations of other LLMs, including a cessation of\\nknowledge updates post-pretraining, potential for non-factual generation such as unqualified advice, and a\\npropensity towards hallucinations.\\nFurthermore,ourinitialversionof Llama 2-Chat predominantlyconcentratedonEnglish-languagedata.\\nWhile our experimental observations suggestthe model has garnered some proficiency in other languages,\\nitsproficiencyislimited,dueprimarilytothelimitedamountofpretrainingdataavailableinnon-English\\nlanguages(asdocumentedinTable10). Consequently,themodel’sperformanceinlanguagesotherthan\\nEnglish remains fragile and should be used with caution.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-31'),\n",
              " 'd8a54029-62a5-4bf2-9346-6fcfb8fa428f': IndexNode(id_='d8a54029-62a5-4bf2-9346-6fcfb8fa428f', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-31', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='7f57c341c1fb0e6031b27dee82789a5abb96223032a259bbf82901d9a15dec0d'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='1c32c690-a789-4826-964f-65dd95526066', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='5003dfc63f5a7309904a4f6c587cf7fe94f10d0fab53a41a5e3f1fa80737a957')}, hash='9918059237ad8ef1e064d50221d526b0e2f34ffd94d9ea2ae92133e1c4ce18e2', text='Like other LLMs, Llama 2 may generate harmful, offensive, or biased content due to its training on publicly\\navailable online datasets.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-31'),\n",
              " 'node-31': IndexNode(id_='node-31', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='415b7efc-e73f-4ac4-bbfd-c1546f099026', node_type=<ObjectType.DOCUMENT: '4'>, metadata={}, hash='231b3bd773f012c01b893ada9e009ecf25ee59934614c5a595c9bf1b3a123292'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='a92a0f1c-074e-4d8f-b30d-5fe748dd9c59', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='a694eade310d000ca9f116f3012716e193bb4804f30e0e7b548ce191ec662096'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='3130d7bc-01b4-4ddc-93f4-f05aced07547', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='605c4bb1c73b7df5fc2d6252477bd11755380b1806702dbfb94fe3cd909358ab')}, hash='7f57c341c1fb0e6031b27dee82789a5abb96223032a259bbf82901d9a15dec0d', text='We prompt each model with a diverse set of\\n10 creative and 10 factual instructions and sample 25 responses. This is repeated for the temperatures\\nT∈ {k/10|k∈N: 1≤k≤15}. For each of the 25 responses we compute the Self-BLEU metric and report\\nthe mean and standard deviation against the temperature.\\nFigure 22: Time awareness — illustration of our model generalizing the notion of time, with 1,000 SFT\\ntime-focused data.\\nLlama 2-Chat Temporal Perception Our model showcased impressive generalization ability, as shown in\\nFigure 22. We manually tested dozens of examples and observed consistently that our model demonstrates a\\nrobustcapabilitytoorganizeitsknowledgeinatemporalmanner,evenwhenprovidedwithminimaldata. To\\ninstillaconceptoftimein Llama 2-Chat ,wecollectedasetof1,000SFTexamplesthatwererelatedtospecific\\ndates. Theseexamplesincludedquestionslike “Howlongago didBarackObama becomepresident?” Eachwas\\nassociated with two critical pieces of metadata: the date when the query was posed — which influenced the\\nresponse — and the event date, a point in time prior to which the question would be nonsensical.\\nThe observation suggests that LLMs have internalized the concept of time to a greater extent than previously\\nassumed,despitetheirtrainingbeingsolelybasedonnext-tokenpredictionanddatathatisrandomlyshuffled\\nwithout regard to their chronological context.\\nTool Use Emergence The integration of LLMs with tools is a growing research area, as highlighted in\\nMialonetal.(2023). TheapproachdevisedinToolformer(Schicketal.,2023)entailsthesamplingofmillions\\n33\\n\\nModel ASDiv SVAMP MAWPS\\nOPT-66B 6.0 4.9 7.9\\nGPT-J 7.5 5.2 9.9\\nGPT-J + CC 9.6 5.0 9.3\\nGPT-3 14.0 10.0 19.8\\nToolformer 40.4 29.4 44.0\\nLlama 2-Chat 67.1 69.2 82.4\\nTable 15: Performance with tool use. Evaluation on the math datasets used in Toolformer. For different\\nbaselines, we report the scores from Schick et al. (2023).\\nof trajectories, complemented by the formulation of few-shot examples for each tool. Nonetheless, this\\ntechniquewasonlyappliedusingasingletoolperexample,andwouldnotscaleforasequenceoftoolusage.\\nFigure23: Tooluseemergence. Llama 2-Chat isabletounderstandthetools’sapplications,andtheAPI\\narguments, just through the semantics, despite never having been trained to use tools.\\nThe release of OpenAI’s plugins‡‡has incited substantial discourse within the academic community, igniting\\nquestions such as: How can we effectively teach models to utilizetools? orDoes the processnecessitate a substantial\\ndataset?Our experiments indicate that tool usage can spontaneously emerge from alignment in a zero-shot\\nmanner. Although we never explicitly annotate tool-use usage, Figure 23 exhibits an instance where the\\nmodel demonstrated the capability to utilize a sequence of tools in a zero-shot context.\\nIn addition, our study extended to evaluating the Llama 2-Chat with access to a calculator. The results from\\nthisparticularexperimentaredocumentedinTable15. LLMtooluse,whileexciting,canalsocausesome\\nsafety concerns. We encourage more community research and red teaming in this area.\\n5.2 Limitations and Ethical Considerations\\nLlama 2-Chat is subject to the same well-recognized limitations of other LLMs, including a cessation of\\nknowledge updates post-pretraining, potential for non-factual generation such as unqualified advice, and a\\npropensity towards hallucinations.\\nFurthermore,ourinitialversionof Llama 2-Chat predominantlyconcentratedonEnglish-languagedata.\\nWhile our experimental observations suggestthe model has garnered some proficiency in other languages,\\nitsproficiencyislimited,dueprimarilytothelimitedamountofpretrainingdataavailableinnon-English\\nlanguages(asdocumentedinTable10). Consequently,themodel’sperformanceinlanguagesotherthan\\nEnglish remains fragile and should be used with caution.\\nLike other LLMs, Llama 2 may generate harmful, offensive, or biased content due to its training on publicly\\navailable online datasets.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-31'),\n",
              " '17bca1e6-8994-4582-962c-d6689d5cd9e1': IndexNode(id_='17bca1e6-8994-4582-962c-d6689d5cd9e1', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-32', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='605c4bb1c73b7df5fc2d6252477bd11755380b1806702dbfb94fe3cd909358ab'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='6c666123-57d4-4595-a40c-c003991e6f3e', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='66c0a67b56c3348e8a2b7a7e0f43880ca5dc945eca7a4449e358589bf50b00c4')}, hash='7732b6eacc5d908d979d4249b670ad2a305722450be77489a77cdc02d217e92f', text='We attempted to mitigate this via fine-tuning, but some issues may remain,\\nparticularlyforlanguagesotherthanEnglish wherepubliclyavailable datasetswerenotavailable. Wewill\\ncontinue to fine-tune and release updated versions in the future as we progress on addressing these issues.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-32'),\n",
              " '6c666123-57d4-4595-a40c-c003991e6f3e': IndexNode(id_='6c666123-57d4-4595-a40c-c003991e6f3e', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-32', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='605c4bb1c73b7df5fc2d6252477bd11755380b1806702dbfb94fe3cd909358ab'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='17bca1e6-8994-4582-962c-d6689d5cd9e1', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='7732b6eacc5d908d979d4249b670ad2a305722450be77489a77cdc02d217e92f'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='3a5c3c4e-2509-4e82-9481-5c65750000ea', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='23b4e3f7b4f18ab5feb953b6b00d271f2c0dcdc27695edb2df8d893966fbc656')}, hash='66c0a67b56c3348e8a2b7a7e0f43880ca5dc945eca7a4449e358589bf50b00c4', text='‡‡https://openai.com/blog/chatgpt-plugins\\n34\\n\\nNoteveryonewhousesAImodelshasgoodintentions,andconversationalAIagentscouldpotentiallybe\\nusedfornefariouspurposessuchasgeneratingmisinformationorretrievinginformationabouttopicslike\\nbioterrorism or cybercrime. We have, however, made efforts to tune the models to avoid these topics and\\ndiminish any capabilities they might have offered for those use cases.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-32'),\n",
              " '3a5c3c4e-2509-4e82-9481-5c65750000ea': IndexNode(id_='3a5c3c4e-2509-4e82-9481-5c65750000ea', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-32', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='605c4bb1c73b7df5fc2d6252477bd11755380b1806702dbfb94fe3cd909358ab'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='6c666123-57d4-4595-a40c-c003991e6f3e', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='66c0a67b56c3348e8a2b7a7e0f43880ca5dc945eca7a4449e358589bf50b00c4'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='3b06b9a1-6a59-44cd-b156-1b622d97697b', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='4aea290dc6a850ef6bd50efac3771e7801e15b00b1cf6d5dceffd17480855946')}, hash='23b4e3f7b4f18ab5feb953b6b00d271f2c0dcdc27695edb2df8d893966fbc656', text='While we attempted to reasonably balance safety with helpfulness, in some instances, our safety tuning goes\\ntoo far. Users of Llama 2-Chat may observe an overly cautious approach, with the model erring on the side\\nof declining certain requests or responding with too many safety details.\\nUsersofthepretrainedmodelsneedtobeparticularlycautious,andshouldtakeextrastepsintuningand\\ndeployment as described in our Responsible Use Guide.§§\\n5.3 Responsible Release Strategy\\nReleaseDetails.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-32'),\n",
              " '3b06b9a1-6a59-44cd-b156-1b622d97697b': IndexNode(id_='3b06b9a1-6a59-44cd-b156-1b622d97697b', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-32', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='605c4bb1c73b7df5fc2d6252477bd11755380b1806702dbfb94fe3cd909358ab'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='3a5c3c4e-2509-4e82-9481-5c65750000ea', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='23b4e3f7b4f18ab5feb953b6b00d271f2c0dcdc27695edb2df8d893966fbc656'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='458ed029-2806-49fb-8fe6-77cb28a46f88', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='b705286d7941c395b0257c757eba8ee17bc695b2875c756878e3bcd510556e96')}, hash='4aea290dc6a850ef6bd50efac3771e7801e15b00b1cf6d5dceffd17480855946', text='Wemake Llama 2 availableforbothresearchandcommercialuseat https://ai.meta.\\ncom/resources/models-and-libraries/llama/ . Thosewhouse Llama 2 mustcomplywiththetermsof\\nthe provided license and our Acceptable Use Policy , which prohibit any uses that would violate applicable\\npolicies, laws, rules, and regulations.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-32'),\n",
              " '458ed029-2806-49fb-8fe6-77cb28a46f88': IndexNode(id_='458ed029-2806-49fb-8fe6-77cb28a46f88', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-32', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='605c4bb1c73b7df5fc2d6252477bd11755380b1806702dbfb94fe3cd909358ab'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='3b06b9a1-6a59-44cd-b156-1b622d97697b', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='4aea290dc6a850ef6bd50efac3771e7801e15b00b1cf6d5dceffd17480855946'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='253616af-4fec-4fed-8092-f92f8187a076', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='beccf14de23cd2293ca246bd3f35b890111711860b3634dcd7ce0bf891ec9608')}, hash='b705286d7941c395b0257c757eba8ee17bc695b2875c756878e3bcd510556e96', text='Wealsoprovidecodeexamplestohelpdevelopersreplicateoursafegenerationswith Llama 2-Chat and\\napplybasicsafetytechniquesattheuserinputandmodeloutputlayers. Thesecodesamplesareavailable\\nhere: https://github.com/facebookresearch/llama . Finally,wearesharinga ResponsibleUseGuide ,which\\nprovides guidelines regarding safe development and deployment.\\nResponsibleRelease.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-32'),\n",
              " '253616af-4fec-4fed-8092-f92f8187a076': IndexNode(id_='253616af-4fec-4fed-8092-f92f8187a076', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-32', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='605c4bb1c73b7df5fc2d6252477bd11755380b1806702dbfb94fe3cd909358ab'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='458ed029-2806-49fb-8fe6-77cb28a46f88', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='b705286d7941c395b0257c757eba8ee17bc695b2875c756878e3bcd510556e96'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='005803cb-e18d-4621-bd75-c097e5c1ed21', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='aa05b1c36220940245560a3a0e4bd8a47424558133bbbd2c7f00ccde198d0dfe')}, hash='beccf14de23cd2293ca246bd3f35b890111711860b3634dcd7ce0bf891ec9608', text='ResponsibleRelease. WhilemanycompanieshaveoptedtobuildAIbehindcloseddoors,wearereleasing\\nLlama 2 openly to encourage responsible AI innovation. Based on our experience, an open approach draws\\nuponthecollectivewisdom,diversity,andingenuityoftheAI-practitionercommunitytorealizethebenefitsof\\nthistechnology. Collaborationwillmakethesemodelsbetterandsafer.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-32'),\n",
              " '005803cb-e18d-4621-bd75-c097e5c1ed21': IndexNode(id_='005803cb-e18d-4621-bd75-c097e5c1ed21', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-32', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='605c4bb1c73b7df5fc2d6252477bd11755380b1806702dbfb94fe3cd909358ab'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='253616af-4fec-4fed-8092-f92f8187a076', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='beccf14de23cd2293ca246bd3f35b890111711860b3634dcd7ce0bf891ec9608'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='31dd7279-b003-4075-84cf-32121dccafb3', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='61c7e12431d8fe3867395b6c78de3ef357c8023d6efd74ae9a2b57f8be6714a7')}, hash='aa05b1c36220940245560a3a0e4bd8a47424558133bbbd2c7f00ccde198d0dfe', text='Collaborationwillmakethesemodelsbetterandsafer. TheentireAIcommunity—academic\\nresearchers, civil society, policymakers, and industry—must work together to rigorously analyze and expose\\nthe risks of current AI systems and to build solutions that address potentially problematic misuse. This\\napproachnotonlyfostersrealcollaborationwithdiversestakeholders—thosebeyondthewallsofbigtech\\ncompanies—but also serves as the cornerstone for democratizing access to foundational models. As argued\\nin Zellers et al.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-32'),\n",
              " '31dd7279-b003-4075-84cf-32121dccafb3': IndexNode(id_='31dd7279-b003-4075-84cf-32121dccafb3', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-32', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='605c4bb1c73b7df5fc2d6252477bd11755380b1806702dbfb94fe3cd909358ab'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='005803cb-e18d-4621-bd75-c097e5c1ed21', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='aa05b1c36220940245560a3a0e4bd8a47424558133bbbd2c7f00ccde198d0dfe'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='069af0bb-1c6f-4c13-be3f-46bf29194727', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='f8986aa79e5afad481ffbb928205c8b1aebf64c5c4612a70534acedc369fa032')}, hash='61c7e12431d8fe3867395b6c78de3ef357c8023d6efd74ae9a2b57f8be6714a7', text='As argued\\nin Zellers et al. (2019b), open releases promote transparency and allow more people to access AI tools,\\ndemocratizingthetechnologyanddecentralizingAIexpertise. WebelievethatthedecentralizationofAI\\nexpertisedoesmorethansimplydistributeknowledge—itstimulatesinnovationandacceleratesprogress\\nin the industry.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-32'),\n",
              " '069af0bb-1c6f-4c13-be3f-46bf29194727': IndexNode(id_='069af0bb-1c6f-4c13-be3f-46bf29194727', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-32', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='605c4bb1c73b7df5fc2d6252477bd11755380b1806702dbfb94fe3cd909358ab'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='31dd7279-b003-4075-84cf-32121dccafb3', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='61c7e12431d8fe3867395b6c78de3ef357c8023d6efd74ae9a2b57f8be6714a7'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='f3afd9c9-f50c-4f83-8428-1a90f085e746', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='11cfc38e99ee8f7e5c937e842174cc3ca8a7620816bb1d8936b5ac7511c03647')}, hash='f8986aa79e5afad481ffbb928205c8b1aebf64c5c4612a70534acedc369fa032', text='Lastly, openly releasing these models consolidates costs and eliminates barriers to entry,\\nallowingsmallbusinessestoleverageinnovationsinLLMstoexploreandbuildtext-generationusecases.\\nUltimately, we believe this will create a more level playing field for organizations of all sizes across the globe\\nto benefit from the economic growth promised by the advancement of AI.\\nWe know that not everyone who uses AI models has good intentions, and we acknowledge that there\\nare reasonable concerns regarding the ways that AI will impact our world.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-32'),\n",
              " 'f3afd9c9-f50c-4f83-8428-1a90f085e746': IndexNode(id_='f3afd9c9-f50c-4f83-8428-1a90f085e746', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-32', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='605c4bb1c73b7df5fc2d6252477bd11755380b1806702dbfb94fe3cd909358ab'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='069af0bb-1c6f-4c13-be3f-46bf29194727', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='f8986aa79e5afad481ffbb928205c8b1aebf64c5c4612a70534acedc369fa032'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='fd1a07ed-0530-4291-ac73-f32881105f47', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='2152629588dfcaf5a7420f1a1cc62428613d0ee450ce049f04132a3779f07cb7')}, hash='11cfc38e99ee8f7e5c937e842174cc3ca8a7620816bb1d8936b5ac7511c03647', text='Toxic content generation and\\nproblematic associations are meaningful risks that the AI community has yet to fully mitigate. As this\\npaper illustrates, we have made strides in limiting the prevalence of these types of responses. While we\\nrecognize there is more work to be done, this realization only deepens our commitment to open science and\\ncollaboration with the AI community.\\n6 Related Work\\nLarge Language Models. The recent years have witnessed a substantial evolution in the field of LLMs.\\nFollowing the scaling laws of Kaplan et al.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-32'),\n",
              " 'fd1a07ed-0530-4291-ac73-f32881105f47': IndexNode(id_='fd1a07ed-0530-4291-ac73-f32881105f47', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-32', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='605c4bb1c73b7df5fc2d6252477bd11755380b1806702dbfb94fe3cd909358ab'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='f3afd9c9-f50c-4f83-8428-1a90f085e746', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='11cfc38e99ee8f7e5c937e842174cc3ca8a7620816bb1d8936b5ac7511c03647')}, hash='2152629588dfcaf5a7420f1a1cc62428613d0ee450ce049f04132a3779f07cb7', text='Following the scaling laws of Kaplan et al. (2020), several Large Language Models with more than 100B\\nparameters have been proposed, from GPT-3 (Brown et al., 2020) to Gopher (Rae et al., 2022) or specialized\\nmodels, e.g.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-32'),\n",
              " '6f8161f4-a213-43af-905b-1293c1920941': IndexNode(id_='6f8161f4-a213-43af-905b-1293c1920941', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-32', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='605c4bb1c73b7df5fc2d6252477bd11755380b1806702dbfb94fe3cd909358ab'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='b61c9132-f6a1-4ae6-bbf6-4c6a4b6cd3cf', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='c78f2c976f711d3783b99f07eec232ea011b40f8aa330b67bacca461eebf54da')}, hash='25a3ed68a4cc84d00f05fca03832b2dfb6c4c90f164fa0f7664a838d0abe5302', text='We attempted to mitigate this via fine-tuning, but some issues may remain,\\nparticularlyforlanguagesotherthanEnglish wherepubliclyavailable datasetswerenotavailable. Wewill\\ncontinue to fine-tune and release updated versions in the future as we progress on addressing these issues.\\n‡‡https://openai.com/blog/chatgpt-plugins\\n34\\n\\nNoteveryonewhousesAImodelshasgoodintentions,andconversationalAIagentscouldpotentiallybe\\nusedfornefariouspurposessuchasgeneratingmisinformationorretrievinginformationabouttopicslike\\nbioterrorism or cybercrime. We have, however, made efforts to tune the models to avoid these topics and\\ndiminish any capabilities they might have offered for those use cases.\\nWhile we attempted to reasonably balance safety with helpfulness, in some instances, our safety tuning goes\\ntoo far. Users of Llama 2-Chat may observe an overly cautious approach, with the model erring on the side\\nof declining certain requests or responding with too many safety details.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-32'),\n",
              " 'b61c9132-f6a1-4ae6-bbf6-4c6a4b6cd3cf': IndexNode(id_='b61c9132-f6a1-4ae6-bbf6-4c6a4b6cd3cf', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-32', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='605c4bb1c73b7df5fc2d6252477bd11755380b1806702dbfb94fe3cd909358ab'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='6f8161f4-a213-43af-905b-1293c1920941', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='25a3ed68a4cc84d00f05fca03832b2dfb6c4c90f164fa0f7664a838d0abe5302'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='0ace08e7-bc92-4b1c-a1f3-d47028c095c5', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='6a7e9c93a6c0dfeac08ea11ec968955f96321c6b1a0b7b85efe4a0876f8a8ffa')}, hash='c78f2c976f711d3783b99f07eec232ea011b40f8aa330b67bacca461eebf54da', text='Usersofthepretrainedmodelsneedtobeparticularlycautious,andshouldtakeextrastepsintuningand\\ndeployment as described in our Responsible Use Guide.§§\\n5.3 Responsible Release Strategy\\nReleaseDetails. Wemake Llama 2 availableforbothresearchandcommercialuseat https://ai.meta.\\ncom/resources/models-and-libraries/llama/ . Thosewhouse Llama 2 mustcomplywiththetermsof\\nthe provided license and our Acceptable Use Policy , which prohibit any uses that would violate applicable\\npolicies, laws, rules, and regulations.\\nWealsoprovidecodeexamplestohelpdevelopersreplicateoursafegenerationswith Llama 2-Chat and\\napplybasicsafetytechniquesattheuserinputandmodeloutputlayers. Thesecodesamplesareavailable\\nhere: https://github.com/facebookresearch/llama . Finally,wearesharinga ResponsibleUseGuide ,which\\nprovides guidelines regarding safe development and deployment.\\nResponsibleRelease.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-32'),\n",
              " '0ace08e7-bc92-4b1c-a1f3-d47028c095c5': IndexNode(id_='0ace08e7-bc92-4b1c-a1f3-d47028c095c5', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-32', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='605c4bb1c73b7df5fc2d6252477bd11755380b1806702dbfb94fe3cd909358ab'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='b61c9132-f6a1-4ae6-bbf6-4c6a4b6cd3cf', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='c78f2c976f711d3783b99f07eec232ea011b40f8aa330b67bacca461eebf54da'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='da3759ef-0b6c-4da5-9bf4-085a831b3754', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='76fd9944d833b73a4f5f2ed1ca01db7bd0f978e6dea3ea0aeb11820c25628b60')}, hash='6a7e9c93a6c0dfeac08ea11ec968955f96321c6b1a0b7b85efe4a0876f8a8ffa', text='ResponsibleRelease. WhilemanycompanieshaveoptedtobuildAIbehindcloseddoors,wearereleasing\\nLlama 2 openly to encourage responsible AI innovation. Based on our experience, an open approach draws\\nuponthecollectivewisdom,diversity,andingenuityoftheAI-practitionercommunitytorealizethebenefitsof\\nthistechnology. Collaborationwillmakethesemodelsbetterandsafer. TheentireAIcommunity—academic\\nresearchers, civil society, policymakers, and industry—must work together to rigorously analyze and expose\\nthe risks of current AI systems and to build solutions that address potentially problematic misuse. This\\napproachnotonlyfostersrealcollaborationwithdiversestakeholders—thosebeyondthewallsofbigtech\\ncompanies—but also serves as the cornerstone for democratizing access to foundational models. As argued\\nin Zellers et al. (2019b), open releases promote transparency and allow more people to access AI tools,\\ndemocratizingthetechnologyanddecentralizingAIexpertise.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-32'),\n",
              " 'da3759ef-0b6c-4da5-9bf4-085a831b3754': IndexNode(id_='da3759ef-0b6c-4da5-9bf4-085a831b3754', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-32', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='605c4bb1c73b7df5fc2d6252477bd11755380b1806702dbfb94fe3cd909358ab'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='0ace08e7-bc92-4b1c-a1f3-d47028c095c5', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='6a7e9c93a6c0dfeac08ea11ec968955f96321c6b1a0b7b85efe4a0876f8a8ffa'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='dffe1c7e-b760-4185-9b42-ebec1811fd36', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='388b6753a8d6139efdc8811ad49f5c524e94c5211928d6d7e9122586da09d4cc')}, hash='76fd9944d833b73a4f5f2ed1ca01db7bd0f978e6dea3ea0aeb11820c25628b60', text='WebelievethatthedecentralizationofAI\\nexpertisedoesmorethansimplydistributeknowledge—itstimulatesinnovationandacceleratesprogress\\nin the industry. Lastly, openly releasing these models consolidates costs and eliminates barriers to entry,\\nallowingsmallbusinessestoleverageinnovationsinLLMstoexploreandbuildtext-generationusecases.\\nUltimately, we believe this will create a more level playing field for organizations of all sizes across the globe\\nto benefit from the economic growth promised by the advancement of AI.\\nWe know that not everyone who uses AI models has good intentions, and we acknowledge that there\\nare reasonable concerns regarding the ways that AI will impact our world. Toxic content generation and\\nproblematic associations are meaningful risks that the AI community has yet to fully mitigate. As this\\npaper illustrates, we have made strides in limiting the prevalence of these types of responses. While we\\nrecognize there is more work to be done, this realization only deepens our commitment to open science and\\ncollaboration with the AI community.\\n6 Related Work\\nLarge Language Models.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-32'),\n",
              " 'dffe1c7e-b760-4185-9b42-ebec1811fd36': IndexNode(id_='dffe1c7e-b760-4185-9b42-ebec1811fd36', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-32', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='605c4bb1c73b7df5fc2d6252477bd11755380b1806702dbfb94fe3cd909358ab'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='da3759ef-0b6c-4da5-9bf4-085a831b3754', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='76fd9944d833b73a4f5f2ed1ca01db7bd0f978e6dea3ea0aeb11820c25628b60')}, hash='388b6753a8d6139efdc8811ad49f5c524e94c5211928d6d7e9122586da09d4cc', text='6 Related Work\\nLarge Language Models. The recent years have witnessed a substantial evolution in the field of LLMs.\\nFollowing the scaling laws of Kaplan et al. (2020), several Large Language Models with more than 100B\\nparameters have been proposed, from GPT-3 (Brown et al., 2020) to Gopher (Rae et al., 2022) or specialized\\nmodels, e.g.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-32'),\n",
              " '55017112-6f85-4660-a861-faac6f0fd717': IndexNode(id_='55017112-6f85-4660-a861-faac6f0fd717', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-32', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='605c4bb1c73b7df5fc2d6252477bd11755380b1806702dbfb94fe3cd909358ab'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='030d386f-a7fe-47d4-81f7-aa092d82c02e', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='4c9a94725c8749c7f64d329a785ff71c8ceb5a08a2c14c0d2f584a36a5864eaa')}, hash='cfa5240b0987693253831d06c6411d882ad29d4afd57ab7107f3f814c2f9ee36', text='We attempted to mitigate this via fine-tuning, but some issues may remain,\\nparticularlyforlanguagesotherthanEnglish wherepubliclyavailable datasetswerenotavailable. Wewill\\ncontinue to fine-tune and release updated versions in the future as we progress on addressing these issues.\\n‡‡https://openai.com/blog/chatgpt-plugins\\n34\\n\\nNoteveryonewhousesAImodelshasgoodintentions,andconversationalAIagentscouldpotentiallybe\\nusedfornefariouspurposessuchasgeneratingmisinformationorretrievinginformationabouttopicslike\\nbioterrorism or cybercrime. We have, however, made efforts to tune the models to avoid these topics and\\ndiminish any capabilities they might have offered for those use cases.\\nWhile we attempted to reasonably balance safety with helpfulness, in some instances, our safety tuning goes\\ntoo far. Users of Llama 2-Chat may observe an overly cautious approach, with the model erring on the side\\nof declining certain requests or responding with too many safety details.\\nUsersofthepretrainedmodelsneedtobeparticularlycautious,andshouldtakeextrastepsintuningand\\ndeployment as described in our Responsible Use Guide.§§\\n5.3 Responsible Release Strategy\\nReleaseDetails. Wemake Llama 2 availableforbothresearchandcommercialuseat https://ai.meta.\\ncom/resources/models-and-libraries/llama/ . Thosewhouse Llama 2 mustcomplywiththetermsof\\nthe provided license and our Acceptable Use Policy , which prohibit any uses that would violate applicable\\npolicies, laws, rules, and regulations.\\nWealsoprovidecodeexamplestohelpdevelopersreplicateoursafegenerationswith Llama 2-Chat and\\napplybasicsafetytechniquesattheuserinputandmodeloutputlayers. Thesecodesamplesareavailable\\nhere: https://github.com/facebookresearch/llama . Finally,wearesharinga ResponsibleUseGuide ,which\\nprovides guidelines regarding safe development and deployment.\\nResponsibleRelease. WhilemanycompanieshaveoptedtobuildAIbehindcloseddoors,wearereleasing\\nLlama 2 openly to encourage responsible AI innovation.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-32'),\n",
              " '030d386f-a7fe-47d4-81f7-aa092d82c02e': IndexNode(id_='030d386f-a7fe-47d4-81f7-aa092d82c02e', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-32', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='605c4bb1c73b7df5fc2d6252477bd11755380b1806702dbfb94fe3cd909358ab'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='55017112-6f85-4660-a861-faac6f0fd717', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='cfa5240b0987693253831d06c6411d882ad29d4afd57ab7107f3f814c2f9ee36'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='ed1d1f18-fa74-4d47-a413-6198343b6964', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='2152629588dfcaf5a7420f1a1cc62428613d0ee450ce049f04132a3779f07cb7')}, hash='4c9a94725c8749c7f64d329a785ff71c8ceb5a08a2c14c0d2f584a36a5864eaa', text='Based on our experience, an open approach draws\\nuponthecollectivewisdom,diversity,andingenuityoftheAI-practitionercommunitytorealizethebenefitsof\\nthistechnology. Collaborationwillmakethesemodelsbetterandsafer. TheentireAIcommunity—academic\\nresearchers, civil society, policymakers, and industry—must work together to rigorously analyze and expose\\nthe risks of current AI systems and to build solutions that address potentially problematic misuse. This\\napproachnotonlyfostersrealcollaborationwithdiversestakeholders—thosebeyondthewallsofbigtech\\ncompanies—but also serves as the cornerstone for democratizing access to foundational models. As argued\\nin Zellers et al. (2019b), open releases promote transparency and allow more people to access AI tools,\\ndemocratizingthetechnologyanddecentralizingAIexpertise. WebelievethatthedecentralizationofAI\\nexpertisedoesmorethansimplydistributeknowledge—itstimulatesinnovationandacceleratesprogress\\nin the industry. Lastly, openly releasing these models consolidates costs and eliminates barriers to entry,\\nallowingsmallbusinessestoleverageinnovationsinLLMstoexploreandbuildtext-generationusecases.\\nUltimately, we believe this will create a more level playing field for organizations of all sizes across the globe\\nto benefit from the economic growth promised by the advancement of AI.\\nWe know that not everyone who uses AI models has good intentions, and we acknowledge that there\\nare reasonable concerns regarding the ways that AI will impact our world. Toxic content generation and\\nproblematic associations are meaningful risks that the AI community has yet to fully mitigate. As this\\npaper illustrates, we have made strides in limiting the prevalence of these types of responses. While we\\nrecognize there is more work to be done, this realization only deepens our commitment to open science and\\ncollaboration with the AI community.\\n6 Related Work\\nLarge Language Models. The recent years have witnessed a substantial evolution in the field of LLMs.\\nFollowing the scaling laws of Kaplan et al.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-32'),\n",
              " 'ed1d1f18-fa74-4d47-a413-6198343b6964': IndexNode(id_='ed1d1f18-fa74-4d47-a413-6198343b6964', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-32', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='605c4bb1c73b7df5fc2d6252477bd11755380b1806702dbfb94fe3cd909358ab'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='030d386f-a7fe-47d4-81f7-aa092d82c02e', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='4c9a94725c8749c7f64d329a785ff71c8ceb5a08a2c14c0d2f584a36a5864eaa')}, hash='2152629588dfcaf5a7420f1a1cc62428613d0ee450ce049f04132a3779f07cb7', text='Following the scaling laws of Kaplan et al. (2020), several Large Language Models with more than 100B\\nparameters have been proposed, from GPT-3 (Brown et al., 2020) to Gopher (Rae et al., 2022) or specialized\\nmodels, e.g.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-32'),\n",
              " 'node-32': IndexNode(id_='node-32', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='415b7efc-e73f-4ac4-bbfd-c1546f099026', node_type=<ObjectType.DOCUMENT: '4'>, metadata={}, hash='231b3bd773f012c01b893ada9e009ecf25ee59934614c5a595c9bf1b3a123292'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='6c10f8cb-ea27-4a14-8dbe-dd177390139d', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='7f57c341c1fb0e6031b27dee82789a5abb96223032a259bbf82901d9a15dec0d'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='ea2012fe-e787-4e99-b5e5-d763611848ff', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='f0fdb8b6107fdcc5607535145133530029c7c8ac6eb663545d1f19a6bdb3acf4')}, hash='605c4bb1c73b7df5fc2d6252477bd11755380b1806702dbfb94fe3cd909358ab', text='We attempted to mitigate this via fine-tuning, but some issues may remain,\\nparticularlyforlanguagesotherthanEnglish wherepubliclyavailable datasetswerenotavailable. Wewill\\ncontinue to fine-tune and release updated versions in the future as we progress on addressing these issues.\\n‡‡https://openai.com/blog/chatgpt-plugins\\n34\\n\\nNoteveryonewhousesAImodelshasgoodintentions,andconversationalAIagentscouldpotentiallybe\\nusedfornefariouspurposessuchasgeneratingmisinformationorretrievinginformationabouttopicslike\\nbioterrorism or cybercrime. We have, however, made efforts to tune the models to avoid these topics and\\ndiminish any capabilities they might have offered for those use cases.\\nWhile we attempted to reasonably balance safety with helpfulness, in some instances, our safety tuning goes\\ntoo far. Users of Llama 2-Chat may observe an overly cautious approach, with the model erring on the side\\nof declining certain requests or responding with too many safety details.\\nUsersofthepretrainedmodelsneedtobeparticularlycautious,andshouldtakeextrastepsintuningand\\ndeployment as described in our Responsible Use Guide.§§\\n5.3 Responsible Release Strategy\\nReleaseDetails. Wemake Llama 2 availableforbothresearchandcommercialuseat https://ai.meta.\\ncom/resources/models-and-libraries/llama/ . Thosewhouse Llama 2 mustcomplywiththetermsof\\nthe provided license and our Acceptable Use Policy , which prohibit any uses that would violate applicable\\npolicies, laws, rules, and regulations.\\nWealsoprovidecodeexamplestohelpdevelopersreplicateoursafegenerationswith Llama 2-Chat and\\napplybasicsafetytechniquesattheuserinputandmodeloutputlayers. Thesecodesamplesareavailable\\nhere: https://github.com/facebookresearch/llama . Finally,wearesharinga ResponsibleUseGuide ,which\\nprovides guidelines regarding safe development and deployment.\\nResponsibleRelease. WhilemanycompanieshaveoptedtobuildAIbehindcloseddoors,wearereleasing\\nLlama 2 openly to encourage responsible AI innovation. Based on our experience, an open approach draws\\nuponthecollectivewisdom,diversity,andingenuityoftheAI-practitionercommunitytorealizethebenefitsof\\nthistechnology. Collaborationwillmakethesemodelsbetterandsafer. TheentireAIcommunity—academic\\nresearchers, civil society, policymakers, and industry—must work together to rigorously analyze and expose\\nthe risks of current AI systems and to build solutions that address potentially problematic misuse. This\\napproachnotonlyfostersrealcollaborationwithdiversestakeholders—thosebeyondthewallsofbigtech\\ncompanies—but also serves as the cornerstone for democratizing access to foundational models. As argued\\nin Zellers et al. (2019b), open releases promote transparency and allow more people to access AI tools,\\ndemocratizingthetechnologyanddecentralizingAIexpertise. WebelievethatthedecentralizationofAI\\nexpertisedoesmorethansimplydistributeknowledge—itstimulatesinnovationandacceleratesprogress\\nin the industry. Lastly, openly releasing these models consolidates costs and eliminates barriers to entry,\\nallowingsmallbusinessestoleverageinnovationsinLLMstoexploreandbuildtext-generationusecases.\\nUltimately, we believe this will create a more level playing field for organizations of all sizes across the globe\\nto benefit from the economic growth promised by the advancement of AI.\\nWe know that not everyone who uses AI models has good intentions, and we acknowledge that there\\nare reasonable concerns regarding the ways that AI will impact our world. Toxic content generation and\\nproblematic associations are meaningful risks that the AI community has yet to fully mitigate. As this\\npaper illustrates, we have made strides in limiting the prevalence of these types of responses. While we\\nrecognize there is more work to be done, this realization only deepens our commitment to open science and\\ncollaboration with the AI community.\\n6 Related Work\\nLarge Language Models. The recent years have witnessed a substantial evolution in the field of LLMs.\\nFollowing the scaling laws of Kaplan et al. (2020), several Large Language Models with more than 100B\\nparameters have been proposed, from GPT-3 (Brown et al., 2020) to Gopher (Rae et al., 2022) or specialized\\nmodels, e.g.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-32'),\n",
              " '3948bc8e-7364-4833-98f6-b45a0c3b44fd': IndexNode(id_='3948bc8e-7364-4833-98f6-b45a0c3b44fd', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-33', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='f0fdb8b6107fdcc5607535145133530029c7c8ac6eb663545d1f19a6bdb3acf4'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='fef4efe4-c22b-4917-a40e-569fdb71a21e', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='a6f87d608d171e53c00a7b9b01fc7c66f9fdee19046440b244a31d372f0d5b3b')}, hash='b2f6699c12262d82ab63d6ba66ed1718c01060a42bb09213af5685a2dc47471d', text='Galactica, for science(Taylor et al., 2022). With 70B parameters, Chinchilla (Hoffmann et al.,\\n2022) redefined those scaling laws towards the number of tokens rather than model weights. Notable in\\nthisprogressionistheriseofLlama,recognizedforitsfocusoncomputationalefficiencyduringinference\\n(Touvron et al., 2023). A parallel discourse has unfolded around the dynamics of open-source versus closed-\\nsourcemodels.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-33'),\n",
              " 'fef4efe4-c22b-4917-a40e-569fdb71a21e': IndexNode(id_='fef4efe4-c22b-4917-a40e-569fdb71a21e', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-33', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='f0fdb8b6107fdcc5607535145133530029c7c8ac6eb663545d1f19a6bdb3acf4'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='3948bc8e-7364-4833-98f6-b45a0c3b44fd', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='b2f6699c12262d82ab63d6ba66ed1718c01060a42bb09213af5685a2dc47471d'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='44c78ccd-6497-4c42-9a31-d2212fd2fab0', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='1a89df54d467129a842044b562c544e6f9de7fa1c07927bad0251fecb61f2d91')}, hash='a6f87d608d171e53c00a7b9b01fc7c66f9fdee19046440b244a31d372f0d5b3b', text='A parallel discourse has unfolded around the dynamics of open-source versus closed-\\nsourcemodels. Open-sourcereleaseslikeBLOOM(Scaoetal.,2022),OPT(Zhangetal.,2022),andFalcon\\n(Penedo et al., 2023) have risen to challenge their closed-source counterparts like GPT-3 and Chinchilla.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-33'),\n",
              " '44c78ccd-6497-4c42-9a31-d2212fd2fab0': IndexNode(id_='44c78ccd-6497-4c42-9a31-d2212fd2fab0', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-33', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='f0fdb8b6107fdcc5607535145133530029c7c8ac6eb663545d1f19a6bdb3acf4'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='fef4efe4-c22b-4917-a40e-569fdb71a21e', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='a6f87d608d171e53c00a7b9b01fc7c66f9fdee19046440b244a31d372f0d5b3b'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='1c2dea32-d7fc-45d9-b121-a0bf005fdd67', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='f1a45dac8c0c8552be56766a2f53bc51a0dbea5027165ba913b69062d3bd9552')}, hash='1a89df54d467129a842044b562c544e6f9de7fa1c07927bad0251fecb61f2d91', text='§§https://ai.meta.com/llama\\n35\\n\\nYet,whenitcomestothe\"production-ready\"LLMssuchasChatGPT,Bard,andClaude,there’samarked\\ndistinction in performance and usability. These models rely on intricate tuning techniques to align with\\nhuman preferences (Gudibande et al., 2023), a process that is still being explored and refined within the\\nopen-source community.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-33'),\n",
              " '1c2dea32-d7fc-45d9-b121-a0bf005fdd67': IndexNode(id_='1c2dea32-d7fc-45d9-b121-a0bf005fdd67', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-33', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='f0fdb8b6107fdcc5607535145133530029c7c8ac6eb663545d1f19a6bdb3acf4'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='44c78ccd-6497-4c42-9a31-d2212fd2fab0', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='1a89df54d467129a842044b562c544e6f9de7fa1c07927bad0251fecb61f2d91'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='50581aba-f1f1-4027-91e8-9141e476a30d', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='35c0e500cfea89c4ac916c05ce50d2918e736558d6b5752b8b85e72f79036601')}, hash='f1a45dac8c0c8552be56766a2f53bc51a0dbea5027165ba913b69062d3bd9552', text='Attempts to close this gap have emerged, with distillation-based models such as Vicuna (Chiang et al., 2023)\\nandAlpaca(Taorietal.,2023)adoptingauniqueapproachtotrainingwithsyntheticinstructions(Honovich\\net al., 2022; Wang et al., 2022). However, while these models show promise, they still fall short of the bar set\\nby their closed-source counterparts.\\nInstructionTuning. Weietal.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-33'),\n",
              " '50581aba-f1f1-4027-91e8-9141e476a30d': IndexNode(id_='50581aba-f1f1-4027-91e8-9141e476a30d', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-33', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='f0fdb8b6107fdcc5607535145133530029c7c8ac6eb663545d1f19a6bdb3acf4'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='1c2dea32-d7fc-45d9-b121-a0bf005fdd67', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='f1a45dac8c0c8552be56766a2f53bc51a0dbea5027165ba913b69062d3bd9552'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='4246186b-9fcb-4997-adcf-ac9523855243', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='2cfddd5daaf2381fd94ea99db3e76ef99bbfb8ae2b2e68b048702237dbad0c9e')}, hash='35c0e500cfea89c4ac916c05ce50d2918e736558d6b5752b8b85e72f79036601', text='InstructionTuning. Weietal.(2021)obtainedzero-shotperformanceonunseentasksbyfine-tuningLLMs\\nonnumerousdatasets. Chungetal.(2022)andLongpreetal.(2023)investigatetheimpactofinstruction\\ntuningasafunctionofnumberoftasks,modelsize,promptsettings,etc.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-33'),\n",
              " '4246186b-9fcb-4997-adcf-ac9523855243': IndexNode(id_='4246186b-9fcb-4997-adcf-ac9523855243', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-33', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='f0fdb8b6107fdcc5607535145133530029c7c8ac6eb663545d1f19a6bdb3acf4'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='50581aba-f1f1-4027-91e8-9141e476a30d', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='35c0e500cfea89c4ac916c05ce50d2918e736558d6b5752b8b85e72f79036601'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='fd98c6c5-1f3f-4328-a0fa-19d3e9538a75', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='12b9881998a5a9f818b3301b715fd8166835515e1586a092f83fb3a96104571f')}, hash='2cfddd5daaf2381fd94ea99db3e76ef99bbfb8ae2b2e68b048702237dbad0c9e', text='Promptsusedforinstructiontuning\\ncanbecreatedbyhumansorbyLLMsthemselves(Zhouetal.,2022),andfollow-upinstructionscanbeused\\ntorefineinitialgenerationstomakethemmoreuseful,engaging,andunbiased(Gangulietal.,2023;Madaan\\net al., 2023).', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-33'),\n",
              " 'fd98c6c5-1f3f-4328-a0fa-19d3e9538a75': IndexNode(id_='fd98c6c5-1f3f-4328-a0fa-19d3e9538a75', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-33', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='f0fdb8b6107fdcc5607535145133530029c7c8ac6eb663545d1f19a6bdb3acf4'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='4246186b-9fcb-4997-adcf-ac9523855243', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='2cfddd5daaf2381fd94ea99db3e76ef99bbfb8ae2b2e68b048702237dbad0c9e'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='ac107f54-eae2-461c-b4e6-530474c31f83', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='4edf26ce07768e43cbd05310c3775262861a978f3308d18ab5d19b1516c4edd3')}, hash='12b9881998a5a9f818b3301b715fd8166835515e1586a092f83fb3a96104571f', text='An approach related to instruction tuning is chain-of-thought prompting (Wei et al., 2022b), in\\nwhichmodels areprompted toexplain theirreasoningwhen givena complexproblem, inorder toincrease\\nthe likelihood that their final answer is correct.\\nRLHF has emerged as a powerful strategy for fine-tuning Large Language Models, enabling significant\\nimprovements in their performance (Christiano et al., 2017). The method, first showcased by Stiennon et al.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-33'),\n",
              " 'ac107f54-eae2-461c-b4e6-530474c31f83': IndexNode(id_='ac107f54-eae2-461c-b4e6-530474c31f83', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-33', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='f0fdb8b6107fdcc5607535145133530029c7c8ac6eb663545d1f19a6bdb3acf4'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='fd98c6c5-1f3f-4328-a0fa-19d3e9538a75', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='12b9881998a5a9f818b3301b715fd8166835515e1586a092f83fb3a96104571f'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='23f5e3f9-03fb-46ec-8c98-0a73c1d728d0', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='a27eee029c536da04434e0bb28db030cd0dc08866709a6efe8d15397b0c5934d')}, hash='4edf26ce07768e43cbd05310c3775262861a978f3308d18ab5d19b1516c4edd3', text='The method, first showcased by Stiennon et al.\\n(2020) in the context of text-summarization tasks, has since been extended to a range of other applications.\\nIn this paradigm, models are fine-tuned based on feedback from human users, thus iteratively aligning the\\nmodels’ responses more closely with human expectations and preferences.\\nOuyang et al. (2022) demonstrates that a combination of instruction fine-tuning and RLHF can help fix\\nissues with factuality, toxicity, and helpfulness that cannot be remedied by simply scaling up LLMs.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-33'),\n",
              " '23f5e3f9-03fb-46ec-8c98-0a73c1d728d0': IndexNode(id_='23f5e3f9-03fb-46ec-8c98-0a73c1d728d0', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-33', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='f0fdb8b6107fdcc5607535145133530029c7c8ac6eb663545d1f19a6bdb3acf4'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='ac107f54-eae2-461c-b4e6-530474c31f83', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='4edf26ce07768e43cbd05310c3775262861a978f3308d18ab5d19b1516c4edd3'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='58a6102d-2789-4377-8f13-773df697f62a', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='a3debfb577cec41a34f06dfa09f009ac4c1733ec5ec1a3cd955eba00b4343f67')}, hash='a27eee029c536da04434e0bb28db030cd0dc08866709a6efe8d15397b0c5934d', text='Bai\\net al. (2022b) partially automates this fine-tuning-plus-RLHF approach by replacing the human-labeled\\nfine-tuningdatawiththemodel’sownself-critiquesandrevisions,andbyreplacinghumanraterswitha\\nmodel when ranking model outputs in RLHF, a process known as “RL from AI Feedback” (RLAIF).\\nKnown LLM Safety Challenges. Recent literature has extensively explored the risks and challenges linked\\nwith Large Language Models. Bender et al.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-33'),\n",
              " '58a6102d-2789-4377-8f13-773df697f62a': IndexNode(id_='58a6102d-2789-4377-8f13-773df697f62a', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-33', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='f0fdb8b6107fdcc5607535145133530029c7c8ac6eb663545d1f19a6bdb3acf4'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='23f5e3f9-03fb-46ec-8c98-0a73c1d728d0', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='a27eee029c536da04434e0bb28db030cd0dc08866709a6efe8d15397b0c5934d'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='810c6366-06b8-4bc5-907a-762e1c7fa217', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='805ea97652f3ffdadf0a437c7149b168479472952f29feff0ecb474cc7960b80')}, hash='a3debfb577cec41a34f06dfa09f009ac4c1733ec5ec1a3cd955eba00b4343f67', text='Bender et al. (2021b) and Weidinger et al. (2021) underscore various hazards\\nlikebias,toxicity,privatedataleakage,andthepotentialformalicioususes. Solaimanetal.(2023)categorizes\\ntheseimpactsintotwogroups—thosethatcanbeassessedwithinthebasesystemandthoserequiringa\\nsocietal context evaluation, while Kumar et al. (2022) offers potential mitigation strategies to curb harm.\\nWorkfromRolleretal.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-33'),\n",
              " '810c6366-06b8-4bc5-907a-762e1c7fa217': IndexNode(id_='810c6366-06b8-4bc5-907a-762e1c7fa217', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-33', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='f0fdb8b6107fdcc5607535145133530029c7c8ac6eb663545d1f19a6bdb3acf4'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='58a6102d-2789-4377-8f13-773df697f62a', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='a3debfb577cec41a34f06dfa09f009ac4c1733ec5ec1a3cd955eba00b4343f67')}, hash='805ea97652f3ffdadf0a437c7149b168479472952f29feff0ecb474cc7960b80', text='WorkfromRolleretal.(2020)andDinanetal.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-33'),\n",
              " 'f2b80103-07c4-4fc2-895d-f5bbadae65ac': IndexNode(id_='f2b80103-07c4-4fc2-895d-f5bbadae65ac', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-33', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='f0fdb8b6107fdcc5607535145133530029c7c8ac6eb663545d1f19a6bdb3acf4'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='49567ff0-964b-467f-93a5-26b55a6d4dfe', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='9f91a703378e30ad497b3f47d91c634f00460dd226e1353241b4b1db9ed5a237')}, hash='ba689b941b683b5f4dfc4c6710687bdfb83e131eb24e1e775f352af510c46961', text='Galactica, for science(Taylor et al., 2022). With 70B parameters, Chinchilla (Hoffmann et al.,\\n2022) redefined those scaling laws towards the number of tokens rather than model weights. Notable in\\nthisprogressionistheriseofLlama,recognizedforitsfocusoncomputationalefficiencyduringinference\\n(Touvron et al., 2023). A parallel discourse has unfolded around the dynamics of open-source versus closed-\\nsourcemodels. Open-sourcereleaseslikeBLOOM(Scaoetal.,2022),OPT(Zhangetal.,2022),andFalcon\\n(Penedo et al., 2023) have risen to challenge their closed-source counterparts like GPT-3 and Chinchilla.\\n§§https://ai.meta.com/llama\\n35\\n\\nYet,whenitcomestothe\"production-ready\"LLMssuchasChatGPT,Bard,andClaude,there’samarked\\ndistinction in performance and usability.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-33'),\n",
              " '49567ff0-964b-467f-93a5-26b55a6d4dfe': IndexNode(id_='49567ff0-964b-467f-93a5-26b55a6d4dfe', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-33', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='f0fdb8b6107fdcc5607535145133530029c7c8ac6eb663545d1f19a6bdb3acf4'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='f2b80103-07c4-4fc2-895d-f5bbadae65ac', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='ba689b941b683b5f4dfc4c6710687bdfb83e131eb24e1e775f352af510c46961'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='3a52e45e-2f95-4a26-bab7-d99d89a57c74', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='4eddd561f3325dcd39f6df31504ddf7e12e9e423efbb75f5eaf1e6b493e8c333')}, hash='9f91a703378e30ad497b3f47d91c634f00460dd226e1353241b4b1db9ed5a237', text='These models rely on intricate tuning techniques to align with\\nhuman preferences (Gudibande et al., 2023), a process that is still being explored and refined within the\\nopen-source community.\\nAttempts to close this gap have emerged, with distillation-based models such as Vicuna (Chiang et al., 2023)\\nandAlpaca(Taorietal.,2023)adoptingauniqueapproachtotrainingwithsyntheticinstructions(Honovich\\net al., 2022; Wang et al., 2022). However, while these models show promise, they still fall short of the bar set\\nby their closed-source counterparts.\\nInstructionTuning. Weietal.(2021)obtainedzero-shotperformanceonunseentasksbyfine-tuningLLMs\\nonnumerousdatasets. Chungetal.(2022)andLongpreetal.(2023)investigatetheimpactofinstruction\\ntuningasafunctionofnumberoftasks,modelsize,promptsettings,etc.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-33'),\n",
              " '3a52e45e-2f95-4a26-bab7-d99d89a57c74': IndexNode(id_='3a52e45e-2f95-4a26-bab7-d99d89a57c74', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-33', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='f0fdb8b6107fdcc5607535145133530029c7c8ac6eb663545d1f19a6bdb3acf4'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='49567ff0-964b-467f-93a5-26b55a6d4dfe', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='9f91a703378e30ad497b3f47d91c634f00460dd226e1353241b4b1db9ed5a237'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='390686a4-3c33-415f-ba01-8f00ebebf06a', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='62da5eda85a150f4eaf9b79e74d584fbea45af1b845a1c58be7eb3e920456b38')}, hash='4eddd561f3325dcd39f6df31504ddf7e12e9e423efbb75f5eaf1e6b493e8c333', text='Promptsusedforinstructiontuning\\ncanbecreatedbyhumansorbyLLMsthemselves(Zhouetal.,2022),andfollow-upinstructionscanbeused\\ntorefineinitialgenerationstomakethemmoreuseful,engaging,andunbiased(Gangulietal.,2023;Madaan\\net al., 2023). An approach related to instruction tuning is chain-of-thought prompting (Wei et al., 2022b), in\\nwhichmodels areprompted toexplain theirreasoningwhen givena complexproblem, inorder toincrease\\nthe likelihood that their final answer is correct.\\nRLHF has emerged as a powerful strategy for fine-tuning Large Language Models, enabling significant\\nimprovements in their performance (Christiano et al., 2017). The method, first showcased by Stiennon et al.\\n(2020) in the context of text-summarization tasks, has since been extended to a range of other applications.\\nIn this paradigm, models are fine-tuned based on feedback from human users, thus iteratively aligning the\\nmodels’ responses more closely with human expectations and preferences.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-33'),\n",
              " '390686a4-3c33-415f-ba01-8f00ebebf06a': IndexNode(id_='390686a4-3c33-415f-ba01-8f00ebebf06a', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-33', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='f0fdb8b6107fdcc5607535145133530029c7c8ac6eb663545d1f19a6bdb3acf4'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='3a52e45e-2f95-4a26-bab7-d99d89a57c74', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='4eddd561f3325dcd39f6df31504ddf7e12e9e423efbb75f5eaf1e6b493e8c333'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='f786d1d3-bff7-4054-8aba-02a65faad162', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='ac5425d6b165522e881aab1eeb33e438372f84d3b3170331dfb86d5516eef787')}, hash='62da5eda85a150f4eaf9b79e74d584fbea45af1b845a1c58be7eb3e920456b38', text='Ouyang et al. (2022) demonstrates that a combination of instruction fine-tuning and RLHF can help fix\\nissues with factuality, toxicity, and helpfulness that cannot be remedied by simply scaling up LLMs. Bai\\net al. (2022b) partially automates this fine-tuning-plus-RLHF approach by replacing the human-labeled\\nfine-tuningdatawiththemodel’sownself-critiquesandrevisions,andbyreplacinghumanraterswitha\\nmodel when ranking model outputs in RLHF, a process known as “RL from AI Feedback” (RLAIF).\\nKnown LLM Safety Challenges. Recent literature has extensively explored the risks and challenges linked\\nwith Large Language Models. Bender et al. (2021b) and Weidinger et al. (2021) underscore various hazards\\nlikebias,toxicity,privatedataleakage,andthepotentialformalicioususes. Solaimanetal.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-33'),\n",
              " 'f786d1d3-bff7-4054-8aba-02a65faad162': IndexNode(id_='f786d1d3-bff7-4054-8aba-02a65faad162', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-33', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='f0fdb8b6107fdcc5607535145133530029c7c8ac6eb663545d1f19a6bdb3acf4'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='390686a4-3c33-415f-ba01-8f00ebebf06a', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='62da5eda85a150f4eaf9b79e74d584fbea45af1b845a1c58be7eb3e920456b38')}, hash='ac5425d6b165522e881aab1eeb33e438372f84d3b3170331dfb86d5516eef787', text='Solaimanetal.(2023)categorizes\\ntheseimpactsintotwogroups—thosethatcanbeassessedwithinthebasesystemandthoserequiringa\\nsocietal context evaluation, while Kumar et al. (2022) offers potential mitigation strategies to curb harm.\\nWorkfromRolleretal.(2020)andDinanetal.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-33'),\n",
              " '09ac7a89-c44f-4afa-b324-f99ae8389d1e': IndexNode(id_='09ac7a89-c44f-4afa-b324-f99ae8389d1e', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-33', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='f0fdb8b6107fdcc5607535145133530029c7c8ac6eb663545d1f19a6bdb3acf4'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='378cb449-be25-4399-bece-3fc0bd00a19d', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='e3741b2ef22f943ce2b8f7f2300e026f285574c3975b7568bd1670a27843343d')}, hash='ba036597ffa3db962ab9c850c13946f74a590cab4ba0ba162d7828392e7ace09', text='Galactica, for science(Taylor et al., 2022). With 70B parameters, Chinchilla (Hoffmann et al.,\\n2022) redefined those scaling laws towards the number of tokens rather than model weights. Notable in\\nthisprogressionistheriseofLlama,recognizedforitsfocusoncomputationalefficiencyduringinference\\n(Touvron et al., 2023). A parallel discourse has unfolded around the dynamics of open-source versus closed-\\nsourcemodels. Open-sourcereleaseslikeBLOOM(Scaoetal.,2022),OPT(Zhangetal.,2022),andFalcon\\n(Penedo et al., 2023) have risen to challenge their closed-source counterparts like GPT-3 and Chinchilla.\\n§§https://ai.meta.com/llama\\n35\\n\\nYet,whenitcomestothe\"production-ready\"LLMssuchasChatGPT,Bard,andClaude,there’samarked\\ndistinction in performance and usability. These models rely on intricate tuning techniques to align with\\nhuman preferences (Gudibande et al., 2023), a process that is still being explored and refined within the\\nopen-source community.\\nAttempts to close this gap have emerged, with distillation-based models such as Vicuna (Chiang et al., 2023)\\nandAlpaca(Taorietal.,2023)adoptingauniqueapproachtotrainingwithsyntheticinstructions(Honovich\\net al., 2022; Wang et al., 2022). However, while these models show promise, they still fall short of the bar set\\nby their closed-source counterparts.\\nInstructionTuning. Weietal.(2021)obtainedzero-shotperformanceonunseentasksbyfine-tuningLLMs\\nonnumerousdatasets. Chungetal.(2022)andLongpreetal.(2023)investigatetheimpactofinstruction\\ntuningasafunctionofnumberoftasks,modelsize,promptsettings,etc.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-33'),\n",
              " '378cb449-be25-4399-bece-3fc0bd00a19d': IndexNode(id_='378cb449-be25-4399-bece-3fc0bd00a19d', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-33', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='f0fdb8b6107fdcc5607535145133530029c7c8ac6eb663545d1f19a6bdb3acf4'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='09ac7a89-c44f-4afa-b324-f99ae8389d1e', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='ba036597ffa3db962ab9c850c13946f74a590cab4ba0ba162d7828392e7ace09'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='2621daf9-c22c-47db-9eb4-e8ef2e54928e', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='ac5425d6b165522e881aab1eeb33e438372f84d3b3170331dfb86d5516eef787')}, hash='e3741b2ef22f943ce2b8f7f2300e026f285574c3975b7568bd1670a27843343d', text='Promptsusedforinstructiontuning\\ncanbecreatedbyhumansorbyLLMsthemselves(Zhouetal.,2022),andfollow-upinstructionscanbeused\\ntorefineinitialgenerationstomakethemmoreuseful,engaging,andunbiased(Gangulietal.,2023;Madaan\\net al., 2023). An approach related to instruction tuning is chain-of-thought prompting (Wei et al., 2022b), in\\nwhichmodels areprompted toexplain theirreasoningwhen givena complexproblem, inorder toincrease\\nthe likelihood that their final answer is correct.\\nRLHF has emerged as a powerful strategy for fine-tuning Large Language Models, enabling significant\\nimprovements in their performance (Christiano et al., 2017). The method, first showcased by Stiennon et al.\\n(2020) in the context of text-summarization tasks, has since been extended to a range of other applications.\\nIn this paradigm, models are fine-tuned based on feedback from human users, thus iteratively aligning the\\nmodels’ responses more closely with human expectations and preferences.\\nOuyang et al. (2022) demonstrates that a combination of instruction fine-tuning and RLHF can help fix\\nissues with factuality, toxicity, and helpfulness that cannot be remedied by simply scaling up LLMs. Bai\\net al. (2022b) partially automates this fine-tuning-plus-RLHF approach by replacing the human-labeled\\nfine-tuningdatawiththemodel’sownself-critiquesandrevisions,andbyreplacinghumanraterswitha\\nmodel when ranking model outputs in RLHF, a process known as “RL from AI Feedback” (RLAIF).\\nKnown LLM Safety Challenges. Recent literature has extensively explored the risks and challenges linked\\nwith Large Language Models. Bender et al. (2021b) and Weidinger et al. (2021) underscore various hazards\\nlikebias,toxicity,privatedataleakage,andthepotentialformalicioususes. Solaimanetal.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-33'),\n",
              " '2621daf9-c22c-47db-9eb4-e8ef2e54928e': IndexNode(id_='2621daf9-c22c-47db-9eb4-e8ef2e54928e', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-33', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='f0fdb8b6107fdcc5607535145133530029c7c8ac6eb663545d1f19a6bdb3acf4'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='378cb449-be25-4399-bece-3fc0bd00a19d', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='e3741b2ef22f943ce2b8f7f2300e026f285574c3975b7568bd1670a27843343d')}, hash='ac5425d6b165522e881aab1eeb33e438372f84d3b3170331dfb86d5516eef787', text='Solaimanetal.(2023)categorizes\\ntheseimpactsintotwogroups—thosethatcanbeassessedwithinthebasesystemandthoserequiringa\\nsocietal context evaluation, while Kumar et al. (2022) offers potential mitigation strategies to curb harm.\\nWorkfromRolleretal.(2020)andDinanetal.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-33'),\n",
              " 'node-33': IndexNode(id_='node-33', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='415b7efc-e73f-4ac4-bbfd-c1546f099026', node_type=<ObjectType.DOCUMENT: '4'>, metadata={}, hash='231b3bd773f012c01b893ada9e009ecf25ee59934614c5a595c9bf1b3a123292'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='3130d7bc-01b4-4ddc-93f4-f05aced07547', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='605c4bb1c73b7df5fc2d6252477bd11755380b1806702dbfb94fe3cd909358ab'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='59ba5f14-f456-40cb-83e6-9df92f58578a', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='9dd26b43aac57d27c44f056cedff0e27e330f8ebe9f74f5a1fde1798eaa6e111')}, hash='f0fdb8b6107fdcc5607535145133530029c7c8ac6eb663545d1f19a6bdb3acf4', text='Galactica, for science(Taylor et al., 2022). With 70B parameters, Chinchilla (Hoffmann et al.,\\n2022) redefined those scaling laws towards the number of tokens rather than model weights. Notable in\\nthisprogressionistheriseofLlama,recognizedforitsfocusoncomputationalefficiencyduringinference\\n(Touvron et al., 2023). A parallel discourse has unfolded around the dynamics of open-source versus closed-\\nsourcemodels. Open-sourcereleaseslikeBLOOM(Scaoetal.,2022),OPT(Zhangetal.,2022),andFalcon\\n(Penedo et al., 2023) have risen to challenge their closed-source counterparts like GPT-3 and Chinchilla.\\n§§https://ai.meta.com/llama\\n35\\n\\nYet,whenitcomestothe\"production-ready\"LLMssuchasChatGPT,Bard,andClaude,there’samarked\\ndistinction in performance and usability. These models rely on intricate tuning techniques to align with\\nhuman preferences (Gudibande et al., 2023), a process that is still being explored and refined within the\\nopen-source community.\\nAttempts to close this gap have emerged, with distillation-based models such as Vicuna (Chiang et al., 2023)\\nandAlpaca(Taorietal.,2023)adoptingauniqueapproachtotrainingwithsyntheticinstructions(Honovich\\net al., 2022; Wang et al., 2022). However, while these models show promise, they still fall short of the bar set\\nby their closed-source counterparts.\\nInstructionTuning. Weietal.(2021)obtainedzero-shotperformanceonunseentasksbyfine-tuningLLMs\\nonnumerousdatasets. Chungetal.(2022)andLongpreetal.(2023)investigatetheimpactofinstruction\\ntuningasafunctionofnumberoftasks,modelsize,promptsettings,etc. Promptsusedforinstructiontuning\\ncanbecreatedbyhumansorbyLLMsthemselves(Zhouetal.,2022),andfollow-upinstructionscanbeused\\ntorefineinitialgenerationstomakethemmoreuseful,engaging,andunbiased(Gangulietal.,2023;Madaan\\net al., 2023). An approach related to instruction tuning is chain-of-thought prompting (Wei et al., 2022b), in\\nwhichmodels areprompted toexplain theirreasoningwhen givena complexproblem, inorder toincrease\\nthe likelihood that their final answer is correct.\\nRLHF has emerged as a powerful strategy for fine-tuning Large Language Models, enabling significant\\nimprovements in their performance (Christiano et al., 2017). The method, first showcased by Stiennon et al.\\n(2020) in the context of text-summarization tasks, has since been extended to a range of other applications.\\nIn this paradigm, models are fine-tuned based on feedback from human users, thus iteratively aligning the\\nmodels’ responses more closely with human expectations and preferences.\\nOuyang et al. (2022) demonstrates that a combination of instruction fine-tuning and RLHF can help fix\\nissues with factuality, toxicity, and helpfulness that cannot be remedied by simply scaling up LLMs. Bai\\net al. (2022b) partially automates this fine-tuning-plus-RLHF approach by replacing the human-labeled\\nfine-tuningdatawiththemodel’sownself-critiquesandrevisions,andbyreplacinghumanraterswitha\\nmodel when ranking model outputs in RLHF, a process known as “RL from AI Feedback” (RLAIF).\\nKnown LLM Safety Challenges. Recent literature has extensively explored the risks and challenges linked\\nwith Large Language Models. Bender et al. (2021b) and Weidinger et al. (2021) underscore various hazards\\nlikebias,toxicity,privatedataleakage,andthepotentialformalicioususes. Solaimanetal.(2023)categorizes\\ntheseimpactsintotwogroups—thosethatcanbeassessedwithinthebasesystemandthoserequiringa\\nsocietal context evaluation, while Kumar et al. (2022) offers potential mitigation strategies to curb harm.\\nWorkfromRolleretal.(2020)andDinanetal.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-33'),\n",
              " '520292a1-cea8-4df0-a1b3-40c3c3531129': IndexNode(id_='520292a1-cea8-4df0-a1b3-40c3c3531129', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-34', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='9dd26b43aac57d27c44f056cedff0e27e330f8ebe9f74f5a1fde1798eaa6e111'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='72163500-5b50-46ce-9a50-ca201dcaed78', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='8e4ae75b6db1eec4762e0bf7c50240e2d8fe684984ed823b58b2bfb07d3dcc54')}, hash='c01e4f5817d1f92d6b2388eea10ddfdb358f8158b50f1954ed7344e435acbd2c', text='WorkfromRolleretal.(2020)andDinanetal.(2021)alsoilluminatesthedifficultiestiedtochatbot-oriented\\nLLMs, with concerns ranging from privacy to misleading expertise claims. Deng et al. (2023) proposes\\na taxonomic framework to tackle these issues, and Bergman et al. (2022) delves into the balance between\\npotential positive and negative impacts from releasing dialogue models.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-34'),\n",
              " '72163500-5b50-46ce-9a50-ca201dcaed78': IndexNode(id_='72163500-5b50-46ce-9a50-ca201dcaed78', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-34', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='9dd26b43aac57d27c44f056cedff0e27e330f8ebe9f74f5a1fde1798eaa6e111'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='520292a1-cea8-4df0-a1b3-40c3c3531129', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='c01e4f5817d1f92d6b2388eea10ddfdb358f8158b50f1954ed7344e435acbd2c'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='cc81a495-2bbd-4006-8b14-022d368594ee', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='c26e0702e8db6c12f78d945bbdd58001f5f163a92e13b2257619126cdf5e1ffa')}, hash='8e4ae75b6db1eec4762e0bf7c50240e2d8fe684984ed823b58b2bfb07d3dcc54', text='InvestigationsintoredteamingrevealspecificchallengesintunedLLMs,withstudiesbyGangulietal.(2022)\\nand Zhuoet al. (2023) showcasing a variety ofsuccessful attack typesand their effects onthe generation of\\nharmful content. National security agencies and various researchers, such as (Mialon et al., 2023), have also\\nraisedredflagsaroundadvancedemergentmodelbehaviors,cyberthreats,andpotentialmisuseinareaslike\\nbiological warfare.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-34'),\n",
              " 'cc81a495-2bbd-4006-8b14-022d368594ee': IndexNode(id_='cc81a495-2bbd-4006-8b14-022d368594ee', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-34', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='9dd26b43aac57d27c44f056cedff0e27e330f8ebe9f74f5a1fde1798eaa6e111'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='72163500-5b50-46ce-9a50-ca201dcaed78', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='8e4ae75b6db1eec4762e0bf7c50240e2d8fe684984ed823b58b2bfb07d3dcc54'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='379aa60e-d18a-4dda-83f6-e4c53b9fe0d8', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='0a11bab7a22e003dbae9e7b58f239491c9d4873b1357314e88ce3b10146cc991')}, hash='c26e0702e8db6c12f78d945bbdd58001f5f163a92e13b2257619126cdf5e1ffa', text='Lastly, broader societal issues like job displacement due to accelerated AI research and an\\nover-reliance on LLMs leading to training data degradation are also pertinent considerations (Acemoglu\\nandRestrepo,2018;AutorandSalomons,2018;Webb,2019;Shumailovetal.,2023). Wearecommittedto\\ncontinuing our work engaging with the broader policy, academic, and industry community on these issues.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-34'),\n",
              " '379aa60e-d18a-4dda-83f6-e4c53b9fe0d8': IndexNode(id_='379aa60e-d18a-4dda-83f6-e4c53b9fe0d8', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-34', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='9dd26b43aac57d27c44f056cedff0e27e330f8ebe9f74f5a1fde1798eaa6e111'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='cc81a495-2bbd-4006-8b14-022d368594ee', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='c26e0702e8db6c12f78d945bbdd58001f5f163a92e13b2257619126cdf5e1ffa'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='4ceca4d9-7bf6-40f5-94a6-de9a9decc36f', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='97b9ef5b65f1d2793fd2edbed21218dd993b517ad8ddd652292cc2fd1cc8c7c9')}, hash='0a11bab7a22e003dbae9e7b58f239491c9d4873b1357314e88ce3b10146cc991', text='7 Conclusion\\nInthisstudy,wehaveintroduced Llama 2,anewfamilyofpretrainedandfine-tunedmodelswithscales\\nof7billionto70billionparameters. Thesemodelshavedemonstratedtheircompetitivenesswithexisting\\nopen-source chat models, as well as competency that is equivalent to some proprietary models on evaluation\\nsetsweexamined,althoughtheystilllagbehindothermodelslikeGPT-4.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-34'),\n",
              " '4ceca4d9-7bf6-40f5-94a6-de9a9decc36f': IndexNode(id_='4ceca4d9-7bf6-40f5-94a6-de9a9decc36f', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-34', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='9dd26b43aac57d27c44f056cedff0e27e330f8ebe9f74f5a1fde1798eaa6e111'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='379aa60e-d18a-4dda-83f6-e4c53b9fe0d8', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='0a11bab7a22e003dbae9e7b58f239491c9d4873b1357314e88ce3b10146cc991'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='ee070575-ad22-46da-812c-aa85b95527be', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='bf0f3d0f7a9d1dae9f8f2c5e7717e6a091dd045365e673d93096894eb7d088d5')}, hash='97b9ef5b65f1d2793fd2edbed21218dd993b517ad8ddd652292cc2fd1cc8c7c9', text='Wemeticulouslyelaboratedonthe\\nmethodsandtechniquesappliedinachievingourmodels,withaheavyemphasisontheiralignmentwiththe\\nprinciplesofhelpfulnessandsafety. Tocontributemoresignificantlytosocietyandfosterthepaceofresearch,\\nwehaveresponsiblyopenedaccessto Llama 2 andLlama 2-Chat . Aspartofourongoingcommitmentto\\ntransparency and safety, we plan to make further improvements to Llama 2-Chat in future work.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-34'),\n",
              " 'ee070575-ad22-46da-812c-aa85b95527be': IndexNode(id_='ee070575-ad22-46da-812c-aa85b95527be', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-34', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='9dd26b43aac57d27c44f056cedff0e27e330f8ebe9f74f5a1fde1798eaa6e111'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='4ceca4d9-7bf6-40f5-94a6-de9a9decc36f', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='97b9ef5b65f1d2793fd2edbed21218dd993b517ad8ddd652292cc2fd1cc8c7c9'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='fa51ca7b-bf1b-43b2-988b-6043926eacbc', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='cb8c4e70c31849af268a82e94111c6cd63f09bbebd0a3d7e9653053125dfd1a4')}, hash='bf0f3d0f7a9d1dae9f8f2c5e7717e6a091dd045365e673d93096894eb7d088d5', text='36\\n\\nReferences\\nDaron Acemoglu and Pascual Restrepo. Artificial intelligence, automation, and work. In The economics of\\nartificial intelligence: An agenda , pages 197–236. University of Chicago Press, 2018.\\nJoshua Ainslie, James Lee-Thorp, Michiel de Jong, Yury Zemlyanskiy, Federico Lebrón, and Sumit Sanghai.\\nGqa: Training generalized multi-query transformer models from multi-head checkpoints, 2023.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-34'),\n",
              " 'fa51ca7b-bf1b-43b2-988b-6043926eacbc': IndexNode(id_='fa51ca7b-bf1b-43b2-988b-6043926eacbc', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-34', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='9dd26b43aac57d27c44f056cedff0e27e330f8ebe9f74f5a1fde1798eaa6e111'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='ee070575-ad22-46da-812c-aa85b95527be', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='bf0f3d0f7a9d1dae9f8f2c5e7717e6a091dd045365e673d93096894eb7d088d5'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='832d6608-e651-4405-8895-cae0d314271b', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='1cc033a9bc33e9f14125b00f52e4a6af9403dc5f81880cad93f207774972e697')}, hash='cb8c4e70c31849af268a82e94111c6cd63f09bbebd0a3d7e9653053125dfd1a4', text='Gqa: Training generalized multi-query transformer models from multi-head checkpoints, 2023.\\nEbtesam Almazrouei, Hamza Alobeidli, Abdulaziz Alshamsi, Alessandro Cappelli, Ruxandra Cojocaru,\\nMerouane Debbah, Etienne Goffinet, Daniel Heslow, Julien Launay, Quentin Malartic, Badreddine Noune,\\nBaptiste Pannier, and Guilherme Penedo.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-34'),\n",
              " '832d6608-e651-4405-8895-cae0d314271b': IndexNode(id_='832d6608-e651-4405-8895-cae0d314271b', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-34', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='9dd26b43aac57d27c44f056cedff0e27e330f8ebe9f74f5a1fde1798eaa6e111'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='fa51ca7b-bf1b-43b2-988b-6043926eacbc', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='cb8c4e70c31849af268a82e94111c6cd63f09bbebd0a3d7e9653053125dfd1a4')}, hash='1cc033a9bc33e9f14125b00f52e4a6af9403dc5f81880cad93f207774972e697', text='Falcon-40B: an open large language model with state-of-the-art\\nperformance. 2023.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-34'),\n",
              " 'cfdd0333-2772-452f-96ef-71887839ee69': IndexNode(id_='cfdd0333-2772-452f-96ef-71887839ee69', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-34', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='9dd26b43aac57d27c44f056cedff0e27e330f8ebe9f74f5a1fde1798eaa6e111'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='a8023334-5a7f-4baa-9bdb-74c7686f8ae5', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='12373811a8e7a1140c1a43de47cbdc48d94f7a1f90ecde2bf1bf9f63c5604c0e')}, hash='683bf6c21e12f98485e3cfa9d7033283183eab121316ea598a85e2b13672ffbb', text='WorkfromRolleretal.(2020)andDinanetal.(2021)alsoilluminatesthedifficultiestiedtochatbot-oriented\\nLLMs, with concerns ranging from privacy to misleading expertise claims. Deng et al. (2023) proposes\\na taxonomic framework to tackle these issues, and Bergman et al. (2022) delves into the balance between\\npotential positive and negative impacts from releasing dialogue models.\\nInvestigationsintoredteamingrevealspecificchallengesintunedLLMs,withstudiesbyGangulietal.(2022)\\nand Zhuoet al. (2023) showcasing a variety ofsuccessful attack typesand their effects onthe generation of\\nharmful content. National security agencies and various researchers, such as (Mialon et al., 2023), have also\\nraisedredflagsaroundadvancedemergentmodelbehaviors,cyberthreats,andpotentialmisuseinareaslike\\nbiological warfare.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-34'),\n",
              " 'a8023334-5a7f-4baa-9bdb-74c7686f8ae5': IndexNode(id_='a8023334-5a7f-4baa-9bdb-74c7686f8ae5', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-34', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='9dd26b43aac57d27c44f056cedff0e27e330f8ebe9f74f5a1fde1798eaa6e111'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='cfdd0333-2772-452f-96ef-71887839ee69', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='683bf6c21e12f98485e3cfa9d7033283183eab121316ea598a85e2b13672ffbb'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='101faffe-8f7f-488e-afb8-69440dfe9cbb', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='300478cf0b897978695035c6fe176582510ae5fdd0c85f3d7bc1fa1401edf622')}, hash='12373811a8e7a1140c1a43de47cbdc48d94f7a1f90ecde2bf1bf9f63c5604c0e', text='Lastly, broader societal issues like job displacement due to accelerated AI research and an\\nover-reliance on LLMs leading to training data degradation are also pertinent considerations (Acemoglu\\nandRestrepo,2018;AutorandSalomons,2018;Webb,2019;Shumailovetal.,2023). Wearecommittedto\\ncontinuing our work engaging with the broader policy, academic, and industry community on these issues.\\n7 Conclusion\\nInthisstudy,wehaveintroduced Llama 2,anewfamilyofpretrainedandfine-tunedmodelswithscales\\nof7billionto70billionparameters. Thesemodelshavedemonstratedtheircompetitivenesswithexisting\\nopen-source chat models, as well as competency that is equivalent to some proprietary models on evaluation\\nsetsweexamined,althoughtheystilllagbehindothermodelslikeGPT-4. Wemeticulouslyelaboratedonthe\\nmethodsandtechniquesappliedinachievingourmodels,withaheavyemphasisontheiralignmentwiththe\\nprinciplesofhelpfulnessandsafety.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-34'),\n",
              " '101faffe-8f7f-488e-afb8-69440dfe9cbb': IndexNode(id_='101faffe-8f7f-488e-afb8-69440dfe9cbb', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-34', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='9dd26b43aac57d27c44f056cedff0e27e330f8ebe9f74f5a1fde1798eaa6e111'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='a8023334-5a7f-4baa-9bdb-74c7686f8ae5', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='12373811a8e7a1140c1a43de47cbdc48d94f7a1f90ecde2bf1bf9f63c5604c0e'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='11b212ec-e9b6-481d-b258-941df0a6624f', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='1f159949dfdcd42dfb1aa0a1abfd61c3b6c10f180da18c6cbf9dfff0c75a9ccc')}, hash='300478cf0b897978695035c6fe176582510ae5fdd0c85f3d7bc1fa1401edf622', text='Tocontributemoresignificantlytosocietyandfosterthepaceofresearch,\\nwehaveresponsiblyopenedaccessto Llama 2 andLlama 2-Chat . Aspartofourongoingcommitmentto\\ntransparency and safety, we plan to make further improvements to Llama 2-Chat in future work.\\n36\\n\\nReferences\\nDaron Acemoglu and Pascual Restrepo. Artificial intelligence, automation, and work. In The economics of\\nartificial intelligence: An agenda , pages 197–236. University of Chicago Press, 2018.\\nJoshua Ainslie, James Lee-Thorp, Michiel de Jong, Yury Zemlyanskiy, Federico Lebrón, and Sumit Sanghai.\\nGqa: Training generalized multi-query transformer models from multi-head checkpoints, 2023.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-34'),\n",
              " '11b212ec-e9b6-481d-b258-941df0a6624f': IndexNode(id_='11b212ec-e9b6-481d-b258-941df0a6624f', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-34', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='9dd26b43aac57d27c44f056cedff0e27e330f8ebe9f74f5a1fde1798eaa6e111'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='101faffe-8f7f-488e-afb8-69440dfe9cbb', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='300478cf0b897978695035c6fe176582510ae5fdd0c85f3d7bc1fa1401edf622')}, hash='1f159949dfdcd42dfb1aa0a1abfd61c3b6c10f180da18c6cbf9dfff0c75a9ccc', text='Gqa: Training generalized multi-query transformer models from multi-head checkpoints, 2023.\\nEbtesam Almazrouei, Hamza Alobeidli, Abdulaziz Alshamsi, Alessandro Cappelli, Ruxandra Cojocaru,\\nMerouane Debbah, Etienne Goffinet, Daniel Heslow, Julien Launay, Quentin Malartic, Badreddine Noune,\\nBaptiste Pannier, and Guilherme Penedo. Falcon-40B: an open large language model with state-of-the-art\\nperformance. 2023.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-34'),\n",
              " 'e3857db2-18e1-4421-92e6-9a0c1fdaeaf0': IndexNode(id_='e3857db2-18e1-4421-92e6-9a0c1fdaeaf0', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-34', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='9dd26b43aac57d27c44f056cedff0e27e330f8ebe9f74f5a1fde1798eaa6e111'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='778d56d8-ec5f-41da-8a84-cb9905ff19ba', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='ed0dc5971bf475acfe96956d7b2b4858fb1d7b2c7545d2036718e8d118bec61f')}, hash='6a8c359da512d2cc426a7b0fdfa4cb1d5b812329aff3edf0eb6f7704cdccc6bd', text='WorkfromRolleretal.(2020)andDinanetal.(2021)alsoilluminatesthedifficultiestiedtochatbot-oriented\\nLLMs, with concerns ranging from privacy to misleading expertise claims. Deng et al. (2023) proposes\\na taxonomic framework to tackle these issues, and Bergman et al. (2022) delves into the balance between\\npotential positive and negative impacts from releasing dialogue models.\\nInvestigationsintoredteamingrevealspecificchallengesintunedLLMs,withstudiesbyGangulietal.(2022)\\nand Zhuoet al. (2023) showcasing a variety ofsuccessful attack typesand their effects onthe generation of\\nharmful content. National security agencies and various researchers, such as (Mialon et al., 2023), have also\\nraisedredflagsaroundadvancedemergentmodelbehaviors,cyberthreats,andpotentialmisuseinareaslike\\nbiological warfare. Lastly, broader societal issues like job displacement due to accelerated AI research and an\\nover-reliance on LLMs leading to training data degradation are also pertinent considerations (Acemoglu\\nandRestrepo,2018;AutorandSalomons,2018;Webb,2019;Shumailovetal.,2023). Wearecommittedto\\ncontinuing our work engaging with the broader policy, academic, and industry community on these issues.\\n7 Conclusion\\nInthisstudy,wehaveintroduced Llama 2,anewfamilyofpretrainedandfine-tunedmodelswithscales\\nof7billionto70billionparameters. Thesemodelshavedemonstratedtheircompetitivenesswithexisting\\nopen-source chat models, as well as competency that is equivalent to some proprietary models on evaluation\\nsetsweexamined,althoughtheystilllagbehindothermodelslikeGPT-4. Wemeticulouslyelaboratedonthe\\nmethodsandtechniquesappliedinachievingourmodels,withaheavyemphasisontheiralignmentwiththe\\nprinciplesofhelpfulnessandsafety. Tocontributemoresignificantlytosocietyandfosterthepaceofresearch,\\nwehaveresponsiblyopenedaccessto Llama 2 andLlama 2-Chat .', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-34'),\n",
              " '778d56d8-ec5f-41da-8a84-cb9905ff19ba': IndexNode(id_='778d56d8-ec5f-41da-8a84-cb9905ff19ba', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-34', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='9dd26b43aac57d27c44f056cedff0e27e330f8ebe9f74f5a1fde1798eaa6e111'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='e3857db2-18e1-4421-92e6-9a0c1fdaeaf0', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='6a8c359da512d2cc426a7b0fdfa4cb1d5b812329aff3edf0eb6f7704cdccc6bd')}, hash='ed0dc5971bf475acfe96956d7b2b4858fb1d7b2c7545d2036718e8d118bec61f', text='Aspartofourongoingcommitmentto\\ntransparency and safety, we plan to make further improvements to Llama 2-Chat in future work.\\n36\\n\\nReferences\\nDaron Acemoglu and Pascual Restrepo. Artificial intelligence, automation, and work. In The economics of\\nartificial intelligence: An agenda , pages 197–236. University of Chicago Press, 2018.\\nJoshua Ainslie, James Lee-Thorp, Michiel de Jong, Yury Zemlyanskiy, Federico Lebrón, and Sumit Sanghai.\\nGqa: Training generalized multi-query transformer models from multi-head checkpoints, 2023.\\nEbtesam Almazrouei, Hamza Alobeidli, Abdulaziz Alshamsi, Alessandro Cappelli, Ruxandra Cojocaru,\\nMerouane Debbah, Etienne Goffinet, Daniel Heslow, Julien Launay, Quentin Malartic, Badreddine Noune,\\nBaptiste Pannier, and Guilherme Penedo. Falcon-40B: an open large language model with state-of-the-art\\nperformance. 2023.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-34'),\n",
              " 'node-34': IndexNode(id_='node-34', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='415b7efc-e73f-4ac4-bbfd-c1546f099026', node_type=<ObjectType.DOCUMENT: '4'>, metadata={}, hash='231b3bd773f012c01b893ada9e009ecf25ee59934614c5a595c9bf1b3a123292'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='ea2012fe-e787-4e99-b5e5-d763611848ff', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='f0fdb8b6107fdcc5607535145133530029c7c8ac6eb663545d1f19a6bdb3acf4'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='585206dc-b82b-4ae7-be2d-a230f7b62dc7', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='f48aeeb4e48fde6d2a388ba2c428bcee92f22da7248c27e5e501741444742ea8')}, hash='9dd26b43aac57d27c44f056cedff0e27e330f8ebe9f74f5a1fde1798eaa6e111', text='WorkfromRolleretal.(2020)andDinanetal.(2021)alsoilluminatesthedifficultiestiedtochatbot-oriented\\nLLMs, with concerns ranging from privacy to misleading expertise claims. Deng et al. (2023) proposes\\na taxonomic framework to tackle these issues, and Bergman et al. (2022) delves into the balance between\\npotential positive and negative impacts from releasing dialogue models.\\nInvestigationsintoredteamingrevealspecificchallengesintunedLLMs,withstudiesbyGangulietal.(2022)\\nand Zhuoet al. (2023) showcasing a variety ofsuccessful attack typesand their effects onthe generation of\\nharmful content. National security agencies and various researchers, such as (Mialon et al., 2023), have also\\nraisedredflagsaroundadvancedemergentmodelbehaviors,cyberthreats,andpotentialmisuseinareaslike\\nbiological warfare. Lastly, broader societal issues like job displacement due to accelerated AI research and an\\nover-reliance on LLMs leading to training data degradation are also pertinent considerations (Acemoglu\\nandRestrepo,2018;AutorandSalomons,2018;Webb,2019;Shumailovetal.,2023). Wearecommittedto\\ncontinuing our work engaging with the broader policy, academic, and industry community on these issues.\\n7 Conclusion\\nInthisstudy,wehaveintroduced Llama 2,anewfamilyofpretrainedandfine-tunedmodelswithscales\\nof7billionto70billionparameters. Thesemodelshavedemonstratedtheircompetitivenesswithexisting\\nopen-source chat models, as well as competency that is equivalent to some proprietary models on evaluation\\nsetsweexamined,althoughtheystilllagbehindothermodelslikeGPT-4. Wemeticulouslyelaboratedonthe\\nmethodsandtechniquesappliedinachievingourmodels,withaheavyemphasisontheiralignmentwiththe\\nprinciplesofhelpfulnessandsafety. Tocontributemoresignificantlytosocietyandfosterthepaceofresearch,\\nwehaveresponsiblyopenedaccessto Llama 2 andLlama 2-Chat . Aspartofourongoingcommitmentto\\ntransparency and safety, we plan to make further improvements to Llama 2-Chat in future work.\\n36\\n\\nReferences\\nDaron Acemoglu and Pascual Restrepo. Artificial intelligence, automation, and work. In The economics of\\nartificial intelligence: An agenda , pages 197–236. University of Chicago Press, 2018.\\nJoshua Ainslie, James Lee-Thorp, Michiel de Jong, Yury Zemlyanskiy, Federico Lebrón, and Sumit Sanghai.\\nGqa: Training generalized multi-query transformer models from multi-head checkpoints, 2023.\\nEbtesam Almazrouei, Hamza Alobeidli, Abdulaziz Alshamsi, Alessandro Cappelli, Ruxandra Cojocaru,\\nMerouane Debbah, Etienne Goffinet, Daniel Heslow, Julien Launay, Quentin Malartic, Badreddine Noune,\\nBaptiste Pannier, and Guilherme Penedo. Falcon-40B: an open large language model with state-of-the-art\\nperformance. 2023.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-34'),\n",
              " '799ba50d-5ba1-462f-a7a5-b795043b9cea': IndexNode(id_='799ba50d-5ba1-462f-a7a5-b795043b9cea', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-35', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='f48aeeb4e48fde6d2a388ba2c428bcee92f22da7248c27e5e501741444742ea8'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='633bcc58-dd22-4bee-9f3c-e7a0fa17e5ad', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='a67dc361e66c0a41c975b971a0777003e11da030f0e83bda5e1ffccb1d4efdef')}, hash='3e83f80f0fd7cfcf4e40adfa3032d0e642e7bc4a520cfe64b90daaf9a6024b71', text='2023.\\nRohan Anil, Andrew M. Dai, Orhan Firat, Melvin Johnson, Dmitry Lepikhin, Alexandre Passos, Siamak\\nShakeri, Emanuel Taropa, Paige Bailey, Zhifeng Chen, Eric Chu, Jonathan H. Clark, Laurent El Shafey,\\nYanping Huang, Kathy Meier-Hellstern, Gaurav Mishra, Erica Moreira, Mark Omernick, Kevin Robinson,\\nSebastian Ruder, Yi Tay, Kefan Xiao, Yuanzhong Xu, Yujing Zhang, Gustavo Hernandez Abrego,', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-35'),\n",
              " '633bcc58-dd22-4bee-9f3c-e7a0fa17e5ad': IndexNode(id_='633bcc58-dd22-4bee-9f3c-e7a0fa17e5ad', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-35', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='f48aeeb4e48fde6d2a388ba2c428bcee92f22da7248c27e5e501741444742ea8'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='799ba50d-5ba1-462f-a7a5-b795043b9cea', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='3e83f80f0fd7cfcf4e40adfa3032d0e642e7bc4a520cfe64b90daaf9a6024b71'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='74965fa8-cab5-4bc6-9665-7ab446504620', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='135df62827a935778583f3de4732f81de099e8c059dd93810ad7ffd8b0f3320a')}, hash='a67dc361e66c0a41c975b971a0777003e11da030f0e83bda5e1ffccb1d4efdef', text='Yuanzhong Xu, Yujing Zhang, Gustavo Hernandez Abrego, Junwhan\\nAhn,JacobAustin,Paul Barham,JanBotha,JamesBradbury,SiddharthaBrahma,Kevin Brooks,Michele\\nCatasta,YongCheng,ColinCherry,ChristopherA.Choquette-Choo,AakankshaChowdhery,Clément\\nCrepy,Shachi Dave, MostafaDehghani, SunipaDev,JacobDevlin, MarkDíaz,Nan Du,EthanDyer,', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-35'),\n",
              " '74965fa8-cab5-4bc6-9665-7ab446504620': IndexNode(id_='74965fa8-cab5-4bc6-9665-7ab446504620', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-35', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='f48aeeb4e48fde6d2a388ba2c428bcee92f22da7248c27e5e501741444742ea8'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='633bcc58-dd22-4bee-9f3c-e7a0fa17e5ad', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='a67dc361e66c0a41c975b971a0777003e11da030f0e83bda5e1ffccb1d4efdef'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='7c5e3363-df28-4e9e-9d0e-6f32e3bb6ae8', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='3fe586995b0aa2739206a330f28c29a34bd668d64ceceb65b713888b093323e3')}, hash='135df62827a935778583f3de4732f81de099e8c059dd93810ad7ffd8b0f3320a', text='JacobDevlin, MarkDíaz,Nan Du,EthanDyer, Vlad\\nFeinberg, Fangxiaoyu Feng, Vlad Fienber, Markus Freitag, Xavier Garcia, Sebastian Gehrmann, Lucas\\nGonzalez, Guy Gur-Ari, Steven Hand, Hadi Hashemi, Le Hou, Joshua Howland, Andrea Hu, Jeffrey\\nHui,JeremyHurwitz,MichaelIsard,AbeIttycheriah,MatthewJagielski,WenhaoJia,KathleenKenealy,\\nMaxim Krikun,', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-35'),\n",
              " '7c5e3363-df28-4e9e-9d0e-6f32e3bb6ae8': IndexNode(id_='7c5e3363-df28-4e9e-9d0e-6f32e3bb6ae8', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-35', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='f48aeeb4e48fde6d2a388ba2c428bcee92f22da7248c27e5e501741444742ea8'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='74965fa8-cab5-4bc6-9665-7ab446504620', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='135df62827a935778583f3de4732f81de099e8c059dd93810ad7ffd8b0f3320a'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='d7c6dbe7-e0fe-4a1e-a2ce-694b24b74a89', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='1114f4e6bbe022147d18b29235e0848b0714794c10c0cc52bb169c28b5dec22b')}, hash='3fe586995b0aa2739206a330f28c29a34bd668d64ceceb65b713888b093323e3', text='WenhaoJia,KathleenKenealy,\\nMaxim Krikun, Sneha Kudugunta, Chang Lan, Katherine Lee, Benjamin Lee, Eric Li, Music Li, Wei Li,\\nYaGuang Li, Jian Li, Hyeontaek Lim, Hanzhao Lin, Zhongtao Liu, Frederick Liu, Marcello Maggioni,\\nAroma Mahendru, Joshua Maynez, Vedant Misra, Maysam Moussalem, Zachary Nado, John Nham, Eric\\nNi,AndrewNystrom,', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-35'),\n",
              " 'd7c6dbe7-e0fe-4a1e-a2ce-694b24b74a89': IndexNode(id_='d7c6dbe7-e0fe-4a1e-a2ce-694b24b74a89', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-35', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='f48aeeb4e48fde6d2a388ba2c428bcee92f22da7248c27e5e501741444742ea8'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='7c5e3363-df28-4e9e-9d0e-6f32e3bb6ae8', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='3fe586995b0aa2739206a330f28c29a34bd668d64ceceb65b713888b093323e3'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='4cae8726-aea2-4efb-b982-7e05536b1857', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='93739142c8cfa83ebfa56787ba9e13211b3353369a68e51947a276e8f55056e1')}, hash='1114f4e6bbe022147d18b29235e0848b0714794c10c0cc52bb169c28b5dec22b', text='Zachary Nado, John Nham, Eric\\nNi,AndrewNystrom,AliciaParrish,MariePellat,MartinPolacek,AlexPolozov,ReinerPope,SiyuanQiao,\\nEmily Reif, Bryan Richter, Parker Riley, Alex Castro Ros, Aurko Roy, Brennan Saeta, Rajkumar Samuel,\\nRenee Shelby, Ambrose Slone, Daniel Smilkov, David R. So, Daniel Sohn, Simon Tokumine, Dasha Valter,\\nVijay Vasudevan, Kiran Vodrahalli,', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-35'),\n",
              " '4cae8726-aea2-4efb-b982-7e05536b1857': IndexNode(id_='4cae8726-aea2-4efb-b982-7e05536b1857', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-35', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='f48aeeb4e48fde6d2a388ba2c428bcee92f22da7248c27e5e501741444742ea8'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='d7c6dbe7-e0fe-4a1e-a2ce-694b24b74a89', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='1114f4e6bbe022147d18b29235e0848b0714794c10c0cc52bb169c28b5dec22b'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='4581ed2e-4ca8-4a73-8f65-8372657d5b56', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='77f7d7b497d66683d7cc40dc17b9c46a5edb3beb907115d1c0fd58b8dcb43d11')}, hash='93739142c8cfa83ebfa56787ba9e13211b3353369a68e51947a276e8f55056e1', text='Vijay Vasudevan, Kiran Vodrahalli, Xuezhi Wang, Pidong Wang, Zirui Wang, Tao Wang, John Wieting,\\nYuhuai Wu, Kelvin Xu, Yunhan Xu, Linting Xue, Pengcheng Yin, Jiahui Yu, Qiao Zhang, Steven Zheng,\\nCe Zheng, Weikang Zhou, Denny Zhou, Slav Petrov, and Yonghui Wu. Palm 2 technical report, 2023.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-35'),\n",
              " '4581ed2e-4ca8-4a73-8f65-8372657d5b56': IndexNode(id_='4581ed2e-4ca8-4a73-8f65-8372657d5b56', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-35', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='f48aeeb4e48fde6d2a388ba2c428bcee92f22da7248c27e5e501741444742ea8'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='4cae8726-aea2-4efb-b982-7e05536b1857', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='93739142c8cfa83ebfa56787ba9e13211b3353369a68e51947a276e8f55056e1'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='57244edf-22d4-4966-8cad-8107a401ab2e', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='ac4439b50b74109a713cd4a15c2dd468fa693ca21fee0b1f2bda287864d5e7e9')}, hash='77f7d7b497d66683d7cc40dc17b9c46a5edb3beb907115d1c0fd58b8dcb43d11', text='and Yonghui Wu. Palm 2 technical report, 2023.\\nAmanda Askell, Yuntao Bai, Anna Chen, Dawn Drain, Deep Ganguli, Tom Henighan, Andy Jones, Nicholas\\nJoseph, Ben Mann, Nova DasSarma, Nelson Elhage, Zac Hatfield-Dodds, Danny Hernandez, Jackson\\nKernion,KamalNdousse,CatherineOlsson,DarioAmodei,TomBrown,JackClark,SamMcCandlish,and\\nChrisOlah.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-35'),\n",
              " '57244edf-22d4-4966-8cad-8107a401ab2e': IndexNode(id_='57244edf-22d4-4966-8cad-8107a401ab2e', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-35', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='f48aeeb4e48fde6d2a388ba2c428bcee92f22da7248c27e5e501741444742ea8'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='4581ed2e-4ca8-4a73-8f65-8372657d5b56', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='77f7d7b497d66683d7cc40dc17b9c46a5edb3beb907115d1c0fd58b8dcb43d11'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='49477cc6-d415-4047-b028-67416bc0da0e', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='5a21d66d03069064653eb8045b600dc93476d867b97c3edd6b90a3ef6be8b4ce')}, hash='ac4439b50b74109a713cd4a15c2dd468fa693ca21fee0b1f2bda287864d5e7e9', text='Agenerallanguageassistantasalaboratoryforalignment. arXivpreprintarXiv:2112.00861 ,\\n2021a.\\nAmanda Askell, Yuntao Bai, Anna Chen, Dawn Drain, Deep Ganguli, Tom Henighan, Andy Jones, Nicholas\\nJoseph,BenMann,NovaDasSarma,etal. Agenerallanguageassistantasalaboratoryforalignment. arXiv\\npreprint arXiv:2112.00861 , 2021b.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-35'),\n",
              " '49477cc6-d415-4047-b028-67416bc0da0e': IndexNode(id_='49477cc6-d415-4047-b028-67416bc0da0e', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-35', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='f48aeeb4e48fde6d2a388ba2c428bcee92f22da7248c27e5e501741444742ea8'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='57244edf-22d4-4966-8cad-8107a401ab2e', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='ac4439b50b74109a713cd4a15c2dd468fa693ca21fee0b1f2bda287864d5e7e9')}, hash='5a21d66d03069064653eb8045b600dc93476d867b97c3edd6b90a3ef6be8b4ce', text='JacobAustin,AugustusOdena,MaxwellNye,MaartenBosma,HenrykMichalewski,DavidDohan,Ellen\\nJiang, Carrie Cai, Michael Terry, Quoc Le, and Charles Sutton. Program synthesis with large language\\nmodels, 2021.\\nDavidAutorandAnnaSalomons. Isautomationlabor-displacing? productivitygrowth,employment,and\\nthe labor share. Technical report, National Bureau of Economic Research, 2018.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-35'),\n",
              " 'bddcb568-88b2-4305-8eb7-0accd0b5c161': IndexNode(id_='bddcb568-88b2-4305-8eb7-0accd0b5c161', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-35', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='f48aeeb4e48fde6d2a388ba2c428bcee92f22da7248c27e5e501741444742ea8'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='cc40d854-fcb1-40a6-8c06-9ea7e1af47bf', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='3b1bc4fae882a8d2960e96a0125e9465100d373e4e7c514dc9f41003f87346c6')}, hash='441078f78a3f4bb672ce7ce8247024ca54d20e37d4494a91a6adb0da0e3dfea0', text='2023.\\nRohan Anil, Andrew M. Dai, Orhan Firat, Melvin Johnson, Dmitry Lepikhin, Alexandre Passos, Siamak\\nShakeri, Emanuel Taropa, Paige Bailey, Zhifeng Chen, Eric Chu, Jonathan H. Clark, Laurent El Shafey,\\nYanping Huang, Kathy Meier-Hellstern, Gaurav Mishra, Erica Moreira, Mark Omernick, Kevin Robinson,\\nSebastian Ruder, Yi Tay, Kefan Xiao, Yuanzhong Xu, Yujing Zhang, Gustavo Hernandez Abrego, Junwhan\\nAhn,JacobAustin,Paul Barham,JanBotha,JamesBradbury,SiddharthaBrahma,Kevin Brooks,Michele\\nCatasta,YongCheng,ColinCherry,ChristopherA.Choquette-Choo,AakankshaChowdhery,Clément\\nCrepy,Shachi Dave, MostafaDehghani, SunipaDev,JacobDevlin, MarkDíaz,Nan Du,EthanDyer, Vlad\\nFeinberg, Fangxiaoyu Feng,', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-35'),\n",
              " 'cc40d854-fcb1-40a6-8c06-9ea7e1af47bf': IndexNode(id_='cc40d854-fcb1-40a6-8c06-9ea7e1af47bf', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-35', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='f48aeeb4e48fde6d2a388ba2c428bcee92f22da7248c27e5e501741444742ea8'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='bddcb568-88b2-4305-8eb7-0accd0b5c161', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='441078f78a3f4bb672ce7ce8247024ca54d20e37d4494a91a6adb0da0e3dfea0'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='3c4fae78-83c3-472b-b899-dcaa6c4ab524', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='ca84de2d31583dd61acf6d48a05b11127dc285418ac0f30473c015e9a70ade43')}, hash='3b1bc4fae882a8d2960e96a0125e9465100d373e4e7c514dc9f41003f87346c6', text='EthanDyer, Vlad\\nFeinberg, Fangxiaoyu Feng, Vlad Fienber, Markus Freitag, Xavier Garcia, Sebastian Gehrmann, Lucas\\nGonzalez, Guy Gur-Ari, Steven Hand, Hadi Hashemi, Le Hou, Joshua Howland, Andrea Hu, Jeffrey\\nHui,JeremyHurwitz,MichaelIsard,AbeIttycheriah,MatthewJagielski,WenhaoJia,KathleenKenealy,\\nMaxim Krikun, Sneha Kudugunta, Chang Lan, Katherine Lee, Benjamin Lee, Eric Li, Music Li, Wei Li,\\nYaGuang Li, Jian Li, Hyeontaek Lim, Hanzhao Lin, Zhongtao Liu, Frederick Liu, Marcello Maggioni,\\nAroma Mahendru, Joshua Maynez, Vedant Misra, Maysam Moussalem, Zachary Nado, John Nham, Eric\\nNi,AndrewNystrom,AliciaParrish,MariePellat,MartinPolacek,AlexPolozov,ReinerPope,SiyuanQiao,\\nEmily Reif,', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-35'),\n",
              " '3c4fae78-83c3-472b-b899-dcaa6c4ab524': IndexNode(id_='3c4fae78-83c3-472b-b899-dcaa6c4ab524', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-35', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='f48aeeb4e48fde6d2a388ba2c428bcee92f22da7248c27e5e501741444742ea8'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='cc40d854-fcb1-40a6-8c06-9ea7e1af47bf', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='3b1bc4fae882a8d2960e96a0125e9465100d373e4e7c514dc9f41003f87346c6'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='c2a55332-b5b3-4231-bc75-24295c928c3d', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='c9752ade0d91fb305354e8a3c5901c76a5c8fb5de67bea0e8216e53a0c965a2f')}, hash='ca84de2d31583dd61acf6d48a05b11127dc285418ac0f30473c015e9a70ade43', text='AlexPolozov,ReinerPope,SiyuanQiao,\\nEmily Reif, Bryan Richter, Parker Riley, Alex Castro Ros, Aurko Roy, Brennan Saeta, Rajkumar Samuel,\\nRenee Shelby, Ambrose Slone, Daniel Smilkov, David R. So, Daniel Sohn, Simon Tokumine, Dasha Valter,\\nVijay Vasudevan, Kiran Vodrahalli, Xuezhi Wang, Pidong Wang, Zirui Wang, Tao Wang, John Wieting,\\nYuhuai Wu, Kelvin Xu, Yunhan Xu, Linting Xue, Pengcheng Yin, Jiahui Yu, Qiao Zhang, Steven Zheng,\\nCe Zheng, Weikang Zhou, Denny Zhou, Slav Petrov, and Yonghui Wu. Palm 2 technical report, 2023.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-35'),\n",
              " 'c2a55332-b5b3-4231-bc75-24295c928c3d': IndexNode(id_='c2a55332-b5b3-4231-bc75-24295c928c3d', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-35', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='f48aeeb4e48fde6d2a388ba2c428bcee92f22da7248c27e5e501741444742ea8'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='3c4fae78-83c3-472b-b899-dcaa6c4ab524', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='ca84de2d31583dd61acf6d48a05b11127dc285418ac0f30473c015e9a70ade43'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='d79ccb47-8df5-4ae7-88f5-ca81ca2f7ea2', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='5a21d66d03069064653eb8045b600dc93476d867b97c3edd6b90a3ef6be8b4ce')}, hash='c9752ade0d91fb305354e8a3c5901c76a5c8fb5de67bea0e8216e53a0c965a2f', text='and Yonghui Wu. Palm 2 technical report, 2023.\\nAmanda Askell, Yuntao Bai, Anna Chen, Dawn Drain, Deep Ganguli, Tom Henighan, Andy Jones, Nicholas\\nJoseph, Ben Mann, Nova DasSarma, Nelson Elhage, Zac Hatfield-Dodds, Danny Hernandez, Jackson\\nKernion,KamalNdousse,CatherineOlsson,DarioAmodei,TomBrown,JackClark,SamMcCandlish,and\\nChrisOlah. Agenerallanguageassistantasalaboratoryforalignment. arXivpreprintarXiv:2112.00861 ,\\n2021a.\\nAmanda Askell, Yuntao Bai, Anna Chen, Dawn Drain, Deep Ganguli, Tom Henighan, Andy Jones, Nicholas\\nJoseph,BenMann,NovaDasSarma,etal. Agenerallanguageassistantasalaboratoryforalignment. arXiv\\npreprint arXiv:2112.00861 , 2021b.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-35'),\n",
              " 'd79ccb47-8df5-4ae7-88f5-ca81ca2f7ea2': IndexNode(id_='d79ccb47-8df5-4ae7-88f5-ca81ca2f7ea2', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-35', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='f48aeeb4e48fde6d2a388ba2c428bcee92f22da7248c27e5e501741444742ea8'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='c2a55332-b5b3-4231-bc75-24295c928c3d', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='c9752ade0d91fb305354e8a3c5901c76a5c8fb5de67bea0e8216e53a0c965a2f')}, hash='5a21d66d03069064653eb8045b600dc93476d867b97c3edd6b90a3ef6be8b4ce', text='JacobAustin,AugustusOdena,MaxwellNye,MaartenBosma,HenrykMichalewski,DavidDohan,Ellen\\nJiang, Carrie Cai, Michael Terry, Quoc Le, and Charles Sutton. Program synthesis with large language\\nmodels, 2021.\\nDavidAutorandAnnaSalomons. Isautomationlabor-displacing? productivitygrowth,employment,and\\nthe labor share. Technical report, National Bureau of Economic Research, 2018.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-35'),\n",
              " '087edacf-c150-42d4-b8ca-df5cc53e4fcd': IndexNode(id_='087edacf-c150-42d4-b8ca-df5cc53e4fcd', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-35', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='f48aeeb4e48fde6d2a388ba2c428bcee92f22da7248c27e5e501741444742ea8'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='c8b373b0-544f-44f2-8c51-70d66e626314', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='e49ae67f598f2d657a83a25b99c3765571778f80dca90e1cf13a0ce7ad440aa2')}, hash='8905804608401e5a8f4f5b9a404b4b189a637ae4db16bb50d0083a99eb9e8641', text='2023.\\nRohan Anil, Andrew M. Dai, Orhan Firat, Melvin Johnson, Dmitry Lepikhin, Alexandre Passos, Siamak\\nShakeri, Emanuel Taropa, Paige Bailey, Zhifeng Chen, Eric Chu, Jonathan H. Clark, Laurent El Shafey,\\nYanping Huang, Kathy Meier-Hellstern, Gaurav Mishra, Erica Moreira, Mark Omernick, Kevin Robinson,\\nSebastian Ruder, Yi Tay, Kefan Xiao, Yuanzhong Xu, Yujing Zhang, Gustavo Hernandez Abrego, Junwhan\\nAhn,JacobAustin,Paul Barham,JanBotha,JamesBradbury,SiddharthaBrahma,Kevin Brooks,Michele\\nCatasta,YongCheng,ColinCherry,ChristopherA.Choquette-Choo,AakankshaChowdhery,Clément\\nCrepy,Shachi Dave, MostafaDehghani, SunipaDev,JacobDevlin, MarkDíaz,Nan Du,EthanDyer, Vlad\\nFeinberg, Fangxiaoyu Feng, Vlad Fienber, Markus Freitag, Xavier Garcia, Sebastian Gehrmann, Lucas\\nGonzalez, Guy Gur-Ari, Steven Hand, Hadi Hashemi, Le Hou, Joshua Howland, Andrea Hu, Jeffrey\\nHui,JeremyHurwitz,MichaelIsard,AbeIttycheriah,MatthewJagielski,WenhaoJia,KathleenKenealy,\\nMaxim Krikun, Sneha Kudugunta, Chang Lan, Katherine Lee, Benjamin Lee, Eric Li, Music Li, Wei Li,\\nYaGuang Li, Jian Li, Hyeontaek Lim, Hanzhao Lin, Zhongtao Liu, Frederick Liu, Marcello Maggioni,\\nAroma Mahendru, Joshua Maynez, Vedant Misra, Maysam Moussalem, Zachary Nado, John Nham, Eric\\nNi,AndrewNystrom,AliciaParrish,MariePellat,MartinPolacek,AlexPolozov,ReinerPope,SiyuanQiao,\\nEmily Reif, Bryan Richter, Parker Riley, Alex Castro Ros, Aurko Roy, Brennan Saeta,', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-35'),\n",
              " 'c8b373b0-544f-44f2-8c51-70d66e626314': IndexNode(id_='c8b373b0-544f-44f2-8c51-70d66e626314', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-35', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='f48aeeb4e48fde6d2a388ba2c428bcee92f22da7248c27e5e501741444742ea8'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='087edacf-c150-42d4-b8ca-df5cc53e4fcd', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='8905804608401e5a8f4f5b9a404b4b189a637ae4db16bb50d0083a99eb9e8641')}, hash='e49ae67f598f2d657a83a25b99c3765571778f80dca90e1cf13a0ce7ad440aa2', text='Bryan Richter, Parker Riley, Alex Castro Ros, Aurko Roy, Brennan Saeta, Rajkumar Samuel,\\nRenee Shelby, Ambrose Slone, Daniel Smilkov, David R. So, Daniel Sohn, Simon Tokumine, Dasha Valter,\\nVijay Vasudevan, Kiran Vodrahalli, Xuezhi Wang, Pidong Wang, Zirui Wang, Tao Wang, John Wieting,\\nYuhuai Wu, Kelvin Xu, Yunhan Xu, Linting Xue, Pengcheng Yin, Jiahui Yu, Qiao Zhang, Steven Zheng,\\nCe Zheng, Weikang Zhou, Denny Zhou, Slav Petrov, and Yonghui Wu. Palm 2 technical report, 2023.\\nAmanda Askell, Yuntao Bai, Anna Chen, Dawn Drain, Deep Ganguli, Tom Henighan, Andy Jones, Nicholas\\nJoseph, Ben Mann, Nova DasSarma, Nelson Elhage, Zac Hatfield-Dodds, Danny Hernandez, Jackson\\nKernion,KamalNdousse,CatherineOlsson,DarioAmodei,TomBrown,JackClark,SamMcCandlish,and\\nChrisOlah. Agenerallanguageassistantasalaboratoryforalignment. arXivpreprintarXiv:2112.00861 ,\\n2021a.\\nAmanda Askell, Yuntao Bai, Anna Chen, Dawn Drain, Deep Ganguli, Tom Henighan, Andy Jones, Nicholas\\nJoseph,BenMann,NovaDasSarma,etal. Agenerallanguageassistantasalaboratoryforalignment. arXiv\\npreprint arXiv:2112.00861 , 2021b.\\nJacobAustin,AugustusOdena,MaxwellNye,MaartenBosma,HenrykMichalewski,DavidDohan,Ellen\\nJiang, Carrie Cai, Michael Terry, Quoc Le, and Charles Sutton. Program synthesis with large language\\nmodels, 2021.\\nDavidAutorandAnnaSalomons. Isautomationlabor-displacing? productivitygrowth,employment,and\\nthe labor share. Technical report, National Bureau of Economic Research, 2018.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-35'),\n",
              " 'node-35': IndexNode(id_='node-35', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='415b7efc-e73f-4ac4-bbfd-c1546f099026', node_type=<ObjectType.DOCUMENT: '4'>, metadata={}, hash='231b3bd773f012c01b893ada9e009ecf25ee59934614c5a595c9bf1b3a123292'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='59ba5f14-f456-40cb-83e6-9df92f58578a', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='9dd26b43aac57d27c44f056cedff0e27e330f8ebe9f74f5a1fde1798eaa6e111'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='d10248ae-15cc-4abc-9fc8-236cb2f29e89', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='a559a98e5baffcba08987fabee98cb54f842afd6466ac56ea460f21b30b35489')}, hash='f48aeeb4e48fde6d2a388ba2c428bcee92f22da7248c27e5e501741444742ea8', text='2023.\\nRohan Anil, Andrew M. Dai, Orhan Firat, Melvin Johnson, Dmitry Lepikhin, Alexandre Passos, Siamak\\nShakeri, Emanuel Taropa, Paige Bailey, Zhifeng Chen, Eric Chu, Jonathan H. Clark, Laurent El Shafey,\\nYanping Huang, Kathy Meier-Hellstern, Gaurav Mishra, Erica Moreira, Mark Omernick, Kevin Robinson,\\nSebastian Ruder, Yi Tay, Kefan Xiao, Yuanzhong Xu, Yujing Zhang, Gustavo Hernandez Abrego, Junwhan\\nAhn,JacobAustin,Paul Barham,JanBotha,JamesBradbury,SiddharthaBrahma,Kevin Brooks,Michele\\nCatasta,YongCheng,ColinCherry,ChristopherA.Choquette-Choo,AakankshaChowdhery,Clément\\nCrepy,Shachi Dave, MostafaDehghani, SunipaDev,JacobDevlin, MarkDíaz,Nan Du,EthanDyer, Vlad\\nFeinberg, Fangxiaoyu Feng, Vlad Fienber, Markus Freitag, Xavier Garcia, Sebastian Gehrmann, Lucas\\nGonzalez, Guy Gur-Ari, Steven Hand, Hadi Hashemi, Le Hou, Joshua Howland, Andrea Hu, Jeffrey\\nHui,JeremyHurwitz,MichaelIsard,AbeIttycheriah,MatthewJagielski,WenhaoJia,KathleenKenealy,\\nMaxim Krikun, Sneha Kudugunta, Chang Lan, Katherine Lee, Benjamin Lee, Eric Li, Music Li, Wei Li,\\nYaGuang Li, Jian Li, Hyeontaek Lim, Hanzhao Lin, Zhongtao Liu, Frederick Liu, Marcello Maggioni,\\nAroma Mahendru, Joshua Maynez, Vedant Misra, Maysam Moussalem, Zachary Nado, John Nham, Eric\\nNi,AndrewNystrom,AliciaParrish,MariePellat,MartinPolacek,AlexPolozov,ReinerPope,SiyuanQiao,\\nEmily Reif, Bryan Richter, Parker Riley, Alex Castro Ros, Aurko Roy, Brennan Saeta, Rajkumar Samuel,\\nRenee Shelby, Ambrose Slone, Daniel Smilkov, David R. So, Daniel Sohn, Simon Tokumine, Dasha Valter,\\nVijay Vasudevan, Kiran Vodrahalli, Xuezhi Wang, Pidong Wang, Zirui Wang, Tao Wang, John Wieting,\\nYuhuai Wu, Kelvin Xu, Yunhan Xu, Linting Xue, Pengcheng Yin, Jiahui Yu, Qiao Zhang, Steven Zheng,\\nCe Zheng, Weikang Zhou, Denny Zhou, Slav Petrov, and Yonghui Wu. Palm 2 technical report, 2023.\\nAmanda Askell, Yuntao Bai, Anna Chen, Dawn Drain, Deep Ganguli, Tom Henighan, Andy Jones, Nicholas\\nJoseph, Ben Mann, Nova DasSarma, Nelson Elhage, Zac Hatfield-Dodds, Danny Hernandez, Jackson\\nKernion,KamalNdousse,CatherineOlsson,DarioAmodei,TomBrown,JackClark,SamMcCandlish,and\\nChrisOlah. Agenerallanguageassistantasalaboratoryforalignment. arXivpreprintarXiv:2112.00861 ,\\n2021a.\\nAmanda Askell, Yuntao Bai, Anna Chen, Dawn Drain, Deep Ganguli, Tom Henighan, Andy Jones, Nicholas\\nJoseph,BenMann,NovaDasSarma,etal. Agenerallanguageassistantasalaboratoryforalignment. arXiv\\npreprint arXiv:2112.00861 , 2021b.\\nJacobAustin,AugustusOdena,MaxwellNye,MaartenBosma,HenrykMichalewski,DavidDohan,Ellen\\nJiang, Carrie Cai, Michael Terry, Quoc Le, and Charles Sutton. Program synthesis with large language\\nmodels, 2021.\\nDavidAutorandAnnaSalomons. Isautomationlabor-displacing? productivitygrowth,employment,and\\nthe labor share. Technical report, National Bureau of Economic Research, 2018.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-35'),\n",
              " 'f72f12fa-72d6-4cf8-a1d0-ed92664b2e26': IndexNode(id_='f72f12fa-72d6-4cf8-a1d0-ed92664b2e26', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-36', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='a559a98e5baffcba08987fabee98cb54f842afd6466ac56ea460f21b30b35489'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='b5f8fde0-f459-48ce-b45c-b76d0f7f27ff', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='275e73eb9f00da7f3ac3726da23867dfdc5c4b102499b27ee2767f4b0204de71')}, hash='b392998cf4dce7cc4a3d1ddce22a50423843081281a1faa599bafa8f5746e543', text='Technical report, National Bureau of Economic Research, 2018.\\nYuntaoBai,AndyJones,KamalNdousse,AmandaAskell,AnnaChen,NovaDasSarma,DawnDrain,Stanislav\\nFort,DeepGanguli,TomHenighan,etal. Trainingahelpfulandharmlessassistantwithreinforcement\\nlearning from human feedback. arXiv preprint arXiv:2204.05862 , 2022a.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-36'),\n",
              " 'b5f8fde0-f459-48ce-b45c-b76d0f7f27ff': IndexNode(id_='b5f8fde0-f459-48ce-b45c-b76d0f7f27ff', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-36', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='a559a98e5baffcba08987fabee98cb54f842afd6466ac56ea460f21b30b35489'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='f72f12fa-72d6-4cf8-a1d0-ed92664b2e26', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='b392998cf4dce7cc4a3d1ddce22a50423843081281a1faa599bafa8f5746e543'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='38250120-6d74-4e09-a562-4b81b65a6536', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='05299da78bcecdb3b560351ed3ba6665b8d8fa03c5cbb67a9f9bbe3c55f000e6')}, hash='275e73eb9f00da7f3ac3726da23867dfdc5c4b102499b27ee2767f4b0204de71', text='arXiv preprint arXiv:2204.05862 , 2022a.\\nYuntao Bai, Saurav Kadavath, Sandipan Kundu, Amanda Askell, Jackson Kernion, Andy Jones, Anna Chen,\\nAnna Goldie, Azalia Mirhoseini, Cameron McKinnon, et al. Constitutional ai: Harmlessness from ai\\nfeedback. arXiv preprint arXiv:2212.08073 , 2022b.\\nAprilHBailey,AdinaWilliams,andAndreiCimpian.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-36'),\n",
              " '38250120-6d74-4e09-a562-4b81b65a6536': IndexNode(id_='38250120-6d74-4e09-a562-4b81b65a6536', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-36', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='a559a98e5baffcba08987fabee98cb54f842afd6466ac56ea460f21b30b35489'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='b5f8fde0-f459-48ce-b45c-b76d0f7f27ff', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='275e73eb9f00da7f3ac3726da23867dfdc5c4b102499b27ee2767f4b0204de71'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='95d39f5f-4b54-4ea2-aef1-a8f07ce4e0d2', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='87373cd270caa61d389719c59ddb772b6757d445529cfffcd08b6508c89813a9')}, hash='05299da78bcecdb3b560351ed3ba6665b8d8fa03c5cbb67a9f9bbe3c55f000e6', text='AprilHBailey,AdinaWilliams,andAndreiCimpian. Basedonbillionsofwordsontheinternet,people=\\nmen.Science Advances , 8(13):eabm2463, 2022.\\nEmily M Bender, Timnit Gebru, Angelina McMillan-Major, and Margaret Mitchell. On the dangers of\\nstochastic parrots: Can language models be too big? In Proceedings of the 2021 ACM Conference on Fairness,\\nAccountability, and Transparency , pages 610–623, 2021a.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-36'),\n",
              " '95d39f5f-4b54-4ea2-aef1-a8f07ce4e0d2': IndexNode(id_='95d39f5f-4b54-4ea2-aef1-a8f07ce4e0d2', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-36', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='a559a98e5baffcba08987fabee98cb54f842afd6466ac56ea460f21b30b35489'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='38250120-6d74-4e09-a562-4b81b65a6536', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='05299da78bcecdb3b560351ed3ba6665b8d8fa03c5cbb67a9f9bbe3c55f000e6'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='a7b8fb75-8f94-4749-b8f1-4036e8d20984', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='85b071d9de1c356161571948136a685e9ab66c578467db33f294fb5f2ff6e9ae')}, hash='87373cd270caa61d389719c59ddb772b6757d445529cfffcd08b6508c89813a9', text='EmilyMBender,TimnitGebru,AngelinaMcMillan-Major,andShmargaretShmitchell. Onthedangersof\\nstochasticparrots: Canlanguagemodelsbetoobig? In Proceedingsofthe2021ACMconferenceonfairness,\\naccountability, and transparency , pages 610–623, 2021b.\\n37\\n\\nA Stevie Bergman, Gavin Abercrombie, Shannon L Spruit, Dirk Hovy, Emily Dinan, Y-Lan Boureau, and\\nVerena Rieser.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-36'),\n",
              " 'a7b8fb75-8f94-4749-b8f1-4036e8d20984': IndexNode(id_='a7b8fb75-8f94-4749-b8f1-4036e8d20984', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-36', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='a559a98e5baffcba08987fabee98cb54f842afd6466ac56ea460f21b30b35489'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='95d39f5f-4b54-4ea2-aef1-a8f07ce4e0d2', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='87373cd270caa61d389719c59ddb772b6757d445529cfffcd08b6508c89813a9'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='7baccf03-0836-48b4-9783-573582ef21ee', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='8601225cf588e836d12effca61263a82cde9c2410bd7e85752820280a554f8f4')}, hash='85b071d9de1c356161571948136a685e9ab66c578467db33f294fb5f2ff6e9ae', text='Guiding the release of safer e2e conversational ai through value sensitive design. In\\nProceedings ofthe23rdAnnualMeeting oftheSpecial InterestGroup onDiscourseandDialogue , pages39–52,\\n2022.\\nShaily Bhatt, Sunipa Dev, Partha Talukdar, Shachi Dave, and Vinodkumar Prabhakaran. Re-contextualizing\\nfairness in nlp: The case of india, 2022.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-36'),\n",
              " '7baccf03-0836-48b4-9783-573582ef21ee': IndexNode(id_='7baccf03-0836-48b4-9783-573582ef21ee', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-36', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='a559a98e5baffcba08987fabee98cb54f842afd6466ac56ea460f21b30b35489'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='a7b8fb75-8f94-4749-b8f1-4036e8d20984', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='85b071d9de1c356161571948136a685e9ab66c578467db33f294fb5f2ff6e9ae'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='d38613f9-983d-4962-bb0c-b560630ab278', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='1c5e8ea35d66ba1e276f5c5cd1936d552172b995096d741b2e43c2ac1200687d')}, hash='8601225cf588e836d12effca61263a82cde9c2410bd7e85752820280a554f8f4', text='Yonatan Bisk, Rowan Zellers, Jianfeng Gao, Yejin Choi, et al. Piqa: Reasoning about physical commonsense\\nin natural language. In Proceedings of the AAAI conference on artificial intelligence , pages 7432–7439, 2020.\\nSuLinBlodgett,GilsiniaLopez,AlexandraOlteanu,RobertSim,andHannaWallach. Stereotypingnorwegian\\nsalmon: Aninventoryofpitfallsinfairnessbenchmarkdatasets.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-36'),\n",
              " 'd38613f9-983d-4962-bb0c-b560630ab278': IndexNode(id_='d38613f9-983d-4962-bb0c-b560630ab278', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-36', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='a559a98e5baffcba08987fabee98cb54f842afd6466ac56ea460f21b30b35489'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='7baccf03-0836-48b4-9783-573582ef21ee', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='8601225cf588e836d12effca61263a82cde9c2410bd7e85752820280a554f8f4'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='d7d61812-421f-4bd2-8b51-f40e2b6caddb', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='4dde48839a178db31d13d2a891cb285daa3435cdbb4f37e3c157df11f0ecb065')}, hash='1c5e8ea35d66ba1e276f5c5cd1936d552172b995096d741b2e43c2ac1200687d', text='In Proceedingsofthe59thAnnualMeetingof\\nthe Association for Computational Linguistics and the 11th International Joint Conference on Natural Language\\nProcessing (Volume 1: Long Papers) , pages 1004–1015, 2021.\\nPiotrBojanowski,EdouardGrave,ArmandJoulin,andTomásMikolov. Enrichingwordvectorswithsubword\\ninformation. CoRR, abs/1607.04606, 2016. URL http://arxiv.org/abs/1607.04606 .', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-36'),\n",
              " 'd7d61812-421f-4bd2-8b51-f40e2b6caddb': IndexNode(id_='d7d61812-421f-4bd2-8b51-f40e2b6caddb', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-36', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='a559a98e5baffcba08987fabee98cb54f842afd6466ac56ea460f21b30b35489'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='d38613f9-983d-4962-bb0c-b560630ab278', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='1c5e8ea35d66ba1e276f5c5cd1936d552172b995096d741b2e43c2ac1200687d'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='96b0d807-4ee7-4f30-b733-f675858dcd20', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='74ac04eecf853b0d7beb9fa87725bc3f32a6bd65c487d3fb97f0d90ecb06f266')}, hash='4dde48839a178db31d13d2a891cb285daa3435cdbb4f37e3c157df11f0ecb065', text='URL http://arxiv.org/abs/1607.04606 .\\nTom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Nee-\\nlakantan,PranavShyam, GirishSastry,AmandaAskell, SandhiniAgarwal,ArielHerbert-Voss, Gretchen\\nKrueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel Ziegler, Jeffrey Wu, Clemens Winter, Chris\\nHesse,', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-36'),\n",
              " '96b0d807-4ee7-4f30-b733-f675858dcd20': IndexNode(id_='96b0d807-4ee7-4f30-b733-f675858dcd20', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-36', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='a559a98e5baffcba08987fabee98cb54f842afd6466ac56ea460f21b30b35489'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='d7d61812-421f-4bd2-8b51-f40e2b6caddb', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='4dde48839a178db31d13d2a891cb285daa3435cdbb4f37e3c157df11f0ecb065')}, hash='74ac04eecf853b0d7beb9fa87725bc3f32a6bd65c487d3fb97f0d90ecb06f266', text='Daniel Ziegler, Jeffrey Wu, Clemens Winter, Chris\\nHesse,MarkChen,EricSigler,MateuszLitwin,ScottGray,BenjaminChess,JackClark,ChristopherBerner,\\nSamMcCandlish,AlecRadford,IlyaSutskever,andDarioAmodei. Languagemodelsarefew-shotlearners.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-36'),\n",
              " '2b61b928-9217-4189-83b5-83a576de35a5': IndexNode(id_='2b61b928-9217-4189-83b5-83a576de35a5', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-36', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='a559a98e5baffcba08987fabee98cb54f842afd6466ac56ea460f21b30b35489'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='04d99419-d88b-497b-86c1-c74a5f31786b', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='4746e51107962de121a7b1794883cf379c72178816924b3d0f0ddd650a539193')}, hash='16c659b1b682d5b431e0f68e8f47fe4c8b96cffacdb74e15a31cef85a2040f53', text='Technical report, National Bureau of Economic Research, 2018.\\nYuntaoBai,AndyJones,KamalNdousse,AmandaAskell,AnnaChen,NovaDasSarma,DawnDrain,Stanislav\\nFort,DeepGanguli,TomHenighan,etal. Trainingahelpfulandharmlessassistantwithreinforcement\\nlearning from human feedback. arXiv preprint arXiv:2204.05862 , 2022a.\\nYuntao Bai, Saurav Kadavath, Sandipan Kundu, Amanda Askell, Jackson Kernion, Andy Jones, Anna Chen,\\nAnna Goldie, Azalia Mirhoseini, Cameron McKinnon, et al. Constitutional ai: Harmlessness from ai\\nfeedback. arXiv preprint arXiv:2212.08073 , 2022b.\\nAprilHBailey,AdinaWilliams,andAndreiCimpian. Basedonbillionsofwordsontheinternet,people=\\nmen.Science Advances , 8(13):eabm2463, 2022.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-36'),\n",
              " '04d99419-d88b-497b-86c1-c74a5f31786b': IndexNode(id_='04d99419-d88b-497b-86c1-c74a5f31786b', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-36', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='a559a98e5baffcba08987fabee98cb54f842afd6466ac56ea460f21b30b35489'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='2b61b928-9217-4189-83b5-83a576de35a5', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='16c659b1b682d5b431e0f68e8f47fe4c8b96cffacdb74e15a31cef85a2040f53'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='ebae5cc1-046b-4c5e-bdae-c5455d1e54ac', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='f0f605a2477e2ede793fee962495e0a452889fdda404e948f34fc7a26f35e3e4')}, hash='4746e51107962de121a7b1794883cf379c72178816924b3d0f0ddd650a539193', text='Emily M Bender, Timnit Gebru, Angelina McMillan-Major, and Margaret Mitchell. On the dangers of\\nstochastic parrots: Can language models be too big? In Proceedings of the 2021 ACM Conference on Fairness,\\nAccountability, and Transparency , pages 610–623, 2021a.\\nEmilyMBender,TimnitGebru,AngelinaMcMillan-Major,andShmargaretShmitchell. Onthedangersof\\nstochasticparrots: Canlanguagemodelsbetoobig? In Proceedingsofthe2021ACMconferenceonfairness,\\naccountability, and transparency , pages 610–623, 2021b.\\n37\\n\\nA Stevie Bergman, Gavin Abercrombie, Shannon L Spruit, Dirk Hovy, Emily Dinan, Y-Lan Boureau, and\\nVerena Rieser. Guiding the release of safer e2e conversational ai through value sensitive design. In\\nProceedings ofthe23rdAnnualMeeting oftheSpecial InterestGroup onDiscourseandDialogue , pages39–52,\\n2022.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-36'),\n",
              " 'ebae5cc1-046b-4c5e-bdae-c5455d1e54ac': IndexNode(id_='ebae5cc1-046b-4c5e-bdae-c5455d1e54ac', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-36', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='a559a98e5baffcba08987fabee98cb54f842afd6466ac56ea460f21b30b35489'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='04d99419-d88b-497b-86c1-c74a5f31786b', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='4746e51107962de121a7b1794883cf379c72178816924b3d0f0ddd650a539193'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='9351aa93-1b80-47fc-9636-46279e47d3ca', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='ef0146d206e56aa0c665288fe43ecaa534ccdd0e4cd2385dd63952eb858c72c9')}, hash='f0f605a2477e2ede793fee962495e0a452889fdda404e948f34fc7a26f35e3e4', text='Shaily Bhatt, Sunipa Dev, Partha Talukdar, Shachi Dave, and Vinodkumar Prabhakaran. Re-contextualizing\\nfairness in nlp: The case of india, 2022.\\nYonatan Bisk, Rowan Zellers, Jianfeng Gao, Yejin Choi, et al. Piqa: Reasoning about physical commonsense\\nin natural language. In Proceedings of the AAAI conference on artificial intelligence , pages 7432–7439, 2020.\\nSuLinBlodgett,GilsiniaLopez,AlexandraOlteanu,RobertSim,andHannaWallach. Stereotypingnorwegian\\nsalmon: Aninventoryofpitfallsinfairnessbenchmarkdatasets. In Proceedingsofthe59thAnnualMeetingof\\nthe Association for Computational Linguistics and the 11th International Joint Conference on Natural Language\\nProcessing (Volume 1: Long Papers) , pages 1004–1015, 2021.\\nPiotrBojanowski,EdouardGrave,ArmandJoulin,andTomásMikolov.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-36'),\n",
              " '9351aa93-1b80-47fc-9636-46279e47d3ca': IndexNode(id_='9351aa93-1b80-47fc-9636-46279e47d3ca', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-36', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='a559a98e5baffcba08987fabee98cb54f842afd6466ac56ea460f21b30b35489'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='ebae5cc1-046b-4c5e-bdae-c5455d1e54ac', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='f0f605a2477e2ede793fee962495e0a452889fdda404e948f34fc7a26f35e3e4')}, hash='ef0146d206e56aa0c665288fe43ecaa534ccdd0e4cd2385dd63952eb858c72c9', text='Enrichingwordvectorswithsubword\\ninformation. CoRR, abs/1607.04606, 2016. URL http://arxiv.org/abs/1607.04606 .\\nTom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Nee-\\nlakantan,PranavShyam, GirishSastry,AmandaAskell, SandhiniAgarwal,ArielHerbert-Voss, Gretchen\\nKrueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel Ziegler, Jeffrey Wu, Clemens Winter, Chris\\nHesse,MarkChen,EricSigler,MateuszLitwin,ScottGray,BenjaminChess,JackClark,ChristopherBerner,\\nSamMcCandlish,AlecRadford,IlyaSutskever,andDarioAmodei. Languagemodelsarefew-shotlearners.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-36'),\n",
              " '421d8d36-b070-4964-bb33-88e215f62922': IndexNode(id_='421d8d36-b070-4964-bb33-88e215f62922', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-36', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='a559a98e5baffcba08987fabee98cb54f842afd6466ac56ea460f21b30b35489'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='1d3ffd7c-1ac3-4583-ace0-30e6d46aaa21', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='f9ab4071d30aca90e5aaa47495b164fb742cdc33ea7cad6be0a3fb3d6fd045b1')}, hash='e7f79670db712275f4aaec252ccbb500bbbb91958a51754b93828b5bfbdeb005', text='Technical report, National Bureau of Economic Research, 2018.\\nYuntaoBai,AndyJones,KamalNdousse,AmandaAskell,AnnaChen,NovaDasSarma,DawnDrain,Stanislav\\nFort,DeepGanguli,TomHenighan,etal. Trainingahelpfulandharmlessassistantwithreinforcement\\nlearning from human feedback. arXiv preprint arXiv:2204.05862 , 2022a.\\nYuntao Bai, Saurav Kadavath, Sandipan Kundu, Amanda Askell, Jackson Kernion, Andy Jones, Anna Chen,\\nAnna Goldie, Azalia Mirhoseini, Cameron McKinnon, et al. Constitutional ai: Harmlessness from ai\\nfeedback. arXiv preprint arXiv:2212.08073 , 2022b.\\nAprilHBailey,AdinaWilliams,andAndreiCimpian. Basedonbillionsofwordsontheinternet,people=\\nmen.Science Advances , 8(13):eabm2463, 2022.\\nEmily M Bender, Timnit Gebru, Angelina McMillan-Major, and Margaret Mitchell. On the dangers of\\nstochastic parrots: Can language models be too big? In Proceedings of the 2021 ACM Conference on Fairness,\\nAccountability, and Transparency , pages 610–623, 2021a.\\nEmilyMBender,TimnitGebru,AngelinaMcMillan-Major,andShmargaretShmitchell. Onthedangersof\\nstochasticparrots: Canlanguagemodelsbetoobig? In Proceedingsofthe2021ACMconferenceonfairness,\\naccountability, and transparency , pages 610–623, 2021b.\\n37\\n\\nA Stevie Bergman, Gavin Abercrombie, Shannon L Spruit, Dirk Hovy, Emily Dinan, Y-Lan Boureau, and\\nVerena Rieser. Guiding the release of safer e2e conversational ai through value sensitive design. In\\nProceedings ofthe23rdAnnualMeeting oftheSpecial InterestGroup onDiscourseandDialogue , pages39–52,\\n2022.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-36'),\n",
              " '1d3ffd7c-1ac3-4583-ace0-30e6d46aaa21': IndexNode(id_='1d3ffd7c-1ac3-4583-ace0-30e6d46aaa21', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-36', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='a559a98e5baffcba08987fabee98cb54f842afd6466ac56ea460f21b30b35489'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='421d8d36-b070-4964-bb33-88e215f62922', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='e7f79670db712275f4aaec252ccbb500bbbb91958a51754b93828b5bfbdeb005')}, hash='f9ab4071d30aca90e5aaa47495b164fb742cdc33ea7cad6be0a3fb3d6fd045b1', text='Shaily Bhatt, Sunipa Dev, Partha Talukdar, Shachi Dave, and Vinodkumar Prabhakaran. Re-contextualizing\\nfairness in nlp: The case of india, 2022.\\nYonatan Bisk, Rowan Zellers, Jianfeng Gao, Yejin Choi, et al. Piqa: Reasoning about physical commonsense\\nin natural language. In Proceedings of the AAAI conference on artificial intelligence , pages 7432–7439, 2020.\\nSuLinBlodgett,GilsiniaLopez,AlexandraOlteanu,RobertSim,andHannaWallach. Stereotypingnorwegian\\nsalmon: Aninventoryofpitfallsinfairnessbenchmarkdatasets. In Proceedingsofthe59thAnnualMeetingof\\nthe Association for Computational Linguistics and the 11th International Joint Conference on Natural Language\\nProcessing (Volume 1: Long Papers) , pages 1004–1015, 2021.\\nPiotrBojanowski,EdouardGrave,ArmandJoulin,andTomásMikolov. Enrichingwordvectorswithsubword\\ninformation. CoRR, abs/1607.04606, 2016. URL http://arxiv.org/abs/1607.04606 .\\nTom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Nee-\\nlakantan,PranavShyam, GirishSastry,AmandaAskell, SandhiniAgarwal,ArielHerbert-Voss, Gretchen\\nKrueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel Ziegler, Jeffrey Wu, Clemens Winter, Chris\\nHesse,MarkChen,EricSigler,MateuszLitwin,ScottGray,BenjaminChess,JackClark,ChristopherBerner,\\nSamMcCandlish,AlecRadford,IlyaSutskever,andDarioAmodei. Languagemodelsarefew-shotlearners.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-36'),\n",
              " 'node-36': IndexNode(id_='node-36', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='415b7efc-e73f-4ac4-bbfd-c1546f099026', node_type=<ObjectType.DOCUMENT: '4'>, metadata={}, hash='231b3bd773f012c01b893ada9e009ecf25ee59934614c5a595c9bf1b3a123292'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='585206dc-b82b-4ae7-be2d-a230f7b62dc7', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='f48aeeb4e48fde6d2a388ba2c428bcee92f22da7248c27e5e501741444742ea8'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='481eb7ec-12cf-4491-be9a-e32ca894748b', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='18200e194553a5d9070920177a76b29b8f5a68dede4ab028a607ccf84a85b75a')}, hash='a559a98e5baffcba08987fabee98cb54f842afd6466ac56ea460f21b30b35489', text='Technical report, National Bureau of Economic Research, 2018.\\nYuntaoBai,AndyJones,KamalNdousse,AmandaAskell,AnnaChen,NovaDasSarma,DawnDrain,Stanislav\\nFort,DeepGanguli,TomHenighan,etal. Trainingahelpfulandharmlessassistantwithreinforcement\\nlearning from human feedback. arXiv preprint arXiv:2204.05862 , 2022a.\\nYuntao Bai, Saurav Kadavath, Sandipan Kundu, Amanda Askell, Jackson Kernion, Andy Jones, Anna Chen,\\nAnna Goldie, Azalia Mirhoseini, Cameron McKinnon, et al. Constitutional ai: Harmlessness from ai\\nfeedback. arXiv preprint arXiv:2212.08073 , 2022b.\\nAprilHBailey,AdinaWilliams,andAndreiCimpian. Basedonbillionsofwordsontheinternet,people=\\nmen.Science Advances , 8(13):eabm2463, 2022.\\nEmily M Bender, Timnit Gebru, Angelina McMillan-Major, and Margaret Mitchell. On the dangers of\\nstochastic parrots: Can language models be too big? In Proceedings of the 2021 ACM Conference on Fairness,\\nAccountability, and Transparency , pages 610–623, 2021a.\\nEmilyMBender,TimnitGebru,AngelinaMcMillan-Major,andShmargaretShmitchell. Onthedangersof\\nstochasticparrots: Canlanguagemodelsbetoobig? In Proceedingsofthe2021ACMconferenceonfairness,\\naccountability, and transparency , pages 610–623, 2021b.\\n37\\n\\nA Stevie Bergman, Gavin Abercrombie, Shannon L Spruit, Dirk Hovy, Emily Dinan, Y-Lan Boureau, and\\nVerena Rieser. Guiding the release of safer e2e conversational ai through value sensitive design. In\\nProceedings ofthe23rdAnnualMeeting oftheSpecial InterestGroup onDiscourseandDialogue , pages39–52,\\n2022.\\nShaily Bhatt, Sunipa Dev, Partha Talukdar, Shachi Dave, and Vinodkumar Prabhakaran. Re-contextualizing\\nfairness in nlp: The case of india, 2022.\\nYonatan Bisk, Rowan Zellers, Jianfeng Gao, Yejin Choi, et al. Piqa: Reasoning about physical commonsense\\nin natural language. In Proceedings of the AAAI conference on artificial intelligence , pages 7432–7439, 2020.\\nSuLinBlodgett,GilsiniaLopez,AlexandraOlteanu,RobertSim,andHannaWallach. Stereotypingnorwegian\\nsalmon: Aninventoryofpitfallsinfairnessbenchmarkdatasets. In Proceedingsofthe59thAnnualMeetingof\\nthe Association for Computational Linguistics and the 11th International Joint Conference on Natural Language\\nProcessing (Volume 1: Long Papers) , pages 1004–1015, 2021.\\nPiotrBojanowski,EdouardGrave,ArmandJoulin,andTomásMikolov. Enrichingwordvectorswithsubword\\ninformation. CoRR, abs/1607.04606, 2016. URL http://arxiv.org/abs/1607.04606 .\\nTom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Nee-\\nlakantan,PranavShyam, GirishSastry,AmandaAskell, SandhiniAgarwal,ArielHerbert-Voss, Gretchen\\nKrueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel Ziegler, Jeffrey Wu, Clemens Winter, Chris\\nHesse,MarkChen,EricSigler,MateuszLitwin,ScottGray,BenjaminChess,JackClark,ChristopherBerner,\\nSamMcCandlish,AlecRadford,IlyaSutskever,andDarioAmodei. Languagemodelsarefew-shotlearners.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-36'),\n",
              " 'afccfcd7-57ad-4139-a6a8-4b509c376536': IndexNode(id_='afccfcd7-57ad-4139-a6a8-4b509c376536', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-37', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='18200e194553a5d9070920177a76b29b8f5a68dede4ab028a607ccf84a85b75a'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='de7bab25-759a-4192-8a39-7afa1884db8a', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='b96e8aeb8179473bacdcb055cc096250ceac40fee9047168b2975807dfa546da')}, hash='19a69f7458bf0461a479f28492f9faf4827bd4c6453dd1e451dc5117b8330a08', text='Languagemodelsarefew-shotlearners.\\nInH.Larochelle,M.Ranzato,R.Hadsell,M.F.Balcan,andH.Lin,editors, AdvancesinNeuralInformation\\nProcessingSystems ,volume33,pages1877–1901.CurranAssociates,Inc.,2020. URL https://proceedings.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-37'),\n",
              " 'de7bab25-759a-4192-8a39-7afa1884db8a': IndexNode(id_='de7bab25-759a-4192-8a39-7afa1884db8a', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-37', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='18200e194553a5d9070920177a76b29b8f5a68dede4ab028a607ccf84a85b75a'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='afccfcd7-57ad-4139-a6a8-4b509c376536', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='19a69f7458bf0461a479f28492f9faf4827bd4c6453dd1e451dc5117b8330a08'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='efe8c03e-fde8-4bb2-9469-21a833cde14d', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='69ea2ac7ea9dd6a96e0e72a491e2c34753168a3c2eb2af55c558e3d87b89ccc5')}, hash='b96e8aeb8179473bacdcb055cc096250ceac40fee9047168b2975807dfa546da', text='URL https://proceedings.\\nneurips.cc/paper_files/paper/2020/file/1457c0d6bfcb4967418bfb8ac142f64a-Paper.pdf .\\nMarkChen,JerryTworek,HeewooJun,QimingYuan,HenriquePondedeOliveiraPinto,JaredKaplan,Harri\\nEdwards,YuriBurda,NicholasJoseph,GregBrockman,AlexRay,RaulPuri,GretchenKrueger,Michael\\nPetrov,', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-37'),\n",
              " 'efe8c03e-fde8-4bb2-9469-21a833cde14d': IndexNode(id_='efe8c03e-fde8-4bb2-9469-21a833cde14d', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-37', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='18200e194553a5d9070920177a76b29b8f5a68dede4ab028a607ccf84a85b75a'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='de7bab25-759a-4192-8a39-7afa1884db8a', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='b96e8aeb8179473bacdcb055cc096250ceac40fee9047168b2975807dfa546da'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='d6cf5d8c-10c3-4d22-b60c-e0c1ef56191b', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='490eb585521f7a10df37e8821120ef572b2c2e97829f9d12220f00e64421d798')}, hash='69ea2ac7ea9dd6a96e0e72a491e2c34753168a3c2eb2af55c558e3d87b89ccc5', text='AlexRay,RaulPuri,GretchenKrueger,Michael\\nPetrov, Heidy Khlaaf, Girish Sastry, Pamela Mishkin, Brooke Chan, Scott Gray, Nick Ryder, Mikhail Pavlov,\\nAlethea Power, Lukasz Kaiser, Mohammad Bavarian, Clemens Winter, Philippe Tillet, Felipe Petroski Such,\\nDaveCummings,MatthiasPlappert,FotiosChantzis,ElizabethBarnes,ArielHerbert-Voss,WilliamHebgen\\nGuss, Alex Nichol, Alex Paino,', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-37'),\n",
              " 'd6cf5d8c-10c3-4d22-b60c-e0c1ef56191b': IndexNode(id_='d6cf5d8c-10c3-4d22-b60c-e0c1ef56191b', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-37', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='18200e194553a5d9070920177a76b29b8f5a68dede4ab028a607ccf84a85b75a'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='efe8c03e-fde8-4bb2-9469-21a833cde14d', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='69ea2ac7ea9dd6a96e0e72a491e2c34753168a3c2eb2af55c558e3d87b89ccc5'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='b98f748c-d416-4279-afee-9ef13b3f48e2', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='4c1a6b74c66713aacdad71bfcf0a22348a7f08bfe52c8348e30acddb44aa4f12')}, hash='490eb585521f7a10df37e8821120ef572b2c2e97829f9d12220f00e64421d798', text='WilliamHebgen\\nGuss, Alex Nichol, Alex Paino, Nikolas Tezak, Jie Tang, Igor Babuschkin, Suchir Balaji, Shantanu Jain,\\nWilliam Saunders, Christopher Hesse, Andrew N. Carr, Jan Leike, Josh Achiam, Vedant Misra, Evan\\nMorikawa, Alec Radford, Matthew Knight, Miles Brundage, Mira Murati, Katie Mayer, Peter Welinder,\\nBobMcGrew,DarioAmodei,SamMcCandlish,IlyaSutskever,', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-37'),\n",
              " 'b98f748c-d416-4279-afee-9ef13b3f48e2': IndexNode(id_='b98f748c-d416-4279-afee-9ef13b3f48e2', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-37', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='18200e194553a5d9070920177a76b29b8f5a68dede4ab028a607ccf84a85b75a'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='d6cf5d8c-10c3-4d22-b60c-e0c1ef56191b', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='490eb585521f7a10df37e8821120ef572b2c2e97829f9d12220f00e64421d798'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='e458e9b6-8c9e-415a-8897-cb2242187db0', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='0f3a58f95296a15af4f9dfd08ebbecdc8928ede16898270491c622346501b3fe')}, hash='4c1a6b74c66713aacdad71bfcf0a22348a7f08bfe52c8348e30acddb44aa4f12', text='DarioAmodei,SamMcCandlish,IlyaSutskever,andWojciechZaremba. Evaluatinglarge\\nlanguage models trained on code, 2021.\\nWei-LinChiang,ZhuohanLi,ZiLin,YingSheng,ZhanghaoWu,HaoZhang,LianminZheng,SiyuanZhuang,\\nYonghaoZhuang,JosephE.Gonzalez,IonStoica,andEricP.Xing.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-37'),\n",
              " 'e458e9b6-8c9e-415a-8897-cb2242187db0': IndexNode(id_='e458e9b6-8c9e-415a-8897-cb2242187db0', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-37', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='18200e194553a5d9070920177a76b29b8f5a68dede4ab028a607ccf84a85b75a'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='b98f748c-d416-4279-afee-9ef13b3f48e2', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='4c1a6b74c66713aacdad71bfcf0a22348a7f08bfe52c8348e30acddb44aa4f12'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='16cfe1d2-bce1-4853-9aba-592a6cfea91e', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='9c015df4fc4d4a8a5ecfd30302d6cfd8156303926506a1155aa6a4254d6a2a2d')}, hash='0f3a58f95296a15af4f9dfd08ebbecdc8928ede16898270491c622346501b3fe', text='Vicuna: Anopen-sourcechatbotimpress-\\ning gpt-4 with 90%* chatgpt quality, March 2023. URL https://lmsys.org/blog/2023-03-30-vicuna/ .\\nEunsol Choi, He He, Mohit Iyyer, Mark Yatskar, Wen-tau Yih, Yejin Choi, Percy Liang, and Luke Zettlemoyer.\\nQuac: Question answering in context.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-37'),\n",
              " '16cfe1d2-bce1-4853-9aba-592a6cfea91e': IndexNode(id_='16cfe1d2-bce1-4853-9aba-592a6cfea91e', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-37', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='18200e194553a5d9070920177a76b29b8f5a68dede4ab028a607ccf84a85b75a'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='e458e9b6-8c9e-415a-8897-cb2242187db0', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='0f3a58f95296a15af4f9dfd08ebbecdc8928ede16898270491c622346501b3fe'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='00e51f86-d19b-49ad-a229-cb339c42a924', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='7ee8d9c0082d48a7170aa6e7640de188070fa35df8cd5b763c0974807a55ac11')}, hash='9c015df4fc4d4a8a5ecfd30302d6cfd8156303926506a1155aa6a4254d6a2a2d', text='Quac: Question answering in context. In Proceedings of the 2018 Conference on Empirical Methods in Natural\\nLanguage Processing , pages 2174–2184, 2018.\\nAakanksha Chowdhery, Sharan Narang, Jacob Devlin, Maarten Bosma, Gaurav Mishra, Adam Roberts,\\nPaul Barham, Hyung Won Chung, Charles Sutton, Sebastian Gehrmann, Parker Schuh, Kensen Shi, Sasha\\nTsvyashchenko, Joshua Maynez, Abhishek Rao, Parker Barnes, Yi Tay, Noam Shazeer,', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-37'),\n",
              " '00e51f86-d19b-49ad-a229-cb339c42a924': IndexNode(id_='00e51f86-d19b-49ad-a229-cb339c42a924', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-37', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='18200e194553a5d9070920177a76b29b8f5a68dede4ab028a607ccf84a85b75a'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='16cfe1d2-bce1-4853-9aba-592a6cfea91e', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='9c015df4fc4d4a8a5ecfd30302d6cfd8156303926506a1155aa6a4254d6a2a2d'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='695a9b94-62cd-4091-bf6b-4ee23a888b29', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='bf904bfc7c6be42545806eb6293ae2f1fa18edf66e05ab9ec6deade7822c7d12')}, hash='7ee8d9c0082d48a7170aa6e7640de188070fa35df8cd5b763c0974807a55ac11', text='Abhishek Rao, Parker Barnes, Yi Tay, Noam Shazeer, Vinodkumar Prab-\\nhakaran, Emily Reif, Nan Du, Ben Hutchinson, Reiner Pope, James Bradbury, Jacob Austin, Michael Isard,\\nGuy Gur-Ari, Pengcheng Yin, Toju Duke, Anselm Levskaya, Sanjay Ghemawat, Sunipa Dev, Henryk\\nMichalewski,XavierGarcia,VedantMisra,KevinRobinson,LiamFedus,DennyZhou,', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-37'),\n",
              " '695a9b94-62cd-4091-bf6b-4ee23a888b29': IndexNode(id_='695a9b94-62cd-4091-bf6b-4ee23a888b29', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-37', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='18200e194553a5d9070920177a76b29b8f5a68dede4ab028a607ccf84a85b75a'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='00e51f86-d19b-49ad-a229-cb339c42a924', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='7ee8d9c0082d48a7170aa6e7640de188070fa35df8cd5b763c0974807a55ac11'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='7a55fa2a-11d2-4edb-9f95-9dbb881a16bd', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='b1ef77def7924e77efc7cace7958453a25a1041100cb16cd5d8d0d6c9ab1c1b3')}, hash='bf904bfc7c6be42545806eb6293ae2f1fa18edf66e05ab9ec6deade7822c7d12', text='VedantMisra,KevinRobinson,LiamFedus,DennyZhou,DaphneIppolito,\\nDavidLuan, HyeontaekLim,BarretZoph, AlexanderSpiridonov,RyanSepassi, DavidDohan, Shivani\\nAgrawal, Mark Omernick, Andrew M. Dai, Thanumalayan Sankaranarayana Pillai, Marie Pellat, Aitor\\nLewkowycz,EricaMoreira,RewonChild,OleksandrPolozov,KatherineLee,', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-37'),\n",
              " '7a55fa2a-11d2-4edb-9f95-9dbb881a16bd': IndexNode(id_='7a55fa2a-11d2-4edb-9f95-9dbb881a16bd', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-37', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='18200e194553a5d9070920177a76b29b8f5a68dede4ab028a607ccf84a85b75a'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='695a9b94-62cd-4091-bf6b-4ee23a888b29', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='bf904bfc7c6be42545806eb6293ae2f1fa18edf66e05ab9ec6deade7822c7d12')}, hash='b1ef77def7924e77efc7cace7958453a25a1041100cb16cd5d8d0d6c9ab1c1b3', text='RewonChild,OleksandrPolozov,KatherineLee,ZongweiZhou,XuezhiWang,\\nBrennan Saeta, Mark Diaz, Orhan Firat, MicheleCatasta, Jason Wei, KathyMeier-Hellstern, Douglas Eck,\\nJeff Dean, Slav Petrov, and Noah Fiedel. Palm: Scaling language modeling with pathways, 2022.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-37'),\n",
              " '2bb0e795-7849-4657-9b6d-babdeafdfb85': IndexNode(id_='2bb0e795-7849-4657-9b6d-babdeafdfb85', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-37', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='18200e194553a5d9070920177a76b29b8f5a68dede4ab028a607ccf84a85b75a'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='e5306c48-de45-494a-a7d3-301acd8d23d8', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='da36876d0e9ed18b5a0a653e0f260ce35b97a34b8ce72aa9ccee90133856c85d')}, hash='8c1717df93dce358d66e56beceb6c868c24389a67d04f97ef21a83b4be71fe44', text='Languagemodelsarefew-shotlearners.\\nInH.Larochelle,M.Ranzato,R.Hadsell,M.F.Balcan,andH.Lin,editors, AdvancesinNeuralInformation\\nProcessingSystems ,volume33,pages1877–1901.CurranAssociates,Inc.,2020. URL https://proceedings.\\nneurips.cc/paper_files/paper/2020/file/1457c0d6bfcb4967418bfb8ac142f64a-Paper.pdf .\\nMarkChen,JerryTworek,HeewooJun,QimingYuan,HenriquePondedeOliveiraPinto,JaredKaplan,Harri\\nEdwards,YuriBurda,NicholasJoseph,GregBrockman,AlexRay,RaulPuri,GretchenKrueger,Michael\\nPetrov, Heidy Khlaaf, Girish Sastry, Pamela Mishkin, Brooke Chan, Scott Gray, Nick Ryder, Mikhail Pavlov,\\nAlethea Power, Lukasz Kaiser, Mohammad Bavarian, Clemens Winter,', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-37'),\n",
              " 'e5306c48-de45-494a-a7d3-301acd8d23d8': IndexNode(id_='e5306c48-de45-494a-a7d3-301acd8d23d8', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-37', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='18200e194553a5d9070920177a76b29b8f5a68dede4ab028a607ccf84a85b75a'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='2bb0e795-7849-4657-9b6d-babdeafdfb85', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='8c1717df93dce358d66e56beceb6c868c24389a67d04f97ef21a83b4be71fe44'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='7c9f1615-50fb-44d7-bbd3-c1d38d97baf0', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='df5a2805d5f42314f865e7a276e72da8567575360cca3565d33ee66ed12ba54e')}, hash='da36876d0e9ed18b5a0a653e0f260ce35b97a34b8ce72aa9ccee90133856c85d', text='Alethea Power, Lukasz Kaiser, Mohammad Bavarian, Clemens Winter, Philippe Tillet, Felipe Petroski Such,\\nDaveCummings,MatthiasPlappert,FotiosChantzis,ElizabethBarnes,ArielHerbert-Voss,WilliamHebgen\\nGuss, Alex Nichol, Alex Paino, Nikolas Tezak, Jie Tang, Igor Babuschkin, Suchir Balaji, Shantanu Jain,\\nWilliam Saunders, Christopher Hesse, Andrew N. Carr, Jan Leike, Josh Achiam, Vedant Misra, Evan\\nMorikawa, Alec Radford, Matthew Knight, Miles Brundage, Mira Murati, Katie Mayer, Peter Welinder,\\nBobMcGrew,DarioAmodei,SamMcCandlish,IlyaSutskever,andWojciechZaremba. Evaluatinglarge\\nlanguage models trained on code, 2021.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-37'),\n",
              " '7c9f1615-50fb-44d7-bbd3-c1d38d97baf0': IndexNode(id_='7c9f1615-50fb-44d7-bbd3-c1d38d97baf0', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-37', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='18200e194553a5d9070920177a76b29b8f5a68dede4ab028a607ccf84a85b75a'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='e5306c48-de45-494a-a7d3-301acd8d23d8', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='da36876d0e9ed18b5a0a653e0f260ce35b97a34b8ce72aa9ccee90133856c85d'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='33821eae-2e60-4b0a-8d14-37ab1a0fc5af', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='a2e6358c91b3cf9e5f46867454c8d77c5f09a9d6cfd182fccd7f0397f6f8e722')}, hash='df5a2805d5f42314f865e7a276e72da8567575360cca3565d33ee66ed12ba54e', text='Evaluatinglarge\\nlanguage models trained on code, 2021.\\nWei-LinChiang,ZhuohanLi,ZiLin,YingSheng,ZhanghaoWu,HaoZhang,LianminZheng,SiyuanZhuang,\\nYonghaoZhuang,JosephE.Gonzalez,IonStoica,andEricP.Xing. Vicuna: Anopen-sourcechatbotimpress-\\ning gpt-4 with 90%* chatgpt quality, March 2023. URL https://lmsys.org/blog/2023-03-30-vicuna/ .\\nEunsol Choi, He He, Mohit Iyyer, Mark Yatskar, Wen-tau Yih, Yejin Choi, Percy Liang, and Luke Zettlemoyer.\\nQuac: Question answering in context. In Proceedings of the 2018 Conference on Empirical Methods in Natural\\nLanguage Processing , pages 2174–2184, 2018.\\nAakanksha Chowdhery, Sharan Narang, Jacob Devlin, Maarten Bosma, Gaurav Mishra, Adam Roberts,', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-37'),\n",
              " '33821eae-2e60-4b0a-8d14-37ab1a0fc5af': IndexNode(id_='33821eae-2e60-4b0a-8d14-37ab1a0fc5af', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-37', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='18200e194553a5d9070920177a76b29b8f5a68dede4ab028a607ccf84a85b75a'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='7c9f1615-50fb-44d7-bbd3-c1d38d97baf0', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='df5a2805d5f42314f865e7a276e72da8567575360cca3565d33ee66ed12ba54e'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='964dc67d-fee6-4793-92b7-4fae25190a1e', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='40b5dbc8203f21d9eaa3b0a438c4d82acf3f0c8430628b6292ed5cafad5cd29e')}, hash='a2e6358c91b3cf9e5f46867454c8d77c5f09a9d6cfd182fccd7f0397f6f8e722', text='Jacob Devlin, Maarten Bosma, Gaurav Mishra, Adam Roberts,\\nPaul Barham, Hyung Won Chung, Charles Sutton, Sebastian Gehrmann, Parker Schuh, Kensen Shi, Sasha\\nTsvyashchenko, Joshua Maynez, Abhishek Rao, Parker Barnes, Yi Tay, Noam Shazeer, Vinodkumar Prab-\\nhakaran, Emily Reif, Nan Du, Ben Hutchinson, Reiner Pope, James Bradbury, Jacob Austin, Michael Isard,\\nGuy Gur-Ari, Pengcheng Yin, Toju Duke, Anselm Levskaya, Sanjay Ghemawat, Sunipa Dev, Henryk\\nMichalewski,XavierGarcia,VedantMisra,KevinRobinson,LiamFedus,DennyZhou,DaphneIppolito,\\nDavidLuan, HyeontaekLim,BarretZoph, AlexanderSpiridonov,RyanSepassi, DavidDohan, Shivani\\nAgrawal, Mark Omernick, Andrew M. Dai, Thanumalayan Sankaranarayana Pillai, Marie Pellat,', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-37'),\n",
              " '964dc67d-fee6-4793-92b7-4fae25190a1e': IndexNode(id_='964dc67d-fee6-4793-92b7-4fae25190a1e', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-37', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='18200e194553a5d9070920177a76b29b8f5a68dede4ab028a607ccf84a85b75a'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='33821eae-2e60-4b0a-8d14-37ab1a0fc5af', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='a2e6358c91b3cf9e5f46867454c8d77c5f09a9d6cfd182fccd7f0397f6f8e722')}, hash='40b5dbc8203f21d9eaa3b0a438c4d82acf3f0c8430628b6292ed5cafad5cd29e', text='Dai, Thanumalayan Sankaranarayana Pillai, Marie Pellat, Aitor\\nLewkowycz,EricaMoreira,RewonChild,OleksandrPolozov,KatherineLee,ZongweiZhou,XuezhiWang,\\nBrennan Saeta, Mark Diaz, Orhan Firat, MicheleCatasta, Jason Wei, KathyMeier-Hellstern, Douglas Eck,\\nJeff Dean, Slav Petrov, and Noah Fiedel. Palm: Scaling language modeling with pathways, 2022.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-37'),\n",
              " 'b914923d-ad29-4d2f-8b2b-c36b61344d3b': IndexNode(id_='b914923d-ad29-4d2f-8b2b-c36b61344d3b', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-37', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='18200e194553a5d9070920177a76b29b8f5a68dede4ab028a607ccf84a85b75a'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='5ecdf7e0-8975-4e0f-865e-2ccdce7792c6', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='c21e3df1466b9a26ecadde130db3fda0a19aaf5bdb56f0306b83cb6f195a3214')}, hash='d59db0fc9a45432b73bb52c395d3eb1163bc402d10508896be915e32d581f3e9', text='Languagemodelsarefew-shotlearners.\\nInH.Larochelle,M.Ranzato,R.Hadsell,M.F.Balcan,andH.Lin,editors, AdvancesinNeuralInformation\\nProcessingSystems ,volume33,pages1877–1901.CurranAssociates,Inc.,2020. URL https://proceedings.\\nneurips.cc/paper_files/paper/2020/file/1457c0d6bfcb4967418bfb8ac142f64a-Paper.pdf .\\nMarkChen,JerryTworek,HeewooJun,QimingYuan,HenriquePondedeOliveiraPinto,JaredKaplan,Harri\\nEdwards,YuriBurda,NicholasJoseph,GregBrockman,AlexRay,RaulPuri,GretchenKrueger,Michael\\nPetrov, Heidy Khlaaf, Girish Sastry, Pamela Mishkin, Brooke Chan, Scott Gray, Nick Ryder, Mikhail Pavlov,\\nAlethea Power, Lukasz Kaiser, Mohammad Bavarian, Clemens Winter, Philippe Tillet, Felipe Petroski Such,\\nDaveCummings,MatthiasPlappert,FotiosChantzis,ElizabethBarnes,ArielHerbert-Voss,WilliamHebgen\\nGuss, Alex Nichol, Alex Paino, Nikolas Tezak, Jie Tang, Igor Babuschkin, Suchir Balaji, Shantanu Jain,\\nWilliam Saunders, Christopher Hesse, Andrew N. Carr, Jan Leike, Josh Achiam, Vedant Misra, Evan\\nMorikawa, Alec Radford, Matthew Knight, Miles Brundage, Mira Murati, Katie Mayer, Peter Welinder,\\nBobMcGrew,DarioAmodei,SamMcCandlish,IlyaSutskever,andWojciechZaremba. Evaluatinglarge\\nlanguage models trained on code, 2021.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-37'),\n",
              " '5ecdf7e0-8975-4e0f-865e-2ccdce7792c6': IndexNode(id_='5ecdf7e0-8975-4e0f-865e-2ccdce7792c6', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-37', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='18200e194553a5d9070920177a76b29b8f5a68dede4ab028a607ccf84a85b75a'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='b914923d-ad29-4d2f-8b2b-c36b61344d3b', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='d59db0fc9a45432b73bb52c395d3eb1163bc402d10508896be915e32d581f3e9'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='97fbf15f-9ee1-4720-b201-f2294b93dd79', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='4af7e02539ee9f92694f1dfb5d22b548719e869170f1c223ab12d80c5e01aff4')}, hash='c21e3df1466b9a26ecadde130db3fda0a19aaf5bdb56f0306b83cb6f195a3214', text='Evaluatinglarge\\nlanguage models trained on code, 2021.\\nWei-LinChiang,ZhuohanLi,ZiLin,YingSheng,ZhanghaoWu,HaoZhang,LianminZheng,SiyuanZhuang,\\nYonghaoZhuang,JosephE.Gonzalez,IonStoica,andEricP.Xing. Vicuna: Anopen-sourcechatbotimpress-\\ning gpt-4 with 90%* chatgpt quality, March 2023. URL https://lmsys.org/blog/2023-03-30-vicuna/ .\\nEunsol Choi, He He, Mohit Iyyer, Mark Yatskar, Wen-tau Yih, Yejin Choi, Percy Liang, and Luke Zettlemoyer.\\nQuac: Question answering in context. In Proceedings of the 2018 Conference on Empirical Methods in Natural\\nLanguage Processing , pages 2174–2184, 2018.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-37'),\n",
              " '97fbf15f-9ee1-4720-b201-f2294b93dd79': IndexNode(id_='97fbf15f-9ee1-4720-b201-f2294b93dd79', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-37', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='18200e194553a5d9070920177a76b29b8f5a68dede4ab028a607ccf84a85b75a'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='5ecdf7e0-8975-4e0f-865e-2ccdce7792c6', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='c21e3df1466b9a26ecadde130db3fda0a19aaf5bdb56f0306b83cb6f195a3214')}, hash='4af7e02539ee9f92694f1dfb5d22b548719e869170f1c223ab12d80c5e01aff4', text='Aakanksha Chowdhery, Sharan Narang, Jacob Devlin, Maarten Bosma, Gaurav Mishra, Adam Roberts,\\nPaul Barham, Hyung Won Chung, Charles Sutton, Sebastian Gehrmann, Parker Schuh, Kensen Shi, Sasha\\nTsvyashchenko, Joshua Maynez, Abhishek Rao, Parker Barnes, Yi Tay, Noam Shazeer, Vinodkumar Prab-\\nhakaran, Emily Reif, Nan Du, Ben Hutchinson, Reiner Pope, James Bradbury, Jacob Austin, Michael Isard,\\nGuy Gur-Ari, Pengcheng Yin, Toju Duke, Anselm Levskaya, Sanjay Ghemawat, Sunipa Dev, Henryk\\nMichalewski,XavierGarcia,VedantMisra,KevinRobinson,LiamFedus,DennyZhou,DaphneIppolito,\\nDavidLuan, HyeontaekLim,BarretZoph, AlexanderSpiridonov,RyanSepassi, DavidDohan, Shivani\\nAgrawal, Mark Omernick, Andrew M. Dai, Thanumalayan Sankaranarayana Pillai, Marie Pellat, Aitor\\nLewkowycz,EricaMoreira,RewonChild,OleksandrPolozov,KatherineLee,ZongweiZhou,XuezhiWang,\\nBrennan Saeta, Mark Diaz, Orhan Firat, MicheleCatasta, Jason Wei, KathyMeier-Hellstern, Douglas Eck,\\nJeff Dean, Slav Petrov, and Noah Fiedel. Palm: Scaling language modeling with pathways, 2022.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-37'),\n",
              " 'node-37': IndexNode(id_='node-37', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='415b7efc-e73f-4ac4-bbfd-c1546f099026', node_type=<ObjectType.DOCUMENT: '4'>, metadata={}, hash='231b3bd773f012c01b893ada9e009ecf25ee59934614c5a595c9bf1b3a123292'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='d10248ae-15cc-4abc-9fc8-236cb2f29e89', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='a559a98e5baffcba08987fabee98cb54f842afd6466ac56ea460f21b30b35489'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='d62815b2-9819-4933-88b8-4f1ec146bd33', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='8fc645f8314bf3b4190ff3ed466011d007294292af3e921655a6b74f2f2b1f7a')}, hash='18200e194553a5d9070920177a76b29b8f5a68dede4ab028a607ccf84a85b75a', text='Languagemodelsarefew-shotlearners.\\nInH.Larochelle,M.Ranzato,R.Hadsell,M.F.Balcan,andH.Lin,editors, AdvancesinNeuralInformation\\nProcessingSystems ,volume33,pages1877–1901.CurranAssociates,Inc.,2020. URL https://proceedings.\\nneurips.cc/paper_files/paper/2020/file/1457c0d6bfcb4967418bfb8ac142f64a-Paper.pdf .\\nMarkChen,JerryTworek,HeewooJun,QimingYuan,HenriquePondedeOliveiraPinto,JaredKaplan,Harri\\nEdwards,YuriBurda,NicholasJoseph,GregBrockman,AlexRay,RaulPuri,GretchenKrueger,Michael\\nPetrov, Heidy Khlaaf, Girish Sastry, Pamela Mishkin, Brooke Chan, Scott Gray, Nick Ryder, Mikhail Pavlov,\\nAlethea Power, Lukasz Kaiser, Mohammad Bavarian, Clemens Winter, Philippe Tillet, Felipe Petroski Such,\\nDaveCummings,MatthiasPlappert,FotiosChantzis,ElizabethBarnes,ArielHerbert-Voss,WilliamHebgen\\nGuss, Alex Nichol, Alex Paino, Nikolas Tezak, Jie Tang, Igor Babuschkin, Suchir Balaji, Shantanu Jain,\\nWilliam Saunders, Christopher Hesse, Andrew N. Carr, Jan Leike, Josh Achiam, Vedant Misra, Evan\\nMorikawa, Alec Radford, Matthew Knight, Miles Brundage, Mira Murati, Katie Mayer, Peter Welinder,\\nBobMcGrew,DarioAmodei,SamMcCandlish,IlyaSutskever,andWojciechZaremba. Evaluatinglarge\\nlanguage models trained on code, 2021.\\nWei-LinChiang,ZhuohanLi,ZiLin,YingSheng,ZhanghaoWu,HaoZhang,LianminZheng,SiyuanZhuang,\\nYonghaoZhuang,JosephE.Gonzalez,IonStoica,andEricP.Xing. Vicuna: Anopen-sourcechatbotimpress-\\ning gpt-4 with 90%* chatgpt quality, March 2023. URL https://lmsys.org/blog/2023-03-30-vicuna/ .\\nEunsol Choi, He He, Mohit Iyyer, Mark Yatskar, Wen-tau Yih, Yejin Choi, Percy Liang, and Luke Zettlemoyer.\\nQuac: Question answering in context. In Proceedings of the 2018 Conference on Empirical Methods in Natural\\nLanguage Processing , pages 2174–2184, 2018.\\nAakanksha Chowdhery, Sharan Narang, Jacob Devlin, Maarten Bosma, Gaurav Mishra, Adam Roberts,\\nPaul Barham, Hyung Won Chung, Charles Sutton, Sebastian Gehrmann, Parker Schuh, Kensen Shi, Sasha\\nTsvyashchenko, Joshua Maynez, Abhishek Rao, Parker Barnes, Yi Tay, Noam Shazeer, Vinodkumar Prab-\\nhakaran, Emily Reif, Nan Du, Ben Hutchinson, Reiner Pope, James Bradbury, Jacob Austin, Michael Isard,\\nGuy Gur-Ari, Pengcheng Yin, Toju Duke, Anselm Levskaya, Sanjay Ghemawat, Sunipa Dev, Henryk\\nMichalewski,XavierGarcia,VedantMisra,KevinRobinson,LiamFedus,DennyZhou,DaphneIppolito,\\nDavidLuan, HyeontaekLim,BarretZoph, AlexanderSpiridonov,RyanSepassi, DavidDohan, Shivani\\nAgrawal, Mark Omernick, Andrew M. Dai, Thanumalayan Sankaranarayana Pillai, Marie Pellat, Aitor\\nLewkowycz,EricaMoreira,RewonChild,OleksandrPolozov,KatherineLee,ZongweiZhou,XuezhiWang,\\nBrennan Saeta, Mark Diaz, Orhan Firat, MicheleCatasta, Jason Wei, KathyMeier-Hellstern, Douglas Eck,\\nJeff Dean, Slav Petrov, and Noah Fiedel. Palm: Scaling language modeling with pathways, 2022.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-37'),\n",
              " 'f388e591-4cc7-4815-817b-37f27f30bdde': IndexNode(id_='f388e591-4cc7-4815-817b-37f27f30bdde', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-38', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='8fc645f8314bf3b4190ff3ed466011d007294292af3e921655a6b74f2f2b1f7a'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='ecb612df-a989-4304-8b59-e6587a74fb34', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='3338555842ce7702d925e436d698e4da02c7178634b802ef19d1fc47cd099bf9')}, hash='4bcce64e6ede5f46caa002430e25d11e312615ab445a3652a40eea78958413b7', text='Palm: Scaling language modeling with pathways, 2022.\\nPaulFChristiano,JanLeike,TomBrown,MiljanMartic,ShaneLegg,andDarioAmodei. Deepreinforcement\\nlearning from human preferences. Advances in neural information processing systems , 30, 2017.\\nHyung Won Chung, Le Hou, S. Longpre, Barret Zoph, Yi Tay, William Fedus, Eric Li, Xuezhi Wang, Mostafa\\nDehghani,SiddharthaBrahma,AlbertWebson,ShixiangShaneGu,', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-38'),\n",
              " 'ecb612df-a989-4304-8b59-e6587a74fb34': IndexNode(id_='ecb612df-a989-4304-8b59-e6587a74fb34', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-38', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='8fc645f8314bf3b4190ff3ed466011d007294292af3e921655a6b74f2f2b1f7a'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='f388e591-4cc7-4815-817b-37f27f30bdde', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='4bcce64e6ede5f46caa002430e25d11e312615ab445a3652a40eea78958413b7'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='f3815c20-8a98-46d5-a283-3e31ee664e04', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='ea74809d7b030b72cc885b60bdcac384f92ba0f3256aea8b66f28885c82a5246')}, hash='3338555842ce7702d925e436d698e4da02c7178634b802ef19d1fc47cd099bf9', text='SiddharthaBrahma,AlbertWebson,ShixiangShaneGu,ZhuyunDai,MiracSuzgun,Xinyun\\nChen,AakankshaChowdhery,DashaValter,SharanNarang,GauravMishra,AdamsWeiYu,VincentZhao,\\nYanping Huang, Andrew M. Dai, Hongkun Yu, Slav Petrov, Ed Huai hsin Chi, Jeff Dean, Jacob Devlin,\\n38\\n\\nAdam Roberts,Denny Zhou,QuocV.Le,', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-38'),\n",
              " 'f3815c20-8a98-46d5-a283-3e31ee664e04': IndexNode(id_='f3815c20-8a98-46d5-a283-3e31ee664e04', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-38', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='8fc645f8314bf3b4190ff3ed466011d007294292af3e921655a6b74f2f2b1f7a'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='ecb612df-a989-4304-8b59-e6587a74fb34', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='3338555842ce7702d925e436d698e4da02c7178634b802ef19d1fc47cd099bf9'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='817ce722-ad82-444e-a45e-83fbd5422b6b', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='568a002e7fd585fc050e3723d6ce761b48cc969076be30eb481bcf3b7c9e6de5')}, hash='ea74809d7b030b72cc885b60bdcac384f92ba0f3256aea8b66f28885c82a5246', text='38\\n\\nAdam Roberts,Denny Zhou,QuocV.Le, andJasonWei. Scaling instruction-finetunedlanguage models.\\narXiv preprint arXiv:2210.11416 , 2022.\\nChristopherClark,KentonLee,Ming-WeiChang,TomKwiatkowski,MichaelCollins,andKristinaToutanova.\\nBoolq: Exploring the surprising difficulty of natural yes/no questions. arXiv preprint arXiv:1905.10044 ,\\n2019.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-38'),\n",
              " '817ce722-ad82-444e-a45e-83fbd5422b6b': IndexNode(id_='817ce722-ad82-444e-a45e-83fbd5422b6b', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-38', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='8fc645f8314bf3b4190ff3ed466011d007294292af3e921655a6b74f2f2b1f7a'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='f3815c20-8a98-46d5-a283-3e31ee664e04', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='ea74809d7b030b72cc885b60bdcac384f92ba0f3256aea8b66f28885c82a5246'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='8e3e683c-1eb3-4163-960d-bfe536df88df', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='bf6fdf7b449e6ee58f7ea73cb0433daaae3bc8d1efe5ab763f4fd2b29ec96bc9')}, hash='568a002e7fd585fc050e3723d6ce761b48cc969076be30eb481bcf3b7c9e6de5', text='arXiv preprint arXiv:1905.10044 ,\\n2019.\\nElizabethClark,TalAugust,SofiaSerrano,NikitaHaduong,SuchinGururangan,andNoahA.Smith.Allthat’s\\n‘human’isnotgold: Evaluatinghumanevaluationofgeneratedtext.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-38'),\n",
              " '8e3e683c-1eb3-4163-960d-bfe536df88df': IndexNode(id_='8e3e683c-1eb3-4163-960d-bfe536df88df', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-38', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='8fc645f8314bf3b4190ff3ed466011d007294292af3e921655a6b74f2f2b1f7a'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='817ce722-ad82-444e-a45e-83fbd5422b6b', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='568a002e7fd585fc050e3723d6ce761b48cc969076be30eb481bcf3b7c9e6de5'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='a9d6bd02-9c50-4bec-bcc6-8ffef435bd63', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='b8aa86295a7236fad7e59929b4c03098508d27e9265fdd14948d8669311a1dad')}, hash='bf6fdf7b449e6ee58f7ea73cb0433daaae3bc8d1efe5ab763f4fd2b29ec96bc9', text='In Proceedingsofthe59thAnnualMeeting\\nof the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language\\nProcessing (Volume 1: Long Papers) , pages 7282–7296, Online, August 2021. Association for Computational\\nLinguistics. doi: 10.18653/v1/2021.acl-long.565. URL https://aclanthology.org/2021.acl-long.565 .', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-38'),\n",
              " 'a9d6bd02-9c50-4bec-bcc6-8ffef435bd63': IndexNode(id_='a9d6bd02-9c50-4bec-bcc6-8ffef435bd63', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-38', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='8fc645f8314bf3b4190ff3ed466011d007294292af3e921655a6b74f2f2b1f7a'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='8e3e683c-1eb3-4163-960d-bfe536df88df', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='bf6fdf7b449e6ee58f7ea73cb0433daaae3bc8d1efe5ab763f4fd2b29ec96bc9'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='427545f4-18a5-4d39-ac81-342d79417aa0', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='5e52a609850d6fa6683ffbab59ff8550cd1c262f9d91d781cd05a8ffbb0c46f5')}, hash='b8aa86295a7236fad7e59929b4c03098508d27e9265fdd14948d8669311a1dad', text='URL https://aclanthology.org/2021.acl-long.565 .\\nPeterClark,IsaacCowhey,OrenEtzioni,TusharKhot,AshishSabharwal,CarissaSchoenick,andOyvind\\nTafjord. Thinkyouhavesolvedquestionanswering? tryarc,theai2reasoningchallenge. arXivpreprint\\narXiv:1803.05457 , 2018.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-38'),\n",
              " '427545f4-18a5-4d39-ac81-342d79417aa0': IndexNode(id_='427545f4-18a5-4d39-ac81-342d79417aa0', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-38', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='8fc645f8314bf3b4190ff3ed466011d007294292af3e921655a6b74f2f2b1f7a'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='a9d6bd02-9c50-4bec-bcc6-8ffef435bd63', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='b8aa86295a7236fad7e59929b4c03098508d27e9265fdd14948d8669311a1dad'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='fcb7b100-db4c-411c-bbc9-10c24848e6c9', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='8fd374f9977492b67ab356899aa2035d37beda48d5823bdac4e524cae4b016e7')}, hash='5e52a609850d6fa6683ffbab59ff8550cd1c262f9d91d781cd05a8ffbb0c46f5', text='arXivpreprint\\narXiv:1803.05457 , 2018.\\nKarl Cobbe, Vineet Kosaraju, Mohammad Bavarian, Mark Chen, Heewoo Jun, Lukasz Kaiser, Matthias\\nPlappert, Jerry Tworek, Jacob Hilton, Reiichiro Nakano, et al. Training verifiers to solve math word\\nproblems. arXiv preprint arXiv:2110.14168 , 2021.\\nJiawen Deng, Hao Sun, Zhexin Zhang, Jiale Cheng, and Minlie Huang.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-38'),\n",
              " 'fcb7b100-db4c-411c-bbc9-10c24848e6c9': IndexNode(id_='fcb7b100-db4c-411c-bbc9-10c24848e6c9', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-38', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='8fc645f8314bf3b4190ff3ed466011d007294292af3e921655a6b74f2f2b1f7a'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='427545f4-18a5-4d39-ac81-342d79417aa0', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='5e52a609850d6fa6683ffbab59ff8550cd1c262f9d91d781cd05a8ffbb0c46f5'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='dfb61e97-a273-4e1d-95cc-c146d9001db5', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='64c61fe7c91b5b9ad2e6c96d9fc25b4c50d8c521771ef78c6918793388f8d7d8')}, hash='8fd374f9977492b67ab356899aa2035d37beda48d5823bdac4e524cae4b016e7', text='Recent advances towards safe,\\nresponsible, and moral dialogue systems: A survey. arXiv preprint arXiv:2302.09270 , 2023.\\nYuntianDeng,AntonBakhtin,MyleOtt,ArthurSzlam,andMarc’AurelioRanzato. Residualenergy-based\\nmodels for text generation. In International Conference on Learning Representations , 2019.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-38'),\n",
              " 'dfb61e97-a273-4e1d-95cc-c146d9001db5': IndexNode(id_='dfb61e97-a273-4e1d-95cc-c146d9001db5', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-38', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='8fc645f8314bf3b4190ff3ed466011d007294292af3e921655a6b74f2f2b1f7a'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='fcb7b100-db4c-411c-bbc9-10c24848e6c9', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='8fd374f9977492b67ab356899aa2035d37beda48d5823bdac4e524cae4b016e7'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='408e1aca-3ad6-4bce-a653-d3c9797059d7', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='5a4551ebaa8336e54d4cf3b49ec6316bd91fdcc8906b67888fdaa9a7ec053e6f')}, hash='64c61fe7c91b5b9ad2e6c96d9fc25b4c50d8c521771ef78c6918793388f8d7d8', text='In International Conference on Learning Representations , 2019.\\nJwala Dhamala, Tony Sun, Varun Kumar, Satyapriya Krishna, Yada Pruksachatkun, Kai-Wei Chang, and\\nRahulGupta. BOLD:Datasetandmetricsformeasuringbiasesinopen-endedlanguagegeneration. In\\nProceedings of the 2021 ACM conference on fairness, accountability, and transparency , pages 862–872, 2021.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-38'),\n",
              " '408e1aca-3ad6-4bce-a653-d3c9797059d7': IndexNode(id_='408e1aca-3ad6-4bce-a653-d3c9797059d7', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-38', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='8fc645f8314bf3b4190ff3ed466011d007294292af3e921655a6b74f2f2b1f7a'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='dfb61e97-a273-4e1d-95cc-c146d9001db5', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='64c61fe7c91b5b9ad2e6c96d9fc25b4c50d8c521771ef78c6918793388f8d7d8')}, hash='5a4551ebaa8336e54d4cf3b49ec6316bd91fdcc8906b67888fdaa9a7ec053e6f', text='Emily Dinan, Gavin Abercrombie, A Stevie Bergman, Shannon Spruit, Dirk Hovy, Y-Lan Boureau, and\\nVerena Rieser. Anticipating safetyissuesine2e conversationalai: Frameworkandtooling. arXivpreprint\\narXiv:2107.03451 , 2021.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-38'),\n",
              " 'bfe6c5af-90a4-401c-8044-073a6a6064a4': IndexNode(id_='bfe6c5af-90a4-401c-8044-073a6a6064a4', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-38', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='8fc645f8314bf3b4190ff3ed466011d007294292af3e921655a6b74f2f2b1f7a'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='6b8cb534-37dc-4e3d-903e-df9b88e80c0b', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='f74213bb219c396f2580d3b6b0254fd36c8189dd54f41bbeeb451e12aa2c4eca')}, hash='b9872b34fe0c101c31278979a442e68c42b1df4a6334322e739afb09aa45a221', text='Palm: Scaling language modeling with pathways, 2022.\\nPaulFChristiano,JanLeike,TomBrown,MiljanMartic,ShaneLegg,andDarioAmodei. Deepreinforcement\\nlearning from human preferences. Advances in neural information processing systems , 30, 2017.\\nHyung Won Chung, Le Hou, S. Longpre, Barret Zoph, Yi Tay, William Fedus, Eric Li, Xuezhi Wang, Mostafa\\nDehghani,SiddharthaBrahma,AlbertWebson,ShixiangShaneGu,ZhuyunDai,MiracSuzgun,Xinyun\\nChen,AakankshaChowdhery,DashaValter,SharanNarang,GauravMishra,AdamsWeiYu,VincentZhao,\\nYanping Huang, Andrew M. Dai, Hongkun Yu, Slav Petrov, Ed Huai hsin Chi, Jeff Dean, Jacob Devlin,\\n38\\n\\nAdam Roberts,Denny Zhou,QuocV.Le, andJasonWei. Scaling instruction-finetunedlanguage models.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-38'),\n",
              " '6b8cb534-37dc-4e3d-903e-df9b88e80c0b': IndexNode(id_='6b8cb534-37dc-4e3d-903e-df9b88e80c0b', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-38', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='8fc645f8314bf3b4190ff3ed466011d007294292af3e921655a6b74f2f2b1f7a'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='bfe6c5af-90a4-401c-8044-073a6a6064a4', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='b9872b34fe0c101c31278979a442e68c42b1df4a6334322e739afb09aa45a221'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='45531504-b753-4e6a-98ad-7ae3e1380715', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='30b1e314d48ddfdbc2aefa822cf76bf6ff59d16a209880eff85b0073e9f8c0f3')}, hash='f74213bb219c396f2580d3b6b0254fd36c8189dd54f41bbeeb451e12aa2c4eca', text='Scaling instruction-finetunedlanguage models.\\narXiv preprint arXiv:2210.11416 , 2022.\\nChristopherClark,KentonLee,Ming-WeiChang,TomKwiatkowski,MichaelCollins,andKristinaToutanova.\\nBoolq: Exploring the surprising difficulty of natural yes/no questions. arXiv preprint arXiv:1905.10044 ,\\n2019.\\nElizabethClark,TalAugust,SofiaSerrano,NikitaHaduong,SuchinGururangan,andNoahA.Smith.Allthat’s\\n‘human’isnotgold: Evaluatinghumanevaluationofgeneratedtext. In Proceedingsofthe59thAnnualMeeting\\nof the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language\\nProcessing (Volume 1: Long Papers) , pages 7282–7296, Online, August 2021. Association for Computational\\nLinguistics. doi: 10.18653/v1/2021.acl-long.565.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-38'),\n",
              " '45531504-b753-4e6a-98ad-7ae3e1380715': IndexNode(id_='45531504-b753-4e6a-98ad-7ae3e1380715', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-38', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='8fc645f8314bf3b4190ff3ed466011d007294292af3e921655a6b74f2f2b1f7a'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='6b8cb534-37dc-4e3d-903e-df9b88e80c0b', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='f74213bb219c396f2580d3b6b0254fd36c8189dd54f41bbeeb451e12aa2c4eca'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='2a6a38bd-0fd3-43ab-a382-b5f8a31a206a', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='359c47e0babc5cc1fc2aa58380be4f61d3100d14633702f50a137fa13da33c72')}, hash='30b1e314d48ddfdbc2aefa822cf76bf6ff59d16a209880eff85b0073e9f8c0f3', text='doi: 10.18653/v1/2021.acl-long.565. URL https://aclanthology.org/2021.acl-long.565 .\\nPeterClark,IsaacCowhey,OrenEtzioni,TusharKhot,AshishSabharwal,CarissaSchoenick,andOyvind\\nTafjord. Thinkyouhavesolvedquestionanswering? tryarc,theai2reasoningchallenge. arXivpreprint\\narXiv:1803.05457 , 2018.\\nKarl Cobbe, Vineet Kosaraju, Mohammad Bavarian, Mark Chen, Heewoo Jun, Lukasz Kaiser, Matthias\\nPlappert, Jerry Tworek, Jacob Hilton, Reiichiro Nakano, et al. Training verifiers to solve math word\\nproblems. arXiv preprint arXiv:2110.14168 , 2021.\\nJiawen Deng, Hao Sun, Zhexin Zhang, Jiale Cheng, and Minlie Huang. Recent advances towards safe,\\nresponsible, and moral dialogue systems: A survey.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-38'),\n",
              " '2a6a38bd-0fd3-43ab-a382-b5f8a31a206a': IndexNode(id_='2a6a38bd-0fd3-43ab-a382-b5f8a31a206a', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-38', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='8fc645f8314bf3b4190ff3ed466011d007294292af3e921655a6b74f2f2b1f7a'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='45531504-b753-4e6a-98ad-7ae3e1380715', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='30b1e314d48ddfdbc2aefa822cf76bf6ff59d16a209880eff85b0073e9f8c0f3'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='7b0ad9c9-adac-406d-85cc-2a841cd9244c', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='450eb2efe6b2c74747dc722a41bfb626271785bc47ee63ce007e892a3c5d38a7')}, hash='359c47e0babc5cc1fc2aa58380be4f61d3100d14633702f50a137fa13da33c72', text='Recent advances towards safe,\\nresponsible, and moral dialogue systems: A survey. arXiv preprint arXiv:2302.09270 , 2023.\\nYuntianDeng,AntonBakhtin,MyleOtt,ArthurSzlam,andMarc’AurelioRanzato. Residualenergy-based\\nmodels for text generation. In International Conference on Learning Representations , 2019.\\nJwala Dhamala, Tony Sun, Varun Kumar, Satyapriya Krishna, Yada Pruksachatkun, Kai-Wei Chang, and\\nRahulGupta. BOLD:Datasetandmetricsformeasuringbiasesinopen-endedlanguagegeneration. In\\nProceedings of the 2021 ACM conference on fairness, accountability, and transparency , pages 862–872, 2021.\\nEmily Dinan, Gavin Abercrombie, A Stevie Bergman, Shannon Spruit, Dirk Hovy, Y-Lan Boureau, and\\nVerena Rieser. Anticipating safetyissuesine2e conversationalai: Frameworkandtooling.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-38'),\n",
              " '7b0ad9c9-adac-406d-85cc-2a841cd9244c': IndexNode(id_='7b0ad9c9-adac-406d-85cc-2a841cd9244c', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-38', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='8fc645f8314bf3b4190ff3ed466011d007294292af3e921655a6b74f2f2b1f7a'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='2a6a38bd-0fd3-43ab-a382-b5f8a31a206a', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='359c47e0babc5cc1fc2aa58380be4f61d3100d14633702f50a137fa13da33c72')}, hash='450eb2efe6b2c74747dc722a41bfb626271785bc47ee63ce007e892a3c5d38a7', text='Anticipating safetyissuesine2e conversationalai: Frameworkandtooling. arXivpreprint\\narXiv:2107.03451 , 2021.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-38'),\n",
              " 'bb8386e9-cadb-431e-a69d-61a0c30bbf16': IndexNode(id_='bb8386e9-cadb-431e-a69d-61a0c30bbf16', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-38', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='8fc645f8314bf3b4190ff3ed466011d007294292af3e921655a6b74f2f2b1f7a'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='3bee5e73-75b5-43c4-8da7-cd05632955c0', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='a54f02f7ffef2459fb36df6720408dd459b7bb9693d734966a07015d4bd542a6')}, hash='4a60862dd84277b0030913fb91be5786290a06f2937a259e893324bc324f6c4b', text='Palm: Scaling language modeling with pathways, 2022.\\nPaulFChristiano,JanLeike,TomBrown,MiljanMartic,ShaneLegg,andDarioAmodei. Deepreinforcement\\nlearning from human preferences. Advances in neural information processing systems , 30, 2017.\\nHyung Won Chung, Le Hou, S. Longpre, Barret Zoph, Yi Tay, William Fedus, Eric Li, Xuezhi Wang, Mostafa\\nDehghani,SiddharthaBrahma,AlbertWebson,ShixiangShaneGu,ZhuyunDai,MiracSuzgun,Xinyun\\nChen,AakankshaChowdhery,DashaValter,SharanNarang,GauravMishra,AdamsWeiYu,VincentZhao,\\nYanping Huang, Andrew M. Dai, Hongkun Yu, Slav Petrov, Ed Huai hsin Chi, Jeff Dean, Jacob Devlin,\\n38\\n\\nAdam Roberts,Denny Zhou,QuocV.Le, andJasonWei. Scaling instruction-finetunedlanguage models.\\narXiv preprint arXiv:2210.11416 , 2022.\\nChristopherClark,KentonLee,Ming-WeiChang,TomKwiatkowski,MichaelCollins,andKristinaToutanova.\\nBoolq: Exploring the surprising difficulty of natural yes/no questions. arXiv preprint arXiv:1905.10044 ,\\n2019.\\nElizabethClark,TalAugust,SofiaSerrano,NikitaHaduong,SuchinGururangan,andNoahA.Smith.Allthat’s\\n‘human’isnotgold: Evaluatinghumanevaluationofgeneratedtext. In Proceedingsofthe59thAnnualMeeting\\nof the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language\\nProcessing (Volume 1: Long Papers) , pages 7282–7296, Online, August 2021. Association for Computational\\nLinguistics. doi: 10.18653/v1/2021.acl-long.565. URL https://aclanthology.org/2021.acl-long.565 .', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-38'),\n",
              " '3bee5e73-75b5-43c4-8da7-cd05632955c0': IndexNode(id_='3bee5e73-75b5-43c4-8da7-cd05632955c0', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-38', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='8fc645f8314bf3b4190ff3ed466011d007294292af3e921655a6b74f2f2b1f7a'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='bb8386e9-cadb-431e-a69d-61a0c30bbf16', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='4a60862dd84277b0030913fb91be5786290a06f2937a259e893324bc324f6c4b')}, hash='a54f02f7ffef2459fb36df6720408dd459b7bb9693d734966a07015d4bd542a6', text='URL https://aclanthology.org/2021.acl-long.565 .\\nPeterClark,IsaacCowhey,OrenEtzioni,TusharKhot,AshishSabharwal,CarissaSchoenick,andOyvind\\nTafjord. Thinkyouhavesolvedquestionanswering? tryarc,theai2reasoningchallenge. arXivpreprint\\narXiv:1803.05457 , 2018.\\nKarl Cobbe, Vineet Kosaraju, Mohammad Bavarian, Mark Chen, Heewoo Jun, Lukasz Kaiser, Matthias\\nPlappert, Jerry Tworek, Jacob Hilton, Reiichiro Nakano, et al. Training verifiers to solve math word\\nproblems. arXiv preprint arXiv:2110.14168 , 2021.\\nJiawen Deng, Hao Sun, Zhexin Zhang, Jiale Cheng, and Minlie Huang. Recent advances towards safe,\\nresponsible, and moral dialogue systems: A survey. arXiv preprint arXiv:2302.09270 , 2023.\\nYuntianDeng,AntonBakhtin,MyleOtt,ArthurSzlam,andMarc’AurelioRanzato. Residualenergy-based\\nmodels for text generation. In International Conference on Learning Representations , 2019.\\nJwala Dhamala, Tony Sun, Varun Kumar, Satyapriya Krishna, Yada Pruksachatkun, Kai-Wei Chang, and\\nRahulGupta. BOLD:Datasetandmetricsformeasuringbiasesinopen-endedlanguagegeneration. In\\nProceedings of the 2021 ACM conference on fairness, accountability, and transparency , pages 862–872, 2021.\\nEmily Dinan, Gavin Abercrombie, A Stevie Bergman, Shannon Spruit, Dirk Hovy, Y-Lan Boureau, and\\nVerena Rieser. Anticipating safetyissuesine2e conversationalai: Frameworkandtooling. arXivpreprint\\narXiv:2107.03451 , 2021.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-38'),\n",
              " 'node-38': IndexNode(id_='node-38', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='415b7efc-e73f-4ac4-bbfd-c1546f099026', node_type=<ObjectType.DOCUMENT: '4'>, metadata={}, hash='231b3bd773f012c01b893ada9e009ecf25ee59934614c5a595c9bf1b3a123292'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='481eb7ec-12cf-4491-be9a-e32ca894748b', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='18200e194553a5d9070920177a76b29b8f5a68dede4ab028a607ccf84a85b75a'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='d2255d6f-c185-41b0-b0b7-0cfbccf0c46c', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='b293f131ac43be9c94605b5f94094f5373338d4dc1ee92d740def5bc907b981a')}, hash='8fc645f8314bf3b4190ff3ed466011d007294292af3e921655a6b74f2f2b1f7a', text='Palm: Scaling language modeling with pathways, 2022.\\nPaulFChristiano,JanLeike,TomBrown,MiljanMartic,ShaneLegg,andDarioAmodei. Deepreinforcement\\nlearning from human preferences. Advances in neural information processing systems , 30, 2017.\\nHyung Won Chung, Le Hou, S. Longpre, Barret Zoph, Yi Tay, William Fedus, Eric Li, Xuezhi Wang, Mostafa\\nDehghani,SiddharthaBrahma,AlbertWebson,ShixiangShaneGu,ZhuyunDai,MiracSuzgun,Xinyun\\nChen,AakankshaChowdhery,DashaValter,SharanNarang,GauravMishra,AdamsWeiYu,VincentZhao,\\nYanping Huang, Andrew M. Dai, Hongkun Yu, Slav Petrov, Ed Huai hsin Chi, Jeff Dean, Jacob Devlin,\\n38\\n\\nAdam Roberts,Denny Zhou,QuocV.Le, andJasonWei. Scaling instruction-finetunedlanguage models.\\narXiv preprint arXiv:2210.11416 , 2022.\\nChristopherClark,KentonLee,Ming-WeiChang,TomKwiatkowski,MichaelCollins,andKristinaToutanova.\\nBoolq: Exploring the surprising difficulty of natural yes/no questions. arXiv preprint arXiv:1905.10044 ,\\n2019.\\nElizabethClark,TalAugust,SofiaSerrano,NikitaHaduong,SuchinGururangan,andNoahA.Smith.Allthat’s\\n‘human’isnotgold: Evaluatinghumanevaluationofgeneratedtext. In Proceedingsofthe59thAnnualMeeting\\nof the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language\\nProcessing (Volume 1: Long Papers) , pages 7282–7296, Online, August 2021. Association for Computational\\nLinguistics. doi: 10.18653/v1/2021.acl-long.565. URL https://aclanthology.org/2021.acl-long.565 .\\nPeterClark,IsaacCowhey,OrenEtzioni,TusharKhot,AshishSabharwal,CarissaSchoenick,andOyvind\\nTafjord. Thinkyouhavesolvedquestionanswering? tryarc,theai2reasoningchallenge. arXivpreprint\\narXiv:1803.05457 , 2018.\\nKarl Cobbe, Vineet Kosaraju, Mohammad Bavarian, Mark Chen, Heewoo Jun, Lukasz Kaiser, Matthias\\nPlappert, Jerry Tworek, Jacob Hilton, Reiichiro Nakano, et al. Training verifiers to solve math word\\nproblems. arXiv preprint arXiv:2110.14168 , 2021.\\nJiawen Deng, Hao Sun, Zhexin Zhang, Jiale Cheng, and Minlie Huang. Recent advances towards safe,\\nresponsible, and moral dialogue systems: A survey. arXiv preprint arXiv:2302.09270 , 2023.\\nYuntianDeng,AntonBakhtin,MyleOtt,ArthurSzlam,andMarc’AurelioRanzato. Residualenergy-based\\nmodels for text generation. In International Conference on Learning Representations , 2019.\\nJwala Dhamala, Tony Sun, Varun Kumar, Satyapriya Krishna, Yada Pruksachatkun, Kai-Wei Chang, and\\nRahulGupta. BOLD:Datasetandmetricsformeasuringbiasesinopen-endedlanguagegeneration. In\\nProceedings of the 2021 ACM conference on fairness, accountability, and transparency , pages 862–872, 2021.\\nEmily Dinan, Gavin Abercrombie, A Stevie Bergman, Shannon Spruit, Dirk Hovy, Y-Lan Boureau, and\\nVerena Rieser. Anticipating safetyissuesine2e conversationalai: Frameworkandtooling. arXivpreprint\\narXiv:2107.03451 , 2021.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-38'),\n",
              " '0f997ac0-dbcd-4faf-9ee2-a839e6b058b1': IndexNode(id_='0f997ac0-dbcd-4faf-9ee2-a839e6b058b1', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-39', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='b293f131ac43be9c94605b5f94094f5373338d4dc1ee92d740def5bc907b981a'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='c6b3bec9-af8c-4a47-940b-d225b7d1eab1', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='17b058aef81962836bf9773aa460f204d5013396b591b752cdff07a6a3b5a1a5')}, hash='c666661264e665fd6754d8cd7cf9acd981fc8237af6112f8716af067b5562cd1', text='arXivpreprint\\narXiv:2107.03451 , 2021.\\nJesse Dodge, Maarten Sap, Ana Marasović, William Agnew, Gabriel Ilharco, Dirk Groeneveld, Margaret\\nMitchell,andMattGardner.Documentinglargewebtextcorpora: Acasestudyonthecolossalcleancrawled\\ncorpus. In Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing , pages\\n1286–1305, Online and Punta Cana, Dominican Republic, November 2021.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-39'),\n",
              " 'c6b3bec9-af8c-4a47-940b-d225b7d1eab1': IndexNode(id_='c6b3bec9-af8c-4a47-940b-d225b7d1eab1', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-39', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='b293f131ac43be9c94605b5f94094f5373338d4dc1ee92d740def5bc907b981a'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='0f997ac0-dbcd-4faf-9ee2-a839e6b058b1', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='c666661264e665fd6754d8cd7cf9acd981fc8237af6112f8716af067b5562cd1'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='2c6449ee-0bc8-4e58-94e9-85420ef0ed08', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='85da700db1611a58b58ccd6fbdebcd1877b8b4115a9db53742a17394f1a6df1a')}, hash='17b058aef81962836bf9773aa460f204d5013396b591b752cdff07a6a3b5a1a5', text='Association for Computational\\nLinguistics. doi: 10.18653/v1/2021.emnlp-main.98. URL https://aclanthology.org/2021.emnlp-main.\\n98.\\nJesseDodge,TaylorPrewitt,RemiTachetDesCombes,ErikaOdmark,RoySchwartz,EmmaStrubell,Alexan-\\ndra Sasha Luccioni, Noah A Smith, Nicole DeCario, and Will Buchanan.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-39'),\n",
              " '2c6449ee-0bc8-4e58-94e9-85420ef0ed08': IndexNode(id_='2c6449ee-0bc8-4e58-94e9-85420ef0ed08', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-39', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='b293f131ac43be9c94605b5f94094f5373338d4dc1ee92d740def5bc907b981a'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='c6b3bec9-af8c-4a47-940b-d225b7d1eab1', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='17b058aef81962836bf9773aa460f204d5013396b591b752cdff07a6a3b5a1a5'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='0f41ce0f-625a-47fd-ad3f-f131374b4f30', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='cfbbb6c0e7f9d68e48336d842b325d36dacaeb7fb204dce975a0d8ef485d7a53')}, hash='85da700db1611a58b58ccd6fbdebcd1877b8b4115a9db53742a17394f1a6df1a', text='Measuring the carbon intensity of\\nai in cloud instances. arXiv preprint arXiv:2206.05229 , 2022.\\nNanDu,YanpingHuang,AndrewMDai,SimonTong,DmitryLepikhin,YuanzhongXu,MaximKrikun,\\nYanqi Zhou, Adams Wei Yu, Orhan Firat, Barret Zoph, Liam Fedus, Maarten P Bosma, Zongwei Zhou, Tao\\nWang, EmmaWang,KellieWebster, MariePellat, KevinRobinson,', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-39'),\n",
              " '0f41ce0f-625a-47fd-ad3f-f131374b4f30': IndexNode(id_='0f41ce0f-625a-47fd-ad3f-f131374b4f30', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-39', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='b293f131ac43be9c94605b5f94094f5373338d4dc1ee92d740def5bc907b981a'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='2c6449ee-0bc8-4e58-94e9-85420ef0ed08', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='85da700db1611a58b58ccd6fbdebcd1877b8b4115a9db53742a17394f1a6df1a'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='66c2243b-9caf-4fe5-a3dd-d3af5aa0b5a1', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='53c03b4c2404f01be2c1ea2b7781bb4690e38ce090e4231e0f82e7ccc555477d')}, hash='cfbbb6c0e7f9d68e48336d842b325d36dacaeb7fb204dce975a0d8ef485d7a53', text='EmmaWang,KellieWebster, MariePellat, KevinRobinson,Kathleen Meier-Hellstern,TojuDuke,\\nLucasDixon,KunZhang,QuocLe,YonghuiWu,ZhifengChen,andClaireCui. GLaM:Efficientscaling\\noflanguagemodelswithmixture-of-experts.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-39'),\n",
              " '66c2243b-9caf-4fe5-a3dd-d3af5aa0b5a1': IndexNode(id_='66c2243b-9caf-4fe5-a3dd-d3af5aa0b5a1', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-39', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='b293f131ac43be9c94605b5f94094f5373338d4dc1ee92d740def5bc907b981a'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='0f41ce0f-625a-47fd-ad3f-f131374b4f30', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='cfbbb6c0e7f9d68e48336d842b325d36dacaeb7fb204dce975a0d8ef485d7a53'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='3d360a4d-85e0-4380-9248-4d38fab8380d', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='f60ed6bb3dbd8080287b40029eb3aa6246b2d4b2ffda78e18d871e811e5e71dc')}, hash='53c03b4c2404f01be2c1ea2b7781bb4690e38ce090e4231e0f82e7ccc555477d', text='InKamalikaChaudhuri,StefanieJegelka,LeSong,Csaba\\nSzepesvari, Gang Niu, and Sivan Sabato, editors, Proceedings of the 39th International Conference on Machine\\nLearning,volume162of ProceedingsofMachineLearningResearch ,pages5547–5569.PMLR,17–23Jul2022.\\nURL https://proceedings.mlr.press/v162/du22c.html .', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-39'),\n",
              " '3d360a4d-85e0-4380-9248-4d38fab8380d': IndexNode(id_='3d360a4d-85e0-4380-9248-4d38fab8380d', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-39', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='b293f131ac43be9c94605b5f94094f5373338d4dc1ee92d740def5bc907b981a'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='66c2243b-9caf-4fe5-a3dd-d3af5aa0b5a1', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='53c03b4c2404f01be2c1ea2b7781bb4690e38ce090e4231e0f82e7ccc555477d'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='e5772f26-4aa8-4dac-b624-8e396ad081b8', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='4e529e5a01a3591e2e6323f8ac1878f14aa7fe6398de227cbb382f3297053936')}, hash='f60ed6bb3dbd8080287b40029eb3aa6246b2d4b2ffda78e18d871e811e5e71dc', text='KawinEthayarajh,YejinChoi,andSwabhaSwayamdipta. Understandingdatasetdifficultywith V-usable\\ninformation. InKamalikaChaudhuri,StefanieJegelka,LeSong,CsabaSzepesvari,GangNiu,andSivan\\nSabato,editors, Proceedingsofthe39thInternationalConferenceonMachineLearning ,volume162of Proceedings\\nof Machine Learning Research , pages 5988–6008. PMLR, 17–23 Jul 2022.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-39'),\n",
              " 'e5772f26-4aa8-4dac-b624-8e396ad081b8': IndexNode(id_='e5772f26-4aa8-4dac-b624-8e396ad081b8', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-39', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='b293f131ac43be9c94605b5f94094f5373338d4dc1ee92d740def5bc907b981a'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='3d360a4d-85e0-4380-9248-4d38fab8380d', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='f60ed6bb3dbd8080287b40029eb3aa6246b2d4b2ffda78e18d871e811e5e71dc'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='9a9a442b-ff80-42b3-8e63-f93bb7887cd8', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='bc96b594af1891005ac8981b48bb480cf710794207612b3dcaf358a263a2cd8a')}, hash='4e529e5a01a3591e2e6323f8ac1878f14aa7fe6398de227cbb382f3297053936', text='PMLR, 17–23 Jul 2022.\\nPrakhar Ganesh, Hongyan Chang, Martin Strobel, and Reza Shokri. On the impact of machine learning\\nrandomnessongroupfairness. In Proceedingsofthe2023ACMConferenceonFairness,Accountability,and\\nTransparency , pages 1789–1800, 2023.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-39'),\n",
              " '9a9a442b-ff80-42b3-8e63-f93bb7887cd8': IndexNode(id_='9a9a442b-ff80-42b3-8e63-f93bb7887cd8', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-39', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='b293f131ac43be9c94605b5f94094f5373338d4dc1ee92d740def5bc907b981a'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='e5772f26-4aa8-4dac-b624-8e396ad081b8', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='4e529e5a01a3591e2e6323f8ac1878f14aa7fe6398de227cbb382f3297053936'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='1b8f2456-a70e-40a1-ab62-16bd8699bfe1', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='ee5753801b7f007fb34ada07c97a388dccca3a46e586235d73d2e3e9865f3a72')}, hash='bc96b594af1891005ac8981b48bb480cf710794207612b3dcaf358a263a2cd8a', text='Deep Ganguli, Liane Lovitt, Jackson Kernion, Amanda Askell, Yuntao Bai, Saurav Kadavath, Ben Mann,\\nEthan Perez, Nicholas Schiefer, Kamal Ndousse, et al. Red teaming language models to reduce harms:\\nMethods, scaling behaviors, and lessons learned. arXiv preprint arXiv:2209.07858 , 2022.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-39'),\n",
              " '1b8f2456-a70e-40a1-ab62-16bd8699bfe1': IndexNode(id_='1b8f2456-a70e-40a1-ab62-16bd8699bfe1', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-39', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='b293f131ac43be9c94605b5f94094f5373338d4dc1ee92d740def5bc907b981a'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='9a9a442b-ff80-42b3-8e63-f93bb7887cd8', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='bc96b594af1891005ac8981b48bb480cf710794207612b3dcaf358a263a2cd8a'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='98ed99e2-22a3-4cf9-ab82-7dad45fba287', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='9b9c349b351c7dd77442d8b959d9699dc409e5cca79d756dead6a5b01add732f')}, hash='ee5753801b7f007fb34ada07c97a388dccca3a46e586235d73d2e3e9865f3a72', text='arXiv preprint arXiv:2209.07858 , 2022.\\n39\\n\\nDeepGanguli,AmandaAskell,NicholasSchiefer,ThomasLiao,Kamil ˙eLukoši ¯ut˙e,AnnaChen,AnnaGoldie,\\nAzaliaMirhoseini,CatherineOlsson,DannyHernandez,etal. Thecapacityformoralself-correctionin\\nlarge language models. arXiv preprint arXiv:2302.07459 , 2023.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-39'),\n",
              " '98ed99e2-22a3-4cf9-ab82-7dad45fba287': IndexNode(id_='98ed99e2-22a3-4cf9-ab82-7dad45fba287', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-39', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='b293f131ac43be9c94605b5f94094f5373338d4dc1ee92d740def5bc907b981a'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='1b8f2456-a70e-40a1-ab62-16bd8699bfe1', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='ee5753801b7f007fb34ada07c97a388dccca3a46e586235d73d2e3e9865f3a72')}, hash='9b9c349b351c7dd77442d8b959d9699dc409e5cca79d756dead6a5b01add732f', text='arXiv preprint arXiv:2302.07459 , 2023.\\nLeoGao,JonathanTow,StellaBiderman,SidBlack,AnthonyDiPofi,CharlesFoster,LaurenceGolding,Jeffrey\\nHsu, Kyle McDonell, Niklas Muennighoff, Jason Phang, Laria Reynolds, Eric Tang, Anish Thite, Ben Wang,\\nKevin Wang, and Andy Zou.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-39'),\n",
              " '042aba0f-725f-4835-93da-ed604f5731db': IndexNode(id_='042aba0f-725f-4835-93da-ed604f5731db', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-39', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='b293f131ac43be9c94605b5f94094f5373338d4dc1ee92d740def5bc907b981a'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='de1eea0e-2c98-4fbd-80fb-596b657e8c89', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='fecf020d591bcbf7ef9cfb210f3affcbe02e11921099da144e1c6c24dedb8055')}, hash='37a1a205d504598a348085b04a6b67c49476ffa5f0df3f47dcec3d77453b807a', text='arXivpreprint\\narXiv:2107.03451 , 2021.\\nJesse Dodge, Maarten Sap, Ana Marasović, William Agnew, Gabriel Ilharco, Dirk Groeneveld, Margaret\\nMitchell,andMattGardner.Documentinglargewebtextcorpora: Acasestudyonthecolossalcleancrawled\\ncorpus. In Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing , pages\\n1286–1305, Online and Punta Cana, Dominican Republic, November 2021. Association for Computational\\nLinguistics. doi: 10.18653/v1/2021.emnlp-main.98. URL https://aclanthology.org/2021.emnlp-main.\\n98.\\nJesseDodge,TaylorPrewitt,RemiTachetDesCombes,ErikaOdmark,RoySchwartz,EmmaStrubell,Alexan-\\ndra Sasha Luccioni, Noah A Smith, Nicole DeCario, and Will Buchanan. Measuring the carbon intensity of\\nai in cloud instances.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-39'),\n",
              " 'de1eea0e-2c98-4fbd-80fb-596b657e8c89': IndexNode(id_='de1eea0e-2c98-4fbd-80fb-596b657e8c89', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-39', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='b293f131ac43be9c94605b5f94094f5373338d4dc1ee92d740def5bc907b981a'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='042aba0f-725f-4835-93da-ed604f5731db', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='37a1a205d504598a348085b04a6b67c49476ffa5f0df3f47dcec3d77453b807a'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='b10ff622-68d1-4ad5-87f9-cec530196d8b', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='6e33c248f4313d43ec157c15dd0242e810dc2bcaee756a45126ce16d820b7607')}, hash='fecf020d591bcbf7ef9cfb210f3affcbe02e11921099da144e1c6c24dedb8055', text='Measuring the carbon intensity of\\nai in cloud instances. arXiv preprint arXiv:2206.05229 , 2022.\\nNanDu,YanpingHuang,AndrewMDai,SimonTong,DmitryLepikhin,YuanzhongXu,MaximKrikun,\\nYanqi Zhou, Adams Wei Yu, Orhan Firat, Barret Zoph, Liam Fedus, Maarten P Bosma, Zongwei Zhou, Tao\\nWang, EmmaWang,KellieWebster, MariePellat, KevinRobinson,Kathleen Meier-Hellstern,TojuDuke,\\nLucasDixon,KunZhang,QuocLe,YonghuiWu,ZhifengChen,andClaireCui. GLaM:Efficientscaling\\noflanguagemodelswithmixture-of-experts.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-39'),\n",
              " 'b10ff622-68d1-4ad5-87f9-cec530196d8b': IndexNode(id_='b10ff622-68d1-4ad5-87f9-cec530196d8b', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-39', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='b293f131ac43be9c94605b5f94094f5373338d4dc1ee92d740def5bc907b981a'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='de1eea0e-2c98-4fbd-80fb-596b657e8c89', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='fecf020d591bcbf7ef9cfb210f3affcbe02e11921099da144e1c6c24dedb8055'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='ae0e6aca-9803-4d0b-9134-b23d85de680f', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='76a27dac545b2e20acf274655006bf81ee442e99bc1c2b7a7c08d7aebf52d558')}, hash='6e33c248f4313d43ec157c15dd0242e810dc2bcaee756a45126ce16d820b7607', text='InKamalikaChaudhuri,StefanieJegelka,LeSong,Csaba\\nSzepesvari, Gang Niu, and Sivan Sabato, editors, Proceedings of the 39th International Conference on Machine\\nLearning,volume162of ProceedingsofMachineLearningResearch ,pages5547–5569.PMLR,17–23Jul2022.\\nURL https://proceedings.mlr.press/v162/du22c.html .\\nKawinEthayarajh,YejinChoi,andSwabhaSwayamdipta. Understandingdatasetdifficultywith V-usable\\ninformation. InKamalikaChaudhuri,StefanieJegelka,LeSong,CsabaSzepesvari,GangNiu,andSivan\\nSabato,editors, Proceedingsofthe39thInternationalConferenceonMachineLearning ,volume162of Proceedings\\nof Machine Learning Research , pages 5988–6008. PMLR, 17–23 Jul 2022.\\nPrakhar Ganesh, Hongyan Chang, Martin Strobel, and Reza Shokri.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-39'),\n",
              " 'ae0e6aca-9803-4d0b-9134-b23d85de680f': IndexNode(id_='ae0e6aca-9803-4d0b-9134-b23d85de680f', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-39', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='b293f131ac43be9c94605b5f94094f5373338d4dc1ee92d740def5bc907b981a'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='b10ff622-68d1-4ad5-87f9-cec530196d8b', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='6e33c248f4313d43ec157c15dd0242e810dc2bcaee756a45126ce16d820b7607'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='8fcf9369-0366-423a-a273-3ab30f800afe', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='9b9c349b351c7dd77442d8b959d9699dc409e5cca79d756dead6a5b01add732f')}, hash='76a27dac545b2e20acf274655006bf81ee442e99bc1c2b7a7c08d7aebf52d558', text='On the impact of machine learning\\nrandomnessongroupfairness. In Proceedingsofthe2023ACMConferenceonFairness,Accountability,and\\nTransparency , pages 1789–1800, 2023.\\nDeep Ganguli, Liane Lovitt, Jackson Kernion, Amanda Askell, Yuntao Bai, Saurav Kadavath, Ben Mann,\\nEthan Perez, Nicholas Schiefer, Kamal Ndousse, et al. Red teaming language models to reduce harms:\\nMethods, scaling behaviors, and lessons learned. arXiv preprint arXiv:2209.07858 , 2022.\\n39\\n\\nDeepGanguli,AmandaAskell,NicholasSchiefer,ThomasLiao,Kamil ˙eLukoši ¯ut˙e,AnnaChen,AnnaGoldie,\\nAzaliaMirhoseini,CatherineOlsson,DannyHernandez,etal. Thecapacityformoralself-correctionin\\nlarge language models. arXiv preprint arXiv:2302.07459 , 2023.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-39'),\n",
              " '8fcf9369-0366-423a-a273-3ab30f800afe': IndexNode(id_='8fcf9369-0366-423a-a273-3ab30f800afe', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-39', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='b293f131ac43be9c94605b5f94094f5373338d4dc1ee92d740def5bc907b981a'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='ae0e6aca-9803-4d0b-9134-b23d85de680f', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='76a27dac545b2e20acf274655006bf81ee442e99bc1c2b7a7c08d7aebf52d558')}, hash='9b9c349b351c7dd77442d8b959d9699dc409e5cca79d756dead6a5b01add732f', text='arXiv preprint arXiv:2302.07459 , 2023.\\nLeoGao,JonathanTow,StellaBiderman,SidBlack,AnthonyDiPofi,CharlesFoster,LaurenceGolding,Jeffrey\\nHsu, Kyle McDonell, Niklas Muennighoff, Jason Phang, Laria Reynolds, Eric Tang, Anish Thite, Ben Wang,\\nKevin Wang, and Andy Zou.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-39'),\n",
              " '0d9f92bf-d0be-4a58-a419-834251a238c6': IndexNode(id_='0d9f92bf-d0be-4a58-a419-834251a238c6', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-39', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='b293f131ac43be9c94605b5f94094f5373338d4dc1ee92d740def5bc907b981a'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='6f84d7df-0d95-462b-9b0d-8d218f4f2e6c', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='522d8fd4dda119b6f4084a45948b7285d988d85b5b77c39fcf030ea343ae75a6')}, hash='d60dc4fad95a37d1f66827b93c02c3f735550c2655d82e61d81bc51a39149d55', text='arXivpreprint\\narXiv:2107.03451 , 2021.\\nJesse Dodge, Maarten Sap, Ana Marasović, William Agnew, Gabriel Ilharco, Dirk Groeneveld, Margaret\\nMitchell,andMattGardner.Documentinglargewebtextcorpora: Acasestudyonthecolossalcleancrawled\\ncorpus. In Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing , pages\\n1286–1305, Online and Punta Cana, Dominican Republic, November 2021. Association for Computational\\nLinguistics. doi: 10.18653/v1/2021.emnlp-main.98. URL https://aclanthology.org/2021.emnlp-main.\\n98.\\nJesseDodge,TaylorPrewitt,RemiTachetDesCombes,ErikaOdmark,RoySchwartz,EmmaStrubell,Alexan-\\ndra Sasha Luccioni, Noah A Smith, Nicole DeCario, and Will Buchanan. Measuring the carbon intensity of\\nai in cloud instances. arXiv preprint arXiv:2206.05229 , 2022.\\nNanDu,YanpingHuang,AndrewMDai,SimonTong,DmitryLepikhin,YuanzhongXu,MaximKrikun,\\nYanqi Zhou, Adams Wei Yu, Orhan Firat, Barret Zoph, Liam Fedus, Maarten P Bosma, Zongwei Zhou, Tao\\nWang, EmmaWang,KellieWebster, MariePellat, KevinRobinson,Kathleen Meier-Hellstern,TojuDuke,\\nLucasDixon,KunZhang,QuocLe,YonghuiWu,ZhifengChen,andClaireCui. GLaM:Efficientscaling\\noflanguagemodelswithmixture-of-experts.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-39'),\n",
              " '6f84d7df-0d95-462b-9b0d-8d218f4f2e6c': IndexNode(id_='6f84d7df-0d95-462b-9b0d-8d218f4f2e6c', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-39', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='b293f131ac43be9c94605b5f94094f5373338d4dc1ee92d740def5bc907b981a'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='0d9f92bf-d0be-4a58-a419-834251a238c6', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='d60dc4fad95a37d1f66827b93c02c3f735550c2655d82e61d81bc51a39149d55'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='b9761739-6146-411d-a5a4-411461519e8a', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='9b9c349b351c7dd77442d8b959d9699dc409e5cca79d756dead6a5b01add732f')}, hash='522d8fd4dda119b6f4084a45948b7285d988d85b5b77c39fcf030ea343ae75a6', text='InKamalikaChaudhuri,StefanieJegelka,LeSong,Csaba\\nSzepesvari, Gang Niu, and Sivan Sabato, editors, Proceedings of the 39th International Conference on Machine\\nLearning,volume162of ProceedingsofMachineLearningResearch ,pages5547–5569.PMLR,17–23Jul2022.\\nURL https://proceedings.mlr.press/v162/du22c.html .\\nKawinEthayarajh,YejinChoi,andSwabhaSwayamdipta. Understandingdatasetdifficultywith V-usable\\ninformation. InKamalikaChaudhuri,StefanieJegelka,LeSong,CsabaSzepesvari,GangNiu,andSivan\\nSabato,editors, Proceedingsofthe39thInternationalConferenceonMachineLearning ,volume162of Proceedings\\nof Machine Learning Research , pages 5988–6008. PMLR, 17–23 Jul 2022.\\nPrakhar Ganesh, Hongyan Chang, Martin Strobel, and Reza Shokri. On the impact of machine learning\\nrandomnessongroupfairness. In Proceedingsofthe2023ACMConferenceonFairness,Accountability,and\\nTransparency , pages 1789–1800, 2023.\\nDeep Ganguli, Liane Lovitt, Jackson Kernion, Amanda Askell, Yuntao Bai, Saurav Kadavath, Ben Mann,\\nEthan Perez, Nicholas Schiefer, Kamal Ndousse, et al. Red teaming language models to reduce harms:\\nMethods, scaling behaviors, and lessons learned. arXiv preprint arXiv:2209.07858 , 2022.\\n39\\n\\nDeepGanguli,AmandaAskell,NicholasSchiefer,ThomasLiao,Kamil ˙eLukoši ¯ut˙e,AnnaChen,AnnaGoldie,\\nAzaliaMirhoseini,CatherineOlsson,DannyHernandez,etal. Thecapacityformoralself-correctionin\\nlarge language models. arXiv preprint arXiv:2302.07459 , 2023.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-39'),\n",
              " 'b9761739-6146-411d-a5a4-411461519e8a': IndexNode(id_='b9761739-6146-411d-a5a4-411461519e8a', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-39', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='b293f131ac43be9c94605b5f94094f5373338d4dc1ee92d740def5bc907b981a'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='6f84d7df-0d95-462b-9b0d-8d218f4f2e6c', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='522d8fd4dda119b6f4084a45948b7285d988d85b5b77c39fcf030ea343ae75a6')}, hash='9b9c349b351c7dd77442d8b959d9699dc409e5cca79d756dead6a5b01add732f', text='arXiv preprint arXiv:2302.07459 , 2023.\\nLeoGao,JonathanTow,StellaBiderman,SidBlack,AnthonyDiPofi,CharlesFoster,LaurenceGolding,Jeffrey\\nHsu, Kyle McDonell, Niklas Muennighoff, Jason Phang, Laria Reynolds, Eric Tang, Anish Thite, Ben Wang,\\nKevin Wang, and Andy Zou.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-39'),\n",
              " 'node-39': IndexNode(id_='node-39', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='415b7efc-e73f-4ac4-bbfd-c1546f099026', node_type=<ObjectType.DOCUMENT: '4'>, metadata={}, hash='231b3bd773f012c01b893ada9e009ecf25ee59934614c5a595c9bf1b3a123292'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='d62815b2-9819-4933-88b8-4f1ec146bd33', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='8fc645f8314bf3b4190ff3ed466011d007294292af3e921655a6b74f2f2b1f7a'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='5233fe08-5b3c-466d-ac96-00b64228d0bb', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='735e4de1b62bce44b196855be30610425bc2c53b01d9059f2fb43d352b941d26')}, hash='b293f131ac43be9c94605b5f94094f5373338d4dc1ee92d740def5bc907b981a', text='arXivpreprint\\narXiv:2107.03451 , 2021.\\nJesse Dodge, Maarten Sap, Ana Marasović, William Agnew, Gabriel Ilharco, Dirk Groeneveld, Margaret\\nMitchell,andMattGardner.Documentinglargewebtextcorpora: Acasestudyonthecolossalcleancrawled\\ncorpus. In Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing , pages\\n1286–1305, Online and Punta Cana, Dominican Republic, November 2021. Association for Computational\\nLinguistics. doi: 10.18653/v1/2021.emnlp-main.98. URL https://aclanthology.org/2021.emnlp-main.\\n98.\\nJesseDodge,TaylorPrewitt,RemiTachetDesCombes,ErikaOdmark,RoySchwartz,EmmaStrubell,Alexan-\\ndra Sasha Luccioni, Noah A Smith, Nicole DeCario, and Will Buchanan. Measuring the carbon intensity of\\nai in cloud instances. arXiv preprint arXiv:2206.05229 , 2022.\\nNanDu,YanpingHuang,AndrewMDai,SimonTong,DmitryLepikhin,YuanzhongXu,MaximKrikun,\\nYanqi Zhou, Adams Wei Yu, Orhan Firat, Barret Zoph, Liam Fedus, Maarten P Bosma, Zongwei Zhou, Tao\\nWang, EmmaWang,KellieWebster, MariePellat, KevinRobinson,Kathleen Meier-Hellstern,TojuDuke,\\nLucasDixon,KunZhang,QuocLe,YonghuiWu,ZhifengChen,andClaireCui. GLaM:Efficientscaling\\noflanguagemodelswithmixture-of-experts. InKamalikaChaudhuri,StefanieJegelka,LeSong,Csaba\\nSzepesvari, Gang Niu, and Sivan Sabato, editors, Proceedings of the 39th International Conference on Machine\\nLearning,volume162of ProceedingsofMachineLearningResearch ,pages5547–5569.PMLR,17–23Jul2022.\\nURL https://proceedings.mlr.press/v162/du22c.html .\\nKawinEthayarajh,YejinChoi,andSwabhaSwayamdipta. Understandingdatasetdifficultywith V-usable\\ninformation. InKamalikaChaudhuri,StefanieJegelka,LeSong,CsabaSzepesvari,GangNiu,andSivan\\nSabato,editors, Proceedingsofthe39thInternationalConferenceonMachineLearning ,volume162of Proceedings\\nof Machine Learning Research , pages 5988–6008. PMLR, 17–23 Jul 2022.\\nPrakhar Ganesh, Hongyan Chang, Martin Strobel, and Reza Shokri. On the impact of machine learning\\nrandomnessongroupfairness. In Proceedingsofthe2023ACMConferenceonFairness,Accountability,and\\nTransparency , pages 1789–1800, 2023.\\nDeep Ganguli, Liane Lovitt, Jackson Kernion, Amanda Askell, Yuntao Bai, Saurav Kadavath, Ben Mann,\\nEthan Perez, Nicholas Schiefer, Kamal Ndousse, et al. Red teaming language models to reduce harms:\\nMethods, scaling behaviors, and lessons learned. arXiv preprint arXiv:2209.07858 , 2022.\\n39\\n\\nDeepGanguli,AmandaAskell,NicholasSchiefer,ThomasLiao,Kamil ˙eLukoši ¯ut˙e,AnnaChen,AnnaGoldie,\\nAzaliaMirhoseini,CatherineOlsson,DannyHernandez,etal. Thecapacityformoralself-correctionin\\nlarge language models. arXiv preprint arXiv:2302.07459 , 2023.\\nLeoGao,JonathanTow,StellaBiderman,SidBlack,AnthonyDiPofi,CharlesFoster,LaurenceGolding,Jeffrey\\nHsu, Kyle McDonell, Niklas Muennighoff, Jason Phang, Laria Reynolds, Eric Tang, Anish Thite, Ben Wang,\\nKevin Wang, and Andy Zou.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-39'),\n",
              " '568ce948-d8db-4eee-bbd7-b898b75b3ae0': IndexNode(id_='568ce948-d8db-4eee-bbd7-b898b75b3ae0', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-40', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='735e4de1b62bce44b196855be30610425bc2c53b01d9059f2fb43d352b941d26'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='bef1935c-aee6-4b35-ba82-7b3941fe93f4', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='6bf43cd66527b8c8740920f04c13a7cda90dda5d795a1d88188c0ee7a8fb4021')}, hash='6806029aee6b94a79c8fbc7729681d06578fbbb36bd8eca3393792f9129a3e07', text='A framework for few-shot language model evaluation, September 2021. URL\\nhttps://doi.org/10.5281/zenodo.5371628 .\\nSebastian Gehrmann, Elizabeth Clark, and Thibault Sellam. Repairing the cracked foundation: A survey\\nofobstaclesin evaluationpracticesfor generatedtext. JournalofArtificial IntelligenceResearch ,77:103–166,\\n2023.\\nFabrizioGilardi,MeysamAlizadeh,andMaëlKubli.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-40'),\n",
              " 'bef1935c-aee6-4b35-ba82-7b3941fe93f4': IndexNode(id_='bef1935c-aee6-4b35-ba82-7b3941fe93f4', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-40', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='735e4de1b62bce44b196855be30610425bc2c53b01d9059f2fb43d352b941d26'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='568ce948-d8db-4eee-bbd7-b898b75b3ae0', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='6806029aee6b94a79c8fbc7729681d06578fbbb36bd8eca3393792f9129a3e07'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='af12d733-e5d1-4654-a856-33b21c5d8a2c', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='8fce6d237250591f3a3bd6b30e082d5d8ea32c1428160e92650a9a50490b48ec')}, hash='6bf43cd66527b8c8740920f04c13a7cda90dda5d795a1d88188c0ee7a8fb4021', text='Chatgptoutperformscrowd-workersfortext-annotation\\ntasks.arXiv preprint arXiv:2303.15056 , 2023.\\nArnavGudibande,EricWallace,CharlieSnell,XinyangGeng,HaoLiu,PieterAbbeel,SergeyLevine,and\\nDawn Song. The false promise of imitating proprietary llms. arXiv preprint arXiv:2305.15717 , 2023.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-40'),\n",
              " 'af12d733-e5d1-4654-a856-33b21c5d8a2c': IndexNode(id_='af12d733-e5d1-4654-a856-33b21c5d8a2c', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-40', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='735e4de1b62bce44b196855be30610425bc2c53b01d9059f2fb43d352b941d26'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='bef1935c-aee6-4b35-ba82-7b3941fe93f4', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='6bf43cd66527b8c8740920f04c13a7cda90dda5d795a1d88188c0ee7a8fb4021'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='bf52e3cd-a17d-4dcd-a063-06207dd9f106', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='5faf5229ec24f6d47f56423f898723b29aa398084799d998e8c0b4dde5022024')}, hash='8fce6d237250591f3a3bd6b30e082d5d8ea32c1428160e92650a9a50490b48ec', text='arXiv preprint arXiv:2305.15717 , 2023.\\nUditGupta,MariamElgamal,GageHills,Gu-YeonWei,Hsien-HsinSLee,DavidBrooks,andCarole-JeanWu.\\nAct: designing sustainable computer systems with an architectural carbon modeling tool. In Proceedings of\\nthe 49th Annual International Symposium on Computer Architecture , pages 784–799, 2022a.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-40'),\n",
              " 'bf52e3cd-a17d-4dcd-a063-06207dd9f106': IndexNode(id_='bf52e3cd-a17d-4dcd-a063-06207dd9f106', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-40', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='735e4de1b62bce44b196855be30610425bc2c53b01d9059f2fb43d352b941d26'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='af12d733-e5d1-4654-a856-33b21c5d8a2c', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='8fce6d237250591f3a3bd6b30e082d5d8ea32c1428160e92650a9a50490b48ec'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='2e13c46e-ae7f-4560-9499-d5bcb03e6dad', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='9fab8d21937f473330b94f3a04e26ba4946c11b05f356a7076e252d8d2b75523')}, hash='5faf5229ec24f6d47f56423f898723b29aa398084799d998e8c0b4dde5022024', text='UditGupta,YoungGuenKim,SylviaLee,JordanTse,Hsien-HsinSeanLee,Gu-YeonWei,DavidBrooks,and\\nCarole-Jean Wu. Chasing carbon: The elusive environmental footprint of computing. IEEE Micro , 2022b.\\nKilem L. Gwet. Handbook of inter-rater reliability: The definitive guide to measuring the extent of agreement among\\nraters. Advanced Analytics, LLC, 2014.\\nKilem Li Gwet.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-40'),\n",
              " '2e13c46e-ae7f-4560-9499-d5bcb03e6dad': IndexNode(id_='2e13c46e-ae7f-4560-9499-d5bcb03e6dad', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-40', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='735e4de1b62bce44b196855be30610425bc2c53b01d9059f2fb43d352b941d26'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='bf52e3cd-a17d-4dcd-a063-06207dd9f106', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='5faf5229ec24f6d47f56423f898723b29aa398084799d998e8c0b4dde5022024'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='34fee688-40cb-4f8e-9724-ddf21fce1501', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='1587312eb713a752bf6c6381462653610a4550533908f5eb879f6b9bd6f3a819')}, hash='9fab8d21937f473330b94f3a04e26ba4946c11b05f356a7076e252d8d2b75523', text='Advanced Analytics, LLC, 2014.\\nKilem Li Gwet. Computing inter-rater reliability and its variance in the presence of high agreement. British\\nJournal of Mathematical and Statistical Psychology , 61(1):29–48, 2008.\\nThomasHartvigsen,SaadiaGabriel,HamidPalangi,MaartenSap,DipankarRay,andEceKamar. Toxigen: A\\nlarge-scalemachine-generateddatasetforadversarialandimplicithatespeechdetection.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-40'),\n",
              " '34fee688-40cb-4f8e-9724-ddf21fce1501': IndexNode(id_='34fee688-40cb-4f8e-9724-ddf21fce1501', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-40', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='735e4de1b62bce44b196855be30610425bc2c53b01d9059f2fb43d352b941d26'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='2e13c46e-ae7f-4560-9499-d5bcb03e6dad', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='9fab8d21937f473330b94f3a04e26ba4946c11b05f356a7076e252d8d2b75523'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='5e7d41ac-ddf4-4bb2-84a3-0fe1dc3872d4', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='90c63f4f39e629ccdd6e799405b1e1911da9c17d86b2ba652ff7e154b50e8c07')}, hash='1587312eb713a752bf6c6381462653610a4550533908f5eb879f6b9bd6f3a819', text='In Proceedings\\nof the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers) , pages\\n3309–3326, 2022.\\nAlex Havrilla. synthetic-instruct-gptj-pairwise. https://huggingface.co/datasets/Dahoas/\\nsynthetic-instruct-gptj-pairwise .\\nPengcheng He, Xiaodong Liu, Jianfeng Gao, and Weizhu Chen.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-40'),\n",
              " '5e7d41ac-ddf4-4bb2-84a3-0fe1dc3872d4': IndexNode(id_='5e7d41ac-ddf4-4bb2-84a3-0fe1dc3872d4', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-40', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='735e4de1b62bce44b196855be30610425bc2c53b01d9059f2fb43d352b941d26'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='34fee688-40cb-4f8e-9724-ddf21fce1501', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='1587312eb713a752bf6c6381462653610a4550533908f5eb879f6b9bd6f3a819'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='7b307e8d-5896-4440-b2e3-e6f22aad5de6', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='5fbcb20183f734018f8077228dee5864b95013f269c24fb35ba5c9e3a9c34dc5')}, hash='90c63f4f39e629ccdd6e799405b1e1911da9c17d86b2ba652ff7e154b50e8c07', text='Deberta: Decoding-enhanced bert with\\ndisentangled attention. arXiv preprint arXiv:2006.03654 , 2020.\\nDan Hendrycks, Collin Burns, Steven Basart, Andy Zou, Mantas Mazeika, Dawn Xiaodong Song, and Jacob\\nSteinhardt. Measuring massive multitask language understanding. arXiv preprint arXiv:2009.03300 , 2020.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-40'),\n",
              " '7b307e8d-5896-4440-b2e3-e6f22aad5de6': IndexNode(id_='7b307e8d-5896-4440-b2e3-e6f22aad5de6', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-40', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='735e4de1b62bce44b196855be30610425bc2c53b01d9059f2fb43d352b941d26'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='5e7d41ac-ddf4-4bb2-84a3-0fe1dc3872d4', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='90c63f4f39e629ccdd6e799405b1e1911da9c17d86b2ba652ff7e154b50e8c07'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='a0f48a57-a5f6-4355-92fe-3912dea40366', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='0f0024bc93d050bc4629fd125719784235715d81ccc6324c50729c9c8439ef93')}, hash='5fbcb20183f734018f8077228dee5864b95013f269c24fb35ba5c9e3a9c34dc5', text='arXiv preprint arXiv:2009.03300 , 2020.\\nDanHendrycks,CollinBurns,SauravKadavath,AkulArora,StevenBasart,EricTang,DawnSong,andJacob\\nSteinhardt.Measuringmathematicalproblemsolvingwiththemathdataset. arXivpreprintarXiv:2103.03874 ,\\n2021.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-40'),\n",
              " 'a0f48a57-a5f6-4355-92fe-3912dea40366': IndexNode(id_='a0f48a57-a5f6-4355-92fe-3912dea40366', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-40', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='735e4de1b62bce44b196855be30610425bc2c53b01d9059f2fb43d352b941d26'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='7b307e8d-5896-4440-b2e3-e6f22aad5de6', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='5fbcb20183f734018f8077228dee5864b95013f269c24fb35ba5c9e3a9c34dc5'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='0a25c5b2-8a35-4202-8fd1-438d04935211', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='cd22fd5360a33b68c5af034f49a3cc15a65b393bbfdd970e3cda2dbc22fd09d9')}, hash='0f0024bc93d050bc4629fd125719784235715d81ccc6324c50729c9c8439ef93', text='JordanHoffmann,SebastianBorgeaud,ArthurMensch,ElenaBuchatskaya, TrevorCai, ElizaRutherford,\\nDiego de Las Casas, Lisa Anne Hendricks, Johannes Welbl, Aidan Clark, et al. Training compute-optimal\\nlarge language models. arXiv preprint arXiv:2203.15556 , 2022.\\nAriHoltzman,JanBuys,LiDu,MaxwellForbes,andYejinChoi. Thecuriouscaseofneuraltextdegeneration.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-40'),\n",
              " '0a25c5b2-8a35-4202-8fd1-438d04935211': IndexNode(id_='0a25c5b2-8a35-4202-8fd1-438d04935211', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-40', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='735e4de1b62bce44b196855be30610425bc2c53b01d9059f2fb43d352b941d26'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='a0f48a57-a5f6-4355-92fe-3912dea40366', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='0f0024bc93d050bc4629fd125719784235715d81ccc6324c50729c9c8439ef93')}, hash='cd22fd5360a33b68c5af034f49a3cc15a65b393bbfdd970e3cda2dbc22fd09d9', text='Thecuriouscaseofneuraltextdegeneration.\\nInInternational Conference on Learning Representations , 2020. URL https://openreview.net/forum?id=\\nrygGQyrFvH .\\nOr Honovich, Thomas Scialom, Omer Levy, and Timo Schick.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-40'),\n",
              " 'ff021ad0-f645-470c-905a-5bc49e8f05bf': IndexNode(id_='ff021ad0-f645-470c-905a-5bc49e8f05bf', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-40', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='735e4de1b62bce44b196855be30610425bc2c53b01d9059f2fb43d352b941d26'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='f0b32b1f-b9bf-48dd-87eb-d31422af5131', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='c2e1fdf9c07398fcc99056f8a3de8428ccc34ec156387ad4504d1057924c7904')}, hash='d63d85f92979cfc3bd52fb3d3a2bbbcf99181e54cf4503617bc576ad5ca009b0', text='A framework for few-shot language model evaluation, September 2021. URL\\nhttps://doi.org/10.5281/zenodo.5371628 .\\nSebastian Gehrmann, Elizabeth Clark, and Thibault Sellam. Repairing the cracked foundation: A survey\\nofobstaclesin evaluationpracticesfor generatedtext. JournalofArtificial IntelligenceResearch ,77:103–166,\\n2023.\\nFabrizioGilardi,MeysamAlizadeh,andMaëlKubli. Chatgptoutperformscrowd-workersfortext-annotation\\ntasks.arXiv preprint arXiv:2303.15056 , 2023.\\nArnavGudibande,EricWallace,CharlieSnell,XinyangGeng,HaoLiu,PieterAbbeel,SergeyLevine,and\\nDawn Song. The false promise of imitating proprietary llms. arXiv preprint arXiv:2305.15717 , 2023.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-40'),\n",
              " 'f0b32b1f-b9bf-48dd-87eb-d31422af5131': IndexNode(id_='f0b32b1f-b9bf-48dd-87eb-d31422af5131', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-40', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='735e4de1b62bce44b196855be30610425bc2c53b01d9059f2fb43d352b941d26'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='ff021ad0-f645-470c-905a-5bc49e8f05bf', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='d63d85f92979cfc3bd52fb3d3a2bbbcf99181e54cf4503617bc576ad5ca009b0'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='af2b2c8f-cc3c-4fbf-a990-197b613a6f63', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='a9484bfafbf278620e7bd6a2e0daa8e648afe24933ac51d7cd7527c65e9dc77f')}, hash='c2e1fdf9c07398fcc99056f8a3de8428ccc34ec156387ad4504d1057924c7904', text='arXiv preprint arXiv:2305.15717 , 2023.\\nUditGupta,MariamElgamal,GageHills,Gu-YeonWei,Hsien-HsinSLee,DavidBrooks,andCarole-JeanWu.\\nAct: designing sustainable computer systems with an architectural carbon modeling tool. In Proceedings of\\nthe 49th Annual International Symposium on Computer Architecture , pages 784–799, 2022a.\\nUditGupta,YoungGuenKim,SylviaLee,JordanTse,Hsien-HsinSeanLee,Gu-YeonWei,DavidBrooks,and\\nCarole-Jean Wu. Chasing carbon: The elusive environmental footprint of computing. IEEE Micro , 2022b.\\nKilem L. Gwet. Handbook of inter-rater reliability: The definitive guide to measuring the extent of agreement among\\nraters. Advanced Analytics, LLC, 2014.\\nKilem Li Gwet. Computing inter-rater reliability and its variance in the presence of high agreement.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-40'),\n",
              " 'af2b2c8f-cc3c-4fbf-a990-197b613a6f63': IndexNode(id_='af2b2c8f-cc3c-4fbf-a990-197b613a6f63', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-40', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='735e4de1b62bce44b196855be30610425bc2c53b01d9059f2fb43d352b941d26'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='f0b32b1f-b9bf-48dd-87eb-d31422af5131', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='c2e1fdf9c07398fcc99056f8a3de8428ccc34ec156387ad4504d1057924c7904'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='e9c16105-5697-4067-bb97-89f9d0a8d4d8', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='71c3194ec70a7db1544cf698b803fc857b53636af81a66e56d4389001f7047f7')}, hash='a9484bfafbf278620e7bd6a2e0daa8e648afe24933ac51d7cd7527c65e9dc77f', text='Computing inter-rater reliability and its variance in the presence of high agreement. British\\nJournal of Mathematical and Statistical Psychology , 61(1):29–48, 2008.\\nThomasHartvigsen,SaadiaGabriel,HamidPalangi,MaartenSap,DipankarRay,andEceKamar. Toxigen: A\\nlarge-scalemachine-generateddatasetforadversarialandimplicithatespeechdetection. In Proceedings\\nof the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers) , pages\\n3309–3326, 2022.\\nAlex Havrilla. synthetic-instruct-gptj-pairwise. https://huggingface.co/datasets/Dahoas/\\nsynthetic-instruct-gptj-pairwise .\\nPengcheng He, Xiaodong Liu, Jianfeng Gao, and Weizhu Chen. Deberta: Decoding-enhanced bert with\\ndisentangled attention.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-40'),\n",
              " 'e9c16105-5697-4067-bb97-89f9d0a8d4d8': IndexNode(id_='e9c16105-5697-4067-bb97-89f9d0a8d4d8', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-40', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='735e4de1b62bce44b196855be30610425bc2c53b01d9059f2fb43d352b941d26'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='af2b2c8f-cc3c-4fbf-a990-197b613a6f63', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='a9484bfafbf278620e7bd6a2e0daa8e648afe24933ac51d7cd7527c65e9dc77f'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='410420a6-b307-4cfa-9bab-d813808b391e', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='a50ba7230093e7d0edad40fa75afdf0f4eb021a3903c5c1ae425e73aa2917e3b')}, hash='71c3194ec70a7db1544cf698b803fc857b53636af81a66e56d4389001f7047f7', text='Deberta: Decoding-enhanced bert with\\ndisentangled attention. arXiv preprint arXiv:2006.03654 , 2020.\\nDan Hendrycks, Collin Burns, Steven Basart, Andy Zou, Mantas Mazeika, Dawn Xiaodong Song, and Jacob\\nSteinhardt. Measuring massive multitask language understanding. arXiv preprint arXiv:2009.03300 , 2020.\\nDanHendrycks,CollinBurns,SauravKadavath,AkulArora,StevenBasart,EricTang,DawnSong,andJacob\\nSteinhardt.Measuringmathematicalproblemsolvingwiththemathdataset. arXivpreprintarXiv:2103.03874 ,\\n2021.\\nJordanHoffmann,SebastianBorgeaud,ArthurMensch,ElenaBuchatskaya, TrevorCai, ElizaRutherford,\\nDiego de Las Casas, Lisa Anne Hendricks, Johannes Welbl, Aidan Clark, et al. Training compute-optimal\\nlarge language models.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-40'),\n",
              " '410420a6-b307-4cfa-9bab-d813808b391e': IndexNode(id_='410420a6-b307-4cfa-9bab-d813808b391e', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-40', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='735e4de1b62bce44b196855be30610425bc2c53b01d9059f2fb43d352b941d26'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='e9c16105-5697-4067-bb97-89f9d0a8d4d8', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='71c3194ec70a7db1544cf698b803fc857b53636af81a66e56d4389001f7047f7')}, hash='a50ba7230093e7d0edad40fa75afdf0f4eb021a3903c5c1ae425e73aa2917e3b', text='Training compute-optimal\\nlarge language models. arXiv preprint arXiv:2203.15556 , 2022.\\nAriHoltzman,JanBuys,LiDu,MaxwellForbes,andYejinChoi. Thecuriouscaseofneuraltextdegeneration.\\nInInternational Conference on Learning Representations , 2020. URL https://openreview.net/forum?id=\\nrygGQyrFvH .\\nOr Honovich, Thomas Scialom, Omer Levy, and Timo Schick.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-40'),\n",
              " 'fbb15f7f-e3fc-494d-82d4-652a954f01a0': IndexNode(id_='fbb15f7f-e3fc-494d-82d4-652a954f01a0', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-40', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='735e4de1b62bce44b196855be30610425bc2c53b01d9059f2fb43d352b941d26'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='b7cc1089-11d7-49b2-b024-4a225fd42e28', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='6a3916c2f78e94c59207ea824b96a3fa1d7a9df884525da7456802e8c650fd1b')}, hash='9e02c7889059a445d629a4cb1948849e29da7803946634dbc02fdd50fc48715d', text='A framework for few-shot language model evaluation, September 2021. URL\\nhttps://doi.org/10.5281/zenodo.5371628 .\\nSebastian Gehrmann, Elizabeth Clark, and Thibault Sellam. Repairing the cracked foundation: A survey\\nofobstaclesin evaluationpracticesfor generatedtext. JournalofArtificial IntelligenceResearch ,77:103–166,\\n2023.\\nFabrizioGilardi,MeysamAlizadeh,andMaëlKubli. Chatgptoutperformscrowd-workersfortext-annotation\\ntasks.arXiv preprint arXiv:2303.15056 , 2023.\\nArnavGudibande,EricWallace,CharlieSnell,XinyangGeng,HaoLiu,PieterAbbeel,SergeyLevine,and\\nDawn Song. The false promise of imitating proprietary llms. arXiv preprint arXiv:2305.15717 , 2023.\\nUditGupta,MariamElgamal,GageHills,Gu-YeonWei,Hsien-HsinSLee,DavidBrooks,andCarole-JeanWu.\\nAct: designing sustainable computer systems with an architectural carbon modeling tool. In Proceedings of\\nthe 49th Annual International Symposium on Computer Architecture , pages 784–799, 2022a.\\nUditGupta,YoungGuenKim,SylviaLee,JordanTse,Hsien-HsinSeanLee,Gu-YeonWei,DavidBrooks,and\\nCarole-Jean Wu. Chasing carbon: The elusive environmental footprint of computing. IEEE Micro , 2022b.\\nKilem L. Gwet. Handbook of inter-rater reliability: The definitive guide to measuring the extent of agreement among\\nraters. Advanced Analytics, LLC, 2014.\\nKilem Li Gwet. Computing inter-rater reliability and its variance in the presence of high agreement. British\\nJournal of Mathematical and Statistical Psychology , 61(1):29–48, 2008.\\nThomasHartvigsen,SaadiaGabriel,HamidPalangi,MaartenSap,DipankarRay,andEceKamar.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-40'),\n",
              " 'b7cc1089-11d7-49b2-b024-4a225fd42e28': IndexNode(id_='b7cc1089-11d7-49b2-b024-4a225fd42e28', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-40', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='735e4de1b62bce44b196855be30610425bc2c53b01d9059f2fb43d352b941d26'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='fbb15f7f-e3fc-494d-82d4-652a954f01a0', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='9e02c7889059a445d629a4cb1948849e29da7803946634dbc02fdd50fc48715d')}, hash='6a3916c2f78e94c59207ea824b96a3fa1d7a9df884525da7456802e8c650fd1b', text='Toxigen: A\\nlarge-scalemachine-generateddatasetforadversarialandimplicithatespeechdetection. In Proceedings\\nof the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers) , pages\\n3309–3326, 2022.\\nAlex Havrilla. synthetic-instruct-gptj-pairwise. https://huggingface.co/datasets/Dahoas/\\nsynthetic-instruct-gptj-pairwise .\\nPengcheng He, Xiaodong Liu, Jianfeng Gao, and Weizhu Chen. Deberta: Decoding-enhanced bert with\\ndisentangled attention. arXiv preprint arXiv:2006.03654 , 2020.\\nDan Hendrycks, Collin Burns, Steven Basart, Andy Zou, Mantas Mazeika, Dawn Xiaodong Song, and Jacob\\nSteinhardt. Measuring massive multitask language understanding. arXiv preprint arXiv:2009.03300 , 2020.\\nDanHendrycks,CollinBurns,SauravKadavath,AkulArora,StevenBasart,EricTang,DawnSong,andJacob\\nSteinhardt.Measuringmathematicalproblemsolvingwiththemathdataset. arXivpreprintarXiv:2103.03874 ,\\n2021.\\nJordanHoffmann,SebastianBorgeaud,ArthurMensch,ElenaBuchatskaya, TrevorCai, ElizaRutherford,\\nDiego de Las Casas, Lisa Anne Hendricks, Johannes Welbl, Aidan Clark, et al. Training compute-optimal\\nlarge language models. arXiv preprint arXiv:2203.15556 , 2022.\\nAriHoltzman,JanBuys,LiDu,MaxwellForbes,andYejinChoi. Thecuriouscaseofneuraltextdegeneration.\\nInInternational Conference on Learning Representations , 2020. URL https://openreview.net/forum?id=\\nrygGQyrFvH .\\nOr Honovich, Thomas Scialom, Omer Levy, and Timo Schick.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-40'),\n",
              " 'node-40': IndexNode(id_='node-40', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='415b7efc-e73f-4ac4-bbfd-c1546f099026', node_type=<ObjectType.DOCUMENT: '4'>, metadata={}, hash='231b3bd773f012c01b893ada9e009ecf25ee59934614c5a595c9bf1b3a123292'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='d2255d6f-c185-41b0-b0b7-0cfbccf0c46c', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='b293f131ac43be9c94605b5f94094f5373338d4dc1ee92d740def5bc907b981a'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='1c240945-6d85-448d-a108-bd2f62ee0f46', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='8944b2b1a73036fb3525acc9f234407e65fa12cacf2e46c9fd1146551f062361')}, hash='735e4de1b62bce44b196855be30610425bc2c53b01d9059f2fb43d352b941d26', text='A framework for few-shot language model evaluation, September 2021. URL\\nhttps://doi.org/10.5281/zenodo.5371628 .\\nSebastian Gehrmann, Elizabeth Clark, and Thibault Sellam. Repairing the cracked foundation: A survey\\nofobstaclesin evaluationpracticesfor generatedtext. JournalofArtificial IntelligenceResearch ,77:103–166,\\n2023.\\nFabrizioGilardi,MeysamAlizadeh,andMaëlKubli. Chatgptoutperformscrowd-workersfortext-annotation\\ntasks.arXiv preprint arXiv:2303.15056 , 2023.\\nArnavGudibande,EricWallace,CharlieSnell,XinyangGeng,HaoLiu,PieterAbbeel,SergeyLevine,and\\nDawn Song. The false promise of imitating proprietary llms. arXiv preprint arXiv:2305.15717 , 2023.\\nUditGupta,MariamElgamal,GageHills,Gu-YeonWei,Hsien-HsinSLee,DavidBrooks,andCarole-JeanWu.\\nAct: designing sustainable computer systems with an architectural carbon modeling tool. In Proceedings of\\nthe 49th Annual International Symposium on Computer Architecture , pages 784–799, 2022a.\\nUditGupta,YoungGuenKim,SylviaLee,JordanTse,Hsien-HsinSeanLee,Gu-YeonWei,DavidBrooks,and\\nCarole-Jean Wu. Chasing carbon: The elusive environmental footprint of computing. IEEE Micro , 2022b.\\nKilem L. Gwet. Handbook of inter-rater reliability: The definitive guide to measuring the extent of agreement among\\nraters. Advanced Analytics, LLC, 2014.\\nKilem Li Gwet. Computing inter-rater reliability and its variance in the presence of high agreement. British\\nJournal of Mathematical and Statistical Psychology , 61(1):29–48, 2008.\\nThomasHartvigsen,SaadiaGabriel,HamidPalangi,MaartenSap,DipankarRay,andEceKamar. Toxigen: A\\nlarge-scalemachine-generateddatasetforadversarialandimplicithatespeechdetection. In Proceedings\\nof the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers) , pages\\n3309–3326, 2022.\\nAlex Havrilla. synthetic-instruct-gptj-pairwise. https://huggingface.co/datasets/Dahoas/\\nsynthetic-instruct-gptj-pairwise .\\nPengcheng He, Xiaodong Liu, Jianfeng Gao, and Weizhu Chen. Deberta: Decoding-enhanced bert with\\ndisentangled attention. arXiv preprint arXiv:2006.03654 , 2020.\\nDan Hendrycks, Collin Burns, Steven Basart, Andy Zou, Mantas Mazeika, Dawn Xiaodong Song, and Jacob\\nSteinhardt. Measuring massive multitask language understanding. arXiv preprint arXiv:2009.03300 , 2020.\\nDanHendrycks,CollinBurns,SauravKadavath,AkulArora,StevenBasart,EricTang,DawnSong,andJacob\\nSteinhardt.Measuringmathematicalproblemsolvingwiththemathdataset. arXivpreprintarXiv:2103.03874 ,\\n2021.\\nJordanHoffmann,SebastianBorgeaud,ArthurMensch,ElenaBuchatskaya, TrevorCai, ElizaRutherford,\\nDiego de Las Casas, Lisa Anne Hendricks, Johannes Welbl, Aidan Clark, et al. Training compute-optimal\\nlarge language models. arXiv preprint arXiv:2203.15556 , 2022.\\nAriHoltzman,JanBuys,LiDu,MaxwellForbes,andYejinChoi. Thecuriouscaseofneuraltextdegeneration.\\nInInternational Conference on Learning Representations , 2020. URL https://openreview.net/forum?id=\\nrygGQyrFvH .\\nOr Honovich, Thomas Scialom, Omer Levy, and Timo Schick.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-40'),\n",
              " 'e5f87082-9f04-4fae-a465-9a38b3234c26': IndexNode(id_='e5f87082-9f04-4fae-a465-9a38b3234c26', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-41', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='8944b2b1a73036fb3525acc9f234407e65fa12cacf2e46c9fd1146551f062361'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='4ec59a7d-c7e4-40a2-9203-bbab77f8591c', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='b0f86ff36c4665bd582b68ca241acaa08286bcecc9cac55922844d6bf8d5cab4')}, hash='877ade622d88d3c17008fa7a8fecc57c65241fcb373131ffdd2db07bbb8587da', text='Or Honovich, Thomas Scialom, Omer Levy, and Timo Schick. Unnatural instructions: Tuning language\\nmodels with (almost) no human labor. arXiv preprint arXiv:2212.09689 , 2022.\\nSaghar Hosseini, Hamid Palangi, and Ahmed Hassan Awadallah. An empirical study of metrics to measure\\nrepresentational harms in pre-trained language models. arXiv preprint arXiv:2301.09211 , 2023.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-41'),\n",
              " '4ec59a7d-c7e4-40a2-9203-bbab77f8591c': IndexNode(id_='4ec59a7d-c7e4-40a2-9203-bbab77f8591c', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-41', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='8944b2b1a73036fb3525acc9f234407e65fa12cacf2e46c9fd1146551f062361'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='e5f87082-9f04-4fae-a465-9a38b3234c26', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='877ade622d88d3c17008fa7a8fecc57c65241fcb373131ffdd2db07bbb8587da'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='52112024-d416-4eb7-bc86-71040b855bb2', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='bf5200ef46e0f6cc01d65379229acf7e0bbc8637f94defa7fc105a9882641ecd')}, hash='b0f86ff36c4665bd582b68ca241acaa08286bcecc9cac55922844d6bf8d5cab4', text='arXiv preprint arXiv:2301.09211 , 2023.\\nFanHuang,HaewoonKwak,andJisunAn. Ischatgptbetterthanhumanannotators? potentialandlimitations\\nof chatgpt in explaining implicit hate speech. arXiv preprint arXiv:2302.07736 , 2023.\\nClaytonHuttoandEricGilbert. Vader: Aparsimoniousrule-basedmodelforsentimentanalysisofsocial\\nmedia text.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-41'),\n",
              " '52112024-d416-4eb7-bc86-71040b855bb2': IndexNode(id_='52112024-d416-4eb7-bc86-71040b855bb2', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-41', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='8944b2b1a73036fb3525acc9f234407e65fa12cacf2e46c9fd1146551f062361'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='4ec59a7d-c7e4-40a2-9203-bbab77f8591c', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='b0f86ff36c4665bd582b68ca241acaa08286bcecc9cac55922844d6bf8d5cab4'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='a76cf2ed-1348-4b18-b140-ee1d25bbbe15', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='7eede249b762cd4a27edbdeb6bf26bbe65150c765e6d867e3d65072587b29375')}, hash='bf5200ef46e0f6cc01d65379229acf7e0bbc8637f94defa7fc105a9882641ecd', text='In Proceedings of the international AAAI conference on web and social media , volume 8, pages\\n216–225, 2014.\\nMandarJoshi,EunsolChoi,DanielSWeld,andLukeZettlemoyer. Triviaqa: Alargescaledistantlysupervised\\nchallenge dataset for reading comprehension. arXiv preprint arXiv:1705.03551 , 2017.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-41'),\n",
              " 'a76cf2ed-1348-4b18-b140-ee1d25bbbe15': IndexNode(id_='a76cf2ed-1348-4b18-b140-ee1d25bbbe15', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-41', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='8944b2b1a73036fb3525acc9f234407e65fa12cacf2e46c9fd1146551f062361'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='52112024-d416-4eb7-bc86-71040b855bb2', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='bf5200ef46e0f6cc01d65379229acf7e0bbc8637f94defa7fc105a9882641ecd'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='8f98d41d-2133-44de-82f5-0babc5330e85', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='9a6b372fa8a47143716cd660ee03e8a6a12caa7b196bfac1dccb719e6b1d9168')}, hash='7eede249b762cd4a27edbdeb6bf26bbe65150c765e6d867e3d65072587b29375', text='arXiv preprint arXiv:1705.03551 , 2017.\\n40\\n\\nJaredKaplan,SamMcCandlish,TomHenighan,TomBBrown,BenjaminChess,RewonChild,ScottGray,\\nAlec Radford, Jeffrey Wu, and Dario Amodei. Scaling laws for neural language models. arXiv preprint\\narXiv:2001.08361 , 2020.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-41'),\n",
              " '8f98d41d-2133-44de-82f5-0babc5330e85': IndexNode(id_='8f98d41d-2133-44de-82f5-0babc5330e85', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-41', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='8944b2b1a73036fb3525acc9f234407e65fa12cacf2e46c9fd1146551f062361'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='a76cf2ed-1348-4b18-b140-ee1d25bbbe15', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='7eede249b762cd4a27edbdeb6bf26bbe65150c765e6d867e3d65072587b29375'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='0fc4aee4-746a-4826-9511-af11d5dcd3b3', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='227fc2b4bfb8338e402518f21fc20aca17725faa0ed3ab97bcaf9431ed692de9')}, hash='9a6b372fa8a47143716cd660ee03e8a6a12caa7b196bfac1dccb719e6b1d9168', text='arXiv preprint\\narXiv:2001.08361 , 2020.\\nJamesKirkpatrick,RazvanPascanu,NeilRabinowitz,JoelVeness,GuillaumeDesjardins,AndreiARusu,\\nKieran Milan, John Quan, Tiago Ramalho, Agnieszka Grabska-Barwinska, et al. Overcoming catastrophic\\nforgetting in neural networks. Proceedings of the national academy of sciences , 114(13):3521–3526, 2017.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-41'),\n",
              " '0fc4aee4-746a-4826-9511-af11d5dcd3b3': IndexNode(id_='0fc4aee4-746a-4826-9511-af11d5dcd3b3', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-41', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='8944b2b1a73036fb3525acc9f234407e65fa12cacf2e46c9fd1146551f062361'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='8f98d41d-2133-44de-82f5-0babc5330e85', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='9a6b372fa8a47143716cd660ee03e8a6a12caa7b196bfac1dccb719e6b1d9168'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='740ad791-70a2-43b2-ad02-4d4c5f849909', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='d4dd1de5385c12a833db7592d2e2cb76e0ba81a5308a06630e992ae97752c1a7')}, hash='227fc2b4bfb8338e402518f21fc20aca17725faa0ed3ab97bcaf9431ed692de9', text='Andreas Köpf, Yannic Kilcher, Dimitri von Rütte, Sotiris Anagnostidis, Zhi-Rui Tam, Keith Stevens, Ab-\\ndullahBarhoum,NguyenMinhDuc,OliverStanley,RichárdNagyfi,etal. Openassistantconversations–\\ndemocratizing large language model alignment. arXiv preprint arXiv:2304.07327 , 2023.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-41'),\n",
              " '740ad791-70a2-43b2-ad02-4d4c5f849909': IndexNode(id_='740ad791-70a2-43b2-ad02-4d4c5f849909', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-41', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='8944b2b1a73036fb3525acc9f234407e65fa12cacf2e46c9fd1146551f062361'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='0fc4aee4-746a-4826-9511-af11d5dcd3b3', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='227fc2b4bfb8338e402518f21fc20aca17725faa0ed3ab97bcaf9431ed692de9'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='576e06a1-f4f1-490b-a215-8896b3166750', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='307d8c468b4a8f971868694871cd8f92a63a65a9d08a90a9b62868ded9d0d010')}, hash='d4dd1de5385c12a833db7592d2e2cb76e0ba81a5308a06630e992ae97752c1a7', text='arXiv preprint arXiv:2304.07327 , 2023.\\nTomasz Korbak, Kejian Shi, Angelica Chen, Rasika Bhalerao, Christopher L Buckley, Jason Phang, Samuel R\\nBowman, and Ethan Perez. Pretraining language models with human preferences. arXiv preprint\\narXiv:2302.08582 , 2023.\\nTakuKudoandJohnRichardson.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-41'),\n",
              " '576e06a1-f4f1-490b-a215-8896b3166750': IndexNode(id_='576e06a1-f4f1-490b-a215-8896b3166750', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-41', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='8944b2b1a73036fb3525acc9f234407e65fa12cacf2e46c9fd1146551f062361'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='740ad791-70a2-43b2-ad02-4d4c5f849909', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='d4dd1de5385c12a833db7592d2e2cb76e0ba81a5308a06630e992ae97752c1a7'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='17f7e705-20e6-44cb-a028-19697e7145af', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='af916d9f38f26e9a1f12c8ec6e434ac5a64d4bf3564b7c7293ae40ed8ed7452f')}, hash='307d8c468b4a8f971868694871cd8f92a63a65a9d08a90a9b62868ded9d0d010', text='TakuKudoandJohnRichardson. Sentencepiece: Asimpleandlanguageindependentsubwordtokenizer\\nand detokenizer for neural text processing, 2018.\\nSachinKumar,VidhishaBalachandran,LucilleNjoo,AntoniosAnastasopoulos,andYuliaTsvetkov. Language\\ngeneration models can cause harm: So what can we do about it? an actionable survey. arXiv preprint\\narXiv:2210.07700 , 2022.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-41'),\n",
              " '17f7e705-20e6-44cb-a028-19697e7145af': IndexNode(id_='17f7e705-20e6-44cb-a028-19697e7145af', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-41', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='8944b2b1a73036fb3525acc9f234407e65fa12cacf2e46c9fd1146551f062361'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='576e06a1-f4f1-490b-a215-8896b3166750', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='307d8c468b4a8f971868694871cd8f92a63a65a9d08a90a9b62868ded9d0d010'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='105c358f-7864-4e71-9855-22ad3d321e17', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='1b26da5a0f452fbe018da832318c8ba300ca85a915bd5e610042f4989af8325a')}, hash='af916d9f38f26e9a1f12c8ec6e434ac5a64d4bf3564b7c7293ae40ed8ed7452f', text='arXiv preprint\\narXiv:2210.07700 , 2022.\\nTom Kwiatkowski, Jennimaria Palomaki, Olivia Redfield, Michael Collins, Ankur Parikh, Chris Alberti,\\nDanielle Epstein, Illia Polosukhin, Jacob Devlin, Kenton Lee, et al. Natural questions: a benchmark for\\nquestion answering research. Transactions of the Association for Computational Linguistics , 7:453–466, 2019.\\nNathan Lambert, Lewis Tunstall, Nazneen Rajani, and Tristan Thrush.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-41'),\n",
              " '105c358f-7864-4e71-9855-22ad3d321e17': IndexNode(id_='105c358f-7864-4e71-9855-22ad3d321e17', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-41', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='8944b2b1a73036fb3525acc9f234407e65fa12cacf2e46c9fd1146551f062361'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='17f7e705-20e6-44cb-a028-19697e7145af', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='af916d9f38f26e9a1f12c8ec6e434ac5a64d4bf3564b7c7293ae40ed8ed7452f')}, hash='1b26da5a0f452fbe018da832318c8ba300ca85a915bd5e610042f4989af8325a', text='Huggingface h4 stack\\nexchange preference dataset. 2023. URL https://huggingface.co/datasets/HuggingFaceH4/\\nstack-exchange-preferences .\\nKatherine Lee, Daphne Ippolito, Andrew Nystrom, Chiyuan Zhang, Douglas Eck, Chris Callison-Burch, and\\nNicholas Carlini. Deduplicating training data makes language models better.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-41'),\n",
              " '4fc993a7-4774-4201-8533-0d9314925ac5': IndexNode(id_='4fc993a7-4774-4201-8533-0d9314925ac5', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-41', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='8944b2b1a73036fb3525acc9f234407e65fa12cacf2e46c9fd1146551f062361'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='a64dca48-4085-4bb9-a505-92ac3c8ff70f', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='03835830f2bb70debc4a8204366393391af8254143c4a0b06042c9da21f969bd')}, hash='4dc7a05943961c941d03663103b25ee876cb28cac592a6e11beca68511552e16', text='Or Honovich, Thomas Scialom, Omer Levy, and Timo Schick. Unnatural instructions: Tuning language\\nmodels with (almost) no human labor. arXiv preprint arXiv:2212.09689 , 2022.\\nSaghar Hosseini, Hamid Palangi, and Ahmed Hassan Awadallah. An empirical study of metrics to measure\\nrepresentational harms in pre-trained language models. arXiv preprint arXiv:2301.09211 , 2023.\\nFanHuang,HaewoonKwak,andJisunAn. Ischatgptbetterthanhumanannotators? potentialandlimitations\\nof chatgpt in explaining implicit hate speech. arXiv preprint arXiv:2302.07736 , 2023.\\nClaytonHuttoandEricGilbert. Vader: Aparsimoniousrule-basedmodelforsentimentanalysisofsocial\\nmedia text. In Proceedings of the international AAAI conference on web and social media , volume 8, pages\\n216–225, 2014.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-41'),\n",
              " 'a64dca48-4085-4bb9-a505-92ac3c8ff70f': IndexNode(id_='a64dca48-4085-4bb9-a505-92ac3c8ff70f', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-41', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='8944b2b1a73036fb3525acc9f234407e65fa12cacf2e46c9fd1146551f062361'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='4fc993a7-4774-4201-8533-0d9314925ac5', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='4dc7a05943961c941d03663103b25ee876cb28cac592a6e11beca68511552e16'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='777a7dc6-28a0-48c2-9085-bd40fbc54344', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='b193422b7223cbf9796626559d17b117314f9c3ebbc1f0f5b55ffdaf23653886')}, hash='03835830f2bb70debc4a8204366393391af8254143c4a0b06042c9da21f969bd', text='MandarJoshi,EunsolChoi,DanielSWeld,andLukeZettlemoyer. Triviaqa: Alargescaledistantlysupervised\\nchallenge dataset for reading comprehension. arXiv preprint arXiv:1705.03551 , 2017.\\n40\\n\\nJaredKaplan,SamMcCandlish,TomHenighan,TomBBrown,BenjaminChess,RewonChild,ScottGray,\\nAlec Radford, Jeffrey Wu, and Dario Amodei. Scaling laws for neural language models. arXiv preprint\\narXiv:2001.08361 , 2020.\\nJamesKirkpatrick,RazvanPascanu,NeilRabinowitz,JoelVeness,GuillaumeDesjardins,AndreiARusu,\\nKieran Milan, John Quan, Tiago Ramalho, Agnieszka Grabska-Barwinska, et al. Overcoming catastrophic\\nforgetting in neural networks. Proceedings of the national academy of sciences , 114(13):3521–3526, 2017.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-41'),\n",
              " '777a7dc6-28a0-48c2-9085-bd40fbc54344': IndexNode(id_='777a7dc6-28a0-48c2-9085-bd40fbc54344', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-41', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='8944b2b1a73036fb3525acc9f234407e65fa12cacf2e46c9fd1146551f062361'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='a64dca48-4085-4bb9-a505-92ac3c8ff70f', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='03835830f2bb70debc4a8204366393391af8254143c4a0b06042c9da21f969bd'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='b848d895-08f7-427b-8ab2-b66b547d4d45', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='0bf5e8fc8a9d3fc8878906d30e69966df49800454103e58fb2c807302d999418')}, hash='b193422b7223cbf9796626559d17b117314f9c3ebbc1f0f5b55ffdaf23653886', text='Andreas Köpf, Yannic Kilcher, Dimitri von Rütte, Sotiris Anagnostidis, Zhi-Rui Tam, Keith Stevens, Ab-\\ndullahBarhoum,NguyenMinhDuc,OliverStanley,RichárdNagyfi,etal. Openassistantconversations–\\ndemocratizing large language model alignment. arXiv preprint arXiv:2304.07327 , 2023.\\nTomasz Korbak, Kejian Shi, Angelica Chen, Rasika Bhalerao, Christopher L Buckley, Jason Phang, Samuel R\\nBowman, and Ethan Perez. Pretraining language models with human preferences. arXiv preprint\\narXiv:2302.08582 , 2023.\\nTakuKudoandJohnRichardson. Sentencepiece: Asimpleandlanguageindependentsubwordtokenizer\\nand detokenizer for neural text processing, 2018.\\nSachinKumar,VidhishaBalachandran,LucilleNjoo,AntoniosAnastasopoulos,andYuliaTsvetkov.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-41'),\n",
              " 'b848d895-08f7-427b-8ab2-b66b547d4d45': IndexNode(id_='b848d895-08f7-427b-8ab2-b66b547d4d45', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-41', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='8944b2b1a73036fb3525acc9f234407e65fa12cacf2e46c9fd1146551f062361'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='777a7dc6-28a0-48c2-9085-bd40fbc54344', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='b193422b7223cbf9796626559d17b117314f9c3ebbc1f0f5b55ffdaf23653886')}, hash='0bf5e8fc8a9d3fc8878906d30e69966df49800454103e58fb2c807302d999418', text='Language\\ngeneration models can cause harm: So what can we do about it? an actionable survey. arXiv preprint\\narXiv:2210.07700 , 2022.\\nTom Kwiatkowski, Jennimaria Palomaki, Olivia Redfield, Michael Collins, Ankur Parikh, Chris Alberti,\\nDanielle Epstein, Illia Polosukhin, Jacob Devlin, Kenton Lee, et al. Natural questions: a benchmark for\\nquestion answering research. Transactions of the Association for Computational Linguistics , 7:453–466, 2019.\\nNathan Lambert, Lewis Tunstall, Nazneen Rajani, and Tristan Thrush. Huggingface h4 stack\\nexchange preference dataset. 2023. URL https://huggingface.co/datasets/HuggingFaceH4/\\nstack-exchange-preferences .\\nKatherine Lee, Daphne Ippolito, Andrew Nystrom, Chiyuan Zhang, Douglas Eck, Chris Callison-Burch, and\\nNicholas Carlini. Deduplicating training data makes language models better.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-41'),\n",
              " 'e8988ec4-b098-4a0e-97eb-a71f40fd4d73': IndexNode(id_='e8988ec4-b098-4a0e-97eb-a71f40fd4d73', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-41', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='8944b2b1a73036fb3525acc9f234407e65fa12cacf2e46c9fd1146551f062361'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='4437ad3e-1afe-4a51-994a-0e264da17dee', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='1ce4740303c71ca3537bf51147f7f2803203d48bb08dcd8bd911ed4d42e1b7e3')}, hash='5e8913e652d180fc5e10c96c88ac825bd5ebc32445aa404acbffc1b249077fa5', text='Or Honovich, Thomas Scialom, Omer Levy, and Timo Schick. Unnatural instructions: Tuning language\\nmodels with (almost) no human labor. arXiv preprint arXiv:2212.09689 , 2022.\\nSaghar Hosseini, Hamid Palangi, and Ahmed Hassan Awadallah. An empirical study of metrics to measure\\nrepresentational harms in pre-trained language models. arXiv preprint arXiv:2301.09211 , 2023.\\nFanHuang,HaewoonKwak,andJisunAn. Ischatgptbetterthanhumanannotators? potentialandlimitations\\nof chatgpt in explaining implicit hate speech. arXiv preprint arXiv:2302.07736 , 2023.\\nClaytonHuttoandEricGilbert. Vader: Aparsimoniousrule-basedmodelforsentimentanalysisofsocial\\nmedia text. In Proceedings of the international AAAI conference on web and social media , volume 8, pages\\n216–225, 2014.\\nMandarJoshi,EunsolChoi,DanielSWeld,andLukeZettlemoyer. Triviaqa: Alargescaledistantlysupervised\\nchallenge dataset for reading comprehension. arXiv preprint arXiv:1705.03551 , 2017.\\n40\\n\\nJaredKaplan,SamMcCandlish,TomHenighan,TomBBrown,BenjaminChess,RewonChild,ScottGray,\\nAlec Radford, Jeffrey Wu, and Dario Amodei. Scaling laws for neural language models. arXiv preprint\\narXiv:2001.08361 , 2020.\\nJamesKirkpatrick,RazvanPascanu,NeilRabinowitz,JoelVeness,GuillaumeDesjardins,AndreiARusu,\\nKieran Milan, John Quan, Tiago Ramalho, Agnieszka Grabska-Barwinska, et al. Overcoming catastrophic\\nforgetting in neural networks. Proceedings of the national academy of sciences , 114(13):3521–3526, 2017.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-41'),\n",
              " '4437ad3e-1afe-4a51-994a-0e264da17dee': IndexNode(id_='4437ad3e-1afe-4a51-994a-0e264da17dee', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-41', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='8944b2b1a73036fb3525acc9f234407e65fa12cacf2e46c9fd1146551f062361'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='e8988ec4-b098-4a0e-97eb-a71f40fd4d73', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='5e8913e652d180fc5e10c96c88ac825bd5ebc32445aa404acbffc1b249077fa5')}, hash='1ce4740303c71ca3537bf51147f7f2803203d48bb08dcd8bd911ed4d42e1b7e3', text='Andreas Köpf, Yannic Kilcher, Dimitri von Rütte, Sotiris Anagnostidis, Zhi-Rui Tam, Keith Stevens, Ab-\\ndullahBarhoum,NguyenMinhDuc,OliverStanley,RichárdNagyfi,etal. Openassistantconversations–\\ndemocratizing large language model alignment. arXiv preprint arXiv:2304.07327 , 2023.\\nTomasz Korbak, Kejian Shi, Angelica Chen, Rasika Bhalerao, Christopher L Buckley, Jason Phang, Samuel R\\nBowman, and Ethan Perez. Pretraining language models with human preferences. arXiv preprint\\narXiv:2302.08582 , 2023.\\nTakuKudoandJohnRichardson. Sentencepiece: Asimpleandlanguageindependentsubwordtokenizer\\nand detokenizer for neural text processing, 2018.\\nSachinKumar,VidhishaBalachandran,LucilleNjoo,AntoniosAnastasopoulos,andYuliaTsvetkov. Language\\ngeneration models can cause harm: So what can we do about it? an actionable survey. arXiv preprint\\narXiv:2210.07700 , 2022.\\nTom Kwiatkowski, Jennimaria Palomaki, Olivia Redfield, Michael Collins, Ankur Parikh, Chris Alberti,\\nDanielle Epstein, Illia Polosukhin, Jacob Devlin, Kenton Lee, et al. Natural questions: a benchmark for\\nquestion answering research. Transactions of the Association for Computational Linguistics , 7:453–466, 2019.\\nNathan Lambert, Lewis Tunstall, Nazneen Rajani, and Tristan Thrush. Huggingface h4 stack\\nexchange preference dataset. 2023. URL https://huggingface.co/datasets/HuggingFaceH4/\\nstack-exchange-preferences .\\nKatherine Lee, Daphne Ippolito, Andrew Nystrom, Chiyuan Zhang, Douglas Eck, Chris Callison-Burch, and\\nNicholas Carlini. Deduplicating training data makes language models better.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-41'),\n",
              " 'node-41': IndexNode(id_='node-41', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='415b7efc-e73f-4ac4-bbfd-c1546f099026', node_type=<ObjectType.DOCUMENT: '4'>, metadata={}, hash='231b3bd773f012c01b893ada9e009ecf25ee59934614c5a595c9bf1b3a123292'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='5233fe08-5b3c-466d-ac96-00b64228d0bb', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='735e4de1b62bce44b196855be30610425bc2c53b01d9059f2fb43d352b941d26'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='bab3f8d1-326d-4b03-8a9c-f9e50146f252', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='e02db946402a06ccf41ed0d6bc9fac8e7747b96842663e5e2537e48b8fd595fa')}, hash='8944b2b1a73036fb3525acc9f234407e65fa12cacf2e46c9fd1146551f062361', text='Or Honovich, Thomas Scialom, Omer Levy, and Timo Schick. Unnatural instructions: Tuning language\\nmodels with (almost) no human labor. arXiv preprint arXiv:2212.09689 , 2022.\\nSaghar Hosseini, Hamid Palangi, and Ahmed Hassan Awadallah. An empirical study of metrics to measure\\nrepresentational harms in pre-trained language models. arXiv preprint arXiv:2301.09211 , 2023.\\nFanHuang,HaewoonKwak,andJisunAn. Ischatgptbetterthanhumanannotators? potentialandlimitations\\nof chatgpt in explaining implicit hate speech. arXiv preprint arXiv:2302.07736 , 2023.\\nClaytonHuttoandEricGilbert. Vader: Aparsimoniousrule-basedmodelforsentimentanalysisofsocial\\nmedia text. In Proceedings of the international AAAI conference on web and social media , volume 8, pages\\n216–225, 2014.\\nMandarJoshi,EunsolChoi,DanielSWeld,andLukeZettlemoyer. Triviaqa: Alargescaledistantlysupervised\\nchallenge dataset for reading comprehension. arXiv preprint arXiv:1705.03551 , 2017.\\n40\\n\\nJaredKaplan,SamMcCandlish,TomHenighan,TomBBrown,BenjaminChess,RewonChild,ScottGray,\\nAlec Radford, Jeffrey Wu, and Dario Amodei. Scaling laws for neural language models. arXiv preprint\\narXiv:2001.08361 , 2020.\\nJamesKirkpatrick,RazvanPascanu,NeilRabinowitz,JoelVeness,GuillaumeDesjardins,AndreiARusu,\\nKieran Milan, John Quan, Tiago Ramalho, Agnieszka Grabska-Barwinska, et al. Overcoming catastrophic\\nforgetting in neural networks. Proceedings of the national academy of sciences , 114(13):3521–3526, 2017.\\nAndreas Köpf, Yannic Kilcher, Dimitri von Rütte, Sotiris Anagnostidis, Zhi-Rui Tam, Keith Stevens, Ab-\\ndullahBarhoum,NguyenMinhDuc,OliverStanley,RichárdNagyfi,etal. Openassistantconversations–\\ndemocratizing large language model alignment. arXiv preprint arXiv:2304.07327 , 2023.\\nTomasz Korbak, Kejian Shi, Angelica Chen, Rasika Bhalerao, Christopher L Buckley, Jason Phang, Samuel R\\nBowman, and Ethan Perez. Pretraining language models with human preferences. arXiv preprint\\narXiv:2302.08582 , 2023.\\nTakuKudoandJohnRichardson. Sentencepiece: Asimpleandlanguageindependentsubwordtokenizer\\nand detokenizer for neural text processing, 2018.\\nSachinKumar,VidhishaBalachandran,LucilleNjoo,AntoniosAnastasopoulos,andYuliaTsvetkov. Language\\ngeneration models can cause harm: So what can we do about it? an actionable survey. arXiv preprint\\narXiv:2210.07700 , 2022.\\nTom Kwiatkowski, Jennimaria Palomaki, Olivia Redfield, Michael Collins, Ankur Parikh, Chris Alberti,\\nDanielle Epstein, Illia Polosukhin, Jacob Devlin, Kenton Lee, et al. Natural questions: a benchmark for\\nquestion answering research. Transactions of the Association for Computational Linguistics , 7:453–466, 2019.\\nNathan Lambert, Lewis Tunstall, Nazneen Rajani, and Tristan Thrush. Huggingface h4 stack\\nexchange preference dataset. 2023. URL https://huggingface.co/datasets/HuggingFaceH4/\\nstack-exchange-preferences .\\nKatherine Lee, Daphne Ippolito, Andrew Nystrom, Chiyuan Zhang, Douglas Eck, Chris Callison-Burch, and\\nNicholas Carlini. Deduplicating training data makes language models better.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-41'),\n",
              " '313c4845-faef-404d-ac5e-f7dd5dd1ccb6': IndexNode(id_='313c4845-faef-404d-ac5e-f7dd5dd1ccb6', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-42', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='e02db946402a06ccf41ed0d6bc9fac8e7747b96842663e5e2537e48b8fd595fa'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='98e45440-dbec-4355-a15c-63f0990c6e5e', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='1c742ac14cc5cf28a7feae53970ac5c2a9388e31f8ef78c179a3e73dc4f608a5')}, hash='e292ac4ad5ebffc275be131ea8d1bddd01066e1c77d62c2e34be9469279d5889', text='Deduplicating training data makes language models better. In Proceedings of the 60th\\nAnnualMeetingoftheAssociationforComputationalLinguistics .AssociationforComputationalLinguistics,\\n2022.\\nKevin Leeand Shubho Sengupta. Introducing theai researchsupercluster— meta’s cutting-edge aisuper-\\ncomputer for ai research, 2022. URL https://ai.facebook.com/blog/ai-rsc/ .\\nStephanieLin,JacobHilton,andOwainEvans.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-42'),\n",
              " '98e45440-dbec-4355-a15c-63f0990c6e5e': IndexNode(id_='98e45440-dbec-4355-a15c-63f0990c6e5e', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-42', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='e02db946402a06ccf41ed0d6bc9fac8e7747b96842663e5e2537e48b8fd595fa'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='313c4845-faef-404d-ac5e-f7dd5dd1ccb6', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='e292ac4ad5ebffc275be131ea8d1bddd01066e1c77d62c2e34be9469279d5889'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='4bf6b954-4752-45a2-af82-d90731935e24', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='b1a5692bedd4302bbd228d87a1b96de5970c401f95ea4de1e600f6f7f6fc53e1')}, hash='1c742ac14cc5cf28a7feae53970ac5c2a9388e31f8ef78c179a3e73dc4f608a5', text='StephanieLin,JacobHilton,andOwainEvans. Truthfulqa: Measuringhowmodelsmimichumanfalsehoods.\\narXiv preprint arXiv:2109.07958 , 2021.\\nYinhan Liu,Myle Ott, NamanGoyal, Jingfei Du,Mandar Joshi, DanqiChen, Omer Levy,Mike Lewis, Luke\\nZettlemoyer,andVeselinStoyanov. Roberta: Arobustlyoptimizedbertpretrainingapproach.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-42'),\n",
              " '4bf6b954-4752-45a2-af82-d90731935e24': IndexNode(id_='4bf6b954-4752-45a2-af82-d90731935e24', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-42', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='e02db946402a06ccf41ed0d6bc9fac8e7747b96842663e5e2537e48b8fd595fa'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='98e45440-dbec-4355-a15c-63f0990c6e5e', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='1c742ac14cc5cf28a7feae53970ac5c2a9388e31f8ef78c179a3e73dc4f608a5'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='f84585c3-5f57-4ed4-bab8-50f6b3876c6f', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='f75af7720051961a240c8093a8db29303238d7d9f0566f9345f7ea6b7561ccb7')}, hash='b1a5692bedd4302bbd228d87a1b96de5970c401f95ea4de1e600f6f7f6fc53e1', text='Roberta: Arobustlyoptimizedbertpretrainingapproach. arXivpreprint\\narXiv:1907.11692 , 2019.\\nShayneLongpre,LeHou,TuVu,AlbertWebson,HyungWonChung,YiTay,DennyZhou,QuocVLe,Barret\\nZoph,JasonWei,etal. Theflancollection: Designingdataandmethodsforeffectiveinstructiontuning.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-42'),\n",
              " 'f84585c3-5f57-4ed4-bab8-50f6b3876c6f': IndexNode(id_='f84585c3-5f57-4ed4-bab8-50f6b3876c6f', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-42', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='e02db946402a06ccf41ed0d6bc9fac8e7747b96842663e5e2537e48b8fd595fa'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='4bf6b954-4752-45a2-af82-d90731935e24', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='b1a5692bedd4302bbd228d87a1b96de5970c401f95ea4de1e600f6f7f6fc53e1'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='9d116688-0030-44d3-b144-466a1db4e08e', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='b5403a1bace943c2c933f4865de659016ac1c9ce4922cec27b4e6a0895cb2751')}, hash='f75af7720051961a240c8093a8db29303238d7d9f0566f9345f7ea6b7561ccb7', text='arXiv preprint arXiv:2301.13688 , 2023.\\nIlya Loshchilov and Frank Hutter. Decoupled weight decay regularization. arXiv preprint arXiv:1711.05101 ,\\n2017.\\nAmanMadaan,NiketTandon,PrakharGupta, SkylerHallinan, LuyuGao,SarahWiegreffe,UriAlon,Nouha\\nDziri, Shrimai Prabhumoye, Yiming Yang, et al.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-42'),\n",
              " '9d116688-0030-44d3-b144-466a1db4e08e': IndexNode(id_='9d116688-0030-44d3-b144-466a1db4e08e', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-42', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='e02db946402a06ccf41ed0d6bc9fac8e7747b96842663e5e2537e48b8fd595fa'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='f84585c3-5f57-4ed4-bab8-50f6b3876c6f', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='f75af7720051961a240c8093a8db29303238d7d9f0566f9345f7ea6b7561ccb7'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='322c7fb3-d74e-4235-b3d9-627385ced7b2', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='c5b851ac2f076cfd41e34fdd7ec0a6845bfa0633d6f439446b33f3b38ae60d53')}, hash='b5403a1bace943c2c933f4865de659016ac1c9ce4922cec27b4e6a0895cb2751', text='Self-refine: Iterative refinement with self-feedback. arXiv\\npreprint arXiv:2303.17651 , 2023.\\nGrégoire Mialon, Roberto Dessì, Maria Lomeli, Christoforos Nalmpantis, Ram Pasunuru, Roberta Raileanu,\\nBaptisteRozière,TimoSchick,JaneDwivedi-Yu,AsliCelikyilmaz,etal.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-42'),\n",
              " '322c7fb3-d74e-4235-b3d9-627385ced7b2': IndexNode(id_='322c7fb3-d74e-4235-b3d9-627385ced7b2', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-42', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='e02db946402a06ccf41ed0d6bc9fac8e7747b96842663e5e2537e48b8fd595fa'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='9d116688-0030-44d3-b144-466a1db4e08e', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='b5403a1bace943c2c933f4865de659016ac1c9ce4922cec27b4e6a0895cb2751'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='f345172e-87cc-4c18-8f80-ed45e5531f12', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='f6df69715361db828a883643837fe2cfb6aeec7c8dd96413fdc01e28afeb3e48')}, hash='c5b851ac2f076cfd41e34fdd7ec0a6845bfa0633d6f439446b33f3b38ae60d53', text='Augmentedlanguagemodels: a\\nsurvey.arXiv preprint arXiv:2302.07842 , 2023.\\nTodor Mihaylov, Peter Clark, Tushar Khot, and Ashish Sabharwal. Can a suit of armor conduct electricity? a\\nnew dataset for open book question answering. arXiv preprint arXiv:1809.02789 , 2018.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-42'),\n",
              " 'f345172e-87cc-4c18-8f80-ed45e5531f12': IndexNode(id_='f345172e-87cc-4c18-8f80-ed45e5531f12', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-42', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='e02db946402a06ccf41ed0d6bc9fac8e7747b96842663e5e2537e48b8fd595fa'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='322c7fb3-d74e-4235-b3d9-627385ced7b2', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='c5b851ac2f076cfd41e34fdd7ec0a6845bfa0633d6f439446b33f3b38ae60d53'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='90682a75-ccaa-4c1c-9fdf-e1c513369d07', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='2a90a0a1e0a64af8b33f60c6a02803d6994c9b17c851a3eb8a26f6c3b4f0dddc')}, hash='f6df69715361db828a883643837fe2cfb6aeec7c8dd96413fdc01e28afeb3e48', text='arXiv preprint arXiv:1809.02789 , 2018.\\nMargaretMitchell,SimoneWu,AndrewZaldivar,ParkerBarnes,LucyVasserman,BenHutchinson,Elena\\nSpitzer,InioluwaDeborahRaji,andTimnitGebru. Modelcardsformodelreporting. CoRR,abs/1810.03993,\\n2018. URL http://arxiv.org/abs/1810.03993 .\\nMosaicML NLP Team et al.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-42'),\n",
              " '90682a75-ccaa-4c1c-9fdf-e1c513369d07': IndexNode(id_='90682a75-ccaa-4c1c-9fdf-e1c513369d07', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-42', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='e02db946402a06ccf41ed0d6bc9fac8e7747b96842663e5e2537e48b8fd595fa'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='f345172e-87cc-4c18-8f80-ed45e5531f12', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='f6df69715361db828a883643837fe2cfb6aeec7c8dd96413fdc01e28afeb3e48'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='5b84f9eb-063e-458e-ab97-ed6b07e9f35a', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='830b1e25967349346c3117999b6be39ce6c6449eee0ce8c44f9d2a9973657dbb')}, hash='2a90a0a1e0a64af8b33f60c6a02803d6994c9b17c851a3eb8a26f6c3b4f0dddc', text='MosaicML NLP Team et al. Introducing mpt-7b: A new standard for open-source, commercially usable llms,\\n2023.\\n41\\n\\nReiichiro Nakano, Jacob Hilton, Suchir Balaji, Jeff Wu, Lonbrown Ouyanbrown, Christina Kim, Christopher\\nHesse, Shantanu Jain, Vineet Kosaraju, William Saunders, Xu Jiang, Karl Cobbe, Tyna Eloundou, Gretchen\\nKrueger, Kevin Button, Matthew Knight, Benjamin Chess, and John Schulman.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-42'),\n",
              " '5b84f9eb-063e-458e-ab97-ed6b07e9f35a': IndexNode(id_='5b84f9eb-063e-458e-ab97-ed6b07e9f35a', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-42', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='e02db946402a06ccf41ed0d6bc9fac8e7747b96842663e5e2537e48b8fd595fa'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='90682a75-ccaa-4c1c-9fdf-e1c513369d07', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='2a90a0a1e0a64af8b33f60c6a02803d6994c9b17c851a3eb8a26f6c3b4f0dddc'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='ff203f49-097f-4a5f-a418-1d04855dffee', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='e2beb661d1b6ff2eee7a552a8775790beb946b32178ce650f3e1745eb2d8bd5d')}, hash='830b1e25967349346c3117999b6be39ce6c6449eee0ce8c44f9d2a9973657dbb', text='Webgpt: Browser-assisted\\nquestion-answering with human feedback. In arXiv, 2021.\\nCuong V. Nguyen, Alessandro Achille, Michael Lam, Tal Hassner, Vijay Mahadevan, and Stefano Soatto.\\nToward understanding catastrophic forgetting in continual learning. arXiv preprint arXiv:1908.01091 , 2019.\\nOpenAI. GPT-4 technical report.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-42'),\n",
              " 'ff203f49-097f-4a5f-a418-1d04855dffee': IndexNode(id_='ff203f49-097f-4a5f-a418-1d04855dffee', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-42', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='e02db946402a06ccf41ed0d6bc9fac8e7747b96842663e5e2537e48b8fd595fa'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='5b84f9eb-063e-458e-ab97-ed6b07e9f35a', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='830b1e25967349346c3117999b6be39ce6c6449eee0ce8c44f9d2a9973657dbb')}, hash='e2beb661d1b6ff2eee7a552a8775790beb946b32178ce650f3e1745eb2d8bd5d', text='OpenAI. GPT-4 technical report. CoRR, abs/2303.08774, 2023. doi: 10.48550/arXiv.2303.08774.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-42'),\n",
              " '214b34ee-36d3-4913-a995-17474e074a0a': IndexNode(id_='214b34ee-36d3-4913-a995-17474e074a0a', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-42', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='e02db946402a06ccf41ed0d6bc9fac8e7747b96842663e5e2537e48b8fd595fa'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='102997cd-5c7d-4278-89fc-ac33feedeb62', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='9521b1bea7ae8155c7c97a2a2b11ab0c0287461b77a4b5b8aa86da5012cf9f2c')}, hash='352969150fe851ca8add483096501a8097fd12856714f7993476330c0f02caa6', text='Deduplicating training data makes language models better. In Proceedings of the 60th\\nAnnualMeetingoftheAssociationforComputationalLinguistics .AssociationforComputationalLinguistics,\\n2022.\\nKevin Leeand Shubho Sengupta. Introducing theai researchsupercluster— meta’s cutting-edge aisuper-\\ncomputer for ai research, 2022. URL https://ai.facebook.com/blog/ai-rsc/ .\\nStephanieLin,JacobHilton,andOwainEvans. Truthfulqa: Measuringhowmodelsmimichumanfalsehoods.\\narXiv preprint arXiv:2109.07958 , 2021.\\nYinhan Liu,Myle Ott, NamanGoyal, Jingfei Du,Mandar Joshi, DanqiChen, Omer Levy,Mike Lewis, Luke\\nZettlemoyer,andVeselinStoyanov. Roberta: Arobustlyoptimizedbertpretrainingapproach. arXivpreprint\\narXiv:1907.11692 , 2019.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-42'),\n",
              " '102997cd-5c7d-4278-89fc-ac33feedeb62': IndexNode(id_='102997cd-5c7d-4278-89fc-ac33feedeb62', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-42', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='e02db946402a06ccf41ed0d6bc9fac8e7747b96842663e5e2537e48b8fd595fa'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='214b34ee-36d3-4913-a995-17474e074a0a', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='352969150fe851ca8add483096501a8097fd12856714f7993476330c0f02caa6'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='cde05746-e078-49ba-b131-b7be422d14e5', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='7c78bbc10ea792a2b71934549011bb94cfc0983c3abb9df54eb19869caa95de4')}, hash='9521b1bea7ae8155c7c97a2a2b11ab0c0287461b77a4b5b8aa86da5012cf9f2c', text='arXivpreprint\\narXiv:1907.11692 , 2019.\\nShayneLongpre,LeHou,TuVu,AlbertWebson,HyungWonChung,YiTay,DennyZhou,QuocVLe,Barret\\nZoph,JasonWei,etal. Theflancollection: Designingdataandmethodsforeffectiveinstructiontuning.\\narXiv preprint arXiv:2301.13688 , 2023.\\nIlya Loshchilov and Frank Hutter. Decoupled weight decay regularization. arXiv preprint arXiv:1711.05101 ,\\n2017.\\nAmanMadaan,NiketTandon,PrakharGupta, SkylerHallinan, LuyuGao,SarahWiegreffe,UriAlon,Nouha\\nDziri, Shrimai Prabhumoye, Yiming Yang, et al. Self-refine: Iterative refinement with self-feedback. arXiv\\npreprint arXiv:2303.17651 , 2023.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-42'),\n",
              " 'cde05746-e078-49ba-b131-b7be422d14e5': IndexNode(id_='cde05746-e078-49ba-b131-b7be422d14e5', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-42', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='e02db946402a06ccf41ed0d6bc9fac8e7747b96842663e5e2537e48b8fd595fa'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='102997cd-5c7d-4278-89fc-ac33feedeb62', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='9521b1bea7ae8155c7c97a2a2b11ab0c0287461b77a4b5b8aa86da5012cf9f2c'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='5c23ab7a-3265-478c-914b-d5237960ccee', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='487b3c4e71f66c58a225323c3cb0b21da393b4ce3aa0797d96f45dc07f7c5fb5')}, hash='7c78bbc10ea792a2b71934549011bb94cfc0983c3abb9df54eb19869caa95de4', text='arXiv\\npreprint arXiv:2303.17651 , 2023.\\nGrégoire Mialon, Roberto Dessì, Maria Lomeli, Christoforos Nalmpantis, Ram Pasunuru, Roberta Raileanu,\\nBaptisteRozière,TimoSchick,JaneDwivedi-Yu,AsliCelikyilmaz,etal. Augmentedlanguagemodels: a\\nsurvey.arXiv preprint arXiv:2302.07842 , 2023.\\nTodor Mihaylov, Peter Clark, Tushar Khot, and Ashish Sabharwal. Can a suit of armor conduct electricity? a\\nnew dataset for open book question answering. arXiv preprint arXiv:1809.02789 , 2018.\\nMargaretMitchell,SimoneWu,AndrewZaldivar,ParkerBarnes,LucyVasserman,BenHutchinson,Elena\\nSpitzer,InioluwaDeborahRaji,andTimnitGebru. Modelcardsformodelreporting.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-42'),\n",
              " '5c23ab7a-3265-478c-914b-d5237960ccee': IndexNode(id_='5c23ab7a-3265-478c-914b-d5237960ccee', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-42', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='e02db946402a06ccf41ed0d6bc9fac8e7747b96842663e5e2537e48b8fd595fa'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='cde05746-e078-49ba-b131-b7be422d14e5', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='7c78bbc10ea792a2b71934549011bb94cfc0983c3abb9df54eb19869caa95de4'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='07918807-ca58-4468-9436-14c67a52b174', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='e2beb661d1b6ff2eee7a552a8775790beb946b32178ce650f3e1745eb2d8bd5d')}, hash='487b3c4e71f66c58a225323c3cb0b21da393b4ce3aa0797d96f45dc07f7c5fb5', text='Modelcardsformodelreporting. CoRR,abs/1810.03993,\\n2018. URL http://arxiv.org/abs/1810.03993 .\\nMosaicML NLP Team et al. Introducing mpt-7b: A new standard for open-source, commercially usable llms,\\n2023.\\n41\\n\\nReiichiro Nakano, Jacob Hilton, Suchir Balaji, Jeff Wu, Lonbrown Ouyanbrown, Christina Kim, Christopher\\nHesse, Shantanu Jain, Vineet Kosaraju, William Saunders, Xu Jiang, Karl Cobbe, Tyna Eloundou, Gretchen\\nKrueger, Kevin Button, Matthew Knight, Benjamin Chess, and John Schulman. Webgpt: Browser-assisted\\nquestion-answering with human feedback. In arXiv, 2021.\\nCuong V. Nguyen, Alessandro Achille, Michael Lam, Tal Hassner, Vijay Mahadevan, and Stefano Soatto.\\nToward understanding catastrophic forgetting in continual learning. arXiv preprint arXiv:1908.01091 , 2019.\\nOpenAI.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-42'),\n",
              " '07918807-ca58-4468-9436-14c67a52b174': IndexNode(id_='07918807-ca58-4468-9436-14c67a52b174', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-42', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='e02db946402a06ccf41ed0d6bc9fac8e7747b96842663e5e2537e48b8fd595fa'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='5c23ab7a-3265-478c-914b-d5237960ccee', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='487b3c4e71f66c58a225323c3cb0b21da393b4ce3aa0797d96f45dc07f7c5fb5')}, hash='e2beb661d1b6ff2eee7a552a8775790beb946b32178ce650f3e1745eb2d8bd5d', text='OpenAI. GPT-4 technical report. CoRR, abs/2303.08774, 2023. doi: 10.48550/arXiv.2303.08774.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-42'),\n",
              " '42f0053b-5a3c-4f4f-9921-09e276dc2fa6': IndexNode(id_='42f0053b-5a3c-4f4f-9921-09e276dc2fa6', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-42', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='e02db946402a06ccf41ed0d6bc9fac8e7747b96842663e5e2537e48b8fd595fa'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='3acab437-c380-46f8-b670-bafc1d2fa261', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='f998b96529c04db7ad2ad3b366332c729a22a453af731d62a9954366217ea9cf')}, hash='22f7f96b710c7c62024d70600632d38e356861a1d59b1a7eea2980cdce899256', text='Deduplicating training data makes language models better. In Proceedings of the 60th\\nAnnualMeetingoftheAssociationforComputationalLinguistics .AssociationforComputationalLinguistics,\\n2022.\\nKevin Leeand Shubho Sengupta. Introducing theai researchsupercluster— meta’s cutting-edge aisuper-\\ncomputer for ai research, 2022. URL https://ai.facebook.com/blog/ai-rsc/ .\\nStephanieLin,JacobHilton,andOwainEvans. Truthfulqa: Measuringhowmodelsmimichumanfalsehoods.\\narXiv preprint arXiv:2109.07958 , 2021.\\nYinhan Liu,Myle Ott, NamanGoyal, Jingfei Du,Mandar Joshi, DanqiChen, Omer Levy,Mike Lewis, Luke\\nZettlemoyer,andVeselinStoyanov. Roberta: Arobustlyoptimizedbertpretrainingapproach. arXivpreprint\\narXiv:1907.11692 , 2019.\\nShayneLongpre,LeHou,TuVu,AlbertWebson,HyungWonChung,YiTay,DennyZhou,QuocVLe,Barret\\nZoph,JasonWei,etal. Theflancollection: Designingdataandmethodsforeffectiveinstructiontuning.\\narXiv preprint arXiv:2301.13688 , 2023.\\nIlya Loshchilov and Frank Hutter. Decoupled weight decay regularization. arXiv preprint arXiv:1711.05101 ,\\n2017.\\nAmanMadaan,NiketTandon,PrakharGupta, SkylerHallinan, LuyuGao,SarahWiegreffe,UriAlon,Nouha\\nDziri, Shrimai Prabhumoye, Yiming Yang, et al. Self-refine: Iterative refinement with self-feedback. arXiv\\npreprint arXiv:2303.17651 , 2023.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-42'),\n",
              " '3acab437-c380-46f8-b670-bafc1d2fa261': IndexNode(id_='3acab437-c380-46f8-b670-bafc1d2fa261', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-42', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='e02db946402a06ccf41ed0d6bc9fac8e7747b96842663e5e2537e48b8fd595fa'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='42f0053b-5a3c-4f4f-9921-09e276dc2fa6', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='22f7f96b710c7c62024d70600632d38e356861a1d59b1a7eea2980cdce899256'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='d501f54d-7fd7-4f74-9eb3-754bd58cd67e', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='e2beb661d1b6ff2eee7a552a8775790beb946b32178ce650f3e1745eb2d8bd5d')}, hash='f998b96529c04db7ad2ad3b366332c729a22a453af731d62a9954366217ea9cf', text='arXiv\\npreprint arXiv:2303.17651 , 2023.\\nGrégoire Mialon, Roberto Dessì, Maria Lomeli, Christoforos Nalmpantis, Ram Pasunuru, Roberta Raileanu,\\nBaptisteRozière,TimoSchick,JaneDwivedi-Yu,AsliCelikyilmaz,etal. Augmentedlanguagemodels: a\\nsurvey.arXiv preprint arXiv:2302.07842 , 2023.\\nTodor Mihaylov, Peter Clark, Tushar Khot, and Ashish Sabharwal. Can a suit of armor conduct electricity? a\\nnew dataset for open book question answering. arXiv preprint arXiv:1809.02789 , 2018.\\nMargaretMitchell,SimoneWu,AndrewZaldivar,ParkerBarnes,LucyVasserman,BenHutchinson,Elena\\nSpitzer,InioluwaDeborahRaji,andTimnitGebru. Modelcardsformodelreporting. CoRR,abs/1810.03993,\\n2018. URL http://arxiv.org/abs/1810.03993 .\\nMosaicML NLP Team et al. Introducing mpt-7b: A new standard for open-source, commercially usable llms,\\n2023.\\n41\\n\\nReiichiro Nakano, Jacob Hilton, Suchir Balaji, Jeff Wu, Lonbrown Ouyanbrown, Christina Kim, Christopher\\nHesse, Shantanu Jain, Vineet Kosaraju, William Saunders, Xu Jiang, Karl Cobbe, Tyna Eloundou, Gretchen\\nKrueger, Kevin Button, Matthew Knight, Benjamin Chess, and John Schulman. Webgpt: Browser-assisted\\nquestion-answering with human feedback. In arXiv, 2021.\\nCuong V. Nguyen, Alessandro Achille, Michael Lam, Tal Hassner, Vijay Mahadevan, and Stefano Soatto.\\nToward understanding catastrophic forgetting in continual learning. arXiv preprint arXiv:1908.01091 , 2019.\\nOpenAI. GPT-4 technical report.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-42'),\n",
              " 'd501f54d-7fd7-4f74-9eb3-754bd58cd67e': IndexNode(id_='d501f54d-7fd7-4f74-9eb3-754bd58cd67e', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-42', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='e02db946402a06ccf41ed0d6bc9fac8e7747b96842663e5e2537e48b8fd595fa'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='3acab437-c380-46f8-b670-bafc1d2fa261', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='f998b96529c04db7ad2ad3b366332c729a22a453af731d62a9954366217ea9cf')}, hash='e2beb661d1b6ff2eee7a552a8775790beb946b32178ce650f3e1745eb2d8bd5d', text='OpenAI. GPT-4 technical report. CoRR, abs/2303.08774, 2023. doi: 10.48550/arXiv.2303.08774.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-42'),\n",
              " 'node-42': IndexNode(id_='node-42', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='415b7efc-e73f-4ac4-bbfd-c1546f099026', node_type=<ObjectType.DOCUMENT: '4'>, metadata={}, hash='231b3bd773f012c01b893ada9e009ecf25ee59934614c5a595c9bf1b3a123292'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='1c240945-6d85-448d-a108-bd2f62ee0f46', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='8944b2b1a73036fb3525acc9f234407e65fa12cacf2e46c9fd1146551f062361'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='21e3a4e1-5209-4b1e-8b0f-5ff81c93a336', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='8139ff09b55b424c48584e2c277f913e26d461bf641f75b0e02ee283ff909b7c')}, hash='e02db946402a06ccf41ed0d6bc9fac8e7747b96842663e5e2537e48b8fd595fa', text='Deduplicating training data makes language models better. In Proceedings of the 60th\\nAnnualMeetingoftheAssociationforComputationalLinguistics .AssociationforComputationalLinguistics,\\n2022.\\nKevin Leeand Shubho Sengupta. Introducing theai researchsupercluster— meta’s cutting-edge aisuper-\\ncomputer for ai research, 2022. URL https://ai.facebook.com/blog/ai-rsc/ .\\nStephanieLin,JacobHilton,andOwainEvans. Truthfulqa: Measuringhowmodelsmimichumanfalsehoods.\\narXiv preprint arXiv:2109.07958 , 2021.\\nYinhan Liu,Myle Ott, NamanGoyal, Jingfei Du,Mandar Joshi, DanqiChen, Omer Levy,Mike Lewis, Luke\\nZettlemoyer,andVeselinStoyanov. Roberta: Arobustlyoptimizedbertpretrainingapproach. arXivpreprint\\narXiv:1907.11692 , 2019.\\nShayneLongpre,LeHou,TuVu,AlbertWebson,HyungWonChung,YiTay,DennyZhou,QuocVLe,Barret\\nZoph,JasonWei,etal. Theflancollection: Designingdataandmethodsforeffectiveinstructiontuning.\\narXiv preprint arXiv:2301.13688 , 2023.\\nIlya Loshchilov and Frank Hutter. Decoupled weight decay regularization. arXiv preprint arXiv:1711.05101 ,\\n2017.\\nAmanMadaan,NiketTandon,PrakharGupta, SkylerHallinan, LuyuGao,SarahWiegreffe,UriAlon,Nouha\\nDziri, Shrimai Prabhumoye, Yiming Yang, et al. Self-refine: Iterative refinement with self-feedback. arXiv\\npreprint arXiv:2303.17651 , 2023.\\nGrégoire Mialon, Roberto Dessì, Maria Lomeli, Christoforos Nalmpantis, Ram Pasunuru, Roberta Raileanu,\\nBaptisteRozière,TimoSchick,JaneDwivedi-Yu,AsliCelikyilmaz,etal. Augmentedlanguagemodels: a\\nsurvey.arXiv preprint arXiv:2302.07842 , 2023.\\nTodor Mihaylov, Peter Clark, Tushar Khot, and Ashish Sabharwal. Can a suit of armor conduct electricity? a\\nnew dataset for open book question answering. arXiv preprint arXiv:1809.02789 , 2018.\\nMargaretMitchell,SimoneWu,AndrewZaldivar,ParkerBarnes,LucyVasserman,BenHutchinson,Elena\\nSpitzer,InioluwaDeborahRaji,andTimnitGebru. Modelcardsformodelreporting. CoRR,abs/1810.03993,\\n2018. URL http://arxiv.org/abs/1810.03993 .\\nMosaicML NLP Team et al. Introducing mpt-7b: A new standard for open-source, commercially usable llms,\\n2023.\\n41\\n\\nReiichiro Nakano, Jacob Hilton, Suchir Balaji, Jeff Wu, Lonbrown Ouyanbrown, Christina Kim, Christopher\\nHesse, Shantanu Jain, Vineet Kosaraju, William Saunders, Xu Jiang, Karl Cobbe, Tyna Eloundou, Gretchen\\nKrueger, Kevin Button, Matthew Knight, Benjamin Chess, and John Schulman. Webgpt: Browser-assisted\\nquestion-answering with human feedback. In arXiv, 2021.\\nCuong V. Nguyen, Alessandro Achille, Michael Lam, Tal Hassner, Vijay Mahadevan, and Stefano Soatto.\\nToward understanding catastrophic forgetting in continual learning. arXiv preprint arXiv:1908.01091 , 2019.\\nOpenAI. GPT-4 technical report. CoRR, abs/2303.08774, 2023. doi: 10.48550/arXiv.2303.08774.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-42'),\n",
              " 'fb669da3-819f-4c2f-b307-15338d231a37': IndexNode(id_='fb669da3-819f-4c2f-b307-15338d231a37', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-43', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='8139ff09b55b424c48584e2c277f913e26d461bf641f75b0e02ee283ff909b7c'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='ba6b76a2-5150-4b15-bee1-763ac136a883', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='bb9b8c83caaf3e95c6026eedc58f21fb25ccb13685206eb7a21449ef726e74f3')}, hash='cf4cbd463f052174c2b4b409d3ca3717a8cc12ace0b2e11a2205b79d02845de4', text='URL\\nhttps://doi.org/10.48550/arXiv.2303.08774 .\\nLongOuyang,JeffreyWu,XuJiang,DiogoAlmeida,CarrollWainwright,PamelaMishkin,ChongZhang,\\nSandhini Agarwal, Katarina Slama, Alex Ray, et al. Training language models to follow instructions with\\nhuman feedback. Advances in Neural Information Processing Systems , 35:27730–27744, 2022.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-43'),\n",
              " 'ba6b76a2-5150-4b15-bee1-763ac136a883': IndexNode(id_='ba6b76a2-5150-4b15-bee1-763ac136a883', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-43', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='8139ff09b55b424c48584e2c277f913e26d461bf641f75b0e02ee283ff909b7c'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='fb669da3-819f-4c2f-b307-15338d231a37', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='cf4cbd463f052174c2b4b409d3ca3717a8cc12ace0b2e11a2205b79d02845de4'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='be1c2ad5-2c75-4682-9b55-6abef3a4457d', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='3dcb7be5d3ab1a8adf90636eda34101ff68d5aa7201b0ef1179995e3e0f26a41')}, hash='bb9b8c83caaf3e95c6026eedc58f21fb25ccb13685206eb7a21449ef726e74f3', text='Advances in Neural Information Processing Systems , 35:27730–27744, 2022.\\nDavidPatterson,JosephGonzalez,QuocLe,ChenLiang,Lluis-MiquelMunguia,DanielRothchild,David\\nSo, Maud Texier, and Jeff Dean. Carbon emissions and large neural network training. arXiv preprint\\narXiv:2104.10350 , 2021.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-43'),\n",
              " 'be1c2ad5-2c75-4682-9b55-6abef3a4457d': IndexNode(id_='be1c2ad5-2c75-4682-9b55-6abef3a4457d', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-43', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='8139ff09b55b424c48584e2c277f913e26d461bf641f75b0e02ee283ff909b7c'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='ba6b76a2-5150-4b15-bee1-763ac136a883', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='bb9b8c83caaf3e95c6026eedc58f21fb25ccb13685206eb7a21449ef726e74f3'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='68a1c59b-c665-48a2-9c1d-0de6c4dbca82', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='8260a545ab0aeb16cd2c5e483adb775c4306a18ecc236bd173ccf0291f287c58')}, hash='3dcb7be5d3ab1a8adf90636eda34101ff68d5aa7201b0ef1179995e3e0f26a41', text='arXiv preprint\\narXiv:2104.10350 , 2021.\\nGuilherme Penedo, Quentin Malartic, Daniel Hesslow, Ruxandra Cojocaru, Alessandro Cappelli, Hamza\\nAlobeidli,BaptistePannier,EbtesamAlmazrouei,andJulienLaunay. Therefinedwebdatasetforfalcon\\nllm: Outperforming curated corpora with web data, and web data only, 2023.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-43'),\n",
              " '68a1c59b-c665-48a2-9c1d-0de6c4dbca82': IndexNode(id_='68a1c59b-c665-48a2-9c1d-0de6c4dbca82', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-43', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='8139ff09b55b424c48584e2c277f913e26d461bf641f75b0e02ee283ff909b7c'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='be1c2ad5-2c75-4682-9b55-6abef3a4457d', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='3dcb7be5d3ab1a8adf90636eda34101ff68d5aa7201b0ef1179995e3e0f26a41'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='d229e040-e41c-45ab-a0a5-955554bc523c', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='6db02ee5148c948760697d1a4ee040d3eacac3fc76f6c5dca21b376d33c6ee36')}, hash='8260a545ab0aeb16cd2c5e483adb775c4306a18ecc236bd173ccf0291f287c58', text='Reiner Pope, Sholto Douglas, Aakanksha Chowdhery, Jacob Devlin, James Bradbury, Anselm Levskaya,\\nJonathan Heek, Kefan Xiao, Shivani Agrawal, and Jeff Dean. Efficiently scaling transformer inference, 2022.\\nJack W. Rae, Sebastian Borgeaud, Trevor Cai, Katie Millican, Jordan Hoffmann, Francis Song, John Aslanides,\\nSarah Henderson, Roman Ring, Susannah Young, Eliza Rutherford, Tom Hennigan, Jacob Menick, Al-\\nbin Cassirer,', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-43'),\n",
              " 'd229e040-e41c-45ab-a0a5-955554bc523c': IndexNode(id_='d229e040-e41c-45ab-a0a5-955554bc523c', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-43', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='8139ff09b55b424c48584e2c277f913e26d461bf641f75b0e02ee283ff909b7c'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='68a1c59b-c665-48a2-9c1d-0de6c4dbca82', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='8260a545ab0aeb16cd2c5e483adb775c4306a18ecc236bd173ccf0291f287c58'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='61301acf-9a62-4d59-a7e9-283a8e288eaf', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='e8855c242b8b0211fc858de9dff6857833b3330f585f54fbb171ba29607b824f')}, hash='6db02ee5148c948760697d1a4ee040d3eacac3fc76f6c5dca21b376d33c6ee36', text='Tom Hennigan, Jacob Menick, Al-\\nbin Cassirer, Richard Powell, George van den Driessche, Lisa Anne Hendricks, Maribeth Rauh, Po-Sen\\nHuang,Amelia Glaese,JohannesWelbl, SumanthDathathri,Saffron Huang,JonathanUesato,John Mel-\\nlor, Irina Higgins, Antonia Creswell, Nat McAleese, Amy Wu, Erich Elsen, Siddhant Jayakumar, Elena\\nBuchatskaya,DavidBudden,', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-43'),\n",
              " '61301acf-9a62-4d59-a7e9-283a8e288eaf': IndexNode(id_='61301acf-9a62-4d59-a7e9-283a8e288eaf', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-43', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='8139ff09b55b424c48584e2c277f913e26d461bf641f75b0e02ee283ff909b7c'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='d229e040-e41c-45ab-a0a5-955554bc523c', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='6db02ee5148c948760697d1a4ee040d3eacac3fc76f6c5dca21b376d33c6ee36'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='b074ae2a-f9d6-47d2-a30c-d1b28016c134', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='eff1243c7736d7c29517425363b22edb534a6e11aab4f32558da5a93bfa3368e')}, hash='e8855c242b8b0211fc858de9dff6857833b3330f585f54fbb171ba29607b824f', text='Siddhant Jayakumar, Elena\\nBuchatskaya,DavidBudden,EsmeSutherland,KarenSimonyan,MichelaPaganini,LaurentSifre,Lena\\nMartens, Xiang Lorraine Li, Adhiguna Kuncoro, Aida Nematzadeh, Elena Gribovskaya, Domenic Donato,\\nAngeliki Lazaridou, Arthur Mensch, Jean-Baptiste Lespiau, Maria Tsimpoukelli, Nikolai Grigorev, Doug\\nFritz,', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-43'),\n",
              " 'b074ae2a-f9d6-47d2-a30c-d1b28016c134': IndexNode(id_='b074ae2a-f9d6-47d2-a30c-d1b28016c134', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-43', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='8139ff09b55b424c48584e2c277f913e26d461bf641f75b0e02ee283ff909b7c'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='61301acf-9a62-4d59-a7e9-283a8e288eaf', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='e8855c242b8b0211fc858de9dff6857833b3330f585f54fbb171ba29607b824f'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='92bf5edd-f4f2-4d40-bbf7-e3ff3aa71207', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='2f40b353cf14eb20a519aba2a46f8fafda0c6ee43e776675b3cbf8e4086328cf')}, hash='eff1243c7736d7c29517425363b22edb534a6e11aab4f32558da5a93bfa3368e', text='Maria Tsimpoukelli, Nikolai Grigorev, Doug\\nFritz,ThibaultSottiaux,MantasPajarskas,TobyPohlen,ZhitaoGong,DanielToyama,CypriendeMas-\\nsond’Autume,YujiaLi,TayfunTerzi,VladimirMikulik,IgorBabuschkin,AidanClark,DiegodeLasCasas,\\nAureliaGuy,ChrisJones,JamesBradbury,MatthewJohnson,BlakeHechtman,', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-43'),\n",
              " '92bf5edd-f4f2-4d40-bbf7-e3ff3aa71207': IndexNode(id_='92bf5edd-f4f2-4d40-bbf7-e3ff3aa71207', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-43', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='8139ff09b55b424c48584e2c277f913e26d461bf641f75b0e02ee283ff909b7c'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='b074ae2a-f9d6-47d2-a30c-d1b28016c134', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='eff1243c7736d7c29517425363b22edb534a6e11aab4f32558da5a93bfa3368e'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='4b1db09c-9d02-485a-8752-a2d7701f9098', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='3273bfed152aa165d026ddbf95fb8125f25eedf6cc1fd8cd966d692067c01282')}, hash='2f40b353cf14eb20a519aba2a46f8fafda0c6ee43e776675b3cbf8e4086328cf', text='ChrisJones,JamesBradbury,MatthewJohnson,BlakeHechtman,LauraWeidinger,Iason\\nGabriel,WilliamIsaac,EdLockhart,SimonOsindero,LauraRimell,ChrisDyer,OriolVinyals,Kareem\\nAyoub, Jeff Stanway, Lorrayne Bennett, Demis Hassabis, Koray Kavukcuoglu, and Geoffrey Irving. Scaling\\nlanguage models: Methods, analysis & insights from training gopher, 2022.\\nPranav Rajpurkar, Robin Jia, and Percy Liang.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-43'),\n",
              " '4b1db09c-9d02-485a-8752-a2d7701f9098': IndexNode(id_='4b1db09c-9d02-485a-8752-a2d7701f9098', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-43', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='8139ff09b55b424c48584e2c277f913e26d461bf641f75b0e02ee283ff909b7c'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='92bf5edd-f4f2-4d40-bbf7-e3ff3aa71207', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='2f40b353cf14eb20a519aba2a46f8fafda0c6ee43e776675b3cbf8e4086328cf'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='41d74bd4-20bb-4fd6-bfbc-adb266764039', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='1323242946e89f9ae1c7667a56c575d10e95b54c3678eeae546e0263395e2ab4')}, hash='3273bfed152aa165d026ddbf95fb8125f25eedf6cc1fd8cd966d692067c01282', text='Pranav Rajpurkar, Robin Jia, and Percy Liang. Know what you don’t know: Unanswerable questions for\\nsquad.arXiv preprint arXiv:1806.03822 , 2018.\\nVinay Venkatesh Ramasesh, Aitor Lewkowycz, and Ethan Dyer. Effect of scale on catastrophic forgetting in\\nneural networks. In International Conference on Learning Representations , 2021.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-43'),\n",
              " '41d74bd4-20bb-4fd6-bfbc-adb266764039': IndexNode(id_='41d74bd4-20bb-4fd6-bfbc-adb266764039', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-43', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='8139ff09b55b424c48584e2c277f913e26d461bf641f75b0e02ee283ff909b7c'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='4b1db09c-9d02-485a-8752-a2d7701f9098', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='3273bfed152aa165d026ddbf95fb8125f25eedf6cc1fd8cd966d692067c01282')}, hash='1323242946e89f9ae1c7667a56c575d10e95b54c3678eeae546e0263395e2ab4', text='In International Conference on Learning Representations , 2021.\\nStephenRoller,Y-LanBoureau,JasonWeston,AntoineBordes,EmilyDinan,AngelaFan,DavidGunning,\\nDa Ju, Margaret Li, Spencer Poff, et al. Open-domain conversational agents: Current progress, open\\nproblems, and future directions. arXiv preprint arXiv:2006.12442 , 2020.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-43'),\n",
              " '7400450b-94e6-457a-b8c4-8dd60ff8ad60': IndexNode(id_='7400450b-94e6-457a-b8c4-8dd60ff8ad60', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-43', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='8139ff09b55b424c48584e2c277f913e26d461bf641f75b0e02ee283ff909b7c'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='f4ba2cc1-5441-42a4-b6fb-b0ec8166431c', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='70d7621ddbdc979d57451ce59d96209aaf5498f28c58022fc564e2038bc8c417')}, hash='2d140d3cbff0b166ae5bcc59146ada59665c275f317842ee3ad1c9551ebc8903', text='URL\\nhttps://doi.org/10.48550/arXiv.2303.08774 .\\nLongOuyang,JeffreyWu,XuJiang,DiogoAlmeida,CarrollWainwright,PamelaMishkin,ChongZhang,\\nSandhini Agarwal, Katarina Slama, Alex Ray, et al. Training language models to follow instructions with\\nhuman feedback. Advances in Neural Information Processing Systems , 35:27730–27744, 2022.\\nDavidPatterson,JosephGonzalez,QuocLe,ChenLiang,Lluis-MiquelMunguia,DanielRothchild,David\\nSo, Maud Texier, and Jeff Dean. Carbon emissions and large neural network training. arXiv preprint\\narXiv:2104.10350 , 2021.\\nGuilherme Penedo, Quentin Malartic, Daniel Hesslow, Ruxandra Cojocaru, Alessandro Cappelli, Hamza\\nAlobeidli,BaptistePannier,EbtesamAlmazrouei,andJulienLaunay.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-43'),\n",
              " 'f4ba2cc1-5441-42a4-b6fb-b0ec8166431c': IndexNode(id_='f4ba2cc1-5441-42a4-b6fb-b0ec8166431c', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-43', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='8139ff09b55b424c48584e2c277f913e26d461bf641f75b0e02ee283ff909b7c'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='7400450b-94e6-457a-b8c4-8dd60ff8ad60', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='2d140d3cbff0b166ae5bcc59146ada59665c275f317842ee3ad1c9551ebc8903'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='4e21cf81-34b2-47df-a285-de67713cfc52', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='819ab520e8b0fade3e7d8049f330ed7edb4612e394e50d92a85285bd4ec282cd')}, hash='70d7621ddbdc979d57451ce59d96209aaf5498f28c58022fc564e2038bc8c417', text='Therefinedwebdatasetforfalcon\\nllm: Outperforming curated corpora with web data, and web data only, 2023.\\nReiner Pope, Sholto Douglas, Aakanksha Chowdhery, Jacob Devlin, James Bradbury, Anselm Levskaya,\\nJonathan Heek, Kefan Xiao, Shivani Agrawal, and Jeff Dean. Efficiently scaling transformer inference, 2022.\\nJack W. Rae, Sebastian Borgeaud, Trevor Cai, Katie Millican, Jordan Hoffmann, Francis Song, John Aslanides,\\nSarah Henderson, Roman Ring, Susannah Young, Eliza Rutherford, Tom Hennigan, Jacob Menick, Al-\\nbin Cassirer, Richard Powell, George van den Driessche, Lisa Anne Hendricks, Maribeth Rauh, Po-Sen\\nHuang,Amelia Glaese,JohannesWelbl, SumanthDathathri,Saffron Huang,JonathanUesato,John Mel-\\nlor, Irina Higgins, Antonia Creswell, Nat McAleese, Amy Wu, Erich Elsen, Siddhant Jayakumar,', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-43'),\n",
              " '4e21cf81-34b2-47df-a285-de67713cfc52': IndexNode(id_='4e21cf81-34b2-47df-a285-de67713cfc52', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-43', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='8139ff09b55b424c48584e2c277f913e26d461bf641f75b0e02ee283ff909b7c'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='f4ba2cc1-5441-42a4-b6fb-b0ec8166431c', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='70d7621ddbdc979d57451ce59d96209aaf5498f28c58022fc564e2038bc8c417'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='9259d24e-4cd2-440a-8789-0e2f0adf18b5', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='b4af51d29329948f7481109f6de1c90621e35a52e5390d1874cf294a3531e8a8')}, hash='819ab520e8b0fade3e7d8049f330ed7edb4612e394e50d92a85285bd4ec282cd', text='Nat McAleese, Amy Wu, Erich Elsen, Siddhant Jayakumar, Elena\\nBuchatskaya,DavidBudden,EsmeSutherland,KarenSimonyan,MichelaPaganini,LaurentSifre,Lena\\nMartens, Xiang Lorraine Li, Adhiguna Kuncoro, Aida Nematzadeh, Elena Gribovskaya, Domenic Donato,\\nAngeliki Lazaridou, Arthur Mensch, Jean-Baptiste Lespiau, Maria Tsimpoukelli, Nikolai Grigorev, Doug\\nFritz,ThibaultSottiaux,MantasPajarskas,TobyPohlen,ZhitaoGong,DanielToyama,CypriendeMas-\\nsond’Autume,YujiaLi,TayfunTerzi,VladimirMikulik,IgorBabuschkin,AidanClark,DiegodeLasCasas,\\nAureliaGuy,ChrisJones,JamesBradbury,MatthewJohnson,BlakeHechtman,LauraWeidinger,Iason\\nGabriel,WilliamIsaac,', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-43'),\n",
              " '9259d24e-4cd2-440a-8789-0e2f0adf18b5': IndexNode(id_='9259d24e-4cd2-440a-8789-0e2f0adf18b5', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-43', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='8139ff09b55b424c48584e2c277f913e26d461bf641f75b0e02ee283ff909b7c'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='4e21cf81-34b2-47df-a285-de67713cfc52', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='819ab520e8b0fade3e7d8049f330ed7edb4612e394e50d92a85285bd4ec282cd'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='fbcb0ef7-3ba0-41e6-8483-f20c7e725d38', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='9fe337cdcfae13e14cec8fa629766a5f4bd016951b600e80540138482615ea7e')}, hash='b4af51d29329948f7481109f6de1c90621e35a52e5390d1874cf294a3531e8a8', text='BlakeHechtman,LauraWeidinger,Iason\\nGabriel,WilliamIsaac,EdLockhart,SimonOsindero,LauraRimell,ChrisDyer,OriolVinyals,Kareem\\nAyoub, Jeff Stanway, Lorrayne Bennett, Demis Hassabis, Koray Kavukcuoglu, and Geoffrey Irving. Scaling\\nlanguage models: Methods, analysis & insights from training gopher, 2022.\\nPranav Rajpurkar, Robin Jia, and Percy Liang. Know what you don’t know: Unanswerable questions for\\nsquad.arXiv preprint arXiv:1806.03822 , 2018.\\nVinay Venkatesh Ramasesh, Aitor Lewkowycz, and Ethan Dyer. Effect of scale on catastrophic forgetting in\\nneural networks. In International Conference on Learning Representations , 2021.\\nStephenRoller,Y-LanBoureau,JasonWeston,AntoineBordes,EmilyDinan,AngelaFan,DavidGunning,\\nDa Ju, Margaret Li, Spencer Poff, et al.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-43'),\n",
              " 'fbcb0ef7-3ba0-41e6-8483-f20c7e725d38': IndexNode(id_='fbcb0ef7-3ba0-41e6-8483-f20c7e725d38', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-43', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='8139ff09b55b424c48584e2c277f913e26d461bf641f75b0e02ee283ff909b7c'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='9259d24e-4cd2-440a-8789-0e2f0adf18b5', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='b4af51d29329948f7481109f6de1c90621e35a52e5390d1874cf294a3531e8a8')}, hash='9fe337cdcfae13e14cec8fa629766a5f4bd016951b600e80540138482615ea7e', text='Open-domain conversational agents: Current progress, open\\nproblems, and future directions. arXiv preprint arXiv:2006.12442 , 2020.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-43'),\n",
              " 'a8a5caf8-5e3e-4d36-bef7-015da565fc1c': IndexNode(id_='a8a5caf8-5e3e-4d36-bef7-015da565fc1c', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-43', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='8139ff09b55b424c48584e2c277f913e26d461bf641f75b0e02ee283ff909b7c'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='edcff115-ac14-47ff-9731-0cc8635d8ec4', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='12925809297f0e539a28f1c0b7df174efab07f8c2c067d49830d7e8b088ca311')}, hash='b4346a0af2edc01b419bce9d47fa5b5f3e6f4252f8be409aabd672a3e31b7c3f', text='URL\\nhttps://doi.org/10.48550/arXiv.2303.08774 .\\nLongOuyang,JeffreyWu,XuJiang,DiogoAlmeida,CarrollWainwright,PamelaMishkin,ChongZhang,\\nSandhini Agarwal, Katarina Slama, Alex Ray, et al. Training language models to follow instructions with\\nhuman feedback. Advances in Neural Information Processing Systems , 35:27730–27744, 2022.\\nDavidPatterson,JosephGonzalez,QuocLe,ChenLiang,Lluis-MiquelMunguia,DanielRothchild,David\\nSo, Maud Texier, and Jeff Dean. Carbon emissions and large neural network training. arXiv preprint\\narXiv:2104.10350 , 2021.\\nGuilherme Penedo, Quentin Malartic, Daniel Hesslow, Ruxandra Cojocaru, Alessandro Cappelli, Hamza\\nAlobeidli,BaptistePannier,EbtesamAlmazrouei,andJulienLaunay. Therefinedwebdatasetforfalcon\\nllm: Outperforming curated corpora with web data, and web data only, 2023.\\nReiner Pope, Sholto Douglas, Aakanksha Chowdhery, Jacob Devlin, James Bradbury, Anselm Levskaya,\\nJonathan Heek, Kefan Xiao, Shivani Agrawal, and Jeff Dean. Efficiently scaling transformer inference, 2022.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-43'),\n",
              " 'edcff115-ac14-47ff-9731-0cc8635d8ec4': IndexNode(id_='edcff115-ac14-47ff-9731-0cc8635d8ec4', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-43', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='8139ff09b55b424c48584e2c277f913e26d461bf641f75b0e02ee283ff909b7c'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='a8a5caf8-5e3e-4d36-bef7-015da565fc1c', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='b4346a0af2edc01b419bce9d47fa5b5f3e6f4252f8be409aabd672a3e31b7c3f'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='94b8e49b-7b0a-4d74-ae10-52ffada5ab3c', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='c65293c56c858282c5be7394272647d84a3276f5cba2b4de1f9f817840a80471')}, hash='12925809297f0e539a28f1c0b7df174efab07f8c2c067d49830d7e8b088ca311', text='Efficiently scaling transformer inference, 2022.\\nJack W. Rae, Sebastian Borgeaud, Trevor Cai, Katie Millican, Jordan Hoffmann, Francis Song, John Aslanides,\\nSarah Henderson, Roman Ring, Susannah Young, Eliza Rutherford, Tom Hennigan, Jacob Menick, Al-\\nbin Cassirer, Richard Powell, George van den Driessche, Lisa Anne Hendricks, Maribeth Rauh, Po-Sen\\nHuang,Amelia Glaese,JohannesWelbl, SumanthDathathri,Saffron Huang,JonathanUesato,John Mel-\\nlor, Irina Higgins, Antonia Creswell, Nat McAleese, Amy Wu, Erich Elsen, Siddhant Jayakumar, Elena\\nBuchatskaya,DavidBudden,EsmeSutherland,KarenSimonyan,MichelaPaganini,LaurentSifre,Lena\\nMartens, Xiang Lorraine Li, Adhiguna Kuncoro, Aida Nematzadeh, Elena Gribovskaya, Domenic Donato,\\nAngeliki Lazaridou, Arthur Mensch, Jean-Baptiste Lespiau, Maria Tsimpoukelli, Nikolai Grigorev, Doug\\nFritz,ThibaultSottiaux,MantasPajarskas,TobyPohlen,ZhitaoGong,DanielToyama,CypriendeMas-\\nsond’Autume,YujiaLi,TayfunTerzi,VladimirMikulik,IgorBabuschkin,AidanClark,DiegodeLasCasas,\\nAureliaGuy,ChrisJones,JamesBradbury,MatthewJohnson,BlakeHechtman,LauraWeidinger,Iason\\nGabriel,WilliamIsaac,EdLockhart,SimonOsindero,LauraRimell,ChrisDyer,OriolVinyals,Kareem\\nAyoub, Jeff Stanway, Lorrayne Bennett, Demis Hassabis, Koray Kavukcuoglu, and Geoffrey Irving. Scaling\\nlanguage models: Methods, analysis & insights from training gopher, 2022.\\nPranav Rajpurkar, Robin Jia, and Percy Liang.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-43'),\n",
              " '94b8e49b-7b0a-4d74-ae10-52ffada5ab3c': IndexNode(id_='94b8e49b-7b0a-4d74-ae10-52ffada5ab3c', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-43', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='8139ff09b55b424c48584e2c277f913e26d461bf641f75b0e02ee283ff909b7c'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='edcff115-ac14-47ff-9731-0cc8635d8ec4', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='12925809297f0e539a28f1c0b7df174efab07f8c2c067d49830d7e8b088ca311')}, hash='c65293c56c858282c5be7394272647d84a3276f5cba2b4de1f9f817840a80471', text='Pranav Rajpurkar, Robin Jia, and Percy Liang. Know what you don’t know: Unanswerable questions for\\nsquad.arXiv preprint arXiv:1806.03822 , 2018.\\nVinay Venkatesh Ramasesh, Aitor Lewkowycz, and Ethan Dyer. Effect of scale on catastrophic forgetting in\\nneural networks. In International Conference on Learning Representations , 2021.\\nStephenRoller,Y-LanBoureau,JasonWeston,AntoineBordes,EmilyDinan,AngelaFan,DavidGunning,\\nDa Ju, Margaret Li, Spencer Poff, et al. Open-domain conversational agents: Current progress, open\\nproblems, and future directions. arXiv preprint arXiv:2006.12442 , 2020.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-43'),\n",
              " 'node-43': IndexNode(id_='node-43', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='415b7efc-e73f-4ac4-bbfd-c1546f099026', node_type=<ObjectType.DOCUMENT: '4'>, metadata={}, hash='231b3bd773f012c01b893ada9e009ecf25ee59934614c5a595c9bf1b3a123292'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='bab3f8d1-326d-4b03-8a9c-f9e50146f252', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='e02db946402a06ccf41ed0d6bc9fac8e7747b96842663e5e2537e48b8fd595fa'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='232652a9-ea53-4229-8e3d-509e826ede62', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='23ac98aee8bc10de55432b8e4fbcd972a0b77ba30589c92fda58872b7d477255')}, hash='8139ff09b55b424c48584e2c277f913e26d461bf641f75b0e02ee283ff909b7c', text='URL\\nhttps://doi.org/10.48550/arXiv.2303.08774 .\\nLongOuyang,JeffreyWu,XuJiang,DiogoAlmeida,CarrollWainwright,PamelaMishkin,ChongZhang,\\nSandhini Agarwal, Katarina Slama, Alex Ray, et al. Training language models to follow instructions with\\nhuman feedback. Advances in Neural Information Processing Systems , 35:27730–27744, 2022.\\nDavidPatterson,JosephGonzalez,QuocLe,ChenLiang,Lluis-MiquelMunguia,DanielRothchild,David\\nSo, Maud Texier, and Jeff Dean. Carbon emissions and large neural network training. arXiv preprint\\narXiv:2104.10350 , 2021.\\nGuilherme Penedo, Quentin Malartic, Daniel Hesslow, Ruxandra Cojocaru, Alessandro Cappelli, Hamza\\nAlobeidli,BaptistePannier,EbtesamAlmazrouei,andJulienLaunay. Therefinedwebdatasetforfalcon\\nllm: Outperforming curated corpora with web data, and web data only, 2023.\\nReiner Pope, Sholto Douglas, Aakanksha Chowdhery, Jacob Devlin, James Bradbury, Anselm Levskaya,\\nJonathan Heek, Kefan Xiao, Shivani Agrawal, and Jeff Dean. Efficiently scaling transformer inference, 2022.\\nJack W. Rae, Sebastian Borgeaud, Trevor Cai, Katie Millican, Jordan Hoffmann, Francis Song, John Aslanides,\\nSarah Henderson, Roman Ring, Susannah Young, Eliza Rutherford, Tom Hennigan, Jacob Menick, Al-\\nbin Cassirer, Richard Powell, George van den Driessche, Lisa Anne Hendricks, Maribeth Rauh, Po-Sen\\nHuang,Amelia Glaese,JohannesWelbl, SumanthDathathri,Saffron Huang,JonathanUesato,John Mel-\\nlor, Irina Higgins, Antonia Creswell, Nat McAleese, Amy Wu, Erich Elsen, Siddhant Jayakumar, Elena\\nBuchatskaya,DavidBudden,EsmeSutherland,KarenSimonyan,MichelaPaganini,LaurentSifre,Lena\\nMartens, Xiang Lorraine Li, Adhiguna Kuncoro, Aida Nematzadeh, Elena Gribovskaya, Domenic Donato,\\nAngeliki Lazaridou, Arthur Mensch, Jean-Baptiste Lespiau, Maria Tsimpoukelli, Nikolai Grigorev, Doug\\nFritz,ThibaultSottiaux,MantasPajarskas,TobyPohlen,ZhitaoGong,DanielToyama,CypriendeMas-\\nsond’Autume,YujiaLi,TayfunTerzi,VladimirMikulik,IgorBabuschkin,AidanClark,DiegodeLasCasas,\\nAureliaGuy,ChrisJones,JamesBradbury,MatthewJohnson,BlakeHechtman,LauraWeidinger,Iason\\nGabriel,WilliamIsaac,EdLockhart,SimonOsindero,LauraRimell,ChrisDyer,OriolVinyals,Kareem\\nAyoub, Jeff Stanway, Lorrayne Bennett, Demis Hassabis, Koray Kavukcuoglu, and Geoffrey Irving. Scaling\\nlanguage models: Methods, analysis & insights from training gopher, 2022.\\nPranav Rajpurkar, Robin Jia, and Percy Liang. Know what you don’t know: Unanswerable questions for\\nsquad.arXiv preprint arXiv:1806.03822 , 2018.\\nVinay Venkatesh Ramasesh, Aitor Lewkowycz, and Ethan Dyer. Effect of scale on catastrophic forgetting in\\nneural networks. In International Conference on Learning Representations , 2021.\\nStephenRoller,Y-LanBoureau,JasonWeston,AntoineBordes,EmilyDinan,AngelaFan,DavidGunning,\\nDa Ju, Margaret Li, Spencer Poff, et al. Open-domain conversational agents: Current progress, open\\nproblems, and future directions. arXiv preprint arXiv:2006.12442 , 2020.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-43'),\n",
              " '79196bd0-716e-426e-bc77-50033f33024d': IndexNode(id_='79196bd0-716e-426e-bc77-50033f33024d', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-44', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='23ac98aee8bc10de55432b8e4fbcd972a0b77ba30589c92fda58872b7d477255'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='c370a192-0ba0-4cb4-a170-51551abd91ec', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='c6268ae56c00b7f488ca088a70f61ee81e57707263612eabb6ddb18b3eb47e45')}, hash='4e8ca19a48a6ddea8087be9ec7b91eb7a13d9798bb89e47021d05e05bbac67a5', text='arXiv preprint arXiv:2006.12442 , 2020.\\nKeisuke Sakaguchi, Ronan Le Bras, Chandra Bhagavatula, and Yejin Choi. Winogrande: An adversarial\\nwinograd schema challenge at scale. Communications of the ACM , 64(9):99–106, 2021.\\nMaarten Sap, Hannah Rashkin, Derek Chen, Ronan LeBras, and Yejin Choi. Socialiqa: Commonsense\\nreasoning about social interactions.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-44'),\n",
              " 'c370a192-0ba0-4cb4-a170-51551abd91ec': IndexNode(id_='c370a192-0ba0-4cb4-a170-51551abd91ec', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-44', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='23ac98aee8bc10de55432b8e4fbcd972a0b77ba30589c92fda58872b7d477255'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='79196bd0-716e-426e-bc77-50033f33024d', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='4e8ca19a48a6ddea8087be9ec7b91eb7a13d9798bb89e47021d05e05bbac67a5'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='db0f93cd-b001-43f9-9031-d8dffe82f14a', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='45859af1168424c51800a922dfef8fc9af79f62bce3f926e3f7bf68999ccb914')}, hash='c6268ae56c00b7f488ca088a70f61ee81e57707263612eabb6ddb18b3eb47e45', text='Socialiqa: Commonsense\\nreasoning about social interactions. arXiv preprint arXiv:1904.09728 , 2019.\\nTevenLeScao,AngelaFan,ChristopherAkiki,ElliePavlick,SuzanaIlić,DanielHesslow,RomanCastagné,\\nAlexandra Sasha Luccioni, François Yvon, Matthias Gallé, et al. Bloom: A 176b-parameter open-access\\nmultilingual language model. arXiv preprint arXiv:2211.05100 , 2022.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-44'),\n",
              " 'db0f93cd-b001-43f9-9031-d8dffe82f14a': IndexNode(id_='db0f93cd-b001-43f9-9031-d8dffe82f14a', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-44', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='23ac98aee8bc10de55432b8e4fbcd972a0b77ba30589c92fda58872b7d477255'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='c370a192-0ba0-4cb4-a170-51551abd91ec', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='c6268ae56c00b7f488ca088a70f61ee81e57707263612eabb6ddb18b3eb47e45'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='1b3bdf25-1b04-408b-8ad4-1fe5694e5ab1', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='f4903964d935f543cd31550d6098fb7d786d7b12e820b9ea52248075cf574877')}, hash='45859af1168424c51800a922dfef8fc9af79f62bce3f926e3f7bf68999ccb914', text='arXiv preprint arXiv:2211.05100 , 2022.\\nTimoSchick,JaneDwivedi-Yu,RobertoDessì,RobertaRaileanu,MariaLomeli,LukeZettlemoyer,Nicola\\nCancedda,andThomasScialom. Toolformer: Languagemodelscanteachthemselvestousetools. arXiv\\npreprint arXiv:2302.04761 , 2023.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-44'),\n",
              " '1b3bdf25-1b04-408b-8ad4-1fe5694e5ab1': IndexNode(id_='1b3bdf25-1b04-408b-8ad4-1fe5694e5ab1', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-44', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='23ac98aee8bc10de55432b8e4fbcd972a0b77ba30589c92fda58872b7d477255'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='db0f93cd-b001-43f9-9031-d8dffe82f14a', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='45859af1168424c51800a922dfef8fc9af79f62bce3f926e3f7bf68999ccb914'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='9bab3654-0058-483d-a87f-67348bdd9634', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='495d67b9fc02ccbdb41472597707922b63c8f544c7284ed8add101c5b2fae27f')}, hash='f4903964d935f543cd31550d6098fb7d786d7b12e820b9ea52248075cf574877', text='arXiv\\npreprint arXiv:2302.04761 , 2023.\\nJohnSchulman,FilipWolski,PrafullaDhariwal,AlecRadford,andOlegKlimov.Proximalpolicyoptimization\\nalgorithms. arXiv preprint arXiv:1707.06347 , 2017.\\n42\\n\\nThomasScialom,Paul-AlexisDray,SylvainLamprier,BenjaminPiwowarski,andJacopoStaiano.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-44'),\n",
              " '9bab3654-0058-483d-a87f-67348bdd9634': IndexNode(id_='9bab3654-0058-483d-a87f-67348bdd9634', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-44', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='23ac98aee8bc10de55432b8e4fbcd972a0b77ba30589c92fda58872b7d477255'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='1b3bdf25-1b04-408b-8ad4-1fe5694e5ab1', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='f4903964d935f543cd31550d6098fb7d786d7b12e820b9ea52248075cf574877'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='a0624878-30dd-4bbb-9e06-ac16c5447a88', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='f2cad3d196fea3542b42c05a0df15ac55a9db8269ec170c339d6a2bfedb443a3')}, hash='495d67b9fc02ccbdb41472597707922b63c8f544c7284ed8add101c5b2fae27f', text='Discrim-\\ninative adversarial search for abstractive summarization. In Hal Daumé III and Aarti Singh, editors,\\nProceedings of the 37th International Conference on Machine Learning , volume 119 of Proceedings of Machine\\nLearningResearch ,pages8555–8564.PMLR,13–18Jul2020a. URL https://proceedings.mlr.press/v119/\\nscialom20a.html .', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-44'),\n",
              " 'a0624878-30dd-4bbb-9e06-ac16c5447a88': IndexNode(id_='a0624878-30dd-4bbb-9e06-ac16c5447a88', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-44', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='23ac98aee8bc10de55432b8e4fbcd972a0b77ba30589c92fda58872b7d477255'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='9bab3654-0058-483d-a87f-67348bdd9634', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='495d67b9fc02ccbdb41472597707922b63c8f544c7284ed8add101c5b2fae27f'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='d84db186-adbd-4c24-9c8d-10691c6b74ef', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='e43af6dce0cc9addfb27b1ddca8307c9d65f063be5355104cfc993c3d7f62d25')}, hash='f2cad3d196fea3542b42c05a0df15ac55a9db8269ec170c339d6a2bfedb443a3', text='ThomasScialom,Paul-AlexisDray,SylvainLamprier,BenjaminPiwowarski,andJacopoStaiano. Coldgans:\\nTaming language gans with cautious sampling strategies. Advances in Neural Information Processing Systems ,\\n33:18978–18989, 2020b.\\nRicoSennrich,BarryHaddow,andAlexandraBirch. Neuralmachinetranslationofrarewordswithsubword\\nunits, 2016.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-44'),\n",
              " 'd84db186-adbd-4c24-9c8d-10691c6b74ef': IndexNode(id_='d84db186-adbd-4c24-9c8d-10691c6b74ef', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-44', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='23ac98aee8bc10de55432b8e4fbcd972a0b77ba30589c92fda58872b7d477255'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='a0624878-30dd-4bbb-9e06-ac16c5447a88', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='f2cad3d196fea3542b42c05a0df15ac55a9db8269ec170c339d6a2bfedb443a3'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='24db9f55-86b7-4275-82e9-343a841486d6', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='5ad7948791e4ddab0bfa4731f2a56048bf124e6f656da9eb426802d9fabe4885')}, hash='e43af6dce0cc9addfb27b1ddca8307c9d65f063be5355104cfc993c3d7f62d25', text='UriShaham,EladSegal,MaorIvgi,AviaEfrat,OriYoran,AdiHaviv,AnkitGupta,WenhanXiong,MorGeva,\\nJonathan Berant, and Omer Levy. SCROLLS: Standardized CompaRison over long language sequences. In\\nProceedingsofthe2022ConferenceonEmpiricalMethodsinNaturalLanguageProcessing ,pages12007–12021,\\nAbu Dhabi, United Arab Emirates, December 2022.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-44'),\n",
              " '24db9f55-86b7-4275-82e9-343a841486d6': IndexNode(id_='24db9f55-86b7-4275-82e9-343a841486d6', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-44', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='23ac98aee8bc10de55432b8e4fbcd972a0b77ba30589c92fda58872b7d477255'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='d84db186-adbd-4c24-9c8d-10691c6b74ef', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='e43af6dce0cc9addfb27b1ddca8307c9d65f063be5355104cfc993c3d7f62d25'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='8281afec-d766-4afa-bb82-1621a1047726', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='f37b867548e13d5819ca08b5158b2d455bcde9e6921a099b31781b9e0b79e516')}, hash='5ad7948791e4ddab0bfa4731f2a56048bf124e6f656da9eb426802d9fabe4885', text='Association for Computational Linguistics. URL\\nhttps://aclanthology.org/2022.emnlp-main.823 .\\nNoam Shazeer. Fast transformer decoding: One write-head is all you need, 2019.\\nNoam Shazeer. Glu variants improve transformer, 2020.\\nMohammadShoeybi, MostofaPatwary, RaulPuri, PatrickLeGresley, JaredCasper, andBryanCatanzaro.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-44'),\n",
              " '8281afec-d766-4afa-bb82-1621a1047726': IndexNode(id_='8281afec-d766-4afa-bb82-1621a1047726', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-44', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='23ac98aee8bc10de55432b8e4fbcd972a0b77ba30589c92fda58872b7d477255'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='24db9f55-86b7-4275-82e9-343a841486d6', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='5ad7948791e4ddab0bfa4731f2a56048bf124e6f656da9eb426802d9fabe4885'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='627f47e2-613a-4111-b714-df20909fb46a', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='51c43212d5c1079d8b44a26c003cba545b4aa30f7a5ab3eac9f4473761e40c17')}, hash='f37b867548e13d5819ca08b5158b2d455bcde9e6921a099b31781b9e0b79e516', text='Megatron-lm: Training multi-billion parameter language models using model parallelism, 2019.\\nIlia Shumailov, Zakhar Shumaylov, Yiren Zhao, Yarin Gal, Nicolas Papernot, and Ross Anderson. The curse\\nof recursion: Training on generated data makes models forget. arXiv preprint arxiv:2305.17493 , 2023.\\nEric Michael Smith and Adina Williams. Hi, my name is martha: Using names to measure and mitigate bias\\nin generative dialogue models.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-44'),\n",
              " '627f47e2-613a-4111-b714-df20909fb46a': IndexNode(id_='627f47e2-613a-4111-b714-df20909fb46a', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-44', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='23ac98aee8bc10de55432b8e4fbcd972a0b77ba30589c92fda58872b7d477255'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='8281afec-d766-4afa-bb82-1621a1047726', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='f37b867548e13d5819ca08b5158b2d455bcde9e6921a099b31781b9e0b79e516')}, hash='51c43212d5c1079d8b44a26c003cba545b4aa30f7a5ab3eac9f4473761e40c17', text='arXiv preprint arXiv:2109.03300 , 2021.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-44'),\n",
              " 'd01e5f31-cb90-4669-a7ea-5d05fd5f8368': IndexNode(id_='d01e5f31-cb90-4669-a7ea-5d05fd5f8368', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-44', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='23ac98aee8bc10de55432b8e4fbcd972a0b77ba30589c92fda58872b7d477255'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='d584aaa3-d23a-4a01-ae4b-d785a556ee46', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='9dacdc035b17b20a114e1dae4190ee625699a7426353b2508ec0c02b801c1001')}, hash='3816fa168a5210f8c029cc33fda38e88aed9d4abbd48e9e9fb55ef5b7e65157c', text='arXiv preprint arXiv:2006.12442 , 2020.\\nKeisuke Sakaguchi, Ronan Le Bras, Chandra Bhagavatula, and Yejin Choi. Winogrande: An adversarial\\nwinograd schema challenge at scale. Communications of the ACM , 64(9):99–106, 2021.\\nMaarten Sap, Hannah Rashkin, Derek Chen, Ronan LeBras, and Yejin Choi. Socialiqa: Commonsense\\nreasoning about social interactions. arXiv preprint arXiv:1904.09728 , 2019.\\nTevenLeScao,AngelaFan,ChristopherAkiki,ElliePavlick,SuzanaIlić,DanielHesslow,RomanCastagné,\\nAlexandra Sasha Luccioni, François Yvon, Matthias Gallé, et al. Bloom: A 176b-parameter open-access\\nmultilingual language model. arXiv preprint arXiv:2211.05100 , 2022.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-44'),\n",
              " 'd584aaa3-d23a-4a01-ae4b-d785a556ee46': IndexNode(id_='d584aaa3-d23a-4a01-ae4b-d785a556ee46', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-44', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='23ac98aee8bc10de55432b8e4fbcd972a0b77ba30589c92fda58872b7d477255'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='d01e5f31-cb90-4669-a7ea-5d05fd5f8368', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='3816fa168a5210f8c029cc33fda38e88aed9d4abbd48e9e9fb55ef5b7e65157c'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='880338ac-6822-4ea8-97b0-6e640cee7d16', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='49a8d121a00ae9d31b7e86d34ea01a0ee49ef673c65a189b1eaaf940397dd379')}, hash='9dacdc035b17b20a114e1dae4190ee625699a7426353b2508ec0c02b801c1001', text='arXiv preprint arXiv:2211.05100 , 2022.\\nTimoSchick,JaneDwivedi-Yu,RobertoDessì,RobertaRaileanu,MariaLomeli,LukeZettlemoyer,Nicola\\nCancedda,andThomasScialom. Toolformer: Languagemodelscanteachthemselvestousetools. arXiv\\npreprint arXiv:2302.04761 , 2023.\\nJohnSchulman,FilipWolski,PrafullaDhariwal,AlecRadford,andOlegKlimov.Proximalpolicyoptimization\\nalgorithms. arXiv preprint arXiv:1707.06347 , 2017.\\n42\\n\\nThomasScialom,Paul-AlexisDray,SylvainLamprier,BenjaminPiwowarski,andJacopoStaiano. Discrim-\\ninative adversarial search for abstractive summarization.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-44'),\n",
              " '880338ac-6822-4ea8-97b0-6e640cee7d16': IndexNode(id_='880338ac-6822-4ea8-97b0-6e640cee7d16', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-44', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='23ac98aee8bc10de55432b8e4fbcd972a0b77ba30589c92fda58872b7d477255'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='d584aaa3-d23a-4a01-ae4b-d785a556ee46', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='9dacdc035b17b20a114e1dae4190ee625699a7426353b2508ec0c02b801c1001'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='4334e90c-e1c1-4fdc-9515-951d26752edc', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='57329266f76d5f3f21bc0ebe53b96a4159a75d7fa5baf96ce35e2057fbb79b22')}, hash='49a8d121a00ae9d31b7e86d34ea01a0ee49ef673c65a189b1eaaf940397dd379', text='Discrim-\\ninative adversarial search for abstractive summarization. In Hal Daumé III and Aarti Singh, editors,\\nProceedings of the 37th International Conference on Machine Learning , volume 119 of Proceedings of Machine\\nLearningResearch ,pages8555–8564.PMLR,13–18Jul2020a. URL https://proceedings.mlr.press/v119/\\nscialom20a.html .\\nThomasScialom,Paul-AlexisDray,SylvainLamprier,BenjaminPiwowarski,andJacopoStaiano. Coldgans:\\nTaming language gans with cautious sampling strategies. Advances in Neural Information Processing Systems ,\\n33:18978–18989, 2020b.\\nRicoSennrich,BarryHaddow,andAlexandraBirch. Neuralmachinetranslationofrarewordswithsubword\\nunits, 2016.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-44'),\n",
              " '4334e90c-e1c1-4fdc-9515-951d26752edc': IndexNode(id_='4334e90c-e1c1-4fdc-9515-951d26752edc', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-44', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='23ac98aee8bc10de55432b8e4fbcd972a0b77ba30589c92fda58872b7d477255'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='880338ac-6822-4ea8-97b0-6e640cee7d16', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='49a8d121a00ae9d31b7e86d34ea01a0ee49ef673c65a189b1eaaf940397dd379'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='c45c7d5e-274c-4006-b790-efe234e263a9', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='684c0797cd2df7520c3f1e8ab0e22a5d647af47a6a42353cece98121c9ec2487')}, hash='57329266f76d5f3f21bc0ebe53b96a4159a75d7fa5baf96ce35e2057fbb79b22', text='UriShaham,EladSegal,MaorIvgi,AviaEfrat,OriYoran,AdiHaviv,AnkitGupta,WenhanXiong,MorGeva,\\nJonathan Berant, and Omer Levy. SCROLLS: Standardized CompaRison over long language sequences. In\\nProceedingsofthe2022ConferenceonEmpiricalMethodsinNaturalLanguageProcessing ,pages12007–12021,\\nAbu Dhabi, United Arab Emirates, December 2022. Association for Computational Linguistics. URL\\nhttps://aclanthology.org/2022.emnlp-main.823 .\\nNoam Shazeer. Fast transformer decoding: One write-head is all you need, 2019.\\nNoam Shazeer. Glu variants improve transformer, 2020.\\nMohammadShoeybi, MostofaPatwary, RaulPuri, PatrickLeGresley, JaredCasper, andBryanCatanzaro.\\nMegatron-lm: Training multi-billion parameter language models using model parallelism, 2019.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-44'),\n",
              " 'c45c7d5e-274c-4006-b790-efe234e263a9': IndexNode(id_='c45c7d5e-274c-4006-b790-efe234e263a9', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-44', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='23ac98aee8bc10de55432b8e4fbcd972a0b77ba30589c92fda58872b7d477255'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='4334e90c-e1c1-4fdc-9515-951d26752edc', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='57329266f76d5f3f21bc0ebe53b96a4159a75d7fa5baf96ce35e2057fbb79b22')}, hash='684c0797cd2df7520c3f1e8ab0e22a5d647af47a6a42353cece98121c9ec2487', text='Ilia Shumailov, Zakhar Shumaylov, Yiren Zhao, Yarin Gal, Nicolas Papernot, and Ross Anderson. The curse\\nof recursion: Training on generated data makes models forget. arXiv preprint arxiv:2305.17493 , 2023.\\nEric Michael Smith and Adina Williams. Hi, my name is martha: Using names to measure and mitigate bias\\nin generative dialogue models. arXiv preprint arXiv:2109.03300 , 2021.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-44'),\n",
              " '39d98cae-b11a-4030-a260-48e53820e6e6': IndexNode(id_='39d98cae-b11a-4030-a260-48e53820e6e6', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-44', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='23ac98aee8bc10de55432b8e4fbcd972a0b77ba30589c92fda58872b7d477255'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='713357b6-418f-46b0-b11e-fc925f8e66fc', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='0daef845f02d4d2559a361a2940562a07524e4e5066ec7c3e2bc0364dea5134c')}, hash='2ded82a6ce733c0fac2d8889d23c14a45a1525b235dd5129b67b15e213bd0635', text='arXiv preprint arXiv:2006.12442 , 2020.\\nKeisuke Sakaguchi, Ronan Le Bras, Chandra Bhagavatula, and Yejin Choi. Winogrande: An adversarial\\nwinograd schema challenge at scale. Communications of the ACM , 64(9):99–106, 2021.\\nMaarten Sap, Hannah Rashkin, Derek Chen, Ronan LeBras, and Yejin Choi. Socialiqa: Commonsense\\nreasoning about social interactions. arXiv preprint arXiv:1904.09728 , 2019.\\nTevenLeScao,AngelaFan,ChristopherAkiki,ElliePavlick,SuzanaIlić,DanielHesslow,RomanCastagné,\\nAlexandra Sasha Luccioni, François Yvon, Matthias Gallé, et al. Bloom: A 176b-parameter open-access\\nmultilingual language model. arXiv preprint arXiv:2211.05100 , 2022.\\nTimoSchick,JaneDwivedi-Yu,RobertoDessì,RobertaRaileanu,MariaLomeli,LukeZettlemoyer,Nicola\\nCancedda,andThomasScialom. Toolformer: Languagemodelscanteachthemselvestousetools. arXiv\\npreprint arXiv:2302.04761 , 2023.\\nJohnSchulman,FilipWolski,PrafullaDhariwal,AlecRadford,andOlegKlimov.Proximalpolicyoptimization\\nalgorithms. arXiv preprint arXiv:1707.06347 , 2017.\\n42\\n\\nThomasScialom,Paul-AlexisDray,SylvainLamprier,BenjaminPiwowarski,andJacopoStaiano. Discrim-\\ninative adversarial search for abstractive summarization. In Hal Daumé III and Aarti Singh, editors,\\nProceedings of the 37th International Conference on Machine Learning , volume 119 of Proceedings of Machine\\nLearningResearch ,pages8555–8564.PMLR,13–18Jul2020a.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-44'),\n",
              " '713357b6-418f-46b0-b11e-fc925f8e66fc': IndexNode(id_='713357b6-418f-46b0-b11e-fc925f8e66fc', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-44', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='23ac98aee8bc10de55432b8e4fbcd972a0b77ba30589c92fda58872b7d477255'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='39d98cae-b11a-4030-a260-48e53820e6e6', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='2ded82a6ce733c0fac2d8889d23c14a45a1525b235dd5129b67b15e213bd0635')}, hash='0daef845f02d4d2559a361a2940562a07524e4e5066ec7c3e2bc0364dea5134c', text='URL https://proceedings.mlr.press/v119/\\nscialom20a.html .\\nThomasScialom,Paul-AlexisDray,SylvainLamprier,BenjaminPiwowarski,andJacopoStaiano. Coldgans:\\nTaming language gans with cautious sampling strategies. Advances in Neural Information Processing Systems ,\\n33:18978–18989, 2020b.\\nRicoSennrich,BarryHaddow,andAlexandraBirch. Neuralmachinetranslationofrarewordswithsubword\\nunits, 2016.\\nUriShaham,EladSegal,MaorIvgi,AviaEfrat,OriYoran,AdiHaviv,AnkitGupta,WenhanXiong,MorGeva,\\nJonathan Berant, and Omer Levy. SCROLLS: Standardized CompaRison over long language sequences. In\\nProceedingsofthe2022ConferenceonEmpiricalMethodsinNaturalLanguageProcessing ,pages12007–12021,\\nAbu Dhabi, United Arab Emirates, December 2022. Association for Computational Linguistics. URL\\nhttps://aclanthology.org/2022.emnlp-main.823 .\\nNoam Shazeer. Fast transformer decoding: One write-head is all you need, 2019.\\nNoam Shazeer. Glu variants improve transformer, 2020.\\nMohammadShoeybi, MostofaPatwary, RaulPuri, PatrickLeGresley, JaredCasper, andBryanCatanzaro.\\nMegatron-lm: Training multi-billion parameter language models using model parallelism, 2019.\\nIlia Shumailov, Zakhar Shumaylov, Yiren Zhao, Yarin Gal, Nicolas Papernot, and Ross Anderson. The curse\\nof recursion: Training on generated data makes models forget. arXiv preprint arxiv:2305.17493 , 2023.\\nEric Michael Smith and Adina Williams. Hi, my name is martha: Using names to measure and mitigate bias\\nin generative dialogue models. arXiv preprint arXiv:2109.03300 , 2021.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-44'),\n",
              " 'node-44': IndexNode(id_='node-44', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='415b7efc-e73f-4ac4-bbfd-c1546f099026', node_type=<ObjectType.DOCUMENT: '4'>, metadata={}, hash='231b3bd773f012c01b893ada9e009ecf25ee59934614c5a595c9bf1b3a123292'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='21e3a4e1-5209-4b1e-8b0f-5ff81c93a336', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='8139ff09b55b424c48584e2c277f913e26d461bf641f75b0e02ee283ff909b7c'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='3c2fc0ea-f51d-4d06-b913-9e00d8477b5f', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='131d7420eaeb36371b272dba10abcafb45e7619fb4d8f7298661c9b80a353379')}, hash='23ac98aee8bc10de55432b8e4fbcd972a0b77ba30589c92fda58872b7d477255', text='arXiv preprint arXiv:2006.12442 , 2020.\\nKeisuke Sakaguchi, Ronan Le Bras, Chandra Bhagavatula, and Yejin Choi. Winogrande: An adversarial\\nwinograd schema challenge at scale. Communications of the ACM , 64(9):99–106, 2021.\\nMaarten Sap, Hannah Rashkin, Derek Chen, Ronan LeBras, and Yejin Choi. Socialiqa: Commonsense\\nreasoning about social interactions. arXiv preprint arXiv:1904.09728 , 2019.\\nTevenLeScao,AngelaFan,ChristopherAkiki,ElliePavlick,SuzanaIlić,DanielHesslow,RomanCastagné,\\nAlexandra Sasha Luccioni, François Yvon, Matthias Gallé, et al. Bloom: A 176b-parameter open-access\\nmultilingual language model. arXiv preprint arXiv:2211.05100 , 2022.\\nTimoSchick,JaneDwivedi-Yu,RobertoDessì,RobertaRaileanu,MariaLomeli,LukeZettlemoyer,Nicola\\nCancedda,andThomasScialom. Toolformer: Languagemodelscanteachthemselvestousetools. arXiv\\npreprint arXiv:2302.04761 , 2023.\\nJohnSchulman,FilipWolski,PrafullaDhariwal,AlecRadford,andOlegKlimov.Proximalpolicyoptimization\\nalgorithms. arXiv preprint arXiv:1707.06347 , 2017.\\n42\\n\\nThomasScialom,Paul-AlexisDray,SylvainLamprier,BenjaminPiwowarski,andJacopoStaiano. Discrim-\\ninative adversarial search for abstractive summarization. In Hal Daumé III and Aarti Singh, editors,\\nProceedings of the 37th International Conference on Machine Learning , volume 119 of Proceedings of Machine\\nLearningResearch ,pages8555–8564.PMLR,13–18Jul2020a. URL https://proceedings.mlr.press/v119/\\nscialom20a.html .\\nThomasScialom,Paul-AlexisDray,SylvainLamprier,BenjaminPiwowarski,andJacopoStaiano. Coldgans:\\nTaming language gans with cautious sampling strategies. Advances in Neural Information Processing Systems ,\\n33:18978–18989, 2020b.\\nRicoSennrich,BarryHaddow,andAlexandraBirch. Neuralmachinetranslationofrarewordswithsubword\\nunits, 2016.\\nUriShaham,EladSegal,MaorIvgi,AviaEfrat,OriYoran,AdiHaviv,AnkitGupta,WenhanXiong,MorGeva,\\nJonathan Berant, and Omer Levy. SCROLLS: Standardized CompaRison over long language sequences. In\\nProceedingsofthe2022ConferenceonEmpiricalMethodsinNaturalLanguageProcessing ,pages12007–12021,\\nAbu Dhabi, United Arab Emirates, December 2022. Association for Computational Linguistics. URL\\nhttps://aclanthology.org/2022.emnlp-main.823 .\\nNoam Shazeer. Fast transformer decoding: One write-head is all you need, 2019.\\nNoam Shazeer. Glu variants improve transformer, 2020.\\nMohammadShoeybi, MostofaPatwary, RaulPuri, PatrickLeGresley, JaredCasper, andBryanCatanzaro.\\nMegatron-lm: Training multi-billion parameter language models using model parallelism, 2019.\\nIlia Shumailov, Zakhar Shumaylov, Yiren Zhao, Yarin Gal, Nicolas Papernot, and Ross Anderson. The curse\\nof recursion: Training on generated data makes models forget. arXiv preprint arxiv:2305.17493 , 2023.\\nEric Michael Smith and Adina Williams. Hi, my name is martha: Using names to measure and mitigate bias\\nin generative dialogue models. arXiv preprint arXiv:2109.03300 , 2021.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-44'),\n",
              " 'e0e0af8e-7208-4fb4-8725-90ae37d61fcd': IndexNode(id_='e0e0af8e-7208-4fb4-8725-90ae37d61fcd', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-45', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='131d7420eaeb36371b272dba10abcafb45e7619fb4d8f7298661c9b80a353379'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='6197afbe-3154-4dcc-8e39-762150081205', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='f34c87400251a335f4b7bc4785311c8fa8d2b07b9fc6dd5a73120ee303efc5f7')}, hash='5d7f3f54b6f6016cab277c8a3060158da99372bdf818fea3475c2bf81785a67e', text='arXiv preprint arXiv:2109.03300 , 2021.\\nEric Michael Smith, Melissa Hall, Melanie Kambadur, Eleonora Presani, and Adina Williams. “i’m sorry to\\nhear that”: Finding new biasesin language models with aholistic descriptor dataset. In Proceedings of the\\n2022 Conference on Empirical Methods in Natural Language Processing , pages 9180–9211, 2022.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-45'),\n",
              " '6197afbe-3154-4dcc-8e39-762150081205': IndexNode(id_='6197afbe-3154-4dcc-8e39-762150081205', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-45', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='131d7420eaeb36371b272dba10abcafb45e7619fb4d8f7298661c9b80a353379'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='e0e0af8e-7208-4fb4-8725-90ae37d61fcd', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='5d7f3f54b6f6016cab277c8a3060158da99372bdf818fea3475c2bf81785a67e'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='7367e95c-c6ba-4891-b4db-bacbf5f7496c', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='c224e53a50a3ec337ff7fed38ed0515cf6cc83de5a474cd7024d521d8b54cccc')}, hash='f34c87400251a335f4b7bc4785311c8fa8d2b07b9fc6dd5a73120ee303efc5f7', text='IreneSolaiman,ZeerakTalat,WilliamAgnew,LamaAhmad,DylanBaker,SuLinBlodgett,HalDauméIII,\\nJesse Dodge, Ellie Evans, Sara Hooker, et al. Evaluating the social impact of generative ai systems in\\nsystems and society. arXiv preprint arXiv:2306.05949 , 2023.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-45'),\n",
              " '7367e95c-c6ba-4891-b4db-bacbf5f7496c': IndexNode(id_='7367e95c-c6ba-4891-b4db-bacbf5f7496c', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-45', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='131d7420eaeb36371b272dba10abcafb45e7619fb4d8f7298661c9b80a353379'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='6197afbe-3154-4dcc-8e39-762150081205', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='f34c87400251a335f4b7bc4785311c8fa8d2b07b9fc6dd5a73120ee303efc5f7'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='b9d2249d-c1d1-4207-95f4-0248b1e095e6', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='6ca3afd1030ad6a63719f37df70bd74fffc50ba9c62d33056dba73a3cd0affa7')}, hash='c224e53a50a3ec337ff7fed38ed0515cf6cc83de5a474cd7024d521d8b54cccc', text='arXiv preprint arXiv:2306.05949 , 2023.\\nNisanStiennon,LongOuyang,JeffWu,DanielM.Ziegler,RyanLowe,ChelseaVoss,AlecRadford,Dario\\nAmodei, and Paul Christiano. Learning to summarize from human feedback. In NeurIPS, 2020.\\nJianlin Su, Yu Lu, Shengfeng Pan, Ahmed Murtadha, Bo Wen, and Yunfeng Liu.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-45'),\n",
              " 'b9d2249d-c1d1-4207-95f4-0248b1e095e6': IndexNode(id_='b9d2249d-c1d1-4207-95f4-0248b1e095e6', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-45', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='131d7420eaeb36371b272dba10abcafb45e7619fb4d8f7298661c9b80a353379'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='7367e95c-c6ba-4891-b4db-bacbf5f7496c', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='c224e53a50a3ec337ff7fed38ed0515cf6cc83de5a474cd7024d521d8b54cccc'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='7487b06c-fb3a-4b3d-9b45-66f693991526', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='971eddf8712358dcb995871979c8aea7e1974bc0669292c46ea0a148a3393af4')}, hash='6ca3afd1030ad6a63719f37df70bd74fffc50ba9c62d33056dba73a3cd0affa7', text='Roformer: Enhanced\\ntransformer with rotary position embedding, 2022.\\nMiracSuzgun,NathanScales,NathanaelSchärli,SebastianGehrmann,YiTay,HyungWonChung,Aakanksha\\nChowdhery, Quoc V Le, Ed H Chi, Denny Zhou, et al. Challenging big-bench tasks and whether chain-of-\\nthought can solve them. arXiv preprint arXiv:2210.09261 , 2022.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-45'),\n",
              " '7487b06c-fb3a-4b3d-9b45-66f693991526': IndexNode(id_='7487b06c-fb3a-4b3d-9b45-66f693991526', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-45', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='131d7420eaeb36371b272dba10abcafb45e7619fb4d8f7298661c9b80a353379'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='b9d2249d-c1d1-4207-95f4-0248b1e095e6', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='6ca3afd1030ad6a63719f37df70bd74fffc50ba9c62d33056dba73a3cd0affa7'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='88e0d57e-10bb-413a-b369-633aa6ef888e', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='7dd15b52362e07aa3805184aa74ea9e69d53e8116070f7be0a6fd04c77a94dae')}, hash='971eddf8712358dcb995871979c8aea7e1974bc0669292c46ea0a148a3393af4', text='arXiv preprint arXiv:2210.09261 , 2022.\\nGabriel Synnaeve, Jonas Gehring, Zeming Lin, Daniel Haziza, Nicolas Usunier, Danielle Rothermel, Vegard\\nMella, Da Ju, Nicolas Carion, Laura Gustafson, et al. Growing up together: Structured exploration for\\nlarge action spaces. 2019.\\nYarden Tal, Inbal Magar, and Roy Schwartz. Fewer errors, but more stereotypes? the effect of model\\nsize on gender bias.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-45'),\n",
              " '88e0d57e-10bb-413a-b369-633aa6ef888e': IndexNode(id_='88e0d57e-10bb-413a-b369-633aa6ef888e', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-45', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='131d7420eaeb36371b272dba10abcafb45e7619fb4d8f7298661c9b80a353379'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='7487b06c-fb3a-4b3d-9b45-66f693991526', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='971eddf8712358dcb995871979c8aea7e1974bc0669292c46ea0a148a3393af4'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='43b5e8d3-5531-46d0-a8dd-1db0602e2529', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='ec50224e0a389bce1f58cb77e2da41aa6589ca37493ffbe0d526eb7217589166')}, hash='7dd15b52362e07aa3805184aa74ea9e69d53e8116070f7be0a6fd04c77a94dae', text='Fewer errors, but more stereotypes? the effect of model\\nsize on gender bias. In Proceedings of the 4th Workshop on Gender Bias in Natural Language Processing\\n(GeBNLP) , pages 112–120, Seattle, Washington, July 2022. Association for Computational Linguistics. doi:\\n10.18653/v1/2022.gebnlp-1.13. URL https://aclanthology.org/2022.gebnlp-1.13 .', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-45'),\n",
              " '43b5e8d3-5531-46d0-a8dd-1db0602e2529': IndexNode(id_='43b5e8d3-5531-46d0-a8dd-1db0602e2529', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-45', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='131d7420eaeb36371b272dba10abcafb45e7619fb4d8f7298661c9b80a353379'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='88e0d57e-10bb-413a-b369-633aa6ef888e', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='7dd15b52362e07aa3805184aa74ea9e69d53e8116070f7be0a6fd04c77a94dae'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='4f49a5e2-6371-4cb9-aa52-2317dae0b282', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='25fe2db228749c45e0457a2f290c70751eca40955ea65ca98fb5630834cb2d24')}, hash='ec50224e0a389bce1f58cb77e2da41aa6589ca37493ffbe0d526eb7217589166', text='AlonTalmor,JonathanHerzig,NicholasLourie,andJonathanBerant.Commonsenseqa: Aquestionanswering\\nchallenge targeting commonsense knowledge. arXiv preprint arXiv:1811.00937 , 2018.\\nRohanTaori,IshaanGulrajani,TianyiZhang,YannDubois,XuechenLi,CarlosGuestrin,PercyLiang,and\\nTatsunoriB.Hashimoto. Stanfordalpaca: Aninstruction-followingllamamodel.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-45'),\n",
              " '4f49a5e2-6371-4cb9-aa52-2317dae0b282': IndexNode(id_='4f49a5e2-6371-4cb9-aa52-2317dae0b282', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-45', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='131d7420eaeb36371b272dba10abcafb45e7619fb4d8f7298661c9b80a353379'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='43b5e8d3-5531-46d0-a8dd-1db0602e2529', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='ec50224e0a389bce1f58cb77e2da41aa6589ca37493ffbe0d526eb7217589166'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='2792f4de-772e-4b6d-b9f2-2e3bf94fd0be', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='35379937a1a489be63b22c5d49a818a738367226c66fa80deedc6a2d1856f9f5')}, hash='25fe2db228749c45e0457a2f290c70751eca40955ea65ca98fb5630834cb2d24', text='Stanfordalpaca: Aninstruction-followingllamamodel. https://github.com/\\ntatsu-lab/stanford_alpaca , 2023.\\nRoss Taylor, Marcin Kardas, Guillem Cucurull, Thomas Scialom, Anthony Hartshorn, Elvis Saravia, Andrew\\nPoulton,ViktorKerkez,andRobertStojnic. Galactica: Alargelanguagemodelforscience.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-45'),\n",
              " '2792f4de-772e-4b6d-b9f2-2e3bf94fd0be': IndexNode(id_='2792f4de-772e-4b6d-b9f2-2e3bf94fd0be', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-45', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='131d7420eaeb36371b272dba10abcafb45e7619fb4d8f7298661c9b80a353379'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='4f49a5e2-6371-4cb9-aa52-2317dae0b282', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='25fe2db228749c45e0457a2f290c70751eca40955ea65ca98fb5630834cb2d24'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='35095d27-62ad-4ad1-a979-339017381402', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='f22f3b06d819f128b4b7a910f6210fef16efad48d3ff8dd8482cabebe5dbae84')}, hash='35379937a1a489be63b22c5d49a818a738367226c66fa80deedc6a2d1856f9f5', text='Galactica: Alargelanguagemodelforscience. arXivpreprint\\narXiv:2211.09085 , 2022.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-45'),\n",
              " '35095d27-62ad-4ad1-a979-339017381402': IndexNode(id_='35095d27-62ad-4ad1-a979-339017381402', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-45', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='131d7420eaeb36371b272dba10abcafb45e7619fb4d8f7298661c9b80a353379'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='2792f4de-772e-4b6d-b9f2-2e3bf94fd0be', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='35379937a1a489be63b22c5d49a818a738367226c66fa80deedc6a2d1856f9f5'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='2d8163f2-92e6-4e99-b7b9-fc703ad36d02', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='030837d8a264cc43c21655ea7dbf49ce95d001d46419649446d2663afa6a97ee')}, hash='f22f3b06d819f128b4b7a910f6210fef16efad48d3ff8dd8482cabebe5dbae84', text='arXivpreprint\\narXiv:2211.09085 , 2022.\\n43\\n\\nHugoTouvron,ThibautLavril,GautierIzacard,XavierMartinet,Marie-AnneLachaux,TimothéeLacroix,\\nBaptiste Rozière, Naman Goyal, Eric Hambro, Faisal Azhar, Aur’elien Rodriguez, Armand Joulin, Edouard\\nGrave, and Guillaume Lample. Llama: Open and efficient foundation language models.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-45'),\n",
              " '2d8163f2-92e6-4e99-b7b9-fc703ad36d02': IndexNode(id_='2d8163f2-92e6-4e99-b7b9-fc703ad36d02', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-45', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='131d7420eaeb36371b272dba10abcafb45e7619fb4d8f7298661c9b80a353379'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='35095d27-62ad-4ad1-a979-339017381402', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='f22f3b06d819f128b4b7a910f6210fef16efad48d3ff8dd8482cabebe5dbae84')}, hash='030837d8a264cc43c21655ea7dbf49ce95d001d46419649446d2663afa6a97ee', text='Llama: Open and efficient foundation language models. arXiv preprint\\narXiv:2302.13971 , 2023.\\nAshish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser,\\nand Illia Polosukhin. Attention is all you need, 2017.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-45'),\n",
              " '9f15a61e-c2b7-41dc-85f8-13c6605ef8af': IndexNode(id_='9f15a61e-c2b7-41dc-85f8-13c6605ef8af', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-45', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='131d7420eaeb36371b272dba10abcafb45e7619fb4d8f7298661c9b80a353379'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='d07835d1-8086-4552-92d6-1561205caad8', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='d74e434a855bdf424461a5e7e1ac548f9b60de814c5e4e0b1a644252d47420d4')}, hash='be776943b033c1f5d090208f79e1eab179ed14dec8822167b01f123dd9d38a02', text='arXiv preprint arXiv:2109.03300 , 2021.\\nEric Michael Smith, Melissa Hall, Melanie Kambadur, Eleonora Presani, and Adina Williams. “i’m sorry to\\nhear that”: Finding new biasesin language models with aholistic descriptor dataset. In Proceedings of the\\n2022 Conference on Empirical Methods in Natural Language Processing , pages 9180–9211, 2022.\\nIreneSolaiman,ZeerakTalat,WilliamAgnew,LamaAhmad,DylanBaker,SuLinBlodgett,HalDauméIII,\\nJesse Dodge, Ellie Evans, Sara Hooker, et al. Evaluating the social impact of generative ai systems in\\nsystems and society. arXiv preprint arXiv:2306.05949 , 2023.\\nNisanStiennon,LongOuyang,JeffWu,DanielM.Ziegler,RyanLowe,ChelseaVoss,AlecRadford,Dario\\nAmodei, and Paul Christiano. Learning to summarize from human feedback.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-45'),\n",
              " 'd07835d1-8086-4552-92d6-1561205caad8': IndexNode(id_='d07835d1-8086-4552-92d6-1561205caad8', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-45', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='131d7420eaeb36371b272dba10abcafb45e7619fb4d8f7298661c9b80a353379'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='9f15a61e-c2b7-41dc-85f8-13c6605ef8af', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='be776943b033c1f5d090208f79e1eab179ed14dec8822167b01f123dd9d38a02'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='51ec760d-094d-47cd-b4ca-40f17e3cc8c2', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='84931d2cfd02d90ea1dee2cdc32a709282a8994cf26eb109ecc7c157f6aa99a1')}, hash='d74e434a855bdf424461a5e7e1ac548f9b60de814c5e4e0b1a644252d47420d4', text='Learning to summarize from human feedback. In NeurIPS, 2020.\\nJianlin Su, Yu Lu, Shengfeng Pan, Ahmed Murtadha, Bo Wen, and Yunfeng Liu. Roformer: Enhanced\\ntransformer with rotary position embedding, 2022.\\nMiracSuzgun,NathanScales,NathanaelSchärli,SebastianGehrmann,YiTay,HyungWonChung,Aakanksha\\nChowdhery, Quoc V Le, Ed H Chi, Denny Zhou, et al. Challenging big-bench tasks and whether chain-of-\\nthought can solve them. arXiv preprint arXiv:2210.09261 , 2022.\\nGabriel Synnaeve, Jonas Gehring, Zeming Lin, Daniel Haziza, Nicolas Usunier, Danielle Rothermel, Vegard\\nMella, Da Ju, Nicolas Carion, Laura Gustafson, et al. Growing up together: Structured exploration for\\nlarge action spaces. 2019.\\nYarden Tal, Inbal Magar, and Roy Schwartz.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-45'),\n",
              " '51ec760d-094d-47cd-b4ca-40f17e3cc8c2': IndexNode(id_='51ec760d-094d-47cd-b4ca-40f17e3cc8c2', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-45', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='131d7420eaeb36371b272dba10abcafb45e7619fb4d8f7298661c9b80a353379'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='d07835d1-8086-4552-92d6-1561205caad8', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='d74e434a855bdf424461a5e7e1ac548f9b60de814c5e4e0b1a644252d47420d4'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='42496ed6-705c-4d08-8074-f9568f7a7051', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='ac2da72e92e329ab642076dc56b808b1d4c4b66dd6c32d4bcd3a6bec9bc4b092')}, hash='84931d2cfd02d90ea1dee2cdc32a709282a8994cf26eb109ecc7c157f6aa99a1', text='2019.\\nYarden Tal, Inbal Magar, and Roy Schwartz. Fewer errors, but more stereotypes? the effect of model\\nsize on gender bias. In Proceedings of the 4th Workshop on Gender Bias in Natural Language Processing\\n(GeBNLP) , pages 112–120, Seattle, Washington, July 2022. Association for Computational Linguistics. doi:\\n10.18653/v1/2022.gebnlp-1.13. URL https://aclanthology.org/2022.gebnlp-1.13 .\\nAlonTalmor,JonathanHerzig,NicholasLourie,andJonathanBerant.Commonsenseqa: Aquestionanswering\\nchallenge targeting commonsense knowledge. arXiv preprint arXiv:1811.00937 , 2018.\\nRohanTaori,IshaanGulrajani,TianyiZhang,YannDubois,XuechenLi,CarlosGuestrin,PercyLiang,and\\nTatsunoriB.Hashimoto. Stanfordalpaca: Aninstruction-followingllamamodel.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-45'),\n",
              " '42496ed6-705c-4d08-8074-f9568f7a7051': IndexNode(id_='42496ed6-705c-4d08-8074-f9568f7a7051', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-45', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='131d7420eaeb36371b272dba10abcafb45e7619fb4d8f7298661c9b80a353379'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='51ec760d-094d-47cd-b4ca-40f17e3cc8c2', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='84931d2cfd02d90ea1dee2cdc32a709282a8994cf26eb109ecc7c157f6aa99a1'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='5e940718-6694-4056-b480-5b2c98488d26', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='addec6efb39d38dd8bb06a8fef9bdf5607558bd5db869cf1390f2d9eff178663')}, hash='ac2da72e92e329ab642076dc56b808b1d4c4b66dd6c32d4bcd3a6bec9bc4b092', text='Stanfordalpaca: Aninstruction-followingllamamodel. https://github.com/\\ntatsu-lab/stanford_alpaca , 2023.\\nRoss Taylor, Marcin Kardas, Guillem Cucurull, Thomas Scialom, Anthony Hartshorn, Elvis Saravia, Andrew\\nPoulton,ViktorKerkez,andRobertStojnic. Galactica: Alargelanguagemodelforscience. arXivpreprint\\narXiv:2211.09085 , 2022.\\n43\\n\\nHugoTouvron,ThibautLavril,GautierIzacard,XavierMartinet,Marie-AnneLachaux,TimothéeLacroix,\\nBaptiste Rozière, Naman Goyal, Eric Hambro, Faisal Azhar, Aur’elien Rodriguez, Armand Joulin, Edouard\\nGrave, and Guillaume Lample. Llama: Open and efficient foundation language models. arXiv preprint\\narXiv:2302.13971 , 2023.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-45'),\n",
              " '5e940718-6694-4056-b480-5b2c98488d26': IndexNode(id_='5e940718-6694-4056-b480-5b2c98488d26', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-45', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='131d7420eaeb36371b272dba10abcafb45e7619fb4d8f7298661c9b80a353379'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='42496ed6-705c-4d08-8074-f9568f7a7051', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='ac2da72e92e329ab642076dc56b808b1d4c4b66dd6c32d4bcd3a6bec9bc4b092')}, hash='addec6efb39d38dd8bb06a8fef9bdf5607558bd5db869cf1390f2d9eff178663', text='arXiv preprint\\narXiv:2302.13971 , 2023.\\nAshish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser,\\nand Illia Polosukhin. Attention is all you need, 2017.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-45'),\n",
              " '8dd99d5d-675b-44f0-a41a-d55598749f64': IndexNode(id_='8dd99d5d-675b-44f0-a41a-d55598749f64', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-45', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='131d7420eaeb36371b272dba10abcafb45e7619fb4d8f7298661c9b80a353379'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='bd1aaf90-8ae1-4b24-a425-419d2d3f2279', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='12eecc02ac87ae898865807460fb637094459beb5041068298f00dde446babb8')}, hash='86391fb7bab80df2133760cb460c5651b259411bdec75d20bbba3d19a0701e03', text='arXiv preprint arXiv:2109.03300 , 2021.\\nEric Michael Smith, Melissa Hall, Melanie Kambadur, Eleonora Presani, and Adina Williams. “i’m sorry to\\nhear that”: Finding new biasesin language models with aholistic descriptor dataset. In Proceedings of the\\n2022 Conference on Empirical Methods in Natural Language Processing , pages 9180–9211, 2022.\\nIreneSolaiman,ZeerakTalat,WilliamAgnew,LamaAhmad,DylanBaker,SuLinBlodgett,HalDauméIII,\\nJesse Dodge, Ellie Evans, Sara Hooker, et al. Evaluating the social impact of generative ai systems in\\nsystems and society. arXiv preprint arXiv:2306.05949 , 2023.\\nNisanStiennon,LongOuyang,JeffWu,DanielM.Ziegler,RyanLowe,ChelseaVoss,AlecRadford,Dario\\nAmodei, and Paul Christiano. Learning to summarize from human feedback. In NeurIPS, 2020.\\nJianlin Su, Yu Lu, Shengfeng Pan, Ahmed Murtadha, Bo Wen, and Yunfeng Liu. Roformer: Enhanced\\ntransformer with rotary position embedding, 2022.\\nMiracSuzgun,NathanScales,NathanaelSchärli,SebastianGehrmann,YiTay,HyungWonChung,Aakanksha\\nChowdhery, Quoc V Le, Ed H Chi, Denny Zhou, et al. Challenging big-bench tasks and whether chain-of-\\nthought can solve them. arXiv preprint arXiv:2210.09261 , 2022.\\nGabriel Synnaeve, Jonas Gehring, Zeming Lin, Daniel Haziza, Nicolas Usunier, Danielle Rothermel, Vegard\\nMella, Da Ju, Nicolas Carion, Laura Gustafson, et al. Growing up together: Structured exploration for\\nlarge action spaces. 2019.\\nYarden Tal, Inbal Magar, and Roy Schwartz. Fewer errors, but more stereotypes? the effect of model\\nsize on gender bias.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-45'),\n",
              " 'bd1aaf90-8ae1-4b24-a425-419d2d3f2279': IndexNode(id_='bd1aaf90-8ae1-4b24-a425-419d2d3f2279', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-45', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='131d7420eaeb36371b272dba10abcafb45e7619fb4d8f7298661c9b80a353379'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='8dd99d5d-675b-44f0-a41a-d55598749f64', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='86391fb7bab80df2133760cb460c5651b259411bdec75d20bbba3d19a0701e03'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='8db8dd04-d06c-4656-96bb-be56f59cbf70', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='addec6efb39d38dd8bb06a8fef9bdf5607558bd5db869cf1390f2d9eff178663')}, hash='12eecc02ac87ae898865807460fb637094459beb5041068298f00dde446babb8', text='Fewer errors, but more stereotypes? the effect of model\\nsize on gender bias. In Proceedings of the 4th Workshop on Gender Bias in Natural Language Processing\\n(GeBNLP) , pages 112–120, Seattle, Washington, July 2022. Association for Computational Linguistics. doi:\\n10.18653/v1/2022.gebnlp-1.13. URL https://aclanthology.org/2022.gebnlp-1.13 .\\nAlonTalmor,JonathanHerzig,NicholasLourie,andJonathanBerant.Commonsenseqa: Aquestionanswering\\nchallenge targeting commonsense knowledge. arXiv preprint arXiv:1811.00937 , 2018.\\nRohanTaori,IshaanGulrajani,TianyiZhang,YannDubois,XuechenLi,CarlosGuestrin,PercyLiang,and\\nTatsunoriB.Hashimoto. Stanfordalpaca: Aninstruction-followingllamamodel. https://github.com/\\ntatsu-lab/stanford_alpaca , 2023.\\nRoss Taylor, Marcin Kardas, Guillem Cucurull, Thomas Scialom, Anthony Hartshorn, Elvis Saravia, Andrew\\nPoulton,ViktorKerkez,andRobertStojnic. Galactica: Alargelanguagemodelforscience. arXivpreprint\\narXiv:2211.09085 , 2022.\\n43\\n\\nHugoTouvron,ThibautLavril,GautierIzacard,XavierMartinet,Marie-AnneLachaux,TimothéeLacroix,\\nBaptiste Rozière, Naman Goyal, Eric Hambro, Faisal Azhar, Aur’elien Rodriguez, Armand Joulin, Edouard\\nGrave, and Guillaume Lample. Llama: Open and efficient foundation language models. arXiv preprint\\narXiv:2302.13971 , 2023.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-45'),\n",
              " '8db8dd04-d06c-4656-96bb-be56f59cbf70': IndexNode(id_='8db8dd04-d06c-4656-96bb-be56f59cbf70', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-45', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='131d7420eaeb36371b272dba10abcafb45e7619fb4d8f7298661c9b80a353379'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='bd1aaf90-8ae1-4b24-a425-419d2d3f2279', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='12eecc02ac87ae898865807460fb637094459beb5041068298f00dde446babb8')}, hash='addec6efb39d38dd8bb06a8fef9bdf5607558bd5db869cf1390f2d9eff178663', text='arXiv preprint\\narXiv:2302.13971 , 2023.\\nAshish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser,\\nand Illia Polosukhin. Attention is all you need, 2017.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-45'),\n",
              " 'node-45': IndexNode(id_='node-45', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='415b7efc-e73f-4ac4-bbfd-c1546f099026', node_type=<ObjectType.DOCUMENT: '4'>, metadata={}, hash='231b3bd773f012c01b893ada9e009ecf25ee59934614c5a595c9bf1b3a123292'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='232652a9-ea53-4229-8e3d-509e826ede62', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='23ac98aee8bc10de55432b8e4fbcd972a0b77ba30589c92fda58872b7d477255'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='b9f3acb0-adf8-407b-a26e-1d8f2a15d6f6', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='51c1798761b8340bb1f3bcccc79abc7af14e4438d32ee97892ccb80d1924764b')}, hash='131d7420eaeb36371b272dba10abcafb45e7619fb4d8f7298661c9b80a353379', text='arXiv preprint arXiv:2109.03300 , 2021.\\nEric Michael Smith, Melissa Hall, Melanie Kambadur, Eleonora Presani, and Adina Williams. “i’m sorry to\\nhear that”: Finding new biasesin language models with aholistic descriptor dataset. In Proceedings of the\\n2022 Conference on Empirical Methods in Natural Language Processing , pages 9180–9211, 2022.\\nIreneSolaiman,ZeerakTalat,WilliamAgnew,LamaAhmad,DylanBaker,SuLinBlodgett,HalDauméIII,\\nJesse Dodge, Ellie Evans, Sara Hooker, et al. Evaluating the social impact of generative ai systems in\\nsystems and society. arXiv preprint arXiv:2306.05949 , 2023.\\nNisanStiennon,LongOuyang,JeffWu,DanielM.Ziegler,RyanLowe,ChelseaVoss,AlecRadford,Dario\\nAmodei, and Paul Christiano. Learning to summarize from human feedback. In NeurIPS, 2020.\\nJianlin Su, Yu Lu, Shengfeng Pan, Ahmed Murtadha, Bo Wen, and Yunfeng Liu. Roformer: Enhanced\\ntransformer with rotary position embedding, 2022.\\nMiracSuzgun,NathanScales,NathanaelSchärli,SebastianGehrmann,YiTay,HyungWonChung,Aakanksha\\nChowdhery, Quoc V Le, Ed H Chi, Denny Zhou, et al. Challenging big-bench tasks and whether chain-of-\\nthought can solve them. arXiv preprint arXiv:2210.09261 , 2022.\\nGabriel Synnaeve, Jonas Gehring, Zeming Lin, Daniel Haziza, Nicolas Usunier, Danielle Rothermel, Vegard\\nMella, Da Ju, Nicolas Carion, Laura Gustafson, et al. Growing up together: Structured exploration for\\nlarge action spaces. 2019.\\nYarden Tal, Inbal Magar, and Roy Schwartz. Fewer errors, but more stereotypes? the effect of model\\nsize on gender bias. In Proceedings of the 4th Workshop on Gender Bias in Natural Language Processing\\n(GeBNLP) , pages 112–120, Seattle, Washington, July 2022. Association for Computational Linguistics. doi:\\n10.18653/v1/2022.gebnlp-1.13. URL https://aclanthology.org/2022.gebnlp-1.13 .\\nAlonTalmor,JonathanHerzig,NicholasLourie,andJonathanBerant.Commonsenseqa: Aquestionanswering\\nchallenge targeting commonsense knowledge. arXiv preprint arXiv:1811.00937 , 2018.\\nRohanTaori,IshaanGulrajani,TianyiZhang,YannDubois,XuechenLi,CarlosGuestrin,PercyLiang,and\\nTatsunoriB.Hashimoto. Stanfordalpaca: Aninstruction-followingllamamodel. https://github.com/\\ntatsu-lab/stanford_alpaca , 2023.\\nRoss Taylor, Marcin Kardas, Guillem Cucurull, Thomas Scialom, Anthony Hartshorn, Elvis Saravia, Andrew\\nPoulton,ViktorKerkez,andRobertStojnic. Galactica: Alargelanguagemodelforscience. arXivpreprint\\narXiv:2211.09085 , 2022.\\n43\\n\\nHugoTouvron,ThibautLavril,GautierIzacard,XavierMartinet,Marie-AnneLachaux,TimothéeLacroix,\\nBaptiste Rozière, Naman Goyal, Eric Hambro, Faisal Azhar, Aur’elien Rodriguez, Armand Joulin, Edouard\\nGrave, and Guillaume Lample. Llama: Open and efficient foundation language models. arXiv preprint\\narXiv:2302.13971 , 2023.\\nAshish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser,\\nand Illia Polosukhin. Attention is all you need, 2017.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-45'),\n",
              " 'c9736e2d-5fb1-4533-9d63-c579955c1595': IndexNode(id_='c9736e2d-5fb1-4533-9d63-c579955c1595', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-46', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='51c1798761b8340bb1f3bcccc79abc7af14e4438d32ee97892ccb80d1924764b'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='0f388790-6594-4c12-934e-5145ecb4ac8e', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='25ea3ab17bfa0554a202b5f8ca90d3440310263fac68949cf9fdfa86180994ca')}, hash='5b9155eb071df2cc46c06ab356f9c316007c6ea390f1307d4beba42a52f04bf2', text='Attention is all you need, 2017.\\nOriol Vinyals, Igor Babuschkin, Wojciech M Czarnecki, Michaël Mathieu, Andrew Dudzik, Junyoung Chung,\\nDavid H Choi, Richard Powell, Timo Ewalds, Petko Georgiev, et al. Grandmaster level in starcraft ii using\\nmulti-agent reinforcement learning. Nature, 575(7782):350–354, 2019.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-46'),\n",
              " '0f388790-6594-4c12-934e-5145ecb4ac8e': IndexNode(id_='0f388790-6594-4c12-934e-5145ecb4ac8e', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-46', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='51c1798761b8340bb1f3bcccc79abc7af14e4438d32ee97892ccb80d1924764b'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='c9736e2d-5fb1-4533-9d63-c579955c1595', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='5b9155eb071df2cc46c06ab356f9c316007c6ea390f1307d4beba42a52f04bf2'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='30166d2b-399d-4b85-80a8-731157b37507', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='ac44e124162ebfa32055ff3e3895dda47b52993dd173e4976dc39985a3f9ec23')}, hash='25ea3ab17bfa0554a202b5f8ca90d3440310263fac68949cf9fdfa86180994ca', text='Nature, 575(7782):350–354, 2019.\\nYizhong Wang, Yeganeh Kordi, Swaroop Mishra, Alisa Liu, Noah A Smith, Daniel Khashabi, and Han-\\nnanehHajishirzi. Self-instruct: Aligninglanguagemodel withselfgeneratedinstructions. arXivpreprint\\narXiv:2212.10560 , 2022.\\nMichael Webb. The impact of artificial intelligence on the labor market. Available at SSRN 3482150 , 2019.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-46'),\n",
              " '30166d2b-399d-4b85-80a8-731157b37507': IndexNode(id_='30166d2b-399d-4b85-80a8-731157b37507', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-46', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='51c1798761b8340bb1f3bcccc79abc7af14e4438d32ee97892ccb80d1924764b'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='0f388790-6594-4c12-934e-5145ecb4ac8e', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='25ea3ab17bfa0554a202b5f8ca90d3440310263fac68949cf9fdfa86180994ca'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='5d9b6e0a-0914-4ccb-8131-1f100492bbbd', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='c802d0bc37b97c7d912cd3071afb2c0b8f68452c744aef983eb08020f77f2d58')}, hash='ac44e124162ebfa32055ff3e3895dda47b52993dd173e4976dc39985a3f9ec23', text='Available at SSRN 3482150 , 2019.\\nJason Wei, MaartenBosma, VincentZhao, KelvinGuu, Adams WeiYu, Brian Lester, NanDu, AndrewM Dai,\\nand Quoc V Le. Finetuned language models are zero-shot learners. In International Conference on Learning\\nRepresentations , 2021.\\nJasonWei,MaartenBosma,VincentZhao,KelvinGuu,AdamsWeiYu,BrianLester,NanDu,AndrewM.Dai,\\nand Quoc V Le.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-46'),\n",
              " '5d9b6e0a-0914-4ccb-8131-1f100492bbbd': IndexNode(id_='5d9b6e0a-0914-4ccb-8131-1f100492bbbd', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-46', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='51c1798761b8340bb1f3bcccc79abc7af14e4438d32ee97892ccb80d1924764b'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='30166d2b-399d-4b85-80a8-731157b37507', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='ac44e124162ebfa32055ff3e3895dda47b52993dd173e4976dc39985a3f9ec23'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='5dfa4bbb-f9e7-497a-8f2c-29cc8388d97e', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='c3c8f8316361457b24276324cdbe28411d2afa92639c36ba20268389020c785b')}, hash='c802d0bc37b97c7d912cd3071afb2c0b8f68452c744aef983eb08020f77f2d58', text='Finetuned language models are zero-shot learners. In International Conference on Learning\\nRepresentations , 2022a. URL https://openreview.net/forum?id=gEZrGCozdqR .\\nJason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Fei Xia, Ed Chi, Quoc V Le, Denny Zhou, et al.\\nChain-of-thoughtpromptingelicitsreasoninginlargelanguagemodels.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-46'),\n",
              " '5dfa4bbb-f9e7-497a-8f2c-29cc8388d97e': IndexNode(id_='5dfa4bbb-f9e7-497a-8f2c-29cc8388d97e', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-46', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='51c1798761b8340bb1f3bcccc79abc7af14e4438d32ee97892ccb80d1924764b'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='5d9b6e0a-0914-4ccb-8131-1f100492bbbd', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='c802d0bc37b97c7d912cd3071afb2c0b8f68452c744aef983eb08020f77f2d58'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='b4cc1fcb-4c83-4d63-ae91-10857e256974', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='a0d0fc73831a90e7d3a43e39ddab4079ab33efc5d3527f982b7ccb53c5c56656')}, hash='c3c8f8316361457b24276324cdbe28411d2afa92639c36ba20268389020c785b', text='AdvancesinNeuralInformation\\nProcessing Systems , 35:24824–24837, 2022b.\\nLaura Weidinger, John Mellor, Maribeth Rauh, Conor Griffin, Jonathan Uesato, Po-Sen Huang, Myra Cheng,\\nMia Glaese, Borja Balle, Atoosa Kasirzadeh, et al. Ethical and social risks of harm from language models.\\narXiv preprint arXiv:2112.04359 , 2021.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-46'),\n",
              " 'b4cc1fcb-4c83-4d63-ae91-10857e256974': IndexNode(id_='b4cc1fcb-4c83-4d63-ae91-10857e256974', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-46', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='51c1798761b8340bb1f3bcccc79abc7af14e4438d32ee97892ccb80d1924764b'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='5dfa4bbb-f9e7-497a-8f2c-29cc8388d97e', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='c3c8f8316361457b24276324cdbe28411d2afa92639c36ba20268389020c785b'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='128e1e4f-1ae5-44bb-9d80-0dc905f39673', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='cf924b9c8cbdaa328a5aaea24831d823b3b900a1e9aab21e21dc0c03edea5a0d')}, hash='a0d0fc73831a90e7d3a43e39ddab4079ab33efc5d3527f982b7ccb53c5c56656', text='arXiv preprint arXiv:2112.04359 , 2021.\\nJohannesWelbl,AmeliaGlaese,JonathanUesato,SumanthDathathri,JohnMellor,LisaAnneHendricks,\\nKirstyAnderson,PushmeetKohli,BenCoppin,andPo-SenHuang. Challengesindetoxifyinglanguage\\nmodels, 2021.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-46'),\n",
              " '128e1e4f-1ae5-44bb-9d80-0dc905f39673': IndexNode(id_='128e1e4f-1ae5-44bb-9d80-0dc905f39673', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-46', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='51c1798761b8340bb1f3bcccc79abc7af14e4438d32ee97892ccb80d1924764b'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='b4cc1fcb-4c83-4d63-ae91-10857e256974', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='a0d0fc73831a90e7d3a43e39ddab4079ab33efc5d3527f982b7ccb53c5c56656'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='23e56a97-5f26-4aba-a93f-2ee4e98d7ef6', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='1f40bc923f749592f45b2c76dd7dad77cc52490ec4f09d387491fba6977cf120')}, hash='cf924b9c8cbdaa328a5aaea24831d823b3b900a1e9aab21e21dc0c03edea5a0d', text='Challengesindetoxifyinglanguage\\nmodels, 2021.\\nCarole-Jean Wu, Ramya Raghavendra, Udit Gupta, Bilge Acun, Newsha Ardalani, Kiwan Maeng, Gloria\\nChang, Fiona Aga, Jinshi Huang, Charles Bai, et al. Sustainable ai: Environmental implications, challenges\\nand opportunities. Proceedings of Machine Learning and Systems , 4:795–813, 2022.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-46'),\n",
              " '23e56a97-5f26-4aba-a93f-2ee4e98d7ef6': IndexNode(id_='23e56a97-5f26-4aba-a93f-2ee4e98d7ef6', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-46', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='51c1798761b8340bb1f3bcccc79abc7af14e4438d32ee97892ccb80d1924764b'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='128e1e4f-1ae5-44bb-9d80-0dc905f39673', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='cf924b9c8cbdaa328a5aaea24831d823b3b900a1e9aab21e21dc0c03edea5a0d'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='1872122f-fc42-49fd-a66f-c5b1597a04d7', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='4a20d041c92959bbbdd22c2f2fce5f02b5a375ae0f9761ad4c6f3d95535de4d9')}, hash='1f40bc923f749592f45b2c76dd7dad77cc52490ec4f09d387491fba6977cf120', text='Proceedings of Machine Learning and Systems , 4:795–813, 2022.\\nJingXu,DaJu,MargaretLi,Y-LanBoureau,JasonWeston,andEmilyDinan.Recipesforsafetyinopen-domain\\nchatbots, 2021.\\nRowanZellers,AriHoltzman,YonatanBisk,AliFarhadi,andYejinChoi. Hellaswag: Canamachinereally\\nfinish your sentence?', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-46'),\n",
              " '1872122f-fc42-49fd-a66f-c5b1597a04d7': IndexNode(id_='1872122f-fc42-49fd-a66f-c5b1597a04d7', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-46', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='51c1798761b8340bb1f3bcccc79abc7af14e4438d32ee97892ccb80d1924764b'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='23e56a97-5f26-4aba-a93f-2ee4e98d7ef6', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='1f40bc923f749592f45b2c76dd7dad77cc52490ec4f09d387491fba6977cf120'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='b5a80923-0e0c-4376-bd16-e284e79ad0f6', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='a06920362c38e592cdc7d5a3339c2198c98ebe937b5ab84b3aa03d22f9e2ae18')}, hash='4a20d041c92959bbbdd22c2f2fce5f02b5a375ae0f9761ad4c6f3d95535de4d9', text='Hellaswag: Canamachinereally\\nfinish your sentence? arXiv preprint arXiv:1905.07830 , 2019a.\\nRowan Zellers, Ari Holtzman, Hannah Rashkin, Yonatan Bisk, Ali Farhadi, Franziska Roesner, and Yejin\\nChoi. Defending against neural fake news. Advances in neural information processing systems , 32, 2019b.\\nBiao Zhang and Rico Sennrich. Root mean square layer normalization, 2019.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-46'),\n",
              " 'b5a80923-0e0c-4376-bd16-e284e79ad0f6': IndexNode(id_='b5a80923-0e0c-4376-bd16-e284e79ad0f6', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-46', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='51c1798761b8340bb1f3bcccc79abc7af14e4438d32ee97892ccb80d1924764b'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='1872122f-fc42-49fd-a66f-c5b1597a04d7', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='4a20d041c92959bbbdd22c2f2fce5f02b5a375ae0f9761ad4c6f3d95535de4d9')}, hash='a06920362c38e592cdc7d5a3339c2198c98ebe937b5ab84b3aa03d22f9e2ae18', text='Biao Zhang and Rico Sennrich. Root mean square layer normalization, 2019.\\nSusan Zhang, Stephen Roller, Naman Goyal, Mikel Artetxe, Moya Chen, Shuohui Chen, Christopher Dewan,\\nMona Diab, Xian Li, Xi Victoria Lin, et al. Opt: Open pre-trained transformer language models. arXiv\\npreprint arXiv:2205.01068 , 2022.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-46'),\n",
              " '2a75ce37-d2ce-4838-990e-1c9ddf049da2': IndexNode(id_='2a75ce37-d2ce-4838-990e-1c9ddf049da2', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-46', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='51c1798761b8340bb1f3bcccc79abc7af14e4438d32ee97892ccb80d1924764b'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='68132316-b511-489a-921e-d4aa2f4644cc', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='2854138c3cbc8e97446380f0264fb61d547077c81affbf4c40c56dbb735ede53')}, hash='3174dfcd27e329fd23f1c1548fe91a71385e285dce417cbc705c64826ce88868', text='Attention is all you need, 2017.\\nOriol Vinyals, Igor Babuschkin, Wojciech M Czarnecki, Michaël Mathieu, Andrew Dudzik, Junyoung Chung,\\nDavid H Choi, Richard Powell, Timo Ewalds, Petko Georgiev, et al. Grandmaster level in starcraft ii using\\nmulti-agent reinforcement learning. Nature, 575(7782):350–354, 2019.\\nYizhong Wang, Yeganeh Kordi, Swaroop Mishra, Alisa Liu, Noah A Smith, Daniel Khashabi, and Han-\\nnanehHajishirzi. Self-instruct: Aligninglanguagemodel withselfgeneratedinstructions. arXivpreprint\\narXiv:2212.10560 , 2022.\\nMichael Webb. The impact of artificial intelligence on the labor market. Available at SSRN 3482150 , 2019.\\nJason Wei, MaartenBosma, VincentZhao, KelvinGuu, Adams WeiYu, Brian Lester, NanDu, AndrewM Dai,\\nand Quoc V Le.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-46'),\n",
              " '68132316-b511-489a-921e-d4aa2f4644cc': IndexNode(id_='68132316-b511-489a-921e-d4aa2f4644cc', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-46', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='51c1798761b8340bb1f3bcccc79abc7af14e4438d32ee97892ccb80d1924764b'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='2a75ce37-d2ce-4838-990e-1c9ddf049da2', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='3174dfcd27e329fd23f1c1548fe91a71385e285dce417cbc705c64826ce88868'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='952dad8d-be7c-4c92-b456-cd7a68cff515', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='1ed0bc3aae1db6a65bd501096ca556fde9c9c3c8600f50f1c4e3d91d3f0aa56a')}, hash='2854138c3cbc8e97446380f0264fb61d547077c81affbf4c40c56dbb735ede53', text='Finetuned language models are zero-shot learners. In International Conference on Learning\\nRepresentations , 2021.\\nJasonWei,MaartenBosma,VincentZhao,KelvinGuu,AdamsWeiYu,BrianLester,NanDu,AndrewM.Dai,\\nand Quoc V Le. Finetuned language models are zero-shot learners. In International Conference on Learning\\nRepresentations , 2022a. URL https://openreview.net/forum?id=gEZrGCozdqR .\\nJason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Fei Xia, Ed Chi, Quoc V Le, Denny Zhou, et al.\\nChain-of-thoughtpromptingelicitsreasoninginlargelanguagemodels. AdvancesinNeuralInformation\\nProcessing Systems , 35:24824–24837, 2022b.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-46'),\n",
              " '952dad8d-be7c-4c92-b456-cd7a68cff515': IndexNode(id_='952dad8d-be7c-4c92-b456-cd7a68cff515', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-46', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='51c1798761b8340bb1f3bcccc79abc7af14e4438d32ee97892ccb80d1924764b'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='68132316-b511-489a-921e-d4aa2f4644cc', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='2854138c3cbc8e97446380f0264fb61d547077c81affbf4c40c56dbb735ede53'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='af8457f6-1b0b-4d99-a7f5-0e340e942087', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='e3ec81bf91360b3d4cd646e3eedb6a596ac3e91177f3511c5c8a6f17cd2649ff')}, hash='1ed0bc3aae1db6a65bd501096ca556fde9c9c3c8600f50f1c4e3d91d3f0aa56a', text='Laura Weidinger, John Mellor, Maribeth Rauh, Conor Griffin, Jonathan Uesato, Po-Sen Huang, Myra Cheng,\\nMia Glaese, Borja Balle, Atoosa Kasirzadeh, et al. Ethical and social risks of harm from language models.\\narXiv preprint arXiv:2112.04359 , 2021.\\nJohannesWelbl,AmeliaGlaese,JonathanUesato,SumanthDathathri,JohnMellor,LisaAnneHendricks,\\nKirstyAnderson,PushmeetKohli,BenCoppin,andPo-SenHuang. Challengesindetoxifyinglanguage\\nmodels, 2021.\\nCarole-Jean Wu, Ramya Raghavendra, Udit Gupta, Bilge Acun, Newsha Ardalani, Kiwan Maeng, Gloria\\nChang, Fiona Aga, Jinshi Huang, Charles Bai, et al. Sustainable ai: Environmental implications, challenges\\nand opportunities. Proceedings of Machine Learning and Systems , 4:795–813, 2022.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-46'),\n",
              " 'af8457f6-1b0b-4d99-a7f5-0e340e942087': IndexNode(id_='af8457f6-1b0b-4d99-a7f5-0e340e942087', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-46', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='51c1798761b8340bb1f3bcccc79abc7af14e4438d32ee97892ccb80d1924764b'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='952dad8d-be7c-4c92-b456-cd7a68cff515', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='1ed0bc3aae1db6a65bd501096ca556fde9c9c3c8600f50f1c4e3d91d3f0aa56a'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='e19a8d56-5f89-460b-ae6c-260291feb48f', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='a06920362c38e592cdc7d5a3339c2198c98ebe937b5ab84b3aa03d22f9e2ae18')}, hash='e3ec81bf91360b3d4cd646e3eedb6a596ac3e91177f3511c5c8a6f17cd2649ff', text='Proceedings of Machine Learning and Systems , 4:795–813, 2022.\\nJingXu,DaJu,MargaretLi,Y-LanBoureau,JasonWeston,andEmilyDinan.Recipesforsafetyinopen-domain\\nchatbots, 2021.\\nRowanZellers,AriHoltzman,YonatanBisk,AliFarhadi,andYejinChoi. Hellaswag: Canamachinereally\\nfinish your sentence? arXiv preprint arXiv:1905.07830 , 2019a.\\nRowan Zellers, Ari Holtzman, Hannah Rashkin, Yonatan Bisk, Ali Farhadi, Franziska Roesner, and Yejin\\nChoi. Defending against neural fake news. Advances in neural information processing systems , 32, 2019b.\\nBiao Zhang and Rico Sennrich. Root mean square layer normalization, 2019.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-46'),\n",
              " 'e19a8d56-5f89-460b-ae6c-260291feb48f': IndexNode(id_='e19a8d56-5f89-460b-ae6c-260291feb48f', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-46', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='51c1798761b8340bb1f3bcccc79abc7af14e4438d32ee97892ccb80d1924764b'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='af8457f6-1b0b-4d99-a7f5-0e340e942087', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='e3ec81bf91360b3d4cd646e3eedb6a596ac3e91177f3511c5c8a6f17cd2649ff')}, hash='a06920362c38e592cdc7d5a3339c2198c98ebe937b5ab84b3aa03d22f9e2ae18', text='Biao Zhang and Rico Sennrich. Root mean square layer normalization, 2019.\\nSusan Zhang, Stephen Roller, Naman Goyal, Mikel Artetxe, Moya Chen, Shuohui Chen, Christopher Dewan,\\nMona Diab, Xian Li, Xi Victoria Lin, et al. Opt: Open pre-trained transformer language models. arXiv\\npreprint arXiv:2205.01068 , 2022.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-46'),\n",
              " '262b0df7-25ba-4fda-b54a-4b0a99a1ca13': IndexNode(id_='262b0df7-25ba-4fda-b54a-4b0a99a1ca13', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-46', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='51c1798761b8340bb1f3bcccc79abc7af14e4438d32ee97892ccb80d1924764b'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='8a5dda9a-b0cb-4dea-b910-d700e25dd8af', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='7e537750945e1eeec065a103fadea1fbc7772f0a5436d0e5afb2e2e5d20167e9')}, hash='e36ae74acc6f505c7c9def4cd89f6db98720848cea1abc76d9813d78bcbd6baf', text='Attention is all you need, 2017.\\nOriol Vinyals, Igor Babuschkin, Wojciech M Czarnecki, Michaël Mathieu, Andrew Dudzik, Junyoung Chung,\\nDavid H Choi, Richard Powell, Timo Ewalds, Petko Georgiev, et al. Grandmaster level in starcraft ii using\\nmulti-agent reinforcement learning. Nature, 575(7782):350–354, 2019.\\nYizhong Wang, Yeganeh Kordi, Swaroop Mishra, Alisa Liu, Noah A Smith, Daniel Khashabi, and Han-\\nnanehHajishirzi. Self-instruct: Aligninglanguagemodel withselfgeneratedinstructions. arXivpreprint\\narXiv:2212.10560 , 2022.\\nMichael Webb. The impact of artificial intelligence on the labor market. Available at SSRN 3482150 , 2019.\\nJason Wei, MaartenBosma, VincentZhao, KelvinGuu, Adams WeiYu, Brian Lester, NanDu, AndrewM Dai,\\nand Quoc V Le. Finetuned language models are zero-shot learners. In International Conference on Learning\\nRepresentations , 2021.\\nJasonWei,MaartenBosma,VincentZhao,KelvinGuu,AdamsWeiYu,BrianLester,NanDu,AndrewM.Dai,\\nand Quoc V Le. Finetuned language models are zero-shot learners. In International Conference on Learning\\nRepresentations , 2022a. URL https://openreview.net/forum?id=gEZrGCozdqR .\\nJason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Fei Xia, Ed Chi, Quoc V Le, Denny Zhou, et al.\\nChain-of-thoughtpromptingelicitsreasoninginlargelanguagemodels. AdvancesinNeuralInformation\\nProcessing Systems , 35:24824–24837, 2022b.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-46'),\n",
              " '8a5dda9a-b0cb-4dea-b910-d700e25dd8af': IndexNode(id_='8a5dda9a-b0cb-4dea-b910-d700e25dd8af', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-46', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='51c1798761b8340bb1f3bcccc79abc7af14e4438d32ee97892ccb80d1924764b'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='262b0df7-25ba-4fda-b54a-4b0a99a1ca13', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='e36ae74acc6f505c7c9def4cd89f6db98720848cea1abc76d9813d78bcbd6baf'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='9cefc92d-6b1a-4643-b746-933c6f7bfd4c', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='c0993a08dd79840856cbb405c6bdb8d73100d5fdabbfdb6223b305b462552ab0')}, hash='7e537750945e1eeec065a103fadea1fbc7772f0a5436d0e5afb2e2e5d20167e9', text='Laura Weidinger, John Mellor, Maribeth Rauh, Conor Griffin, Jonathan Uesato, Po-Sen Huang, Myra Cheng,\\nMia Glaese, Borja Balle, Atoosa Kasirzadeh, et al. Ethical and social risks of harm from language models.\\narXiv preprint arXiv:2112.04359 , 2021.\\nJohannesWelbl,AmeliaGlaese,JonathanUesato,SumanthDathathri,JohnMellor,LisaAnneHendricks,\\nKirstyAnderson,PushmeetKohli,BenCoppin,andPo-SenHuang. Challengesindetoxifyinglanguage\\nmodels, 2021.\\nCarole-Jean Wu, Ramya Raghavendra, Udit Gupta, Bilge Acun, Newsha Ardalani, Kiwan Maeng, Gloria\\nChang, Fiona Aga, Jinshi Huang, Charles Bai, et al. Sustainable ai: Environmental implications, challenges\\nand opportunities. Proceedings of Machine Learning and Systems , 4:795–813, 2022.\\nJingXu,DaJu,MargaretLi,Y-LanBoureau,JasonWeston,andEmilyDinan.Recipesforsafetyinopen-domain\\nchatbots, 2021.\\nRowanZellers,AriHoltzman,YonatanBisk,AliFarhadi,andYejinChoi. Hellaswag: Canamachinereally\\nfinish your sentence? arXiv preprint arXiv:1905.07830 , 2019a.\\nRowan Zellers, Ari Holtzman, Hannah Rashkin, Yonatan Bisk, Ali Farhadi, Franziska Roesner, and Yejin\\nChoi. Defending against neural fake news. Advances in neural information processing systems , 32, 2019b.\\nBiao Zhang and Rico Sennrich. Root mean square layer normalization, 2019.\\nSusan Zhang, Stephen Roller, Naman Goyal, Mikel Artetxe, Moya Chen, Shuohui Chen, Christopher Dewan,\\nMona Diab, Xian Li, Xi Victoria Lin, et al. Opt: Open pre-trained transformer language models.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-46'),\n",
              " '9cefc92d-6b1a-4643-b746-933c6f7bfd4c': IndexNode(id_='9cefc92d-6b1a-4643-b746-933c6f7bfd4c', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-46', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='51c1798761b8340bb1f3bcccc79abc7af14e4438d32ee97892ccb80d1924764b'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='8a5dda9a-b0cb-4dea-b910-d700e25dd8af', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='7e537750945e1eeec065a103fadea1fbc7772f0a5436d0e5afb2e2e5d20167e9')}, hash='c0993a08dd79840856cbb405c6bdb8d73100d5fdabbfdb6223b305b462552ab0', text='Opt: Open pre-trained transformer language models. arXiv\\npreprint arXiv:2205.01068 , 2022.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-46'),\n",
              " 'node-46': IndexNode(id_='node-46', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='415b7efc-e73f-4ac4-bbfd-c1546f099026', node_type=<ObjectType.DOCUMENT: '4'>, metadata={}, hash='231b3bd773f012c01b893ada9e009ecf25ee59934614c5a595c9bf1b3a123292'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='3c2fc0ea-f51d-4d06-b913-9e00d8477b5f', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='131d7420eaeb36371b272dba10abcafb45e7619fb4d8f7298661c9b80a353379'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='aa01f910-4194-40d1-8ded-f0d05fb5bd0e', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='e7be8e41c98472d027204599f287d5cf7b990c5e29df5301d33322afd2c69c0c')}, hash='51c1798761b8340bb1f3bcccc79abc7af14e4438d32ee97892ccb80d1924764b', text='Attention is all you need, 2017.\\nOriol Vinyals, Igor Babuschkin, Wojciech M Czarnecki, Michaël Mathieu, Andrew Dudzik, Junyoung Chung,\\nDavid H Choi, Richard Powell, Timo Ewalds, Petko Georgiev, et al. Grandmaster level in starcraft ii using\\nmulti-agent reinforcement learning. Nature, 575(7782):350–354, 2019.\\nYizhong Wang, Yeganeh Kordi, Swaroop Mishra, Alisa Liu, Noah A Smith, Daniel Khashabi, and Han-\\nnanehHajishirzi. Self-instruct: Aligninglanguagemodel withselfgeneratedinstructions. arXivpreprint\\narXiv:2212.10560 , 2022.\\nMichael Webb. The impact of artificial intelligence on the labor market. Available at SSRN 3482150 , 2019.\\nJason Wei, MaartenBosma, VincentZhao, KelvinGuu, Adams WeiYu, Brian Lester, NanDu, AndrewM Dai,\\nand Quoc V Le. Finetuned language models are zero-shot learners. In International Conference on Learning\\nRepresentations , 2021.\\nJasonWei,MaartenBosma,VincentZhao,KelvinGuu,AdamsWeiYu,BrianLester,NanDu,AndrewM.Dai,\\nand Quoc V Le. Finetuned language models are zero-shot learners. In International Conference on Learning\\nRepresentations , 2022a. URL https://openreview.net/forum?id=gEZrGCozdqR .\\nJason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Fei Xia, Ed Chi, Quoc V Le, Denny Zhou, et al.\\nChain-of-thoughtpromptingelicitsreasoninginlargelanguagemodels. AdvancesinNeuralInformation\\nProcessing Systems , 35:24824–24837, 2022b.\\nLaura Weidinger, John Mellor, Maribeth Rauh, Conor Griffin, Jonathan Uesato, Po-Sen Huang, Myra Cheng,\\nMia Glaese, Borja Balle, Atoosa Kasirzadeh, et al. Ethical and social risks of harm from language models.\\narXiv preprint arXiv:2112.04359 , 2021.\\nJohannesWelbl,AmeliaGlaese,JonathanUesato,SumanthDathathri,JohnMellor,LisaAnneHendricks,\\nKirstyAnderson,PushmeetKohli,BenCoppin,andPo-SenHuang. Challengesindetoxifyinglanguage\\nmodels, 2021.\\nCarole-Jean Wu, Ramya Raghavendra, Udit Gupta, Bilge Acun, Newsha Ardalani, Kiwan Maeng, Gloria\\nChang, Fiona Aga, Jinshi Huang, Charles Bai, et al. Sustainable ai: Environmental implications, challenges\\nand opportunities. Proceedings of Machine Learning and Systems , 4:795–813, 2022.\\nJingXu,DaJu,MargaretLi,Y-LanBoureau,JasonWeston,andEmilyDinan.Recipesforsafetyinopen-domain\\nchatbots, 2021.\\nRowanZellers,AriHoltzman,YonatanBisk,AliFarhadi,andYejinChoi. Hellaswag: Canamachinereally\\nfinish your sentence? arXiv preprint arXiv:1905.07830 , 2019a.\\nRowan Zellers, Ari Holtzman, Hannah Rashkin, Yonatan Bisk, Ali Farhadi, Franziska Roesner, and Yejin\\nChoi. Defending against neural fake news. Advances in neural information processing systems , 32, 2019b.\\nBiao Zhang and Rico Sennrich. Root mean square layer normalization, 2019.\\nSusan Zhang, Stephen Roller, Naman Goyal, Mikel Artetxe, Moya Chen, Shuohui Chen, Christopher Dewan,\\nMona Diab, Xian Li, Xi Victoria Lin, et al. Opt: Open pre-trained transformer language models. arXiv\\npreprint arXiv:2205.01068 , 2022.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-46'),\n",
              " '080409f2-35c0-4b00-8efb-0be67d0ccac0': IndexNode(id_='080409f2-35c0-4b00-8efb-0be67d0ccac0', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-47', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='e7be8e41c98472d027204599f287d5cf7b990c5e29df5301d33322afd2c69c0c'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='47361f40-210e-476f-af82-d4982d8cbff2', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='a5a052d34e0a695b5c2721478564679ab0e89fb485862c527c47ed28881bb8b4')}, hash='1b0d4db63b62c224189ea52d00e76701ed11f805a46f638b170484c3fb3b4761', text='arXiv\\npreprint arXiv:2205.01068 , 2022.\\nYanli Zhao, Andrew Gu, Rohan Varma, Liang Luo, Chien-Chin Huang, Min Xu, Less Wright, Hamid\\nShojanazeri,MyleOtt,SamShleifer,AlbanDesmaison,CanBalioglu,BernardNguyen,GeetaChauhan,\\nYuchen Hao, and Shen Li. Pytorch fsdp: Experiences on scaling fully sharded data parallel, 2023.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-47'),\n",
              " '47361f40-210e-476f-af82-d4982d8cbff2': IndexNode(id_='47361f40-210e-476f-af82-d4982d8cbff2', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-47', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='e7be8e41c98472d027204599f287d5cf7b990c5e29df5301d33322afd2c69c0c'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='080409f2-35c0-4b00-8efb-0be67d0ccac0', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='1b0d4db63b62c224189ea52d00e76701ed11f805a46f638b170484c3fb3b4761'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='da3abbd9-fab1-4f2c-b1d4-03625c7fa7f4', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='6835ad04adc8fe5cac43971faa1feb00f49ba5f680de44265add4dcd6bcf9697')}, hash='a5a052d34e0a695b5c2721478564679ab0e89fb485862c527c47ed28881bb8b4', text='Wanjun Zhong, Ruixiang Cui, Yiduo Guo, Yaobo Liang, Shuai Lu, Yanlin Wang, Amin Saied, Weizhu Chen,\\nandNanDuan. Agieval: Ahuman-centricbenchmarkforevaluatingfoundationmodels. arXivpreprint\\narXiv:2304.06364 , 2023.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-47'),\n",
              " 'da3abbd9-fab1-4f2c-b1d4-03625c7fa7f4': IndexNode(id_='da3abbd9-fab1-4f2c-b1d4-03625c7fa7f4', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-47', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='e7be8e41c98472d027204599f287d5cf7b990c5e29df5301d33322afd2c69c0c'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='47361f40-210e-476f-af82-d4982d8cbff2', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='a5a052d34e0a695b5c2721478564679ab0e89fb485862c527c47ed28881bb8b4'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='5c74a4bc-a30a-4558-95a6-3714dccd015f', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='ef35fc2a3605683e616c2a6646141b39c43799fe849152e33f7de350cf4b4590')}, hash='6835ad04adc8fe5cac43971faa1feb00f49ba5f680de44265add4dcd6bcf9697', text='arXivpreprint\\narXiv:2304.06364 , 2023.\\nChunting Zhou, Pengfei Liu, Puxin Xu, Srini Iyer, Jiao Sun, Yuning Mao, Xuezhe Ma, Avia Efrat, Ping Yu, Lili\\nYu,SusanZhang,GargiGhosh,MikeLewis,LukeZettlemoyer,andOmerLevy. Lima: Lessismorefor\\nalignment. arXiv preprint arXiv:2305.11206 , 2023.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-47'),\n",
              " '5c74a4bc-a30a-4558-95a6-3714dccd015f': IndexNode(id_='5c74a4bc-a30a-4558-95a6-3714dccd015f', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-47', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='e7be8e41c98472d027204599f287d5cf7b990c5e29df5301d33322afd2c69c0c'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='da3abbd9-fab1-4f2c-b1d4-03625c7fa7f4', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='6835ad04adc8fe5cac43971faa1feb00f49ba5f680de44265add4dcd6bcf9697'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='7a29809c-f7d1-4cb2-8e10-84bffc0f3e59', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='9f7b331bb21b76e2586ab2e06f9317cb80666e2c1874af8788060ef907d96aff')}, hash='ef35fc2a3605683e616c2a6646141b39c43799fe849152e33f7de350cf4b4590', text='arXiv preprint arXiv:2305.11206 , 2023.\\nYongchao Zhou, Andrei Ioan Muresanu, Ziwen Han, Keiran Paster, Silviu Pitis, Harris Chan, and Jimmy\\nBa. Largelanguagemodels arehuman-levelpromptengineers. In TheEleventh InternationalConferenceon\\nLearning Representations , 2022.\\n44\\n\\nTerry Yue Zhuo, Yujin Huang, Chunyang Chen, and Zhenchang Xing.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-47'),\n",
              " '7a29809c-f7d1-4cb2-8e10-84bffc0f3e59': IndexNode(id_='7a29809c-f7d1-4cb2-8e10-84bffc0f3e59', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-47', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='e7be8e41c98472d027204599f287d5cf7b990c5e29df5301d33322afd2c69c0c'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='5c74a4bc-a30a-4558-95a6-3714dccd015f', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='ef35fc2a3605683e616c2a6646141b39c43799fe849152e33f7de350cf4b4590'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='59e35e42-70e1-4042-8be5-bcb4198f643c', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='231cd3ee725083377734d8e8897b08b91c0de7f529a9bffa7aec8a8a3a2c0548')}, hash='9f7b331bb21b76e2586ab2e06f9317cb80666e2c1874af8788060ef907d96aff', text='Exploring ai ethics of chatgpt: A\\ndiagnostic analysis. arXiv preprint arXiv:2301.12867 , 2023.\\n45\\n\\nA Appendix\\nA.1 Contributions\\nAll authors sorted alphabetically by last name.\\nScienceandEngineeringLeadership : GuillemCucurull,NamanGoyal,LouisMartin,ThomasScialom,Ruan\\nSilva, Kevin Stone, Hugo Touvron.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-47'),\n",
              " '59e35e42-70e1-4042-8be5-bcb4198f643c': IndexNode(id_='59e35e42-70e1-4042-8be5-bcb4198f643c', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-47', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='e7be8e41c98472d027204599f287d5cf7b990c5e29df5301d33322afd2c69c0c'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='7a29809c-f7d1-4cb2-8e10-84bffc0f3e59', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='9f7b331bb21b76e2586ab2e06f9317cb80666e2c1874af8788060ef907d96aff'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='6c692692-2d7b-4ff9-a8d1-c150f66f15ee', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='ee9d10bf5db7bf9f7eeabdf5ed078f76bc669c96ad0a4f1ed3e3ac04b0d0dcbd')}, hash='231cd3ee725083377734d8e8897b08b91c0de7f529a9bffa7aec8a8a3a2c0548', text='Technical and Management Leadership : Sergey Edunov, Angela Fan, Melanie Kambadur, Sharan Narang,\\nAurelien Rodriguez, Robert Stojnic.\\nCore Contributors : Peter Albert, Nikolay Bashlykov, Prajjwal Bhargava, Moya Chen, David Esiobu, Jeremy Fu,\\nVedanuj Goswami, Anthony Hartshorn, Rui Hou, Marcin Kardas, Punit Singh Koura, Marie-Anne Lachaux,\\nThibaut Lavril, Diana Liskovich, Xavier Martinet, Yuning Mao,', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-47'),\n",
              " '6c692692-2d7b-4ff9-a8d1-c150f66f15ee': IndexNode(id_='6c692692-2d7b-4ff9-a8d1-c150f66f15ee', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-47', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='e7be8e41c98472d027204599f287d5cf7b990c5e29df5301d33322afd2c69c0c'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='59e35e42-70e1-4042-8be5-bcb4198f643c', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='231cd3ee725083377734d8e8897b08b91c0de7f529a9bffa7aec8a8a3a2c0548'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='721ecbd9-66fd-47e2-bef1-0c5f50be39ab', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='f47be09a9da213a3258fef5ebf9d748ef09b264c2655a4a39a67e76f91d03cc4')}, hash='ee9d10bf5db7bf9f7eeabdf5ed078f76bc669c96ad0a4f1ed3e3ac04b0d0dcbd', text='Thibaut Lavril, Diana Liskovich, Xavier Martinet, Yuning Mao, Igor Molybog, Todor Mihaylov, Andrew\\nPoulton, Jeremy Reizenstein, Eric Michael Smith, Ranjan Subramanian, Xiaoqing Ellen Tan, Binh Tang, Ross\\nTaylor, Jacob Xu, Yuchen Zhang, Iliyan Zarov.\\nContributors : Amjad Almahairi, Yasmine Babaei, Soumya Batra, Lukas Blecher, Dan Bikel, Shruti Bhosale,', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-47'),\n",
              " '721ecbd9-66fd-47e2-bef1-0c5f50be39ab': IndexNode(id_='721ecbd9-66fd-47e2-bef1-0c5f50be39ab', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-47', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='e7be8e41c98472d027204599f287d5cf7b990c5e29df5301d33322afd2c69c0c'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='6c692692-2d7b-4ff9-a8d1-c150f66f15ee', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='ee9d10bf5db7bf9f7eeabdf5ed078f76bc669c96ad0a4f1ed3e3ac04b0d0dcbd'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='df0aabe4-6126-489d-8386-71c8bb1470a7', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='fdf0f725e32fe70d440c81ee02950f12ad40bb878642ecf0ad89443045f82a0a')}, hash='f47be09a9da213a3258fef5ebf9d748ef09b264c2655a4a39a67e76f91d03cc4', text='Lukas Blecher, Dan Bikel, Shruti Bhosale,\\nCristian Canton Ferrer, Jude Fernandes, Wenyin Fu, Brian Fuller, Cynthia Gao, Saghar Hosseini, Hakan\\nInan, Isabel Kloumann, Madian Khabsa, Artem Korenev, Viktor Kerkez, Jian Xiang Kuan, Yinghai Lu,\\nJenyaLee,PushkarMishra,YixinNie,RashiRungta,AlanSchelten,KalyanSaladi,AdinaWilliams,ZhengYan.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-47'),\n",
              " 'df0aabe4-6126-489d-8386-71c8bb1470a7': IndexNode(id_='df0aabe4-6126-489d-8386-71c8bb1470a7', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-47', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='e7be8e41c98472d027204599f287d5cf7b990c5e29df5301d33322afd2c69c0c'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='721ecbd9-66fd-47e2-bef1-0c5f50be39ab', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='f47be09a9da213a3258fef5ebf9d748ef09b264c2655a4a39a67e76f91d03cc4')}, hash='fdf0f725e32fe70d440c81ee02950f12ad40bb878642ecf0ad89443045f82a0a', text='AlanSchelten,KalyanSaladi,AdinaWilliams,ZhengYan.\\nWe thank the GenAI executive team for their leadership and support: Ahmad Al-Dahle, Manohar Paluri.\\nA.1.1 Acknowledgments\\nThis work was made possible by a large group of contributors.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-47'),\n",
              " 'd639cafa-c4c8-4691-a30b-92f94836cb08': IndexNode(id_='d639cafa-c4c8-4691-a30b-92f94836cb08', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-47', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='e7be8e41c98472d027204599f287d5cf7b990c5e29df5301d33322afd2c69c0c'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='fbbd8b6e-0942-4ed2-8dfc-84c4f48a2897', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='0a8457b30bc7930e13904bd8fdca016ceeed605f254be259505315114e66aaf7')}, hash='c6acb548569da59ea6bbbbce2519b3c9d7ba3ed0bad2c3738bb3e641b1b984ac', text='arXiv\\npreprint arXiv:2205.01068 , 2022.\\nYanli Zhao, Andrew Gu, Rohan Varma, Liang Luo, Chien-Chin Huang, Min Xu, Less Wright, Hamid\\nShojanazeri,MyleOtt,SamShleifer,AlbanDesmaison,CanBalioglu,BernardNguyen,GeetaChauhan,\\nYuchen Hao, and Shen Li. Pytorch fsdp: Experiences on scaling fully sharded data parallel, 2023.\\nWanjun Zhong, Ruixiang Cui, Yiduo Guo, Yaobo Liang, Shuai Lu, Yanlin Wang, Amin Saied, Weizhu Chen,\\nandNanDuan. Agieval: Ahuman-centricbenchmarkforevaluatingfoundationmodels. arXivpreprint\\narXiv:2304.06364 , 2023.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-47'),\n",
              " 'fbbd8b6e-0942-4ed2-8dfc-84c4f48a2897': IndexNode(id_='fbbd8b6e-0942-4ed2-8dfc-84c4f48a2897', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-47', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='e7be8e41c98472d027204599f287d5cf7b990c5e29df5301d33322afd2c69c0c'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='d639cafa-c4c8-4691-a30b-92f94836cb08', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='c6acb548569da59ea6bbbbce2519b3c9d7ba3ed0bad2c3738bb3e641b1b984ac'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='75e33a46-7e0b-4293-9fbe-3ebaaf473c8c', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='7f5948fde47011c040edc0cad2823603e68b6a644baf65583721a56f0cf92143')}, hash='0a8457b30bc7930e13904bd8fdca016ceeed605f254be259505315114e66aaf7', text='arXivpreprint\\narXiv:2304.06364 , 2023.\\nChunting Zhou, Pengfei Liu, Puxin Xu, Srini Iyer, Jiao Sun, Yuning Mao, Xuezhe Ma, Avia Efrat, Ping Yu, Lili\\nYu,SusanZhang,GargiGhosh,MikeLewis,LukeZettlemoyer,andOmerLevy. Lima: Lessismorefor\\nalignment. arXiv preprint arXiv:2305.11206 , 2023.\\nYongchao Zhou, Andrei Ioan Muresanu, Ziwen Han, Keiran Paster, Silviu Pitis, Harris Chan, and Jimmy\\nBa. Largelanguagemodels arehuman-levelpromptengineers. In TheEleventh InternationalConferenceon\\nLearning Representations , 2022.\\n44\\n\\nTerry Yue Zhuo, Yujin Huang, Chunyang Chen, and Zhenchang Xing. Exploring ai ethics of chatgpt: A\\ndiagnostic analysis.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-47'),\n",
              " '75e33a46-7e0b-4293-9fbe-3ebaaf473c8c': IndexNode(id_='75e33a46-7e0b-4293-9fbe-3ebaaf473c8c', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-47', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='e7be8e41c98472d027204599f287d5cf7b990c5e29df5301d33322afd2c69c0c'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='fbbd8b6e-0942-4ed2-8dfc-84c4f48a2897', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='0a8457b30bc7930e13904bd8fdca016ceeed605f254be259505315114e66aaf7'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='837c1ac1-ee11-4421-851f-e78ac928bfbf', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='cd212dea5edad1d44b4ae4f5c80be8d7c661b4c78d5714146fb25c4285846378')}, hash='7f5948fde47011c040edc0cad2823603e68b6a644baf65583721a56f0cf92143', text='Exploring ai ethics of chatgpt: A\\ndiagnostic analysis. arXiv preprint arXiv:2301.12867 , 2023.\\n45\\n\\nA Appendix\\nA.1 Contributions\\nAll authors sorted alphabetically by last name.\\nScienceandEngineeringLeadership : GuillemCucurull,NamanGoyal,LouisMartin,ThomasScialom,Ruan\\nSilva, Kevin Stone, Hugo Touvron.\\nTechnical and Management Leadership : Sergey Edunov, Angela Fan, Melanie Kambadur, Sharan Narang,\\nAurelien Rodriguez, Robert Stojnic.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-47'),\n",
              " '837c1ac1-ee11-4421-851f-e78ac928bfbf': IndexNode(id_='837c1ac1-ee11-4421-851f-e78ac928bfbf', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-47', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='e7be8e41c98472d027204599f287d5cf7b990c5e29df5301d33322afd2c69c0c'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='75e33a46-7e0b-4293-9fbe-3ebaaf473c8c', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='7f5948fde47011c040edc0cad2823603e68b6a644baf65583721a56f0cf92143'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='74c9c190-5e58-47a9-9fec-03f02025dc0e', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='3b8533f879f93f8fb26856f82b71a7f1ce8eb0a1b9de0caa1dac64b543a86d7b')}, hash='cd212dea5edad1d44b4ae4f5c80be8d7c661b4c78d5714146fb25c4285846378', text='Core Contributors : Peter Albert, Nikolay Bashlykov, Prajjwal Bhargava, Moya Chen, David Esiobu, Jeremy Fu,\\nVedanuj Goswami, Anthony Hartshorn, Rui Hou, Marcin Kardas, Punit Singh Koura, Marie-Anne Lachaux,\\nThibaut Lavril, Diana Liskovich, Xavier Martinet, Yuning Mao, Igor Molybog, Todor Mihaylov, Andrew\\nPoulton, Jeremy Reizenstein, Eric Michael Smith, Ranjan Subramanian, Xiaoqing Ellen Tan, Binh Tang, Ross\\nTaylor, Jacob Xu, Yuchen Zhang, Iliyan Zarov.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-47'),\n",
              " '74c9c190-5e58-47a9-9fec-03f02025dc0e': IndexNode(id_='74c9c190-5e58-47a9-9fec-03f02025dc0e', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-47', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='e7be8e41c98472d027204599f287d5cf7b990c5e29df5301d33322afd2c69c0c'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='837c1ac1-ee11-4421-851f-e78ac928bfbf', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='cd212dea5edad1d44b4ae4f5c80be8d7c661b4c78d5714146fb25c4285846378')}, hash='3b8533f879f93f8fb26856f82b71a7f1ce8eb0a1b9de0caa1dac64b543a86d7b', text='Contributors : Amjad Almahairi, Yasmine Babaei, Soumya Batra, Lukas Blecher, Dan Bikel, Shruti Bhosale,\\nCristian Canton Ferrer, Jude Fernandes, Wenyin Fu, Brian Fuller, Cynthia Gao, Saghar Hosseini, Hakan\\nInan, Isabel Kloumann, Madian Khabsa, Artem Korenev, Viktor Kerkez, Jian Xiang Kuan, Yinghai Lu,\\nJenyaLee,PushkarMishra,YixinNie,RashiRungta,AlanSchelten,KalyanSaladi,AdinaWilliams,ZhengYan.\\nWe thank the GenAI executive team for their leadership and support: Ahmad Al-Dahle, Manohar Paluri.\\nA.1.1 Acknowledgments\\nThis work was made possible by a large group of contributors.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-47'),\n",
              " 'c23be3ea-149f-4b54-b3e0-0a7886ef207c': IndexNode(id_='c23be3ea-149f-4b54-b3e0-0a7886ef207c', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-47', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='e7be8e41c98472d027204599f287d5cf7b990c5e29df5301d33322afd2c69c0c'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='1194665d-fb31-4873-bfff-fc8620b11347', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='17ebdf9f3ba0e2f563ec2c8f680c8e1a570ab95069326c95ee66b03f4a4142d9')}, hash='8a73d966e99289c56f9bfd757cde4f5214c65e1a64f687cd1bfe916aafc7a7ef', text='arXiv\\npreprint arXiv:2205.01068 , 2022.\\nYanli Zhao, Andrew Gu, Rohan Varma, Liang Luo, Chien-Chin Huang, Min Xu, Less Wright, Hamid\\nShojanazeri,MyleOtt,SamShleifer,AlbanDesmaison,CanBalioglu,BernardNguyen,GeetaChauhan,\\nYuchen Hao, and Shen Li. Pytorch fsdp: Experiences on scaling fully sharded data parallel, 2023.\\nWanjun Zhong, Ruixiang Cui, Yiduo Guo, Yaobo Liang, Shuai Lu, Yanlin Wang, Amin Saied, Weizhu Chen,\\nandNanDuan. Agieval: Ahuman-centricbenchmarkforevaluatingfoundationmodels. arXivpreprint\\narXiv:2304.06364 , 2023.\\nChunting Zhou, Pengfei Liu, Puxin Xu, Srini Iyer, Jiao Sun, Yuning Mao, Xuezhe Ma, Avia Efrat, Ping Yu, Lili\\nYu,SusanZhang,GargiGhosh,MikeLewis,LukeZettlemoyer,andOmerLevy. Lima: Lessismorefor\\nalignment. arXiv preprint arXiv:2305.11206 , 2023.\\nYongchao Zhou, Andrei Ioan Muresanu, Ziwen Han, Keiran Paster, Silviu Pitis, Harris Chan, and Jimmy\\nBa. Largelanguagemodels arehuman-levelpromptengineers. In TheEleventh InternationalConferenceon\\nLearning Representations , 2022.\\n44\\n\\nTerry Yue Zhuo, Yujin Huang, Chunyang Chen, and Zhenchang Xing. Exploring ai ethics of chatgpt: A\\ndiagnostic analysis. arXiv preprint arXiv:2301.12867 , 2023.\\n45\\n\\nA Appendix\\nA.1 Contributions\\nAll authors sorted alphabetically by last name.\\nScienceandEngineeringLeadership : GuillemCucurull,NamanGoyal,LouisMartin,ThomasScialom,Ruan\\nSilva, Kevin Stone, Hugo Touvron.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-47'),\n",
              " '1194665d-fb31-4873-bfff-fc8620b11347': IndexNode(id_='1194665d-fb31-4873-bfff-fc8620b11347', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-47', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='e7be8e41c98472d027204599f287d5cf7b990c5e29df5301d33322afd2c69c0c'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='c23be3ea-149f-4b54-b3e0-0a7886ef207c', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='8a73d966e99289c56f9bfd757cde4f5214c65e1a64f687cd1bfe916aafc7a7ef')}, hash='17ebdf9f3ba0e2f563ec2c8f680c8e1a570ab95069326c95ee66b03f4a4142d9', text='Technical and Management Leadership : Sergey Edunov, Angela Fan, Melanie Kambadur, Sharan Narang,\\nAurelien Rodriguez, Robert Stojnic.\\nCore Contributors : Peter Albert, Nikolay Bashlykov, Prajjwal Bhargava, Moya Chen, David Esiobu, Jeremy Fu,\\nVedanuj Goswami, Anthony Hartshorn, Rui Hou, Marcin Kardas, Punit Singh Koura, Marie-Anne Lachaux,\\nThibaut Lavril, Diana Liskovich, Xavier Martinet, Yuning Mao, Igor Molybog, Todor Mihaylov, Andrew\\nPoulton, Jeremy Reizenstein, Eric Michael Smith, Ranjan Subramanian, Xiaoqing Ellen Tan, Binh Tang, Ross\\nTaylor, Jacob Xu, Yuchen Zhang, Iliyan Zarov.\\nContributors : Amjad Almahairi, Yasmine Babaei, Soumya Batra, Lukas Blecher, Dan Bikel, Shruti Bhosale,\\nCristian Canton Ferrer, Jude Fernandes, Wenyin Fu, Brian Fuller, Cynthia Gao, Saghar Hosseini, Hakan\\nInan, Isabel Kloumann, Madian Khabsa, Artem Korenev, Viktor Kerkez, Jian Xiang Kuan, Yinghai Lu,\\nJenyaLee,PushkarMishra,YixinNie,RashiRungta,AlanSchelten,KalyanSaladi,AdinaWilliams,ZhengYan.\\nWe thank the GenAI executive team for their leadership and support: Ahmad Al-Dahle, Manohar Paluri.\\nA.1.1 Acknowledgments\\nThis work was made possible by a large group of contributors.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-47'),\n",
              " 'node-47': IndexNode(id_='node-47', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='415b7efc-e73f-4ac4-bbfd-c1546f099026', node_type=<ObjectType.DOCUMENT: '4'>, metadata={}, hash='231b3bd773f012c01b893ada9e009ecf25ee59934614c5a595c9bf1b3a123292'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='b9f3acb0-adf8-407b-a26e-1d8f2a15d6f6', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='51c1798761b8340bb1f3bcccc79abc7af14e4438d32ee97892ccb80d1924764b'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='83cb2667-549e-4c3a-b076-32692fca37ba', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='c014265e6d14cac3ad09b1994a4a2bb780ffce94f614c4fdb5d7325176d10dec')}, hash='e7be8e41c98472d027204599f287d5cf7b990c5e29df5301d33322afd2c69c0c', text='arXiv\\npreprint arXiv:2205.01068 , 2022.\\nYanli Zhao, Andrew Gu, Rohan Varma, Liang Luo, Chien-Chin Huang, Min Xu, Less Wright, Hamid\\nShojanazeri,MyleOtt,SamShleifer,AlbanDesmaison,CanBalioglu,BernardNguyen,GeetaChauhan,\\nYuchen Hao, and Shen Li. Pytorch fsdp: Experiences on scaling fully sharded data parallel, 2023.\\nWanjun Zhong, Ruixiang Cui, Yiduo Guo, Yaobo Liang, Shuai Lu, Yanlin Wang, Amin Saied, Weizhu Chen,\\nandNanDuan. Agieval: Ahuman-centricbenchmarkforevaluatingfoundationmodels. arXivpreprint\\narXiv:2304.06364 , 2023.\\nChunting Zhou, Pengfei Liu, Puxin Xu, Srini Iyer, Jiao Sun, Yuning Mao, Xuezhe Ma, Avia Efrat, Ping Yu, Lili\\nYu,SusanZhang,GargiGhosh,MikeLewis,LukeZettlemoyer,andOmerLevy. Lima: Lessismorefor\\nalignment. arXiv preprint arXiv:2305.11206 , 2023.\\nYongchao Zhou, Andrei Ioan Muresanu, Ziwen Han, Keiran Paster, Silviu Pitis, Harris Chan, and Jimmy\\nBa. Largelanguagemodels arehuman-levelpromptengineers. In TheEleventh InternationalConferenceon\\nLearning Representations , 2022.\\n44\\n\\nTerry Yue Zhuo, Yujin Huang, Chunyang Chen, and Zhenchang Xing. Exploring ai ethics of chatgpt: A\\ndiagnostic analysis. arXiv preprint arXiv:2301.12867 , 2023.\\n45\\n\\nA Appendix\\nA.1 Contributions\\nAll authors sorted alphabetically by last name.\\nScienceandEngineeringLeadership : GuillemCucurull,NamanGoyal,LouisMartin,ThomasScialom,Ruan\\nSilva, Kevin Stone, Hugo Touvron.\\nTechnical and Management Leadership : Sergey Edunov, Angela Fan, Melanie Kambadur, Sharan Narang,\\nAurelien Rodriguez, Robert Stojnic.\\nCore Contributors : Peter Albert, Nikolay Bashlykov, Prajjwal Bhargava, Moya Chen, David Esiobu, Jeremy Fu,\\nVedanuj Goswami, Anthony Hartshorn, Rui Hou, Marcin Kardas, Punit Singh Koura, Marie-Anne Lachaux,\\nThibaut Lavril, Diana Liskovich, Xavier Martinet, Yuning Mao, Igor Molybog, Todor Mihaylov, Andrew\\nPoulton, Jeremy Reizenstein, Eric Michael Smith, Ranjan Subramanian, Xiaoqing Ellen Tan, Binh Tang, Ross\\nTaylor, Jacob Xu, Yuchen Zhang, Iliyan Zarov.\\nContributors : Amjad Almahairi, Yasmine Babaei, Soumya Batra, Lukas Blecher, Dan Bikel, Shruti Bhosale,\\nCristian Canton Ferrer, Jude Fernandes, Wenyin Fu, Brian Fuller, Cynthia Gao, Saghar Hosseini, Hakan\\nInan, Isabel Kloumann, Madian Khabsa, Artem Korenev, Viktor Kerkez, Jian Xiang Kuan, Yinghai Lu,\\nJenyaLee,PushkarMishra,YixinNie,RashiRungta,AlanSchelten,KalyanSaladi,AdinaWilliams,ZhengYan.\\nWe thank the GenAI executive team for their leadership and support: Ahmad Al-Dahle, Manohar Paluri.\\nA.1.1 Acknowledgments\\nThis work was made possible by a large group of contributors.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-47'),\n",
              " '6d925a7e-2e0e-49d5-90a3-cdd28ce147cc': IndexNode(id_='6d925a7e-2e0e-49d5-90a3-cdd28ce147cc', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-48', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='c014265e6d14cac3ad09b1994a4a2bb780ffce94f614c4fdb5d7325176d10dec'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='5a45c9da-f8cc-4e63-a906-94b2bc76f77d', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='1d5b9902a3bad37a1bf5b6886e6fca37bf71e82832c6336a32a05bd9568fcc35')}, hash='b71c1f81bb9736532563876f71cf87528c19d0e39fba8000b60c5207b800723c', text='We extend our gratitude to the following\\npeople for their assistance:\\n•Our human annotators, whose work we have shown is key to improving tuned model performance,\\nas well as internal leads who organized annotations and quality control: Eric Alamillo, Tamara\\nBest, Debanjali Bose, Adam Kelsey, Meghan Keneally, Rebecca Kogen, Catalina Mejiia, Elisabeth\\nMichaels,MarcoMierke,AlyssaPereira, LeighBelzRay,RachelRodriguez,BardiyaSadeghi,', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-48'),\n",
              " '5a45c9da-f8cc-4e63-a906-94b2bc76f77d': IndexNode(id_='5a45c9da-f8cc-4e63-a906-94b2bc76f77d', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-48', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='c014265e6d14cac3ad09b1994a4a2bb780ffce94f614c4fdb5d7325176d10dec'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='6d925a7e-2e0e-49d5-90a3-cdd28ce147cc', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='b71c1f81bb9736532563876f71cf87528c19d0e39fba8000b60c5207b800723c'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='81a069b2-aa39-487f-b8d5-fe24b486afdf', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='e23fffe59bd378dac0b18a67f5b1e675b9e9f21f6493c41272f0a63198e2316c')}, hash='1d5b9902a3bad37a1bf5b6886e6fca37bf71e82832c6336a32a05bd9568fcc35', text='LeighBelzRay,RachelRodriguez,BardiyaSadeghi,Karthik\\nSivakumar, Laura Warne.\\n•Our large internal red team, and especially the red team organizers (Dan Bikel, Joanna Bitton, Sean\\nBrooks,CristianCantonFerrer,AaronFields,LiChen,IvanEvtimov,AaronGrattafiori,LaurieH,\\nImanol Arrieta Ibarra, Semarley Jarrett, Harshit Maheshwari, Aram Markosyan, Pushkar Mishra,', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-48'),\n",
              " '81a069b2-aa39-487f-b8d5-fe24b486afdf': IndexNode(id_='81a069b2-aa39-487f-b8d5-fe24b486afdf', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-48', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='c014265e6d14cac3ad09b1994a4a2bb780ffce94f614c4fdb5d7325176d10dec'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='5a45c9da-f8cc-4e63-a906-94b2bc76f77d', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='1d5b9902a3bad37a1bf5b6886e6fca37bf71e82832c6336a32a05bd9568fcc35'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='66e8fadb-35cc-4baf-947c-63800f1bc8fe', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='d5b2762683bd1fb2bbfba68ab097a3172b46961e75b968bf79418da762031649')}, hash='e23fffe59bd378dac0b18a67f5b1e675b9e9f21f6493c41272f0a63198e2316c', text='Harshit Maheshwari, Aram Markosyan, Pushkar Mishra,\\nDavid Renardy, Chris Rohlf, Davide Testuggine, Qing Hu, Matt Wilde, Michael Tontchev, and Rashi\\nRungta) helped improve the safety and robustness of our models.\\n•The many members of our infrastructure team, including our production engineers and the builders\\nand maintainers of our Research Super Cluster and production clusters, who were key to our model\\ntraining success. Thanks also to Matthew Oldham and Adi Gangidi for helping us with carbon\\nemission calculations.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-48'),\n",
              " '66e8fadb-35cc-4baf-947c-63800f1bc8fe': IndexNode(id_='66e8fadb-35cc-4baf-947c-63800f1bc8fe', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-48', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='c014265e6d14cac3ad09b1994a4a2bb780ffce94f614c4fdb5d7325176d10dec'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='81a069b2-aa39-487f-b8d5-fe24b486afdf', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='e23fffe59bd378dac0b18a67f5b1e675b9e9f21f6493c41272f0a63198e2316c'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='5c6a37c3-6124-4ee2-b05d-9c6d2af5feed', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='c74962b54cc372a1a0bf2e2317cae2e4fb2fc88503aa2257780f673135d508ab')}, hash='d5b2762683bd1fb2bbfba68ab097a3172b46961e75b968bf79418da762031649', text='•Our closest legal, policy, comms, marketing, and privacy partners, including Mike Clark, Nisha Deo,\\nAhuva Goldstand, Amanda Felix, Dustin Holland, Alex Kessler, Mo Metanat, Harrison Rudolph,\\nAdam Shajnfeld, Beau James, Helen Suk, Britt Montalvo, Allie Vieth and Polina Zvyagina, who\\nhelped guide us through the release.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-48'),\n",
              " '5c6a37c3-6124-4ee2-b05d-9c6d2af5feed': IndexNode(id_='5c6a37c3-6124-4ee2-b05d-9c6d2af5feed', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-48', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='c014265e6d14cac3ad09b1994a4a2bb780ffce94f614c4fdb5d7325176d10dec'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='66e8fadb-35cc-4baf-947c-63800f1bc8fe', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='d5b2762683bd1fb2bbfba68ab097a3172b46961e75b968bf79418da762031649'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='56f7fc92-28ea-47a8-8e55-4f80bfe372f3', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='ccfd38c5c59891b168729d9986276fa9db815fe20ed66bd4f428a7719eeb141d')}, hash='c74962b54cc372a1a0bf2e2317cae2e4fb2fc88503aa2257780f673135d508ab', text='•Our partnerships team including Ash Jhaveri, Alex Boesenberg, Sy Choudhury, Mayumi Matsuno,\\nRicardo Lopez-Barquilla, Marc Shedroff, Kelly Michelena, Allie Feinstein, Amit Sangani, Geeta\\nChauhan,ChesterHu,CharltonGholson,AnjaKomlenovic,EissaJamil,BrandonSpence,Azadeh\\nYazdan, Elisa Garcia Anzano, and Natascha Parks.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-48'),\n",
              " '56f7fc92-28ea-47a8-8e55-4f80bfe372f3': IndexNode(id_='56f7fc92-28ea-47a8-8e55-4f80bfe372f3', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-48', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='c014265e6d14cac3ad09b1994a4a2bb780ffce94f614c4fdb5d7325176d10dec'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='5c6a37c3-6124-4ee2-b05d-9c6d2af5feed', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='c74962b54cc372a1a0bf2e2317cae2e4fb2fc88503aa2257780f673135d508ab'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='aa72ff75-2174-4f68-a2f0-a81dcde342bb', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='706cfcddf24b7fe12c12bc0cd5184b6b721555a73804c8531382e7070c88f956')}, hash='ccfd38c5c59891b168729d9986276fa9db815fe20ed66bd4f428a7719eeb141d', text='•ChrisMarra,ChayaNayak,JacquelinePan,GeorgeOrlin,EdwardDowling,EstebanArcaute,Philom-\\nena Lobo, Eleonora Presani, and Logan Kerr, who provided helpful product and technical organiza-\\ntion support.\\n46\\n\\n•Armand Joulin, Edouard Grave, Guillaume Lample, and Timothee Lacroix, members of the original\\nLlama team who helped get this work started.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-48'),\n",
              " 'aa72ff75-2174-4f68-a2f0-a81dcde342bb': IndexNode(id_='aa72ff75-2174-4f68-a2f0-a81dcde342bb', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-48', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='c014265e6d14cac3ad09b1994a4a2bb780ffce94f614c4fdb5d7325176d10dec'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='56f7fc92-28ea-47a8-8e55-4f80bfe372f3', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='ccfd38c5c59891b168729d9986276fa9db815fe20ed66bd4f428a7719eeb141d'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='8e76b197-f184-4a86-afe5-823aaebbffd8', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='e759ecc3006f856686a2b38703b1dfd04f9e1b1457df7627ae80d78e6b95568b')}, hash='706cfcddf24b7fe12c12bc0cd5184b6b721555a73804c8531382e7070c88f956', text='•Drew Hamlin, Chantal Mora, and Aran Mun, who gave us some design input on the figures in the\\npaper.\\n•Vijai Mohan for the discussions about RLHF that inspired our Figure 20, and his contribution to the\\ninternal demo.\\n•Earlyreviewersofthispaper,whohelpedusimproveitsquality,includingMikeLewis,JoellePineau,\\nLaurens van der Maaten, Jason Weston, and Omer Levy.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-48'),\n",
              " '8e76b197-f184-4a86-afe5-823aaebbffd8': IndexNode(id_='8e76b197-f184-4a86-afe5-823aaebbffd8', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-48', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='c014265e6d14cac3ad09b1994a4a2bb780ffce94f614c4fdb5d7325176d10dec'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='aa72ff75-2174-4f68-a2f0-a81dcde342bb', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='706cfcddf24b7fe12c12bc0cd5184b6b721555a73804c8531382e7070c88f956'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='13af0f5a-aed3-4ff9-b57a-796a237f4466', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='6bc21d52ef81a73d0f2250f2edf5e86c407816df3d955dcb45aea695f8bb62f3')}, hash='e759ecc3006f856686a2b38703b1dfd04f9e1b1457df7627ae80d78e6b95568b', text='A.2 Additional Details for Pretraining\\nA.2.1 Architecture Changes Compared to Llama 1\\nContext Length. We expand the context window for Llama 2 from 2048 tokens to 4096 tokens. The longer\\ncontextwindowenablesmodelstoprocessmoreinformation,whichisparticularlyusefulforsupporting\\nlongerhistoriesinchatapplications,varioussummarizationtasks,andunderstandinglongerdocuments.\\nTable 16 compares the performance of 2k and 4k context pretraining on long-context benchmarks.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-48'),\n",
              " '13af0f5a-aed3-4ff9-b57a-796a237f4466': IndexNode(id_='13af0f5a-aed3-4ff9-b57a-796a237f4466', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-48', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='c014265e6d14cac3ad09b1994a4a2bb780ffce94f614c4fdb5d7325176d10dec'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='8e76b197-f184-4a86-afe5-823aaebbffd8', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='e759ecc3006f856686a2b38703b1dfd04f9e1b1457df7627ae80d78e6b95568b')}, hash='6bc21d52ef81a73d0f2250f2edf5e86c407816df3d955dcb45aea695f8bb62f3', text='Both\\nmodelsaretrainedfor150Btokens,keepingthesamearchitectureandhyperparametersasabaseline,varying\\nonlythecontextlength. WeobserveimprovementonSCROLLS(Shahametal.,2022),wheretheaverage\\ninputlengthis3.5k,andnoperformancedegradationonSQUAD(Rajpurkaretal.,2018). Table17shows\\nthat the longer context model retains strong performance on various general-purpose tasks.\\nGrouped-QueryAttention.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-48'),\n",
              " '2a61ef44-0e7b-4383-acca-3c1db04a53d8': IndexNode(id_='2a61ef44-0e7b-4383-acca-3c1db04a53d8', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-48', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='c014265e6d14cac3ad09b1994a4a2bb780ffce94f614c4fdb5d7325176d10dec'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='03b5a624-4817-4d74-a47c-1b3d0f9303af', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='46e87579e95a5561e3b64f88cb2a737b41d3ddcf82e9c8759847dca0482bc75d')}, hash='a9464e6e570d8c195aa416f12e1c4fc941df572e707366b8dc127cfdb6ba0d77', text='We extend our gratitude to the following\\npeople for their assistance:\\n•Our human annotators, whose work we have shown is key to improving tuned model performance,\\nas well as internal leads who organized annotations and quality control: Eric Alamillo, Tamara\\nBest, Debanjali Bose, Adam Kelsey, Meghan Keneally, Rebecca Kogen, Catalina Mejiia, Elisabeth\\nMichaels,MarcoMierke,AlyssaPereira, LeighBelzRay,RachelRodriguez,BardiyaSadeghi,Karthik\\nSivakumar, Laura Warne.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-48'),\n",
              " '03b5a624-4817-4d74-a47c-1b3d0f9303af': IndexNode(id_='03b5a624-4817-4d74-a47c-1b3d0f9303af', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-48', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='c014265e6d14cac3ad09b1994a4a2bb780ffce94f614c4fdb5d7325176d10dec'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='2a61ef44-0e7b-4383-acca-3c1db04a53d8', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='a9464e6e570d8c195aa416f12e1c4fc941df572e707366b8dc127cfdb6ba0d77'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='f91ed8b3-3147-46f8-afb0-858eb8a60704', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='663246c3d283826e9024f417efba3963c0c62532c097f09c3385731a4ac8faaf')}, hash='46e87579e95a5561e3b64f88cb2a737b41d3ddcf82e9c8759847dca0482bc75d', text='•Our large internal red team, and especially the red team organizers (Dan Bikel, Joanna Bitton, Sean\\nBrooks,CristianCantonFerrer,AaronFields,LiChen,IvanEvtimov,AaronGrattafiori,LaurieH,\\nImanol Arrieta Ibarra, Semarley Jarrett, Harshit Maheshwari, Aram Markosyan, Pushkar Mishra,\\nDavid Renardy, Chris Rohlf, Davide Testuggine, Qing Hu, Matt Wilde, Michael Tontchev, and Rashi\\nRungta) helped improve the safety and robustness of our models.\\n•The many members of our infrastructure team, including our production engineers and the builders\\nand maintainers of our Research Super Cluster and production clusters, who were key to our model\\ntraining success. Thanks also to Matthew Oldham and Adi Gangidi for helping us with carbon\\nemission calculations.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-48'),\n",
              " 'f91ed8b3-3147-46f8-afb0-858eb8a60704': IndexNode(id_='f91ed8b3-3147-46f8-afb0-858eb8a60704', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-48', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='c014265e6d14cac3ad09b1994a4a2bb780ffce94f614c4fdb5d7325176d10dec'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='03b5a624-4817-4d74-a47c-1b3d0f9303af', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='46e87579e95a5561e3b64f88cb2a737b41d3ddcf82e9c8759847dca0482bc75d'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='09b97113-2eb5-4ece-9df0-d7b48340e149', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='702ac4ee702ca17452596aee3b96b5190dcb08efac604b72194ef3eccc0f4903')}, hash='663246c3d283826e9024f417efba3963c0c62532c097f09c3385731a4ac8faaf', text='•Our closest legal, policy, comms, marketing, and privacy partners, including Mike Clark, Nisha Deo,\\nAhuva Goldstand, Amanda Felix, Dustin Holland, Alex Kessler, Mo Metanat, Harrison Rudolph,\\nAdam Shajnfeld, Beau James, Helen Suk, Britt Montalvo, Allie Vieth and Polina Zvyagina, who\\nhelped guide us through the release.\\n•Our partnerships team including Ash Jhaveri, Alex Boesenberg, Sy Choudhury, Mayumi Matsuno,\\nRicardo Lopez-Barquilla, Marc Shedroff, Kelly Michelena, Allie Feinstein, Amit Sangani, Geeta\\nChauhan,ChesterHu,CharltonGholson,AnjaKomlenovic,EissaJamil,BrandonSpence,Azadeh\\nYazdan, Elisa Garcia Anzano, and Natascha Parks.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-48'),\n",
              " '09b97113-2eb5-4ece-9df0-d7b48340e149': IndexNode(id_='09b97113-2eb5-4ece-9df0-d7b48340e149', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-48', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='c014265e6d14cac3ad09b1994a4a2bb780ffce94f614c4fdb5d7325176d10dec'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='f91ed8b3-3147-46f8-afb0-858eb8a60704', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='663246c3d283826e9024f417efba3963c0c62532c097f09c3385731a4ac8faaf'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='ccc35f2c-5d71-4656-87e4-fd67589e0ef5', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='be39ca050c04cdf52c3e7bc47a198148aa12f1d58aef2d4a4549a6a100fee18c')}, hash='702ac4ee702ca17452596aee3b96b5190dcb08efac604b72194ef3eccc0f4903', text='•ChrisMarra,ChayaNayak,JacquelinePan,GeorgeOrlin,EdwardDowling,EstebanArcaute,Philom-\\nena Lobo, Eleonora Presani, and Logan Kerr, who provided helpful product and technical organiza-\\ntion support.\\n46\\n\\n•Armand Joulin, Edouard Grave, Guillaume Lample, and Timothee Lacroix, members of the original\\nLlama team who helped get this work started.\\n•Drew Hamlin, Chantal Mora, and Aran Mun, who gave us some design input on the figures in the\\npaper.\\n•Vijai Mohan for the discussions about RLHF that inspired our Figure 20, and his contribution to the\\ninternal demo.\\n•Earlyreviewersofthispaper,whohelpedusimproveitsquality,includingMikeLewis,JoellePineau,\\nLaurens van der Maaten, Jason Weston, and Omer Levy.\\nA.2 Additional Details for Pretraining\\nA.2.1 Architecture Changes Compared to Llama 1\\nContext Length. We expand the context window for Llama 2 from 2048 tokens to 4096 tokens.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-48'),\n",
              " 'ccc35f2c-5d71-4656-87e4-fd67589e0ef5': IndexNode(id_='ccc35f2c-5d71-4656-87e4-fd67589e0ef5', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-48', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='c014265e6d14cac3ad09b1994a4a2bb780ffce94f614c4fdb5d7325176d10dec'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='09b97113-2eb5-4ece-9df0-d7b48340e149', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='702ac4ee702ca17452596aee3b96b5190dcb08efac604b72194ef3eccc0f4903')}, hash='be39ca050c04cdf52c3e7bc47a198148aa12f1d58aef2d4a4549a6a100fee18c', text='We expand the context window for Llama 2 from 2048 tokens to 4096 tokens. The longer\\ncontextwindowenablesmodelstoprocessmoreinformation,whichisparticularlyusefulforsupporting\\nlongerhistoriesinchatapplications,varioussummarizationtasks,andunderstandinglongerdocuments.\\nTable 16 compares the performance of 2k and 4k context pretraining on long-context benchmarks. Both\\nmodelsaretrainedfor150Btokens,keepingthesamearchitectureandhyperparametersasabaseline,varying\\nonlythecontextlength. WeobserveimprovementonSCROLLS(Shahametal.,2022),wheretheaverage\\ninputlengthis3.5k,andnoperformancedegradationonSQUAD(Rajpurkaretal.,2018). Table17shows\\nthat the longer context model retains strong performance on various general-purpose tasks.\\nGrouped-QueryAttention.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-48'),\n",
              " '109baf8a-0fc3-4694-9ff0-4f4e34f60d1c': IndexNode(id_='109baf8a-0fc3-4694-9ff0-4f4e34f60d1c', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-48', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='c014265e6d14cac3ad09b1994a4a2bb780ffce94f614c4fdb5d7325176d10dec'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='d9dd394a-2121-4c26-ac6f-5de31115420e', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='553fec26cc866ac74643e3946653d60f46543acd4f67dffaf5950288f977b2ba')}, hash='562d0c60be20db378cf2c55dd42a5bfa4dd4b167630960b8e6390c6dcc7e3a38', text='We extend our gratitude to the following\\npeople for their assistance:\\n•Our human annotators, whose work we have shown is key to improving tuned model performance,\\nas well as internal leads who organized annotations and quality control: Eric Alamillo, Tamara\\nBest, Debanjali Bose, Adam Kelsey, Meghan Keneally, Rebecca Kogen, Catalina Mejiia, Elisabeth\\nMichaels,MarcoMierke,AlyssaPereira, LeighBelzRay,RachelRodriguez,BardiyaSadeghi,Karthik\\nSivakumar, Laura Warne.\\n•Our large internal red team, and especially the red team organizers (Dan Bikel, Joanna Bitton, Sean\\nBrooks,CristianCantonFerrer,AaronFields,LiChen,IvanEvtimov,AaronGrattafiori,LaurieH,\\nImanol Arrieta Ibarra, Semarley Jarrett, Harshit Maheshwari, Aram Markosyan, Pushkar Mishra,\\nDavid Renardy, Chris Rohlf, Davide Testuggine, Qing Hu, Matt Wilde, Michael Tontchev, and Rashi\\nRungta) helped improve the safety and robustness of our models.\\n•The many members of our infrastructure team, including our production engineers and the builders\\nand maintainers of our Research Super Cluster and production clusters, who were key to our model\\ntraining success. Thanks also to Matthew Oldham and Adi Gangidi for helping us with carbon\\nemission calculations.\\n•Our closest legal, policy, comms, marketing, and privacy partners, including Mike Clark, Nisha Deo,\\nAhuva Goldstand, Amanda Felix, Dustin Holland, Alex Kessler, Mo Metanat, Harrison Rudolph,\\nAdam Shajnfeld, Beau James, Helen Suk, Britt Montalvo, Allie Vieth and Polina Zvyagina, who\\nhelped guide us through the release.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-48'),\n",
              " 'd9dd394a-2121-4c26-ac6f-5de31115420e': IndexNode(id_='d9dd394a-2121-4c26-ac6f-5de31115420e', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-48', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='c014265e6d14cac3ad09b1994a4a2bb780ffce94f614c4fdb5d7325176d10dec'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='109baf8a-0fc3-4694-9ff0-4f4e34f60d1c', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='562d0c60be20db378cf2c55dd42a5bfa4dd4b167630960b8e6390c6dcc7e3a38'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='588aec02-f3d1-4deb-8fdd-7022655ad372', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='29515617312ae1a56e982c2f4220f9c93fda853ad370c0dec6bf01a235601063')}, hash='553fec26cc866ac74643e3946653d60f46543acd4f67dffaf5950288f977b2ba', text='•Our partnerships team including Ash Jhaveri, Alex Boesenberg, Sy Choudhury, Mayumi Matsuno,\\nRicardo Lopez-Barquilla, Marc Shedroff, Kelly Michelena, Allie Feinstein, Amit Sangani, Geeta\\nChauhan,ChesterHu,CharltonGholson,AnjaKomlenovic,EissaJamil,BrandonSpence,Azadeh\\nYazdan, Elisa Garcia Anzano, and Natascha Parks.\\n•ChrisMarra,ChayaNayak,JacquelinePan,GeorgeOrlin,EdwardDowling,EstebanArcaute,Philom-\\nena Lobo, Eleonora Presani, and Logan Kerr, who provided helpful product and technical organiza-\\ntion support.\\n46\\n\\n•Armand Joulin, Edouard Grave, Guillaume Lample, and Timothee Lacroix, members of the original\\nLlama team who helped get this work started.\\n•Drew Hamlin, Chantal Mora, and Aran Mun, who gave us some design input on the figures in the\\npaper.\\n•Vijai Mohan for the discussions about RLHF that inspired our Figure 20, and his contribution to the\\ninternal demo.\\n•Earlyreviewersofthispaper,whohelpedusimproveitsquality,includingMikeLewis,JoellePineau,\\nLaurens van der Maaten, Jason Weston, and Omer Levy.\\nA.2 Additional Details for Pretraining\\nA.2.1 Architecture Changes Compared to Llama 1\\nContext Length. We expand the context window for Llama 2 from 2048 tokens to 4096 tokens. The longer\\ncontextwindowenablesmodelstoprocessmoreinformation,whichisparticularlyusefulforsupporting\\nlongerhistoriesinchatapplications,varioussummarizationtasks,andunderstandinglongerdocuments.\\nTable 16 compares the performance of 2k and 4k context pretraining on long-context benchmarks. Both\\nmodelsaretrainedfor150Btokens,keepingthesamearchitectureandhyperparametersasabaseline,varying\\nonlythecontextlength.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-48'),\n",
              " '588aec02-f3d1-4deb-8fdd-7022655ad372': IndexNode(id_='588aec02-f3d1-4deb-8fdd-7022655ad372', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-48', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='c014265e6d14cac3ad09b1994a4a2bb780ffce94f614c4fdb5d7325176d10dec'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='d9dd394a-2121-4c26-ac6f-5de31115420e', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='553fec26cc866ac74643e3946653d60f46543acd4f67dffaf5950288f977b2ba')}, hash='29515617312ae1a56e982c2f4220f9c93fda853ad370c0dec6bf01a235601063', text='WeobserveimprovementonSCROLLS(Shahametal.,2022),wheretheaverage\\ninputlengthis3.5k,andnoperformancedegradationonSQUAD(Rajpurkaretal.,2018). Table17shows\\nthat the longer context model retains strong performance on various general-purpose tasks.\\nGrouped-QueryAttention.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-48'),\n",
              " 'node-48': IndexNode(id_='node-48', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='415b7efc-e73f-4ac4-bbfd-c1546f099026', node_type=<ObjectType.DOCUMENT: '4'>, metadata={}, hash='231b3bd773f012c01b893ada9e009ecf25ee59934614c5a595c9bf1b3a123292'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='aa01f910-4194-40d1-8ded-f0d05fb5bd0e', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='e7be8e41c98472d027204599f287d5cf7b990c5e29df5301d33322afd2c69c0c'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='063908b2-281f-4f43-815c-a3b464899bfb', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='99ae0a937fb0a54d3a952ce6a9b555cda8adc64474cc0c2be27d9ef2fe13c593')}, hash='c014265e6d14cac3ad09b1994a4a2bb780ffce94f614c4fdb5d7325176d10dec', text='We extend our gratitude to the following\\npeople for their assistance:\\n•Our human annotators, whose work we have shown is key to improving tuned model performance,\\nas well as internal leads who organized annotations and quality control: Eric Alamillo, Tamara\\nBest, Debanjali Bose, Adam Kelsey, Meghan Keneally, Rebecca Kogen, Catalina Mejiia, Elisabeth\\nMichaels,MarcoMierke,AlyssaPereira, LeighBelzRay,RachelRodriguez,BardiyaSadeghi,Karthik\\nSivakumar, Laura Warne.\\n•Our large internal red team, and especially the red team organizers (Dan Bikel, Joanna Bitton, Sean\\nBrooks,CristianCantonFerrer,AaronFields,LiChen,IvanEvtimov,AaronGrattafiori,LaurieH,\\nImanol Arrieta Ibarra, Semarley Jarrett, Harshit Maheshwari, Aram Markosyan, Pushkar Mishra,\\nDavid Renardy, Chris Rohlf, Davide Testuggine, Qing Hu, Matt Wilde, Michael Tontchev, and Rashi\\nRungta) helped improve the safety and robustness of our models.\\n•The many members of our infrastructure team, including our production engineers and the builders\\nand maintainers of our Research Super Cluster and production clusters, who were key to our model\\ntraining success. Thanks also to Matthew Oldham and Adi Gangidi for helping us with carbon\\nemission calculations.\\n•Our closest legal, policy, comms, marketing, and privacy partners, including Mike Clark, Nisha Deo,\\nAhuva Goldstand, Amanda Felix, Dustin Holland, Alex Kessler, Mo Metanat, Harrison Rudolph,\\nAdam Shajnfeld, Beau James, Helen Suk, Britt Montalvo, Allie Vieth and Polina Zvyagina, who\\nhelped guide us through the release.\\n•Our partnerships team including Ash Jhaveri, Alex Boesenberg, Sy Choudhury, Mayumi Matsuno,\\nRicardo Lopez-Barquilla, Marc Shedroff, Kelly Michelena, Allie Feinstein, Amit Sangani, Geeta\\nChauhan,ChesterHu,CharltonGholson,AnjaKomlenovic,EissaJamil,BrandonSpence,Azadeh\\nYazdan, Elisa Garcia Anzano, and Natascha Parks.\\n•ChrisMarra,ChayaNayak,JacquelinePan,GeorgeOrlin,EdwardDowling,EstebanArcaute,Philom-\\nena Lobo, Eleonora Presani, and Logan Kerr, who provided helpful product and technical organiza-\\ntion support.\\n46\\n\\n•Armand Joulin, Edouard Grave, Guillaume Lample, and Timothee Lacroix, members of the original\\nLlama team who helped get this work started.\\n•Drew Hamlin, Chantal Mora, and Aran Mun, who gave us some design input on the figures in the\\npaper.\\n•Vijai Mohan for the discussions about RLHF that inspired our Figure 20, and his contribution to the\\ninternal demo.\\n•Earlyreviewersofthispaper,whohelpedusimproveitsquality,includingMikeLewis,JoellePineau,\\nLaurens van der Maaten, Jason Weston, and Omer Levy.\\nA.2 Additional Details for Pretraining\\nA.2.1 Architecture Changes Compared to Llama 1\\nContext Length. We expand the context window for Llama 2 from 2048 tokens to 4096 tokens. The longer\\ncontextwindowenablesmodelstoprocessmoreinformation,whichisparticularlyusefulforsupporting\\nlongerhistoriesinchatapplications,varioussummarizationtasks,andunderstandinglongerdocuments.\\nTable 16 compares the performance of 2k and 4k context pretraining on long-context benchmarks. Both\\nmodelsaretrainedfor150Btokens,keepingthesamearchitectureandhyperparametersasabaseline,varying\\nonlythecontextlength. WeobserveimprovementonSCROLLS(Shahametal.,2022),wheretheaverage\\ninputlengthis3.5k,andnoperformancedegradationonSQUAD(Rajpurkaretal.,2018). Table17shows\\nthat the longer context model retains strong performance on various general-purpose tasks.\\nGrouped-QueryAttention.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-48'),\n",
              " '4360de22-8c2a-4acd-8b45-72526e2f6c42': IndexNode(id_='4360de22-8c2a-4acd-8b45-72526e2f6c42', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-49', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='99ae0a937fb0a54d3a952ce6a9b555cda8adc64474cc0c2be27d9ef2fe13c593'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='37c3a32e-43a3-434e-9c0a-f72350bc9d3f', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='7873266ccb7dff0a38a64c71c8985f7d1ff7b593a76a85a5e8269c671f67b8cd')}, hash='8b922418bf38b2ad7f2424a7221b1b8db2a5df3fa7bf45198e02ddf4bca9d635', text='Grouped-QueryAttention. Astandardpracticeforautoregressivedecodingistocachethekey(K)and\\nvalue (V) pairs for the previous tokens in the sequence, speeding up attention computation. With increasing\\ncontext windows or batch sizes, however, the memory costs associated with the KV cache size in multi-head\\nattention (MHA) models grow significantly.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-49'),\n",
              " '37c3a32e-43a3-434e-9c0a-f72350bc9d3f': IndexNode(id_='37c3a32e-43a3-434e-9c0a-f72350bc9d3f', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-49', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='99ae0a937fb0a54d3a952ce6a9b555cda8adc64474cc0c2be27d9ef2fe13c593'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='4360de22-8c2a-4acd-8b45-72526e2f6c42', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='8b922418bf38b2ad7f2424a7221b1b8db2a5df3fa7bf45198e02ddf4bca9d635'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='6f965a5c-696c-46ff-98a7-cbf46e17a451', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='4d9db62835c726ebfc7d2168456314464cd95b8f393f313e4e4b924fb5690d99')}, hash='7873266ccb7dff0a38a64c71c8985f7d1ff7b593a76a85a5e8269c671f67b8cd', text='For larger models, where KV cache size becomes a bottleneck,\\nkeyandvalueprojectionscanbesharedacrossmultipleheadswithoutmuchdegradationofperformance\\n(Chowdheryetal.,2022). Eithertheoriginalmulti-queryformatwithasingleKVprojection(MQA, Shazeer,\\n2019) or a grouped-query attention variant with 8 KV projections (GQA, Ainslie et al., 2023) can be used.\\nIn Table 18, we compare MQA and GQA variants with an MHA baseline.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-49'),\n",
              " '6f965a5c-696c-46ff-98a7-cbf46e17a451': IndexNode(id_='6f965a5c-696c-46ff-98a7-cbf46e17a451', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-49', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='99ae0a937fb0a54d3a952ce6a9b555cda8adc64474cc0c2be27d9ef2fe13c593'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='37c3a32e-43a3-434e-9c0a-f72350bc9d3f', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='7873266ccb7dff0a38a64c71c8985f7d1ff7b593a76a85a5e8269c671f67b8cd'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='7ad70ea8-fd9a-4f65-925a-cd206bbea296', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='48bde04e37dd48bb8640c67d1a4d2477a7c2cc1c4f2141d65b4abc319f9265ee')}, hash='4d9db62835c726ebfc7d2168456314464cd95b8f393f313e4e4b924fb5690d99', text='We train all models with 150B\\ntokens while keeping a fixed 30B model size. To keep a similar overall parameter count across GQA and\\nMQA, we increase the dimension of the feed-forward layers to compensate for the reduction in the attention\\nlayers. For the MQA variant, we increase the FFN dimension by a factor of 1.33, and for the GQA variant, we\\nincrease it by a factor of 1.3.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-49'),\n",
              " '7ad70ea8-fd9a-4f65-925a-cd206bbea296': IndexNode(id_='7ad70ea8-fd9a-4f65-925a-cd206bbea296', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-49', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='99ae0a937fb0a54d3a952ce6a9b555cda8adc64474cc0c2be27d9ef2fe13c593'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='6f965a5c-696c-46ff-98a7-cbf46e17a451', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='4d9db62835c726ebfc7d2168456314464cd95b8f393f313e4e4b924fb5690d99'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='57d9c92d-cb2c-41dd-8437-1d73d58d34da', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='0c65de2a261c464f4c503fc9363765d5029b9f3b063625b050e10a9c57b0817b')}, hash='48bde04e37dd48bb8640c67d1a4d2477a7c2cc1c4f2141d65b4abc319f9265ee', text='From the results, we observe that the GQA variant performs comparably to the\\nMHA baseline on most evaluation tasks and is better than the MQA variant on average.\\nTooptimizeforlatency,wehostourlargestmodelsusing8A100sinasinglenodewithtensorparallelism\\n(Shoeybietal.,2019). Inthissetting, shardingforMQAcannotbedoneacrossheadsanymore, giventhe\\nnumberofheadsislowerthanthenumberofGPUs.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-49'),\n",
              " '57d9c92d-cb2c-41dd-8437-1d73d58d34da': IndexNode(id_='57d9c92d-cb2c-41dd-8437-1d73d58d34da', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-49', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='99ae0a937fb0a54d3a952ce6a9b555cda8adc64474cc0c2be27d9ef2fe13c593'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='7ad70ea8-fd9a-4f65-925a-cd206bbea296', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='48bde04e37dd48bb8640c67d1a4d2477a7c2cc1c4f2141d65b4abc319f9265ee'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='12fb2101-cb6b-4494-b2a9-59a9d429d10d', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='f016353e4516c2d35a673a9b9b6524eb5bff17172c28b33f9492582a0043439b')}, hash='0c65de2a261c464f4c503fc9363765d5029b9f3b063625b050e10a9c57b0817b', text='EitheryouduplicatetheKVvaluesinallGPUs(making\\ntheKVcachesizeequaltoGQA),oranalternativeistoshardacrossthebatchdimensioninstead(Popeetal.,\\n2022). The latter, however, can complicate an inference service, as it works only when batch sizes are larger\\nthan the number of shards and the additional communication cost is not worth it in all cases.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-49'),\n",
              " '12fb2101-cb6b-4494-b2a9-59a9d429d10d': IndexNode(id_='12fb2101-cb6b-4494-b2a9-59a9d429d10d', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-49', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='99ae0a937fb0a54d3a952ce6a9b555cda8adc64474cc0c2be27d9ef2fe13c593'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='57d9c92d-cb2c-41dd-8437-1d73d58d34da', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='0c65de2a261c464f4c503fc9363765d5029b9f3b063625b050e10a9c57b0817b'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='087e0589-a5e2-4a39-a4ac-05a71e91c80b', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='0211cf86291ed7ceb5422adb602e0b4078701972d3d5c1e1675634c720cc4b0a')}, hash='f016353e4516c2d35a673a9b9b6524eb5bff17172c28b33f9492582a0043439b', text='Context NarrativeQA Qasper QuALITY QMSum ContractNLI SQuAD\\nLength (F1) (F1) (acc) (Rouge 1/2/L) (EM) (EM/F1)\\n2k 0.21 0.71 26.1 0.13/0.01/0.12 11.76 57.23/62.89\\n4k 17.26 18.52 29.6 15.08 /3.55/12.16 16.33 57.99 /64.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-49'),\n",
              " '087e0589-a5e2-4a39-a4ac-05a71e91c80b': IndexNode(id_='087e0589-a5e2-4a39-a4ac-05a71e91c80b', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-49', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='99ae0a937fb0a54d3a952ce6a9b555cda8adc64474cc0c2be27d9ef2fe13c593'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='12fb2101-cb6b-4494-b2a9-59a9d429d10d', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='f016353e4516c2d35a673a9b9b6524eb5bff17172c28b33f9492582a0043439b'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='61fca332-e224-4265-b91e-2f6206055b84', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='b154cc5f9d99f70fcb1ac29c8180024eca4ac5753d03b728b6c0f87443c7aa22')}, hash='0211cf86291ed7ceb5422adb602e0b4078701972d3d5c1e1675634c720cc4b0a', text='08 /3.55/12.16 16.33 57.99 /64.46\\nTable 16: Context length ablation on long-context tasks.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-49'),\n",
              " '61fca332-e224-4265-b91e-2f6206055b84': IndexNode(id_='61fca332-e224-4265-b91e-2f6206055b84', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-49', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='99ae0a937fb0a54d3a952ce6a9b555cda8adc64474cc0c2be27d9ef2fe13c593'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='087e0589-a5e2-4a39-a4ac-05a71e91c80b', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='0211cf86291ed7ceb5422adb602e0b4078701972d3d5c1e1675634c720cc4b0a'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='cdec4f88-7f4e-42ff-9c3d-3ad60f235e7d', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='be1bcf4e6511eb94e46dba3563e385a60e66c048e0a0fc1af7d5c1cc2d50d1df')}, hash='b154cc5f9d99f70fcb1ac29c8180024eca4ac5753d03b728b6c0f87443c7aa22', text='99 /64.46\\nTable 16: Context length ablation on long-context tasks.\\nContext Hella-Swag NQ TQA GSM8K Human-Eval\\nLength (0-shot) (64-shot) (64-shot) (8-shot) (0-shot)\\n2k 75.1 25.5 53.7 4.9 7.9\\n4k 74.8 25.5 52.2 6.5 7.3\\nTable 17: Context length ablation on general tasks.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-49'),\n",
              " 'cdec4f88-7f4e-42ff-9c3d-3ad60f235e7d': IndexNode(id_='cdec4f88-7f4e-42ff-9c3d-3ad60f235e7d', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-49', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='99ae0a937fb0a54d3a952ce6a9b555cda8adc64474cc0c2be27d9ef2fe13c593'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='61fca332-e224-4265-b91e-2f6206055b84', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='b154cc5f9d99f70fcb1ac29c8180024eca4ac5753d03b728b6c0f87443c7aa22'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='5f26586d-5198-4c6d-a2d7-9aadacf87ab7', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='3034626c79f5f5cdbae0587db28a1a979f83c49d23a170c0ff031e31bee2fcb4')}, hash='be1bcf4e6511eb94e46dba3563e385a60e66c048e0a0fc1af7d5c1cc2d50d1df', text='47\\n\\nBoolQ PIQA SIQA Hella-Swag ARC-e ARC-c NQ TQA MMLU GSM8K Human-Eval\\nMHA71.0 79.3 48.2 75.1 71.2 43.012.4 44.7 28.0 4.9 7.9\\nMQA 70.6 79.0 47.9 74.5 71.6 41.9 14.542.8 26.5 4.8 7.3\\nGQA 69.4 78.8 48.6 75.4 72.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-49'),\n",
              " '5f26586d-5198-4c6d-a2d7-9aadacf87ab7': IndexNode(id_='5f26586d-5198-4c6d-a2d7-9aadacf87ab7', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-49', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='99ae0a937fb0a54d3a952ce6a9b555cda8adc64474cc0c2be27d9ef2fe13c593'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='cdec4f88-7f4e-42ff-9c3d-3ad60f235e7d', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='be1bcf4e6511eb94e46dba3563e385a60e66c048e0a0fc1af7d5c1cc2d50d1df'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='21a853d6-bad7-41a5-b944-28c1b925485c', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='c4f1fc1972f321d1fd294d625b782f83c48e5863376dca6fa7f6d725d0f77057')}, hash='3034626c79f5f5cdbae0587db28a1a979f83c49d23a170c0ff031e31bee2fcb4', text='3\\nGQA 69.4 78.8 48.6 75.4 72.1 42.5 14.0 46.226.9 5.3 7.9\\nTable 18: Attention architecture ablations. We report 0-shot results for all tasks except MMLU(5-shot) and\\nGSM8K(8-shot). For GSM8K and Human-Eval we report maj@1 and pass@1 results. For NQ and TriviaQA\\nwe report EM. For all other tasks we report accuracy.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-49'),\n",
              " '21a853d6-bad7-41a5-b944-28c1b925485c': IndexNode(id_='21a853d6-bad7-41a5-b944-28c1b925485c', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-49', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='99ae0a937fb0a54d3a952ce6a9b555cda8adc64474cc0c2be27d9ef2fe13c593'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='5f26586d-5198-4c6d-a2d7-9aadacf87ab7', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='3034626c79f5f5cdbae0587db28a1a979f83c49d23a170c0ff031e31bee2fcb4')}, hash='c4f1fc1972f321d1fd294d625b782f83c48e5863376dca6fa7f6d725d0f77057', text='For all other tasks we report accuracy.\\nFigure 24: Multi-query variants enable higher throughput with larger batch sizes, and show similar\\nlatencyonsmallerbatches. Outputlengthisfixedat128tokens.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-49'),\n",
              " '3653b3f1-8e0c-4fbf-a278-5e8c1fac0593': IndexNode(id_='3653b3f1-8e0c-4fbf-a278-5e8c1fac0593', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-49', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='99ae0a937fb0a54d3a952ce6a9b555cda8adc64474cc0c2be27d9ef2fe13c593'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='17fbc003-a430-4e6c-9b27-30cd06e33051', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='ff3c4d4b4bbd284c925e72e1296586cc8b110b1b2e752f22e23bbf0c44bbac27')}, hash='77a41465e80405bd6f150f0977defe8d298ecbe5145965ebb2478b62322a385a', text='Grouped-QueryAttention. Astandardpracticeforautoregressivedecodingistocachethekey(K)and\\nvalue (V) pairs for the previous tokens in the sequence, speeding up attention computation. With increasing\\ncontext windows or batch sizes, however, the memory costs associated with the KV cache size in multi-head\\nattention (MHA) models grow significantly. For larger models, where KV cache size becomes a bottleneck,\\nkeyandvalueprojectionscanbesharedacrossmultipleheadswithoutmuchdegradationofperformance\\n(Chowdheryetal.,2022). Eithertheoriginalmulti-queryformatwithasingleKVprojection(MQA, Shazeer,\\n2019) or a grouped-query attention variant with 8 KV projections (GQA, Ainslie et al., 2023) can be used.\\nIn Table 18, we compare MQA and GQA variants with an MHA baseline. We train all models with 150B\\ntokens while keeping a fixed 30B model size.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-49'),\n",
              " '17fbc003-a430-4e6c-9b27-30cd06e33051': IndexNode(id_='17fbc003-a430-4e6c-9b27-30cd06e33051', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-49', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='99ae0a937fb0a54d3a952ce6a9b555cda8adc64474cc0c2be27d9ef2fe13c593'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='3653b3f1-8e0c-4fbf-a278-5e8c1fac0593', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='77a41465e80405bd6f150f0977defe8d298ecbe5145965ebb2478b62322a385a'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='981fed51-f236-45a1-a11b-340011799808', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='0bb6f7cbc8fdd73844bf9003b5a09859913afbbe6d24cc0a7c60c89b9ec4cb54')}, hash='ff3c4d4b4bbd284c925e72e1296586cc8b110b1b2e752f22e23bbf0c44bbac27', text='To keep a similar overall parameter count across GQA and\\nMQA, we increase the dimension of the feed-forward layers to compensate for the reduction in the attention\\nlayers. For the MQA variant, we increase the FFN dimension by a factor of 1.33, and for the GQA variant, we\\nincrease it by a factor of 1.3. From the results, we observe that the GQA variant performs comparably to the\\nMHA baseline on most evaluation tasks and is better than the MQA variant on average.\\nTooptimizeforlatency,wehostourlargestmodelsusing8A100sinasinglenodewithtensorparallelism\\n(Shoeybietal.,2019). Inthissetting, shardingforMQAcannotbedoneacrossheadsanymore, giventhe\\nnumberofheadsislowerthanthenumberofGPUs. EitheryouduplicatetheKVvaluesinallGPUs(making\\ntheKVcachesizeequaltoGQA),oranalternativeistoshardacrossthebatchdimensioninstead(Popeetal.,\\n2022).', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-49'),\n",
              " '981fed51-f236-45a1-a11b-340011799808': IndexNode(id_='981fed51-f236-45a1-a11b-340011799808', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-49', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='99ae0a937fb0a54d3a952ce6a9b555cda8adc64474cc0c2be27d9ef2fe13c593'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='17fbc003-a430-4e6c-9b27-30cd06e33051', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='ff3c4d4b4bbd284c925e72e1296586cc8b110b1b2e752f22e23bbf0c44bbac27'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='73ddb7e2-7438-4dd9-8ed3-48dfbd9780b1', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='a7daa280c9d0a702739c6d86db0bf1e2df922c3e9953e9fa35d851b21dc48f6e')}, hash='0bb6f7cbc8fdd73844bf9003b5a09859913afbbe6d24cc0a7c60c89b9ec4cb54', text='The latter, however, can complicate an inference service, as it works only when batch sizes are larger\\nthan the number of shards and the additional communication cost is not worth it in all cases.\\nContext NarrativeQA Qasper QuALITY QMSum ContractNLI SQuAD\\nLength (F1) (F1) (acc) (Rouge 1/2/L) (EM) (EM/F1)\\n2k 0.21 0.71 26.1 0.13/0.01/0.12 11.76 57.23/62.89\\n4k 17.26 18.52 29.6 15.08 /3.55/12.16 16.33 57.99 /64.46\\nTable 16: Context length ablation on long-context tasks.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-49'),\n",
              " '73ddb7e2-7438-4dd9-8ed3-48dfbd9780b1': IndexNode(id_='73ddb7e2-7438-4dd9-8ed3-48dfbd9780b1', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-49', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='99ae0a937fb0a54d3a952ce6a9b555cda8adc64474cc0c2be27d9ef2fe13c593'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='981fed51-f236-45a1-a11b-340011799808', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='0bb6f7cbc8fdd73844bf9003b5a09859913afbbe6d24cc0a7c60c89b9ec4cb54'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='07c90ea1-f9d4-426d-b140-fb0bee14581b', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='9784380abfa9f37024100de0f1f754fd4cc59cce37e36b9daaa740589187c75e')}, hash='a7daa280c9d0a702739c6d86db0bf1e2df922c3e9953e9fa35d851b21dc48f6e', text='Context Hella-Swag NQ TQA GSM8K Human-Eval\\nLength (0-shot) (64-shot) (64-shot) (8-shot) (0-shot)\\n2k 75.1 25.5 53.7 4.9 7.9\\n4k 74.8 25.5 52.2 6.5 7.3\\nTable 17: Context length ablation on general tasks.\\n47\\n\\nBoolQ PIQA SIQA Hella-Swag ARC-e ARC-c NQ TQA MMLU GSM8K Human-Eval\\nMHA71.0 79.3 48.2 75.1 71.2 43.012.4 44.7 28.0 4.9 7.9\\nMQA 70.6 79.0 47.9 74.5 71.6 41.9 14.542.8 26.5 4.8 7.3\\nGQA 69.4 78.8 48.6 75.4 72.1 42.5 14.0 46.226.9 5.3 7.9\\nTable 18: Attention architecture ablations.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-49'),\n",
              " '07c90ea1-f9d4-426d-b140-fb0bee14581b': IndexNode(id_='07c90ea1-f9d4-426d-b140-fb0bee14581b', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-49', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='99ae0a937fb0a54d3a952ce6a9b555cda8adc64474cc0c2be27d9ef2fe13c593'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='73ddb7e2-7438-4dd9-8ed3-48dfbd9780b1', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='a7daa280c9d0a702739c6d86db0bf1e2df922c3e9953e9fa35d851b21dc48f6e')}, hash='9784380abfa9f37024100de0f1f754fd4cc59cce37e36b9daaa740589187c75e', text='We report 0-shot results for all tasks except MMLU(5-shot) and\\nGSM8K(8-shot). For GSM8K and Human-Eval we report maj@1 and pass@1 results. For NQ and TriviaQA\\nwe report EM. For all other tasks we report accuracy.\\nFigure 24: Multi-query variants enable higher throughput with larger batch sizes, and show similar\\nlatencyonsmallerbatches. Outputlengthisfixedat128tokens.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-49'),\n",
              " '2befe68e-1d90-4372-af00-908a96ec844c': IndexNode(id_='2befe68e-1d90-4372-af00-908a96ec844c', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-49', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='99ae0a937fb0a54d3a952ce6a9b555cda8adc64474cc0c2be27d9ef2fe13c593'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='54ff4344-98c4-440d-8727-6f94d4de7397', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='7db8da22bc57f09fbd1598918b7d260e876d481f85e44695198d1e1212208381')}, hash='e47a0636a17756654557b310b3ad1138e31ba5a964d641cb5ee3a682e0834b9a', text='Grouped-QueryAttention. Astandardpracticeforautoregressivedecodingistocachethekey(K)and\\nvalue (V) pairs for the previous tokens in the sequence, speeding up attention computation. With increasing\\ncontext windows or batch sizes, however, the memory costs associated with the KV cache size in multi-head\\nattention (MHA) models grow significantly. For larger models, where KV cache size becomes a bottleneck,\\nkeyandvalueprojectionscanbesharedacrossmultipleheadswithoutmuchdegradationofperformance\\n(Chowdheryetal.,2022). Eithertheoriginalmulti-queryformatwithasingleKVprojection(MQA, Shazeer,\\n2019) or a grouped-query attention variant with 8 KV projections (GQA, Ainslie et al., 2023) can be used.\\nIn Table 18, we compare MQA and GQA variants with an MHA baseline. We train all models with 150B\\ntokens while keeping a fixed 30B model size. To keep a similar overall parameter count across GQA and\\nMQA, we increase the dimension of the feed-forward layers to compensate for the reduction in the attention\\nlayers. For the MQA variant, we increase the FFN dimension by a factor of 1.33, and for the GQA variant, we\\nincrease it by a factor of 1.3. From the results, we observe that the GQA variant performs comparably to the\\nMHA baseline on most evaluation tasks and is better than the MQA variant on average.\\nTooptimizeforlatency,wehostourlargestmodelsusing8A100sinasinglenodewithtensorparallelism\\n(Shoeybietal.,2019). Inthissetting, shardingforMQAcannotbedoneacrossheadsanymore, giventhe\\nnumberofheadsislowerthanthenumberofGPUs. EitheryouduplicatetheKVvaluesinallGPUs(making\\ntheKVcachesizeequaltoGQA),oranalternativeistoshardacrossthebatchdimensioninstead(Popeetal.,\\n2022).', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-49'),\n",
              " '54ff4344-98c4-440d-8727-6f94d4de7397': IndexNode(id_='54ff4344-98c4-440d-8727-6f94d4de7397', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-49', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='99ae0a937fb0a54d3a952ce6a9b555cda8adc64474cc0c2be27d9ef2fe13c593'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='2befe68e-1d90-4372-af00-908a96ec844c', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='e47a0636a17756654557b310b3ad1138e31ba5a964d641cb5ee3a682e0834b9a'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='c5c6d082-fbcc-45bc-b7b5-d53d9e5ea389', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='c4f1fc1972f321d1fd294d625b782f83c48e5863376dca6fa7f6d725d0f77057')}, hash='7db8da22bc57f09fbd1598918b7d260e876d481f85e44695198d1e1212208381', text='The latter, however, can complicate an inference service, as it works only when batch sizes are larger\\nthan the number of shards and the additional communication cost is not worth it in all cases.\\nContext NarrativeQA Qasper QuALITY QMSum ContractNLI SQuAD\\nLength (F1) (F1) (acc) (Rouge 1/2/L) (EM) (EM/F1)\\n2k 0.21 0.71 26.1 0.13/0.01/0.12 11.76 57.23/62.89\\n4k 17.26 18.52 29.6 15.08 /3.55/12.16 16.33 57.99 /64.46\\nTable 16: Context length ablation on long-context tasks.\\nContext Hella-Swag NQ TQA GSM8K Human-Eval\\nLength (0-shot) (64-shot) (64-shot) (8-shot) (0-shot)\\n2k 75.1 25.5 53.7 4.9 7.9\\n4k 74.8 25.5 52.2 6.5 7.3\\nTable 17: Context length ablation on general tasks.\\n47\\n\\nBoolQ PIQA SIQA Hella-Swag ARC-e ARC-c NQ TQA MMLU GSM8K Human-Eval\\nMHA71.0 79.3 48.2 75.1 71.2 43.012.4 44.7 28.0 4.9 7.9\\nMQA 70.6 79.0 47.9 74.5 71.6 41.9 14.542.8 26.5 4.8 7.3\\nGQA 69.4 78.8 48.6 75.4 72.1 42.5 14.0 46.226.9 5.3 7.9\\nTable 18: Attention architecture ablations. We report 0-shot results for all tasks except MMLU(5-shot) and\\nGSM8K(8-shot). For GSM8K and Human-Eval we report maj@1 and pass@1 results. For NQ and TriviaQA\\nwe report EM. For all other tasks we report accuracy.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-49'),\n",
              " 'c5c6d082-fbcc-45bc-b7b5-d53d9e5ea389': IndexNode(id_='c5c6d082-fbcc-45bc-b7b5-d53d9e5ea389', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-49', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='99ae0a937fb0a54d3a952ce6a9b555cda8adc64474cc0c2be27d9ef2fe13c593'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='54ff4344-98c4-440d-8727-6f94d4de7397', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='7db8da22bc57f09fbd1598918b7d260e876d481f85e44695198d1e1212208381')}, hash='c4f1fc1972f321d1fd294d625b782f83c48e5863376dca6fa7f6d725d0f77057', text='For all other tasks we report accuracy.\\nFigure 24: Multi-query variants enable higher throughput with larger batch sizes, and show similar\\nlatencyonsmallerbatches. Outputlengthisfixedat128tokens.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-49'),\n",
              " 'node-49': IndexNode(id_='node-49', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='415b7efc-e73f-4ac4-bbfd-c1546f099026', node_type=<ObjectType.DOCUMENT: '4'>, metadata={}, hash='231b3bd773f012c01b893ada9e009ecf25ee59934614c5a595c9bf1b3a123292'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='83cb2667-549e-4c3a-b076-32692fca37ba', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='c014265e6d14cac3ad09b1994a4a2bb780ffce94f614c4fdb5d7325176d10dec'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='eeb076b5-d34d-4d12-80d4-b175d074895a', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='5a1d6743aecd8f51098323290028c4bca5080308d616dfc606af8af7de50c0de')}, hash='99ae0a937fb0a54d3a952ce6a9b555cda8adc64474cc0c2be27d9ef2fe13c593', text='Grouped-QueryAttention. Astandardpracticeforautoregressivedecodingistocachethekey(K)and\\nvalue (V) pairs for the previous tokens in the sequence, speeding up attention computation. With increasing\\ncontext windows or batch sizes, however, the memory costs associated with the KV cache size in multi-head\\nattention (MHA) models grow significantly. For larger models, where KV cache size becomes a bottleneck,\\nkeyandvalueprojectionscanbesharedacrossmultipleheadswithoutmuchdegradationofperformance\\n(Chowdheryetal.,2022). Eithertheoriginalmulti-queryformatwithasingleKVprojection(MQA, Shazeer,\\n2019) or a grouped-query attention variant with 8 KV projections (GQA, Ainslie et al., 2023) can be used.\\nIn Table 18, we compare MQA and GQA variants with an MHA baseline. We train all models with 150B\\ntokens while keeping a fixed 30B model size. To keep a similar overall parameter count across GQA and\\nMQA, we increase the dimension of the feed-forward layers to compensate for the reduction in the attention\\nlayers. For the MQA variant, we increase the FFN dimension by a factor of 1.33, and for the GQA variant, we\\nincrease it by a factor of 1.3. From the results, we observe that the GQA variant performs comparably to the\\nMHA baseline on most evaluation tasks and is better than the MQA variant on average.\\nTooptimizeforlatency,wehostourlargestmodelsusing8A100sinasinglenodewithtensorparallelism\\n(Shoeybietal.,2019). Inthissetting, shardingforMQAcannotbedoneacrossheadsanymore, giventhe\\nnumberofheadsislowerthanthenumberofGPUs. EitheryouduplicatetheKVvaluesinallGPUs(making\\ntheKVcachesizeequaltoGQA),oranalternativeistoshardacrossthebatchdimensioninstead(Popeetal.,\\n2022). The latter, however, can complicate an inference service, as it works only when batch sizes are larger\\nthan the number of shards and the additional communication cost is not worth it in all cases.\\nContext NarrativeQA Qasper QuALITY QMSum ContractNLI SQuAD\\nLength (F1) (F1) (acc) (Rouge 1/2/L) (EM) (EM/F1)\\n2k 0.21 0.71 26.1 0.13/0.01/0.12 11.76 57.23/62.89\\n4k 17.26 18.52 29.6 15.08 /3.55/12.16 16.33 57.99 /64.46\\nTable 16: Context length ablation on long-context tasks.\\nContext Hella-Swag NQ TQA GSM8K Human-Eval\\nLength (0-shot) (64-shot) (64-shot) (8-shot) (0-shot)\\n2k 75.1 25.5 53.7 4.9 7.9\\n4k 74.8 25.5 52.2 6.5 7.3\\nTable 17: Context length ablation on general tasks.\\n47\\n\\nBoolQ PIQA SIQA Hella-Swag ARC-e ARC-c NQ TQA MMLU GSM8K Human-Eval\\nMHA71.0 79.3 48.2 75.1 71.2 43.012.4 44.7 28.0 4.9 7.9\\nMQA 70.6 79.0 47.9 74.5 71.6 41.9 14.542.8 26.5 4.8 7.3\\nGQA 69.4 78.8 48.6 75.4 72.1 42.5 14.0 46.226.9 5.3 7.9\\nTable 18: Attention architecture ablations. We report 0-shot results for all tasks except MMLU(5-shot) and\\nGSM8K(8-shot). For GSM8K and Human-Eval we report maj@1 and pass@1 results. For NQ and TriviaQA\\nwe report EM. For all other tasks we report accuracy.\\nFigure 24: Multi-query variants enable higher throughput with larger batch sizes, and show similar\\nlatencyonsmallerbatches. Outputlengthisfixedat128tokens.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-49'),\n",
              " 'ebbd4fb7-6ce1-407f-843d-7570f07dde6c': IndexNode(id_='ebbd4fb7-6ce1-407f-843d-7570f07dde6c', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-50', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='5a1d6743aecd8f51098323290028c4bca5080308d616dfc606af8af7de50c0de'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='f233759d-3781-40bb-9362-e5935d38482b', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='bd40232760a7eb9fdd4bda75537977f01926f1b71af648f704e5175af0f5ed4e')}, hash='f445a4a546ddda5e4bc979a65e3264bf96eb5a962a7618f847b8f0a07c357984', text='Outputlengthisfixedat128tokens. Thefirstdatapointcorrespondstobatch\\nsize 1, and then we double it until the model runs out of memory. The MHA variant triggers an out-of-\\nmemory error at a batch size of 1024 for a context of 256 tokens and at a batch size of 128 for 2k context,\\nwhereas MQA and GQA have successful runs in those settings.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-50'),\n",
              " 'f233759d-3781-40bb-9362-e5935d38482b': IndexNode(id_='f233759d-3781-40bb-9362-e5935d38482b', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-50', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='5a1d6743aecd8f51098323290028c4bca5080308d616dfc606af8af7de50c0de'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='ebbd4fb7-6ce1-407f-843d-7570f07dde6c', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='f445a4a546ddda5e4bc979a65e3264bf96eb5a962a7618f847b8f0a07c357984'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='ae9b8100-185b-4311-9f30-b5f58505242e', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='77c2fe933e6344c20f4b50c55d4a58ce471fc10500d855c47d7a2e015cb27ea9')}, hash='bd40232760a7eb9fdd4bda75537977f01926f1b71af648f704e5175af0f5ed4e', text='Therefore,basedontheablationresultsandeaseofscalinginference,forthe34Band70B Llama 2 models\\nwe chose to use GQA instead of MQA.\\nFigure 24 shows how inference speed changed for the 30B GQA and MQA ablation models compared to the\\nMHAbaseline,inanexperimentusing8x80GiBA100swithtensorparallelism.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-50'),\n",
              " 'ae9b8100-185b-4311-9f30-b5f58505242e': IndexNode(id_='ae9b8100-185b-4311-9f30-b5f58505242e', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-50', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='5a1d6743aecd8f51098323290028c4bca5080308d616dfc606af8af7de50c0de'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='f233759d-3781-40bb-9362-e5935d38482b', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='bd40232760a7eb9fdd4bda75537977f01926f1b71af648f704e5175af0f5ed4e'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='50814329-6b4e-4466-b8e7-eb4d6eb13f6a', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='378accf791bb0591c364cd03252e7a1711c0895559b4dc02c92603304d1442a4')}, hash='77c2fe933e6344c20f4b50c55d4a58ce471fc10500d855c47d7a2e015cb27ea9', text='Intheserunswesimply\\nduplicated the KV heads for MQA in all GPUs, so the KV cache size for MQA became equal to the GQA and\\nthe two variants behaved very similar (with MQA just having a slightly larger FFN dimension).\\nA.2.2 Additional Details for Pretrained Models Evaluation\\nMMLU details. In Table 19, we report details of the MMLU (Hendrycks et al., 2020) evaluation for Llama\\n2models and others open-source models.\\nStandard Benchmarks.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-50'),\n",
              " '50814329-6b4e-4466-b8e7-eb4d6eb13f6a': IndexNode(id_='50814329-6b4e-4466-b8e7-eb4d6eb13f6a', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-50', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='5a1d6743aecd8f51098323290028c4bca5080308d616dfc606af8af7de50c0de'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='ae9b8100-185b-4311-9f30-b5f58505242e', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='77c2fe933e6344c20f4b50c55d4a58ce471fc10500d855c47d7a2e015cb27ea9'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='f666b83b-cab7-4a1c-aed8-c28a78c08564', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='f9926e933d0f645572bf3266ecae4300ea8e4d15692e6a4a999ca6190f4237c6')}, hash='378accf791bb0591c364cd03252e7a1711c0895559b4dc02c92603304d1442a4', text='Standard Benchmarks. In Table 20, we show results on several standard benchmarks.\\nCodeGeneration. InTable21,wecompareresultsof Llama 2 withpopularopensourcemodelsonthe\\nHuman-Eval and MBPP code generation benchmarks.\\nWorld Knowledge. We evaluate the Llama 2 model together with other open-source models on the Natu-\\nralQuestions and TriviaQA benchmarks (Table 22).', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-50'),\n",
              " 'f666b83b-cab7-4a1c-aed8-c28a78c08564': IndexNode(id_='f666b83b-cab7-4a1c-aed8-c28a78c08564', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-50', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='5a1d6743aecd8f51098323290028c4bca5080308d616dfc606af8af7de50c0de'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='50814329-6b4e-4466-b8e7-eb4d6eb13f6a', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='378accf791bb0591c364cd03252e7a1711c0895559b4dc02c92603304d1442a4'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='7ee8a02f-1bfb-43a9-a81c-c4839266e7fb', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='58c7f460c6de20dfbe1c98df22e06bc9e16c36d718f2d7f99f4e745f11891be4')}, hash='f9926e933d0f645572bf3266ecae4300ea8e4d15692e6a4a999ca6190f4237c6', text='ReadingComprehension InTable23 wereport zero-shotand few-shot resultsonSQUADand zero-shot\\nand one-shot experiments on QUAC. Here Llama 2 performs best on all evaluation settings and models\\nexcept the QUAC 0-shot where Llama 1 30B performs slightly better.\\nExams. In Table 24, we present fine-grained results from the English part of the AGI Eval (Zhong et al.,\\n2023) benchmark. AGI Eval is a collection of standardized exams in different subjects.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-50'),\n",
              " '7ee8a02f-1bfb-43a9-a81c-c4839266e7fb': IndexNode(id_='7ee8a02f-1bfb-43a9-a81c-c4839266e7fb', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-50', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='5a1d6743aecd8f51098323290028c4bca5080308d616dfc606af8af7de50c0de'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='f666b83b-cab7-4a1c-aed8-c28a78c08564', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='f9926e933d0f645572bf3266ecae4300ea8e4d15692e6a4a999ca6190f4237c6'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='6044b05e-ff7f-4f34-b0ef-ba0282487528', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='45b28722dc65e0a0d72d33af4df9de4f47db45d496ef52aee39c3f81089fd373')}, hash='58c7f460c6de20dfbe1c98df22e06bc9e16c36d718f2d7f99f4e745f11891be4', text='AGI Eval is a collection of standardized exams in different subjects.\\n48\\n\\nHumanities STEM Social Sciences Other Average\\nMPT7B 26.7 25.3 27.1 28.2 26.8\\n30B 44.5 39.0 52.8 52.9 46.9\\nFalcon7B 26.4 26.2 24.7 27.4 26.2\\n40B 49.3 45.5 65.4 65.0 55.4\\nLlama 17B 34.0 30.5 38.3 38.1 35.1\\n13B 45.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-50'),\n",
              " '6044b05e-ff7f-4f34-b0ef-ba0282487528': IndexNode(id_='6044b05e-ff7f-4f34-b0ef-ba0282487528', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-50', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='5a1d6743aecd8f51098323290028c4bca5080308d616dfc606af8af7de50c0de'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='7ee8a02f-1bfb-43a9-a81c-c4839266e7fb', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='58c7f460c6de20dfbe1c98df22e06bc9e16c36d718f2d7f99f4e745f11891be4'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='97e63b8a-4051-4266-a12b-331ad0e57eb3', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='5767994ca4d9513ad5e3811797f83ae49dc87956eee5754bd8ada9f502c3bdae')}, hash='45b28722dc65e0a0d72d33af4df9de4f47db45d496ef52aee39c3f81089fd373', text='0 30.5 38.3 38.1 35.1\\n13B 45.0 35.8 53.8 53.3 46.9\\n33B 55.8 46.0 66.7 63.4 57.8\\n65B 61.8 51.7 72.9 67.4 63.4\\nLlama 27B 42.9 36.4 51.2 52.2 45.3\\n13B 52.8 44.1 62.6 61.1 54.8\\n34B 59.4 52.1 71.8 69.2 62.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-50'),\n",
              " '97e63b8a-4051-4266-a12b-331ad0e57eb3': IndexNode(id_='97e63b8a-4051-4266-a12b-331ad0e57eb3', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-50', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='5a1d6743aecd8f51098323290028c4bca5080308d616dfc606af8af7de50c0de'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='6044b05e-ff7f-4f34-b0ef-ba0282487528', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='45b28722dc65e0a0d72d33af4df9de4f47db45d496ef52aee39c3f81089fd373')}, hash='5767994ca4d9513ad5e3811797f83ae49dc87956eee5754bd8ada9f502c3bdae', text='8\\n34B 59.4 52.1 71.8 69.2 62.6\\n70B 65.0 58.0 80.3 74.6 68.9\\nTable19: Five-shotperformanceontheMassiveMultitaskLanguageUnderstanding(MMLU)benchmark.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-50'),\n",
              " '2639cea3-e776-4f3b-829f-4bcd37289c17': IndexNode(id_='2639cea3-e776-4f3b-829f-4bcd37289c17', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-50', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='5a1d6743aecd8f51098323290028c4bca5080308d616dfc606af8af7de50c0de'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='c81e98f1-fc89-40f2-b019-6d3d86350d46', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='b1b772b6b13f27115b05385f2df63ef6c16c911095393c808f9adc35de1fdff6')}, hash='3ca56bc05a077b9c8184b52906ba7b440c0c446e0bc14045d7eb5e8a087690ef', text='Outputlengthisfixedat128tokens. Thefirstdatapointcorrespondstobatch\\nsize 1, and then we double it until the model runs out of memory. The MHA variant triggers an out-of-\\nmemory error at a batch size of 1024 for a context of 256 tokens and at a batch size of 128 for 2k context,\\nwhereas MQA and GQA have successful runs in those settings.\\nTherefore,basedontheablationresultsandeaseofscalinginference,forthe34Band70B Llama 2 models\\nwe chose to use GQA instead of MQA.\\nFigure 24 shows how inference speed changed for the 30B GQA and MQA ablation models compared to the\\nMHAbaseline,inanexperimentusing8x80GiBA100swithtensorparallelism. Intheserunswesimply\\nduplicated the KV heads for MQA in all GPUs, so the KV cache size for MQA became equal to the GQA and\\nthe two variants behaved very similar (with MQA just having a slightly larger FFN dimension).', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-50'),\n",
              " 'c81e98f1-fc89-40f2-b019-6d3d86350d46': IndexNode(id_='c81e98f1-fc89-40f2-b019-6d3d86350d46', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-50', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='5a1d6743aecd8f51098323290028c4bca5080308d616dfc606af8af7de50c0de'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='2639cea3-e776-4f3b-829f-4bcd37289c17', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='3ca56bc05a077b9c8184b52906ba7b440c0c446e0bc14045d7eb5e8a087690ef'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='0d73947e-0514-4064-9393-19b1577532df', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='e0daa30d7ba1fd1b5228b12934213b02200fdd5b3d4cefedb56fa2f6a8f1acd8')}, hash='b1b772b6b13f27115b05385f2df63ef6c16c911095393c808f9adc35de1fdff6', text='A.2.2 Additional Details for Pretrained Models Evaluation\\nMMLU details. In Table 19, we report details of the MMLU (Hendrycks et al., 2020) evaluation for Llama\\n2models and others open-source models.\\nStandard Benchmarks. In Table 20, we show results on several standard benchmarks.\\nCodeGeneration. InTable21,wecompareresultsof Llama 2 withpopularopensourcemodelsonthe\\nHuman-Eval and MBPP code generation benchmarks.\\nWorld Knowledge. We evaluate the Llama 2 model together with other open-source models on the Natu-\\nralQuestions and TriviaQA benchmarks (Table 22).\\nReadingComprehension InTable23 wereport zero-shotand few-shot resultsonSQUADand zero-shot\\nand one-shot experiments on QUAC. Here Llama 2 performs best on all evaluation settings and models\\nexcept the QUAC 0-shot where Llama 1 30B performs slightly better.\\nExams. In Table 24, we present fine-grained results from the English part of the AGI Eval (Zhong et al.,\\n2023) benchmark.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-50'),\n",
              " '0d73947e-0514-4064-9393-19b1577532df': IndexNode(id_='0d73947e-0514-4064-9393-19b1577532df', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-50', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='5a1d6743aecd8f51098323290028c4bca5080308d616dfc606af8af7de50c0de'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='c81e98f1-fc89-40f2-b019-6d3d86350d46', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='b1b772b6b13f27115b05385f2df63ef6c16c911095393c808f9adc35de1fdff6'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='49cc6d35-6a5a-4196-a00f-fc71bfd0ebee', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='2c0e9ff3704bb40d081e8cf023d4d66c0ac5011763f69be1b7bf8f74fbd7f8e8')}, hash='e0daa30d7ba1fd1b5228b12934213b02200fdd5b3d4cefedb56fa2f6a8f1acd8', text='AGI Eval is a collection of standardized exams in different subjects.\\n48\\n\\nHumanities STEM Social Sciences Other Average\\nMPT7B 26.7 25.3 27.1 28.2 26.8\\n30B 44.5 39.0 52.8 52.9 46.9\\nFalcon7B 26.4 26.2 24.7 27.4 26.2\\n40B 49.3 45.5 65.4 65.0 55.4\\nLlama 17B 34.0 30.5 38.3 38.1 35.1\\n13B 45.0 35.8 53.8 53.3 46.9\\n33B 55.8 46.0 66.7 63.4 57.8\\n65B 61.8 51.7 72.9 67.4 63.4\\nLlama 27B 42.9 36.4 51.2 52.2 45.3\\n13B 52.8 44.1 62.6 61.1 54.8\\n34B 59.4 52.1 71.8 69.2 62.6\\n70B 65.0 58.0 80.3 74.6 68.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-50'),\n",
              " '49cc6d35-6a5a-4196-a00f-fc71bfd0ebee': IndexNode(id_='49cc6d35-6a5a-4196-a00f-fc71bfd0ebee', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-50', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='5a1d6743aecd8f51098323290028c4bca5080308d616dfc606af8af7de50c0de'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='0d73947e-0514-4064-9393-19b1577532df', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='e0daa30d7ba1fd1b5228b12934213b02200fdd5b3d4cefedb56fa2f6a8f1acd8')}, hash='2c0e9ff3704bb40d081e8cf023d4d66c0ac5011763f69be1b7bf8f74fbd7f8e8', text='6\\n70B 65.0 58.0 80.3 74.6 68.9\\nTable19: Five-shotperformanceontheMassiveMultitaskLanguageUnderstanding(MMLU)benchmark.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-50'),\n",
              " 'c827bac3-baa8-4e94-9685-8f4e05320e03': IndexNode(id_='c827bac3-baa8-4e94-9685-8f4e05320e03', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-50', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='5a1d6743aecd8f51098323290028c4bca5080308d616dfc606af8af7de50c0de'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='6ca3f9b9-4724-4488-8ffc-3ce121339095', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='9b1a9002b0bd7bf91c003666c155349d56dbc7c137a5b44da228ef7c169caafe')}, hash='f5b4aff196471d843a92291b214813b96346a307f23f46ece0a291926479efd7', text='Outputlengthisfixedat128tokens. Thefirstdatapointcorrespondstobatch\\nsize 1, and then we double it until the model runs out of memory. The MHA variant triggers an out-of-\\nmemory error at a batch size of 1024 for a context of 256 tokens and at a batch size of 128 for 2k context,\\nwhereas MQA and GQA have successful runs in those settings.\\nTherefore,basedontheablationresultsandeaseofscalinginference,forthe34Band70B Llama 2 models\\nwe chose to use GQA instead of MQA.\\nFigure 24 shows how inference speed changed for the 30B GQA and MQA ablation models compared to the\\nMHAbaseline,inanexperimentusing8x80GiBA100swithtensorparallelism. Intheserunswesimply\\nduplicated the KV heads for MQA in all GPUs, so the KV cache size for MQA became equal to the GQA and\\nthe two variants behaved very similar (with MQA just having a slightly larger FFN dimension).\\nA.2.2 Additional Details for Pretrained Models Evaluation\\nMMLU details. In Table 19, we report details of the MMLU (Hendrycks et al., 2020) evaluation for Llama\\n2models and others open-source models.\\nStandard Benchmarks. In Table 20, we show results on several standard benchmarks.\\nCodeGeneration. InTable21,wecompareresultsof Llama 2 withpopularopensourcemodelsonthe\\nHuman-Eval and MBPP code generation benchmarks.\\nWorld Knowledge. We evaluate the Llama 2 model together with other open-source models on the Natu-\\nralQuestions and TriviaQA benchmarks (Table 22).\\nReadingComprehension InTable23 wereport zero-shotand few-shot resultsonSQUADand zero-shot\\nand one-shot experiments on QUAC. Here Llama 2 performs best on all evaluation settings and models\\nexcept the QUAC 0-shot where Llama 1 30B performs slightly better.\\nExams. In Table 24, we present fine-grained results from the English part of the AGI Eval (Zhong et al.,\\n2023) benchmark.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-50'),\n",
              " '6ca3f9b9-4724-4488-8ffc-3ce121339095': IndexNode(id_='6ca3f9b9-4724-4488-8ffc-3ce121339095', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-50', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='5a1d6743aecd8f51098323290028c4bca5080308d616dfc606af8af7de50c0de'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='c827bac3-baa8-4e94-9685-8f4e05320e03', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='f5b4aff196471d843a92291b214813b96346a307f23f46ece0a291926479efd7')}, hash='9b1a9002b0bd7bf91c003666c155349d56dbc7c137a5b44da228ef7c169caafe', text='AGI Eval is a collection of standardized exams in different subjects.\\n48\\n\\nHumanities STEM Social Sciences Other Average\\nMPT7B 26.7 25.3 27.1 28.2 26.8\\n30B 44.5 39.0 52.8 52.9 46.9\\nFalcon7B 26.4 26.2 24.7 27.4 26.2\\n40B 49.3 45.5 65.4 65.0 55.4\\nLlama 17B 34.0 30.5 38.3 38.1 35.1\\n13B 45.0 35.8 53.8 53.3 46.9\\n33B 55.8 46.0 66.7 63.4 57.8\\n65B 61.8 51.7 72.9 67.4 63.4\\nLlama 27B 42.9 36.4 51.2 52.2 45.3\\n13B 52.8 44.1 62.6 61.1 54.8\\n34B 59.4 52.1 71.8 69.2 62.6\\n70B 65.0 58.0 80.3 74.6 68.9\\nTable19: Five-shotperformanceontheMassiveMultitaskLanguageUnderstanding(MMLU)benchmark.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-50'),\n",
              " 'node-50': IndexNode(id_='node-50', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='415b7efc-e73f-4ac4-bbfd-c1546f099026', node_type=<ObjectType.DOCUMENT: '4'>, metadata={}, hash='231b3bd773f012c01b893ada9e009ecf25ee59934614c5a595c9bf1b3a123292'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='063908b2-281f-4f43-815c-a3b464899bfb', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='99ae0a937fb0a54d3a952ce6a9b555cda8adc64474cc0c2be27d9ef2fe13c593'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='5fa6f3e6-2f1e-4bf4-a33c-8333b98b56c6', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='c7d5d6d116b75d1b799ddd97e193257c36b6126a95f63c6a3f9a11e117371906')}, hash='5a1d6743aecd8f51098323290028c4bca5080308d616dfc606af8af7de50c0de', text='Outputlengthisfixedat128tokens. Thefirstdatapointcorrespondstobatch\\nsize 1, and then we double it until the model runs out of memory. The MHA variant triggers an out-of-\\nmemory error at a batch size of 1024 for a context of 256 tokens and at a batch size of 128 for 2k context,\\nwhereas MQA and GQA have successful runs in those settings.\\nTherefore,basedontheablationresultsandeaseofscalinginference,forthe34Band70B Llama 2 models\\nwe chose to use GQA instead of MQA.\\nFigure 24 shows how inference speed changed for the 30B GQA and MQA ablation models compared to the\\nMHAbaseline,inanexperimentusing8x80GiBA100swithtensorparallelism. Intheserunswesimply\\nduplicated the KV heads for MQA in all GPUs, so the KV cache size for MQA became equal to the GQA and\\nthe two variants behaved very similar (with MQA just having a slightly larger FFN dimension).\\nA.2.2 Additional Details for Pretrained Models Evaluation\\nMMLU details. In Table 19, we report details of the MMLU (Hendrycks et al., 2020) evaluation for Llama\\n2models and others open-source models.\\nStandard Benchmarks. In Table 20, we show results on several standard benchmarks.\\nCodeGeneration. InTable21,wecompareresultsof Llama 2 withpopularopensourcemodelsonthe\\nHuman-Eval and MBPP code generation benchmarks.\\nWorld Knowledge. We evaluate the Llama 2 model together with other open-source models on the Natu-\\nralQuestions and TriviaQA benchmarks (Table 22).\\nReadingComprehension InTable23 wereport zero-shotand few-shot resultsonSQUADand zero-shot\\nand one-shot experiments on QUAC. Here Llama 2 performs best on all evaluation settings and models\\nexcept the QUAC 0-shot where Llama 1 30B performs slightly better.\\nExams. In Table 24, we present fine-grained results from the English part of the AGI Eval (Zhong et al.,\\n2023) benchmark. AGI Eval is a collection of standardized exams in different subjects.\\n48\\n\\nHumanities STEM Social Sciences Other Average\\nMPT7B 26.7 25.3 27.1 28.2 26.8\\n30B 44.5 39.0 52.8 52.9 46.9\\nFalcon7B 26.4 26.2 24.7 27.4 26.2\\n40B 49.3 45.5 65.4 65.0 55.4\\nLlama 17B 34.0 30.5 38.3 38.1 35.1\\n13B 45.0 35.8 53.8 53.3 46.9\\n33B 55.8 46.0 66.7 63.4 57.8\\n65B 61.8 51.7 72.9 67.4 63.4\\nLlama 27B 42.9 36.4 51.2 52.2 45.3\\n13B 52.8 44.1 62.6 61.1 54.8\\n34B 59.4 52.1 71.8 69.2 62.6\\n70B 65.0 58.0 80.3 74.6 68.9\\nTable19: Five-shotperformanceontheMassiveMultitaskLanguageUnderstanding(MMLU)benchmark.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-50'),\n",
              " '83ed3ea7-a41e-4e7a-abd1-5484be8a2f79': IndexNode(id_='83ed3ea7-a41e-4e7a-abd1-5484be8a2f79', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-51', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='c7d5d6d116b75d1b799ddd97e193257c36b6126a95f63c6a3f9a11e117371906'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='b8a7be47-357d-4ebe-8637-dad1b5590694', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='5e1e298eb8773361a3dbb13f7dfe70fbe256164d74156b752797197317eebfe9')}, hash='6e9407733af3b62a2cb26d0120132a2d7893b663861b22ce89718b2defda1bb0', text='BoolQ PIQA SIQA HellaSwag WinoGrande ARC-e ARC-c OBQA CSQA MMLU\\nMPT7B 75.0 80.6 48.5 76.4 68.3 70.2 42.6 51.4 21.3 26.8\\n30B 79.0 81.9 48.9 79.9 71.0 76.5 50.6 52.0 58.2 46.9\\nFalcon7B 67.5 76.7 47.2 74.1 66.3 70.0 42.4 51.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-51'),\n",
              " 'b8a7be47-357d-4ebe-8637-dad1b5590694': IndexNode(id_='b8a7be47-357d-4ebe-8637-dad1b5590694', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-51', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='c7d5d6d116b75d1b799ddd97e193257c36b6126a95f63c6a3f9a11e117371906'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='83ed3ea7-a41e-4e7a-abd1-5484be8a2f79', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='6e9407733af3b62a2cb26d0120132a2d7893b663861b22ce89718b2defda1bb0'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='a1187dac-6177-456e-992e-7d3b7c7fbbf7', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='e3f5884c08d8300cbf522cf796f4461c40fd8484375678082d1efca5023e7e41')}, hash='5e1e298eb8773361a3dbb13f7dfe70fbe256164d74156b752797197317eebfe9', text='7 47.2 74.1 66.3 70.0 42.4 51.6 20.8 26.2\\n40B 83.1 82.4 50.1 83.6 76.9 79.2 54.5 56.6 70.4 55.4\\nLlama 17B 76.5 79.8 48.9 76.1 70.1 72.8 47.6 57.2 33.6 35.1\\n13B 78.1 80.1 50.4 79.2 73.0 74.8 52.7 56.4 62.0 46.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-51'),\n",
              " 'a1187dac-6177-456e-992e-7d3b7c7fbbf7': IndexNode(id_='a1187dac-6177-456e-992e-7d3b7c7fbbf7', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-51', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='c7d5d6d116b75d1b799ddd97e193257c36b6126a95f63c6a3f9a11e117371906'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='b8a7be47-357d-4ebe-8637-dad1b5590694', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='5e1e298eb8773361a3dbb13f7dfe70fbe256164d74156b752797197317eebfe9'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='86377118-676e-4418-9938-cfb7a3558ff7', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='1ef7e3fe3cbc19f9a7393a9dfc2258d26bd1488523c1efbead994d96f7766d4b')}, hash='e3f5884c08d8300cbf522cf796f4461c40fd8484375678082d1efca5023e7e41', text='2 73.0 74.8 52.7 56.4 62.0 46.9\\n33B 83.1 82.3 50.4 82.8 76.0 80.0 57.858.6 72.5 57.8\\n65B85.382.852.3 84.2 77.0 78.9 56.0 60.2 74.0 63.4\\nLlama 27B 77.4 78.8 48.3 77.2 69.2 75.2 45.9 58.6 57.8 45.3\\n13B 81.7 80.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-51'),\n",
              " '86377118-676e-4418-9938-cfb7a3558ff7': IndexNode(id_='86377118-676e-4418-9938-cfb7a3558ff7', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-51', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='c7d5d6d116b75d1b799ddd97e193257c36b6126a95f63c6a3f9a11e117371906'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='a1187dac-6177-456e-992e-7d3b7c7fbbf7', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='e3f5884c08d8300cbf522cf796f4461c40fd8484375678082d1efca5023e7e41'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='ddd63f36-4dc8-40df-9518-dcb541307161', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='bec538e9823d4e4fdd648a1266c156a0bdc6d8b64f3c6a45b3d846a945c5eb8e')}, hash='1ef7e3fe3cbc19f9a7393a9dfc2258d26bd1488523c1efbead994d96f7766d4b', text='9 58.6 57.8 45.3\\n13B 81.7 80.5 50.3 80.7 72.8 77.3 49.4 57.0 67.3 54.8\\n34B 83.7 81.9 50.9 83.3 76.7 79.4 54.5 58.2 74.3 62.6\\n70B 85.0 82.850.7 85.3 80.2 80.2 57.460.2 78.5 68.9\\nTable 20: Performance on standard benchmarks.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-51'),\n",
              " 'ddd63f36-4dc8-40df-9518-dcb541307161': IndexNode(id_='ddd63f36-4dc8-40df-9518-dcb541307161', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-51', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='c7d5d6d116b75d1b799ddd97e193257c36b6126a95f63c6a3f9a11e117371906'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='86377118-676e-4418-9938-cfb7a3558ff7', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='1ef7e3fe3cbc19f9a7393a9dfc2258d26bd1488523c1efbead994d96f7766d4b'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='3e24bd62-d44f-4acd-b509-1bf776623a33', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='3f9faa449e5f6356e869be0fb85f998a9a6ff9991d995b360f08931955093f4c')}, hash='bec538e9823d4e4fdd648a1266c156a0bdc6d8b64f3c6a45b3d846a945c5eb8e', text='460.2 78.5 68.9\\nTable 20: Performance on standard benchmarks.\\nHuman-Eval MBPP\\npass@1 pass@100 pass@1 pass@80\\nMPT7B 18.3 - 22.6 -\\n30B 25.0 - 32.8 -\\nFalcon7B 0.0 - 11.2 -\\n40B 0.6 - 29.8 -\\nLlama 17B 10.5 36.5 17.7 56.2\\n13B 15.8 52.5 22.0 64.0\\n33B 21.7 70.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-51'),\n",
              " '3e24bd62-d44f-4acd-b509-1bf776623a33': IndexNode(id_='3e24bd62-d44f-4acd-b509-1bf776623a33', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-51', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='c7d5d6d116b75d1b799ddd97e193257c36b6126a95f63c6a3f9a11e117371906'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='ddd63f36-4dc8-40df-9518-dcb541307161', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='bec538e9823d4e4fdd648a1266c156a0bdc6d8b64f3c6a45b3d846a945c5eb8e'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='89cb684a-7f4f-4d29-8cb5-03152fe7f2f5', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='56aba610853cf7b3dfca053b05361f5370965217136c902fd859439ae5b6d73d')}, hash='3f9faa449e5f6356e869be0fb85f998a9a6ff9991d995b360f08931955093f4c', text='8 52.5 22.0 64.0\\n33B 21.7 70.7 30.2 73.4\\n65B 23.7 79.3 37.7 76.8\\nLlama 27B 12.8 45.6 20.8 62.8\\n13B 18.3 60.2 30.6 69.0\\n34B 22.6 77.2 33.0 76.1\\n70B29.9 89.0 45.0 81.4\\nTable 21: Code generation results on Human-Eval and MBPP .', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-51'),\n",
              " '89cb684a-7f4f-4d29-8cb5-03152fe7f2f5': IndexNode(id_='89cb684a-7f4f-4d29-8cb5-03152fe7f2f5', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-51', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='c7d5d6d116b75d1b799ddd97e193257c36b6126a95f63c6a3f9a11e117371906'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='3e24bd62-d44f-4acd-b509-1bf776623a33', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='3f9faa449e5f6356e869be0fb85f998a9a6ff9991d995b360f08931955093f4c')}, hash='56aba610853cf7b3dfca053b05361f5370965217136c902fd859439ae5b6d73d', text='4\\nTable 21: Code generation results on Human-Eval and MBPP . We report 0-shot and 3-shot results for\\nHuman-Eval and MBPP respectively. For pass@100 and pass@80 scores, we use a temperature of 0.8 and\\ntop-p=0.95. For pass@1 scores, we use a temperature of 0.1 and top- p=0.95.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-51'),\n",
              " '3124707c-c7a3-46cc-ac3f-0db982ffe490': IndexNode(id_='3124707c-c7a3-46cc-ac3f-0db982ffe490', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-51', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='c7d5d6d116b75d1b799ddd97e193257c36b6126a95f63c6a3f9a11e117371906'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='38af6b9f-8f51-402c-8390-78e9d7614e1d', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='6c1a8ffa4709b38d77d50d38d937cd1c6162379c4cf4549eedabf5e1762b8e63')}, hash='343c80164ef2a226202e75fe83ca67c8d4b6afd291057e1e1c8318d4e8d4b3f6', text='BoolQ PIQA SIQA HellaSwag WinoGrande ARC-e ARC-c OBQA CSQA MMLU\\nMPT7B 75.0 80.6 48.5 76.4 68.3 70.2 42.6 51.4 21.3 26.8\\n30B 79.0 81.9 48.9 79.9 71.0 76.5 50.6 52.0 58.2 46.9\\nFalcon7B 67.5 76.7 47.2 74.1 66.3 70.0 42.4 51.6 20.8 26.2\\n40B 83.1 82.4 50.1 83.6 76.9 79.2 54.5 56.6 70.4 55.4\\nLlama 17B 76.5 79.8 48.9 76.1 70.1 72.8 47.6 57.2 33.6 35.1\\n13B 78.1 80.1 50.4 79.2 73.0 74.8 52.7 56.4 62.0 46.9\\n33B 83.1 82.3 50.4 82.8 76.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-51'),\n",
              " '38af6b9f-8f51-402c-8390-78e9d7614e1d': IndexNode(id_='38af6b9f-8f51-402c-8390-78e9d7614e1d', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-51', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='c7d5d6d116b75d1b799ddd97e193257c36b6126a95f63c6a3f9a11e117371906'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='3124707c-c7a3-46cc-ac3f-0db982ffe490', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='343c80164ef2a226202e75fe83ca67c8d4b6afd291057e1e1c8318d4e8d4b3f6'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='cd080c26-098e-44c5-8b7c-aab4286326fe', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='adbc3d9210c358c49fc366c15eaf8278e728e4c4f7688ba4c88f238052fcbb7a')}, hash='6c1a8ffa4709b38d77d50d38d937cd1c6162379c4cf4549eedabf5e1762b8e63', text='9\\n33B 83.1 82.3 50.4 82.8 76.0 80.0 57.858.6 72.5 57.8\\n65B85.382.852.3 84.2 77.0 78.9 56.0 60.2 74.0 63.4\\nLlama 27B 77.4 78.8 48.3 77.2 69.2 75.2 45.9 58.6 57.8 45.3\\n13B 81.7 80.5 50.3 80.7 72.8 77.3 49.4 57.0 67.3 54.8\\n34B 83.7 81.9 50.9 83.3 76.7 79.4 54.5 58.2 74.3 62.6\\n70B 85.0 82.850.7 85.3 80.2 80.2 57.460.2 78.5 68.9\\nTable 20: Performance on standard benchmarks.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-51'),\n",
              " 'cd080c26-098e-44c5-8b7c-aab4286326fe': IndexNode(id_='cd080c26-098e-44c5-8b7c-aab4286326fe', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-51', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='c7d5d6d116b75d1b799ddd97e193257c36b6126a95f63c6a3f9a11e117371906'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='38af6b9f-8f51-402c-8390-78e9d7614e1d', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='6c1a8ffa4709b38d77d50d38d937cd1c6162379c4cf4549eedabf5e1762b8e63'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='4ba4a3af-8557-4659-b4b0-308f4a6fa5d2', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='8e55c4658321cfb6d4d3b04a64c6d4795a3bac0eb79397d3567e828e2ac1e324')}, hash='adbc3d9210c358c49fc366c15eaf8278e728e4c4f7688ba4c88f238052fcbb7a', text='460.2 78.5 68.9\\nTable 20: Performance on standard benchmarks.\\nHuman-Eval MBPP\\npass@1 pass@100 pass@1 pass@80\\nMPT7B 18.3 - 22.6 -\\n30B 25.0 - 32.8 -\\nFalcon7B 0.0 - 11.2 -\\n40B 0.6 - 29.8 -\\nLlama 17B 10.5 36.5 17.7 56.2\\n13B 15.8 52.5 22.0 64.0\\n33B 21.7 70.7 30.2 73.4\\n65B 23.7 79.3 37.7 76.8\\nLlama 27B 12.8 45.6 20.8 62.8\\n13B 18.3 60.2 30.6 69.0\\n34B 22.6 77.2 33.0 76.1\\n70B29.9 89.0 45.0 81.4\\nTable 21: Code generation results on Human-Eval and MBPP . We report 0-shot and 3-shot results for\\nHuman-Eval and MBPP respectively.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-51'),\n",
              " '4ba4a3af-8557-4659-b4b0-308f4a6fa5d2': IndexNode(id_='4ba4a3af-8557-4659-b4b0-308f4a6fa5d2', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-51', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='c7d5d6d116b75d1b799ddd97e193257c36b6126a95f63c6a3f9a11e117371906'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='cd080c26-098e-44c5-8b7c-aab4286326fe', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='adbc3d9210c358c49fc366c15eaf8278e728e4c4f7688ba4c88f238052fcbb7a')}, hash='8e55c4658321cfb6d4d3b04a64c6d4795a3bac0eb79397d3567e828e2ac1e324', text='For pass@100 and pass@80 scores, we use a temperature of 0.8 and\\ntop-p=0.95. For pass@1 scores, we use a temperature of 0.1 and top- p=0.95.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-51'),\n",
              " 'f8c7ac4e-a78d-47e0-adc4-63d79e95a48f': IndexNode(id_='f8c7ac4e-a78d-47e0-adc4-63d79e95a48f', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-51', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='c7d5d6d116b75d1b799ddd97e193257c36b6126a95f63c6a3f9a11e117371906'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='1a3f82a6-254d-450c-bfbb-4b177e1b7f71', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='1056fa2f0c3603572cbb9a6e45eaeb461ddadbc805728d7e925729b1c5116ccc')}, hash='a195f017652ca188fd44d22867e201695b992cb3a6857ce8aca393f34455f2ee', text='BoolQ PIQA SIQA HellaSwag WinoGrande ARC-e ARC-c OBQA CSQA MMLU\\nMPT7B 75.0 80.6 48.5 76.4 68.3 70.2 42.6 51.4 21.3 26.8\\n30B 79.0 81.9 48.9 79.9 71.0 76.5 50.6 52.0 58.2 46.9\\nFalcon7B 67.5 76.7 47.2 74.1 66.3 70.0 42.4 51.6 20.8 26.2\\n40B 83.1 82.4 50.1 83.6 76.9 79.2 54.5 56.6 70.4 55.4\\nLlama 17B 76.5 79.8 48.9 76.1 70.1 72.8 47.6 57.2 33.6 35.1\\n13B 78.1 80.1 50.4 79.2 73.0 74.8 52.7 56.4 62.0 46.9\\n33B 83.1 82.3 50.4 82.8 76.0 80.0 57.858.6 72.5 57.8\\n65B85.382.852.3 84.2 77.0 78.9 56.0 60.2 74.0 63.4\\nLlama 27B 77.4 78.8 48.3 77.2 69.2 75.2 45.9 58.6 57.8 45.3\\n13B 81.7 80.5 50.3 80.7 72.8 77.3 49.4 57.0 67.3 54.8\\n34B 83.7 81.9 50.9 83.3 76.7 79.4 54.5 58.2 74.3 62.6\\n70B 85.0 82.850.7 85.3 80.2 80.2 57.460.2 78.5 68.9\\nTable 20: Performance on standard benchmarks.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-51'),\n",
              " '1a3f82a6-254d-450c-bfbb-4b177e1b7f71': IndexNode(id_='1a3f82a6-254d-450c-bfbb-4b177e1b7f71', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-51', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='c7d5d6d116b75d1b799ddd97e193257c36b6126a95f63c6a3f9a11e117371906'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='f8c7ac4e-a78d-47e0-adc4-63d79e95a48f', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='a195f017652ca188fd44d22867e201695b992cb3a6857ce8aca393f34455f2ee')}, hash='1056fa2f0c3603572cbb9a6e45eaeb461ddadbc805728d7e925729b1c5116ccc', text='Human-Eval MBPP\\npass@1 pass@100 pass@1 pass@80\\nMPT7B 18.3 - 22.6 -\\n30B 25.0 - 32.8 -\\nFalcon7B 0.0 - 11.2 -\\n40B 0.6 - 29.8 -\\nLlama 17B 10.5 36.5 17.7 56.2\\n13B 15.8 52.5 22.0 64.0\\n33B 21.7 70.7 30.2 73.4\\n65B 23.7 79.3 37.7 76.8\\nLlama 27B 12.8 45.6 20.8 62.8\\n13B 18.3 60.2 30.6 69.0\\n34B 22.6 77.2 33.0 76.1\\n70B29.9 89.0 45.0 81.4\\nTable 21: Code generation results on Human-Eval and MBPP . We report 0-shot and 3-shot results for\\nHuman-Eval and MBPP respectively. For pass@100 and pass@80 scores, we use a temperature of 0.8 and\\ntop-p=0.95. For pass@1 scores, we use a temperature of 0.1 and top- p=0.95.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-51'),\n",
              " 'node-51': IndexNode(id_='node-51', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='415b7efc-e73f-4ac4-bbfd-c1546f099026', node_type=<ObjectType.DOCUMENT: '4'>, metadata={}, hash='231b3bd773f012c01b893ada9e009ecf25ee59934614c5a595c9bf1b3a123292'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='eeb076b5-d34d-4d12-80d4-b175d074895a', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='5a1d6743aecd8f51098323290028c4bca5080308d616dfc606af8af7de50c0de'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='61a87ae1-6194-425e-adca-e0d356f79543', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='eacbbb2f15adab2ecc5b435e9b3fbee3b56cb5e9e7e961ac17e8ef79c4bb96c9')}, hash='c7d5d6d116b75d1b799ddd97e193257c36b6126a95f63c6a3f9a11e117371906', text='BoolQ PIQA SIQA HellaSwag WinoGrande ARC-e ARC-c OBQA CSQA MMLU\\nMPT7B 75.0 80.6 48.5 76.4 68.3 70.2 42.6 51.4 21.3 26.8\\n30B 79.0 81.9 48.9 79.9 71.0 76.5 50.6 52.0 58.2 46.9\\nFalcon7B 67.5 76.7 47.2 74.1 66.3 70.0 42.4 51.6 20.8 26.2\\n40B 83.1 82.4 50.1 83.6 76.9 79.2 54.5 56.6 70.4 55.4\\nLlama 17B 76.5 79.8 48.9 76.1 70.1 72.8 47.6 57.2 33.6 35.1\\n13B 78.1 80.1 50.4 79.2 73.0 74.8 52.7 56.4 62.0 46.9\\n33B 83.1 82.3 50.4 82.8 76.0 80.0 57.858.6 72.5 57.8\\n65B85.382.852.3 84.2 77.0 78.9 56.0 60.2 74.0 63.4\\nLlama 27B 77.4 78.8 48.3 77.2 69.2 75.2 45.9 58.6 57.8 45.3\\n13B 81.7 80.5 50.3 80.7 72.8 77.3 49.4 57.0 67.3 54.8\\n34B 83.7 81.9 50.9 83.3 76.7 79.4 54.5 58.2 74.3 62.6\\n70B 85.0 82.850.7 85.3 80.2 80.2 57.460.2 78.5 68.9\\nTable 20: Performance on standard benchmarks.\\nHuman-Eval MBPP\\npass@1 pass@100 pass@1 pass@80\\nMPT7B 18.3 - 22.6 -\\n30B 25.0 - 32.8 -\\nFalcon7B 0.0 - 11.2 -\\n40B 0.6 - 29.8 -\\nLlama 17B 10.5 36.5 17.7 56.2\\n13B 15.8 52.5 22.0 64.0\\n33B 21.7 70.7 30.2 73.4\\n65B 23.7 79.3 37.7 76.8\\nLlama 27B 12.8 45.6 20.8 62.8\\n13B 18.3 60.2 30.6 69.0\\n34B 22.6 77.2 33.0 76.1\\n70B29.9 89.0 45.0 81.4\\nTable 21: Code generation results on Human-Eval and MBPP . We report 0-shot and 3-shot results for\\nHuman-Eval and MBPP respectively. For pass@100 and pass@80 scores, we use a temperature of 0.8 and\\ntop-p=0.95. For pass@1 scores, we use a temperature of 0.1 and top- p=0.95.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-51'),\n",
              " '9a9a95c5-beb1-4317-a2f6-1447c9b816ed': IndexNode(id_='9a9a95c5-beb1-4317-a2f6-1447c9b816ed', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-52', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='eacbbb2f15adab2ecc5b435e9b3fbee3b56cb5e9e7e961ac17e8ef79c4bb96c9'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='4a51529e-2642-4d72-8a15-0d45e42a7751', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='bdae2e21c8ac5e50f4f1bc1704020639ef83729e1d2cb71e46bc9bad137256c6')}, hash='3b67874f6aa18809b711d183698c597af3c36609cd299102af65776850d09889', text='49\\n\\nNaturalQuestions TriviaQA (Wiki)\\n0-shot 1-shot 5-shot 64-shot 0-shot 1-shot 5-shot 64-shot\\nMPT7B 11.6 17.8 20.8 22.7 55.7 59.6 61.2 61.6\\n30B 15.8 23.0 26.6 29.3 68.0 71.3 73.3 73.6\\nFalcon7B 15.7 18.1 21.0 24.0 52.6 56.8 64.6 61.1\\n40B26.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-52'),\n",
              " '4a51529e-2642-4d72-8a15-0d45e42a7751': IndexNode(id_='4a51529e-2642-4d72-8a15-0d45e42a7751', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-52', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='eacbbb2f15adab2ecc5b435e9b3fbee3b56cb5e9e7e961ac17e8ef79c4bb96c9'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='9a9a95c5-beb1-4317-a2f6-1447c9b816ed', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='3b67874f6aa18809b711d183698c597af3c36609cd299102af65776850d09889'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='127e32f7-0887-41fe-a160-9bff3fd9aa80', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='f544380383a78d3695789363f182d9a5167c2897b90aec4d792c01a4e534f93d')}, hash='bdae2e21c8ac5e50f4f1bc1704020639ef83729e1d2cb71e46bc9bad137256c6', text='0 52.6 56.8 64.6 61.1\\n40B26.3 29.5 33.5 35.5 74.6 78.6 79.9 79.6\\nLlama 17B 16.8 18.7 22.0 26.1 63.3 67.4 70.4 71.0\\n13B 20.1 23.4 28.1 31.9 70.1 74.4 77.1 77.9\\n33B 24.9 28.3 32.9 36.0 78.7 80.7 83.8 83.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-52'),\n",
              " '127e32f7-0887-41fe-a160-9bff3fd9aa80': IndexNode(id_='127e32f7-0887-41fe-a160-9bff3fd9aa80', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-52', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='eacbbb2f15adab2ecc5b435e9b3fbee3b56cb5e9e7e961ac17e8ef79c4bb96c9'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='4a51529e-2642-4d72-8a15-0d45e42a7751', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='bdae2e21c8ac5e50f4f1bc1704020639ef83729e1d2cb71e46bc9bad137256c6'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='12ac74eb-c2e4-4ccf-ae28-874a42940d85', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='b1b6b6ca696e2a0aa68bce9b16b27812accc397ae37f89b69143e10e18812431')}, hash='f544380383a78d3695789363f182d9a5167c2897b90aec4d792c01a4e534f93d', text='3 32.9 36.0 78.7 80.7 83.8 83.6\\n65B 23.8 31.0 35.0 39.9 81.7 84.5 85.9 86.0\\nLlama 27B 16.4 22.7 25.7 29.5 65.8 68.9 72.1 73.7\\n13B 16.1 28.0 31.2 34.6 73.1 77.2 79.6 79.4\\n34B 25.1 30.0 32.8 39.9 81.0 83.3 84.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-52'),\n",
              " '12ac74eb-c2e4-4ccf-ae28-874a42940d85': IndexNode(id_='12ac74eb-c2e4-4ccf-ae28-874a42940d85', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-52', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='eacbbb2f15adab2ecc5b435e9b3fbee3b56cb5e9e7e961ac17e8ef79c4bb96c9'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='127e32f7-0887-41fe-a160-9bff3fd9aa80', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='f544380383a78d3695789363f182d9a5167c2897b90aec4d792c01a4e534f93d'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='51fd1673-3b1d-435d-9765-04fdd50e0356', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='6b74e84e058150a75f94486b03b4837101c674a41d8e36d4c8d66ebc5b4a5363')}, hash='b1b6b6ca696e2a0aa68bce9b16b27812accc397ae37f89b69143e10e18812431', text='1 30.0 32.8 39.9 81.0 83.3 84.5 84.6\\n70B 25.3 33.0 39.5 44.3 82.4 85.0 87.6 87.5\\nTable22: (Left)NaturalQuestions. Exactmatchperformance. (Right)TriviaQA. Zero-shotandfew-shot\\nexact match performance on the filtered dev set. For TriviaQA, we evaluate on Wiki validation subset.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-52'),\n",
              " '51fd1673-3b1d-435d-9765-04fdd50e0356': IndexNode(id_='51fd1673-3b1d-435d-9765-04fdd50e0356', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-52', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='eacbbb2f15adab2ecc5b435e9b3fbee3b56cb5e9e7e961ac17e8ef79c4bb96c9'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='12ac74eb-c2e4-4ccf-ae28-874a42940d85', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='b1b6b6ca696e2a0aa68bce9b16b27812accc397ae37f89b69143e10e18812431'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='2139e42b-52a2-4568-94d3-81d0dc12dfed', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='ccb25057af0f7121567040f37a350c2349874f895426e1977c10510411bb6bcb')}, hash='6b74e84e058150a75f94486b03b4837101c674a41d8e36d4c8d66ebc5b4a5363', text='For TriviaQA, we evaluate on Wiki validation subset.\\nSQUAD (EM) QUAC (f1)\\nModel Size 0-shot 1-shot 4-shot 5-shot 0-shot 1-shot\\nMPT 7B 59.5 62.8 62.6 62.7 38.0 37.7\\nMPT 30B 74.7 74.2 72.4 74.2 40.4 41.1\\nFalcon 7B 16.4 16.0 16.9 17.5 24.0 18.8\\nFalcon 40B 72.9 73.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-52'),\n",
              " '2139e42b-52a2-4568-94d3-81d0dc12dfed': IndexNode(id_='2139e42b-52a2-4568-94d3-81d0dc12dfed', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-52', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='eacbbb2f15adab2ecc5b435e9b3fbee3b56cb5e9e7e961ac17e8ef79c4bb96c9'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='51fd1673-3b1d-435d-9765-04fdd50e0356', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='6b74e84e058150a75f94486b03b4837101c674a41d8e36d4c8d66ebc5b4a5363'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='8cd1ac74-c5ef-4e88-aabd-bd52fa814da6', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='65c0c22a9850eedd8ca867e5240840155e644c9490f21b2850b3b9d300bad48d')}, hash='ccb25057af0f7121567040f37a350c2349874f895426e1977c10510411bb6bcb', text='9 17.5 24.0 18.8\\nFalcon 40B 72.9 73.1 71.7 71.0 41.2 43.3\\nLlama 17B 60.0 62.3 63.3 62.8 38.9 32.0\\n13B 68.9 68.4 66.4 66.7 39.9 36.5\\n33B 75.5 77.0 76.3 75.6 44.1 40.3\\n65B 79.4 80.0 78.3 77.9 41.0 39.8\\nLlama 27B 67.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-52'),\n",
              " '8cd1ac74-c5ef-4e88-aabd-bd52fa814da6': IndexNode(id_='8cd1ac74-c5ef-4e88-aabd-bd52fa814da6', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-52', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='eacbbb2f15adab2ecc5b435e9b3fbee3b56cb5e9e7e961ac17e8ef79c4bb96c9'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='2139e42b-52a2-4568-94d3-81d0dc12dfed', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='ccb25057af0f7121567040f37a350c2349874f895426e1977c10510411bb6bcb'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='3831c1ad-c1a3-4bd4-a77f-cb0319c94dc0', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='49371af25d9e6b10cf37663d451a610ace7f4011e6364f6649f9c49c4a310c8c')}, hash='65c0c22a9850eedd8ca867e5240840155e644c9490f21b2850b3b9d300bad48d', text='3 77.9 41.0 39.8\\nLlama 27B 67.2 72.3 72.6 72.5 39.4 39.7\\n13B 72.9 72.1 70.6 71.3 42.7 44.8\\n34B 77.4 78.8 77.5 77.5 42.9 44.4\\n70B80.7 82.6 81.9 81.9 42.4 49.3\\nTable 23: Comparison to open-source models on reading comprehension (SQUAD and QUAC).', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-52'),\n",
              " '3831c1ad-c1a3-4bd4-a77f-cb0319c94dc0': IndexNode(id_='3831c1ad-c1a3-4bd4-a77f-cb0319c94dc0', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-52', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='eacbbb2f15adab2ecc5b435e9b3fbee3b56cb5e9e7e961ac17e8ef79c4bb96c9'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='8cd1ac74-c5ef-4e88-aabd-bd52fa814da6', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='65c0c22a9850eedd8ca867e5240840155e644c9490f21b2850b3b9d300bad48d')}, hash='49371af25d9e6b10cf37663d451a610ace7f4011e6364f6649f9c49c4a310c8c', text='Model Size Avg AQuA-RAT LogiQA LSAT-AR LSAT-LR LSAT-RC SAT-en SAT-en (w/o Psg.)', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-52'),\n",
              " '498da63e-55fd-4b7a-9cb0-00ded7b5366c': IndexNode(id_='498da63e-55fd-4b7a-9cb0-00ded7b5366c', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-52', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='eacbbb2f15adab2ecc5b435e9b3fbee3b56cb5e9e7e961ac17e8ef79c4bb96c9'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='80372914-a59a-4015-a566-b2b269de49a9', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='382f7c4cb3e78dc45803fd646c109bd4bf4c60e605b6ee8cafa5142b2a85e423')}, hash='a5a42a7344a5db22647deabbbe31ea8f9bdd5a477e120efcddd94424a5532652', text='49\\n\\nNaturalQuestions TriviaQA (Wiki)\\n0-shot 1-shot 5-shot 64-shot 0-shot 1-shot 5-shot 64-shot\\nMPT7B 11.6 17.8 20.8 22.7 55.7 59.6 61.2 61.6\\n30B 15.8 23.0 26.6 29.3 68.0 71.3 73.3 73.6\\nFalcon7B 15.7 18.1 21.0 24.0 52.6 56.8 64.6 61.1\\n40B26.3 29.5 33.5 35.5 74.6 78.6 79.9 79.6\\nLlama 17B 16.8 18.7 22.0 26.1 63.3 67.4 70.4 71.0\\n13B 20.1 23.4 28.1 31.9 70.1 74.4 77.1 77.9\\n33B 24.9 28.3 32.9 36.0 78.7 80.7 83.8 83.6\\n65B 23.8 31.0 35.0 39.9 81.7 84.5 85.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-52'),\n",
              " '80372914-a59a-4015-a566-b2b269de49a9': IndexNode(id_='80372914-a59a-4015-a566-b2b269de49a9', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-52', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='eacbbb2f15adab2ecc5b435e9b3fbee3b56cb5e9e7e961ac17e8ef79c4bb96c9'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='498da63e-55fd-4b7a-9cb0-00ded7b5366c', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='a5a42a7344a5db22647deabbbe31ea8f9bdd5a477e120efcddd94424a5532652'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='192e074b-251b-45d6-8976-50ff41e27dac', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='cb18dc99446c7f0d1c0537d0ce8000e650b98484fcd1b5d7dfe9ab99e92bfcd7')}, hash='382f7c4cb3e78dc45803fd646c109bd4bf4c60e605b6ee8cafa5142b2a85e423', text='8 31.0 35.0 39.9 81.7 84.5 85.9 86.0\\nLlama 27B 16.4 22.7 25.7 29.5 65.8 68.9 72.1 73.7\\n13B 16.1 28.0 31.2 34.6 73.1 77.2 79.6 79.4\\n34B 25.1 30.0 32.8 39.9 81.0 83.3 84.5 84.6\\n70B 25.3 33.0 39.5 44.3 82.4 85.0 87.6 87.5\\nTable22: (Left)NaturalQuestions. Exactmatchperformance. (Right)TriviaQA. Zero-shotandfew-shot\\nexact match performance on the filtered dev set. For TriviaQA, we evaluate on Wiki validation subset.\\nSQUAD (EM) QUAC (f1)\\nModel Size 0-shot 1-shot 4-shot 5-shot 0-shot 1-shot\\nMPT 7B 59.5 62.8 62.6 62.7 38.0 37.7\\nMPT 30B 74.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-52'),\n",
              " '192e074b-251b-45d6-8976-50ff41e27dac': IndexNode(id_='192e074b-251b-45d6-8976-50ff41e27dac', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-52', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='eacbbb2f15adab2ecc5b435e9b3fbee3b56cb5e9e7e961ac17e8ef79c4bb96c9'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='80372914-a59a-4015-a566-b2b269de49a9', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='382f7c4cb3e78dc45803fd646c109bd4bf4c60e605b6ee8cafa5142b2a85e423'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='36ba31cf-af1f-4aaf-ac6e-502a28b3a0c5', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='15659cd89d9ab6f43b1b630bdca9950c1a69c9d7f730ed3505f35a1f807cc602')}, hash='cb18dc99446c7f0d1c0537d0ce8000e650b98484fcd1b5d7dfe9ab99e92bfcd7', text='8 62.6 62.7 38.0 37.7\\nMPT 30B 74.7 74.2 72.4 74.2 40.4 41.1\\nFalcon 7B 16.4 16.0 16.9 17.5 24.0 18.8\\nFalcon 40B 72.9 73.1 71.7 71.0 41.2 43.3\\nLlama 17B 60.0 62.3 63.3 62.8 38.9 32.0\\n13B 68.9 68.4 66.4 66.7 39.9 36.5\\n33B 75.5 77.0 76.3 75.6 44.1 40.3\\n65B 79.4 80.0 78.3 77.9 41.0 39.8\\nLlama 27B 67.2 72.3 72.6 72.5 39.4 39.7\\n13B 72.9 72.1 70.6 71.3 42.7 44.8\\n34B 77.4 78.8 77.5 77.5 42.9 44.4\\n70B80.7 82.6 81.9 81.9 42.4 49.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-52'),\n",
              " '36ba31cf-af1f-4aaf-ac6e-502a28b3a0c5': IndexNode(id_='36ba31cf-af1f-4aaf-ac6e-502a28b3a0c5', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-52', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='eacbbb2f15adab2ecc5b435e9b3fbee3b56cb5e9e7e961ac17e8ef79c4bb96c9'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='192e074b-251b-45d6-8976-50ff41e27dac', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='cb18dc99446c7f0d1c0537d0ce8000e650b98484fcd1b5d7dfe9ab99e92bfcd7')}, hash='15659cd89d9ab6f43b1b630bdca9950c1a69c9d7f730ed3505f35a1f807cc602', text='7 82.6 81.9 81.9 42.4 49.3\\nTable 23: Comparison to open-source models on reading comprehension (SQUAD and QUAC).\\nModel Size Avg AQuA-RAT LogiQA LSAT-AR LSAT-LR LSAT-RC SAT-en SAT-en (w/o Psg.)', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-52'),\n",
              " 'a7e01015-189d-43ec-b10c-6631d69c1e85': IndexNode(id_='a7e01015-189d-43ec-b10c-6631d69c1e85', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-52', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='eacbbb2f15adab2ecc5b435e9b3fbee3b56cb5e9e7e961ac17e8ef79c4bb96c9'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='8c7c8e1b-05e9-469a-ad20-181f6b3f1b85', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='1abc4f68877ea9d529afe8b13314459beff00258b03e1466780c78fee29b2d14')}, hash='293a274f00882a9b10e209e5af15f534bb0ea59d3c083a54e59770f0b6a79989', text='49\\n\\nNaturalQuestions TriviaQA (Wiki)\\n0-shot 1-shot 5-shot 64-shot 0-shot 1-shot 5-shot 64-shot\\nMPT7B 11.6 17.8 20.8 22.7 55.7 59.6 61.2 61.6\\n30B 15.8 23.0 26.6 29.3 68.0 71.3 73.3 73.6\\nFalcon7B 15.7 18.1 21.0 24.0 52.6 56.8 64.6 61.1\\n40B26.3 29.5 33.5 35.5 74.6 78.6 79.9 79.6\\nLlama 17B 16.8 18.7 22.0 26.1 63.3 67.4 70.4 71.0\\n13B 20.1 23.4 28.1 31.9 70.1 74.4 77.1 77.9\\n33B 24.9 28.3 32.9 36.0 78.7 80.7 83.8 83.6\\n65B 23.8 31.0 35.0 39.9 81.7 84.5 85.9 86.0\\nLlama 27B 16.4 22.7 25.7 29.5 65.8 68.9 72.1 73.7\\n13B 16.1 28.0 31.2 34.6 73.1 77.2 79.6 79.4\\n34B 25.1 30.0 32.8 39.9 81.0 83.3 84.5 84.6\\n70B 25.3 33.0 39.5 44.3 82.4 85.0 87.6 87.5\\nTable22: (Left)NaturalQuestions. Exactmatchperformance. (Right)TriviaQA. Zero-shotandfew-shot\\nexact match performance on the filtered dev set. For TriviaQA, we evaluate on Wiki validation subset.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-52'),\n",
              " '8c7c8e1b-05e9-469a-ad20-181f6b3f1b85': IndexNode(id_='8c7c8e1b-05e9-469a-ad20-181f6b3f1b85', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-52', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='eacbbb2f15adab2ecc5b435e9b3fbee3b56cb5e9e7e961ac17e8ef79c4bb96c9'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='a7e01015-189d-43ec-b10c-6631d69c1e85', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='293a274f00882a9b10e209e5af15f534bb0ea59d3c083a54e59770f0b6a79989')}, hash='1abc4f68877ea9d529afe8b13314459beff00258b03e1466780c78fee29b2d14', text='For TriviaQA, we evaluate on Wiki validation subset.\\nSQUAD (EM) QUAC (f1)\\nModel Size 0-shot 1-shot 4-shot 5-shot 0-shot 1-shot\\nMPT 7B 59.5 62.8 62.6 62.7 38.0 37.7\\nMPT 30B 74.7 74.2 72.4 74.2 40.4 41.1\\nFalcon 7B 16.4 16.0 16.9 17.5 24.0 18.8\\nFalcon 40B 72.9 73.1 71.7 71.0 41.2 43.3\\nLlama 17B 60.0 62.3 63.3 62.8 38.9 32.0\\n13B 68.9 68.4 66.4 66.7 39.9 36.5\\n33B 75.5 77.0 76.3 75.6 44.1 40.3\\n65B 79.4 80.0 78.3 77.9 41.0 39.8\\nLlama 27B 67.2 72.3 72.6 72.5 39.4 39.7\\n13B 72.9 72.1 70.6 71.3 42.7 44.8\\n34B 77.4 78.8 77.5 77.5 42.9 44.4\\n70B80.7 82.6 81.9 81.9 42.4 49.3\\nTable 23: Comparison to open-source models on reading comprehension (SQUAD and QUAC).\\nModel Size Avg AQuA-RAT LogiQA LSAT-AR LSAT-LR LSAT-RC SAT-en SAT-en (w/o Psg.)', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-52'),\n",
              " 'node-52': IndexNode(id_='node-52', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='415b7efc-e73f-4ac4-bbfd-c1546f099026', node_type=<ObjectType.DOCUMENT: '4'>, metadata={}, hash='231b3bd773f012c01b893ada9e009ecf25ee59934614c5a595c9bf1b3a123292'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='5fa6f3e6-2f1e-4bf4-a33c-8333b98b56c6', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='c7d5d6d116b75d1b799ddd97e193257c36b6126a95f63c6a3f9a11e117371906'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='d1c5beac-0374-4563-80dd-22040db238f7', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='e76af321a5d43a6bea6574d74a7816e3aa9f8d65fce20f719f7f7286e92fa2b6')}, hash='eacbbb2f15adab2ecc5b435e9b3fbee3b56cb5e9e7e961ac17e8ef79c4bb96c9', text='49\\n\\nNaturalQuestions TriviaQA (Wiki)\\n0-shot 1-shot 5-shot 64-shot 0-shot 1-shot 5-shot 64-shot\\nMPT7B 11.6 17.8 20.8 22.7 55.7 59.6 61.2 61.6\\n30B 15.8 23.0 26.6 29.3 68.0 71.3 73.3 73.6\\nFalcon7B 15.7 18.1 21.0 24.0 52.6 56.8 64.6 61.1\\n40B26.3 29.5 33.5 35.5 74.6 78.6 79.9 79.6\\nLlama 17B 16.8 18.7 22.0 26.1 63.3 67.4 70.4 71.0\\n13B 20.1 23.4 28.1 31.9 70.1 74.4 77.1 77.9\\n33B 24.9 28.3 32.9 36.0 78.7 80.7 83.8 83.6\\n65B 23.8 31.0 35.0 39.9 81.7 84.5 85.9 86.0\\nLlama 27B 16.4 22.7 25.7 29.5 65.8 68.9 72.1 73.7\\n13B 16.1 28.0 31.2 34.6 73.1 77.2 79.6 79.4\\n34B 25.1 30.0 32.8 39.9 81.0 83.3 84.5 84.6\\n70B 25.3 33.0 39.5 44.3 82.4 85.0 87.6 87.5\\nTable22: (Left)NaturalQuestions. Exactmatchperformance. (Right)TriviaQA. Zero-shotandfew-shot\\nexact match performance on the filtered dev set. For TriviaQA, we evaluate on Wiki validation subset.\\nSQUAD (EM) QUAC (f1)\\nModel Size 0-shot 1-shot 4-shot 5-shot 0-shot 1-shot\\nMPT 7B 59.5 62.8 62.6 62.7 38.0 37.7\\nMPT 30B 74.7 74.2 72.4 74.2 40.4 41.1\\nFalcon 7B 16.4 16.0 16.9 17.5 24.0 18.8\\nFalcon 40B 72.9 73.1 71.7 71.0 41.2 43.3\\nLlama 17B 60.0 62.3 63.3 62.8 38.9 32.0\\n13B 68.9 68.4 66.4 66.7 39.9 36.5\\n33B 75.5 77.0 76.3 75.6 44.1 40.3\\n65B 79.4 80.0 78.3 77.9 41.0 39.8\\nLlama 27B 67.2 72.3 72.6 72.5 39.4 39.7\\n13B 72.9 72.1 70.6 71.3 42.7 44.8\\n34B 77.4 78.8 77.5 77.5 42.9 44.4\\n70B80.7 82.6 81.9 81.9 42.4 49.3\\nTable 23: Comparison to open-source models on reading comprehension (SQUAD and QUAC).\\nModel Size Avg AQuA-RAT LogiQA LSAT-AR LSAT-LR LSAT-RC SAT-en SAT-en (w/o Psg.)', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-52'),\n",
              " '2ac22e82-da54-422d-90ad-7526cd96044b': IndexNode(id_='2ac22e82-da54-422d-90ad-7526cd96044b', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-53', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='e76af321a5d43a6bea6574d74a7816e3aa9f8d65fce20f719f7f7286e92fa2b6'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='dbe33933-5926-4bcc-b792-3ff8c83dc9ac', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='520d1701bdda8a44247a011d2b7aac6d58c87b9d305b03525d2550dfefb4bc76')}, hash='6cb2394a3332908c7ccfa52ef534c23f374db5a145ffb2aa52c2316981fbfff2', text='SAT-math\\nMPT 7B 23.5 27.6 23.0 18.7 21.2 20.8 25.2 32.5 23.6\\nMPT 30B 33.8 28.0 28.7 23.9 35.1 37.9 63.1 36.9 27.7\\nFalcon 7B 21.2 21.7 22.3 16.1 17.3 20.4 26.2 23.8 26.4\\nFalcon 40B 37.0 18.5 36.4 19.6 40.2 45.7 58.7 58.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-53'),\n",
              " 'dbe33933-5926-4bcc-b792-3ff8c83dc9ac': IndexNode(id_='dbe33933-5926-4bcc-b792-3ff8c83dc9ac', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-53', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='e76af321a5d43a6bea6574d74a7816e3aa9f8d65fce20f719f7f7286e92fa2b6'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='2ac22e82-da54-422d-90ad-7526cd96044b', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='6cb2394a3332908c7ccfa52ef534c23f374db5a145ffb2aa52c2316981fbfff2'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='1e1185ca-ab11-4bd8-b9ff-6812a2740566', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='360249e957aa41bf8ed97373c9613c7b08652a91d18ab4427e3182010cdd9cf1')}, hash='520d1701bdda8a44247a011d2b7aac6d58c87b9d305b03525d2550dfefb4bc76', text='5 36.4 19.6 40.2 45.7 58.7 58.7 32.7\\nLlama 17B 23.9 18.9 24.6 26.1 19.2 21.9 33.0 32.5 22.3\\n13B 33.9 20.1 34.9 22.2 31.6 39.8 52.9 45.1 29.5\\n33B 41.7 18.9 37.3 18.7 48.0 59.5 74.8 44.7 35.0\\n65B 47.6 23.6 42.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-53'),\n",
              " '1e1185ca-ab11-4bd8-b9ff-6812a2740566': IndexNode(id_='1e1185ca-ab11-4bd8-b9ff-6812a2740566', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-53', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='e76af321a5d43a6bea6574d74a7816e3aa9f8d65fce20f719f7f7286e92fa2b6'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='dbe33933-5926-4bcc-b792-3ff8c83dc9ac', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='520d1701bdda8a44247a011d2b7aac6d58c87b9d305b03525d2550dfefb4bc76'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='7cde7f64-8ee3-463f-b73a-ff6eb120146d', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='7478797eb3d6e52100a6678e5db0863871f6e819f8e8248b660a3bbcd5a9a11a')}, hash='360249e957aa41bf8ed97373c9613c7b08652a91d18ab4427e3182010cdd9cf1', text='8 44.7 35.0\\n65B 47.6 23.6 42.1 23.9 56.7 63.6 83.0 48.1 41.8\\nLlama 27B 29.3 23.2 31.0 23.9 22.4 32.7 43.2 37.4 28.2\\n13B 39.1 21.7 38.1 23.0 41.0 54.6 62.1 46.1 27.3\\n34B 43.4 19.3 40.7 21.3 47.5 62.1 77.2 49.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-53'),\n",
              " '7cde7f64-8ee3-463f-b73a-ff6eb120146d': IndexNode(id_='7cde7f64-8ee3-463f-b73a-ff6eb120146d', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-53', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='e76af321a5d43a6bea6574d74a7816e3aa9f8d65fce20f719f7f7286e92fa2b6'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='1e1185ca-ab11-4bd8-b9ff-6812a2740566', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='360249e957aa41bf8ed97373c9613c7b08652a91d18ab4427e3182010cdd9cf1'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='55bad6f4-94be-4129-92d3-012ed460f61a', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='fe0be7b03b827247e54c09a0f2f3a69a0be300ade2cd5e0b3d6c8bfd504b5adc')}, hash='7478797eb3d6e52100a6678e5db0863871f6e819f8e8248b660a3bbcd5a9a11a', text='3 40.7 21.3 47.5 62.1 77.2 49.0 32.7\\n70B 54.2 23.2 48.8 25.7 70.2 76.6 86.9 53.4 41.8\\nTable 24: Comparison to open source models on AGI Eval (English)\\n50\\n\\nModel Size GSM8k MATH\\nMPT7B 6.8 3.0\\n30B 15.2 3.1\\nFalcon7B 6.8 2.3\\n40B 19.6 5.5\\nLlama 17B 11.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-53'),\n",
              " '55bad6f4-94be-4129-92d3-012ed460f61a': IndexNode(id_='55bad6f4-94be-4129-92d3-012ed460f61a', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-53', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='e76af321a5d43a6bea6574d74a7816e3aa9f8d65fce20f719f7f7286e92fa2b6'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='7cde7f64-8ee3-463f-b73a-ff6eb120146d', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='7478797eb3d6e52100a6678e5db0863871f6e819f8e8248b660a3bbcd5a9a11a'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='5b0868ef-39ab-47dc-8b30-a03ec25e56b3', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='f5e0357515dd2035abfde4c7b66dfb826731d1bc20b89337901a36da03c5b136')}, hash='fe0be7b03b827247e54c09a0f2f3a69a0be300ade2cd5e0b3d6c8bfd504b5adc', text='3\\n40B 19.6 5.5\\nLlama 17B 11.0 2.9\\n13B 17.8 3.9\\n33B 35.6 7.1\\n65B 50.9 10.6\\nLlama 27B 14.6 2.5\\n13B 28.7 3.9\\n34B 42.2 6.24\\n70B 56.8 13.5\\nTable 25: Comparison to other open-source models on mathematical reasoning tasks , GSM8k and MATH\\n(maj1@1 is reported).', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-53'),\n",
              " '5b0868ef-39ab-47dc-8b30-a03ec25e56b3': IndexNode(id_='5b0868ef-39ab-47dc-8b30-a03ec25e56b3', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-53', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='e76af321a5d43a6bea6574d74a7816e3aa9f8d65fce20f719f7f7286e92fa2b6'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='55bad6f4-94be-4129-92d3-012ed460f61a', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='fe0be7b03b827247e54c09a0f2f3a69a0be300ade2cd5e0b3d6c8bfd504b5adc'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='411b6c81-9a02-4ce7-a2b3-d7fdfdce3477', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='01daeea79f5bcce7dc276f1dc4ffd6ffa1e130b98785779922df7dfd7b240d9e')}, hash='f5e0357515dd2035abfde4c7b66dfb826731d1bc20b89337901a36da03c5b136', text='GSM8k and MATH\\n(maj1@1 is reported).\\nMathematical Reasoning. In Table 25, we report results for Llama 2 and other open-source datasets on the\\nGSM8k and MATH tasks.\\nA.3 Additional Details for Fine-tuning\\nA.3.1 Detailed Statistics of Meta Human Preference Data\\nTable 26 shows detailed statistics on Meta human preference data.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-53'),\n",
              " '411b6c81-9a02-4ce7-a2b3-d7fdfdce3477': IndexNode(id_='411b6c81-9a02-4ce7-a2b3-d7fdfdce3477', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-53', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='e76af321a5d43a6bea6574d74a7816e3aa9f8d65fce20f719f7f7286e92fa2b6'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='5b0868ef-39ab-47dc-8b30-a03ec25e56b3', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='f5e0357515dd2035abfde4c7b66dfb826731d1bc20b89337901a36da03c5b136'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='9d346785-9aeb-4766-bd43-41518fc11796', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='d34a74d33e2b46be3c8bd283fc7c1228fda03b50f669b9480eee26cef7409a6e')}, hash='01daeea79f5bcce7dc276f1dc4ffd6ffa1e130b98785779922df7dfd7b240d9e', text='In total, we collected 14 batches of human\\npreferencedata(i.e.,MetaSafety+Helpfulness)onaweeklybasis,consistingofover1millionbinarymodel\\ngeneration comparisons. In general, later batches contain more samples as we onboard more annotators over\\ntime and the annotators also become more familiar with the tasks and thus have better work efficiency. We\\nalso intentionally collect more multi-turn samples to increase the complexity of RLHF data and thus the\\naverage number of tokens per sample also increase accordingly over batches.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-53'),\n",
              " '9d346785-9aeb-4766-bd43-41518fc11796': IndexNode(id_='9d346785-9aeb-4766-bd43-41518fc11796', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-53', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='e76af321a5d43a6bea6574d74a7816e3aa9f8d65fce20f719f7f7286e92fa2b6'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='411b6c81-9a02-4ce7-a2b3-d7fdfdce3477', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='01daeea79f5bcce7dc276f1dc4ffd6ffa1e130b98785779922df7dfd7b240d9e'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='c33b54c2-4024-4931-b111-54f3d5529a50', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='f8ce2763805303ee06b8e9f6b5f1ce9c246d7fd015fb423f5227ee00d7c8b744')}, hash='d34a74d33e2b46be3c8bd283fc7c1228fda03b50f669b9480eee26cef7409a6e', text='In Figure 25, we plot out the preference rating change over batches. It can be clearly seen that the share\\nof samples with similar responses (e.g., negligibly better or unsure ) increase dramatically over time while\\nthose with stronger preference (e.g., significantly better ) drop in the meantime.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-53'),\n",
              " 'c33b54c2-4024-4931-b111-54f3d5529a50': IndexNode(id_='c33b54c2-4024-4931-b111-54f3d5529a50', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-53', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='e76af321a5d43a6bea6574d74a7816e3aa9f8d65fce20f719f7f7286e92fa2b6'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='9d346785-9aeb-4766-bd43-41518fc11796', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='d34a74d33e2b46be3c8bd283fc7c1228fda03b50f669b9480eee26cef7409a6e'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='cbc99d6e-1ee8-4e17-b02d-c42b62e16c5f', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='bbc23946cb03ad6908b12ff381bdc3e1e76e12dc9ff6ebaab8b6e51a66af48d8')}, hash='f8ce2763805303ee06b8e9f6b5f1ce9c246d7fd015fb423f5227ee00d7c8b744', text='This reflects the nature of our\\niterativemodelupdateandpreferencedataannotationprocedure-withbetter-performing Llama 2-Chat\\nmodelsusedforresponsesamplingovertime,itbecomeschallengingforannotatorstoselectabetterone\\nfrom two equally high-quality responses.\\nA.3.2 Curriculum Strategy for Meta Human Preference Data\\nHigh quality data is critical for alignment as discussed for SFT. We worked closely with the annotation\\nplatforms during our fine-tuning process, and opted for a curriculum annotation strategy.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-53'),\n",
              " 'cbc99d6e-1ee8-4e17-b02d-c42b62e16c5f': IndexNode(id_='cbc99d6e-1ee8-4e17-b02d-c42b62e16c5f', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-53', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='e76af321a5d43a6bea6574d74a7816e3aa9f8d65fce20f719f7f7286e92fa2b6'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='c33b54c2-4024-4931-b111-54f3d5529a50', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='f8ce2763805303ee06b8e9f6b5f1ce9c246d7fd015fb423f5227ee00d7c8b744')}, hash='bbc23946cb03ad6908b12ff381bdc3e1e76e12dc9ff6ebaab8b6e51a66af48d8', text='With the first\\nmodel,theannotatorswereaskedtomakepromptsrelativelysimple,andthentoprogressivelymovetowards\\nmorecomplexpromptsandteachingnewskillsto Llama 2-Chat . Anillustrationofthiscurriculumannotation\\non our helpfulness preference data is displayed in Figure 26.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-53'),\n",
              " 'd35c4e6a-2d8e-469c-9476-c03d5517559d': IndexNode(id_='d35c4e6a-2d8e-469c-9476-c03d5517559d', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-53', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='e76af321a5d43a6bea6574d74a7816e3aa9f8d65fce20f719f7f7286e92fa2b6'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='362d716e-b2c9-4adf-a75e-732a467551fc', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='4964c45cafe90e79712367cf1554525f0ff24b110b27e389a84213fc74339977')}, hash='992efabe5f37d5a902ddca4a4c9c7ca66cb1481ae7399630c2951b7f620436ba', text='SAT-math\\nMPT 7B 23.5 27.6 23.0 18.7 21.2 20.8 25.2 32.5 23.6\\nMPT 30B 33.8 28.0 28.7 23.9 35.1 37.9 63.1 36.9 27.7\\nFalcon 7B 21.2 21.7 22.3 16.1 17.3 20.4 26.2 23.8 26.4\\nFalcon 40B 37.0 18.5 36.4 19.6 40.2 45.7 58.7 58.7 32.7\\nLlama 17B 23.9 18.9 24.6 26.1 19.2 21.9 33.0 32.5 22.3\\n13B 33.9 20.1 34.9 22.2 31.6 39.8 52.9 45.1 29.5\\n33B 41.7 18.9 37.3 18.7 48.0 59.5 74.8 44.7 35.0\\n65B 47.6 23.6 42.1 23.9 56.7 63.6 83.0 48.1 41.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-53'),\n",
              " '362d716e-b2c9-4adf-a75e-732a467551fc': IndexNode(id_='362d716e-b2c9-4adf-a75e-732a467551fc', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-53', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='e76af321a5d43a6bea6574d74a7816e3aa9f8d65fce20f719f7f7286e92fa2b6'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='d35c4e6a-2d8e-469c-9476-c03d5517559d', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='992efabe5f37d5a902ddca4a4c9c7ca66cb1481ae7399630c2951b7f620436ba'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='dac7c5a7-6664-42ea-89a1-07ab170a1543', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='cc3155c39f460c5d9391e9d0d9883a8bd6de3b0adef0e6426471a1b23ef9c580')}, hash='4964c45cafe90e79712367cf1554525f0ff24b110b27e389a84213fc74339977', text='1 23.9 56.7 63.6 83.0 48.1 41.8\\nLlama 27B 29.3 23.2 31.0 23.9 22.4 32.7 43.2 37.4 28.2\\n13B 39.1 21.7 38.1 23.0 41.0 54.6 62.1 46.1 27.3\\n34B 43.4 19.3 40.7 21.3 47.5 62.1 77.2 49.0 32.7\\n70B 54.2 23.2 48.8 25.7 70.2 76.6 86.9 53.4 41.8\\nTable 24: Comparison to open source models on AGI Eval (English)\\n50\\n\\nModel Size GSM8k MATH\\nMPT7B 6.8 3.0\\n30B 15.2 3.1\\nFalcon7B 6.8 2.3\\n40B 19.6 5.5\\nLlama 17B 11.0 2.9\\n13B 17.8 3.9\\n33B 35.6 7.1\\n65B 50.9 10.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-53'),\n",
              " 'dac7c5a7-6664-42ea-89a1-07ab170a1543': IndexNode(id_='dac7c5a7-6664-42ea-89a1-07ab170a1543', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-53', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='e76af321a5d43a6bea6574d74a7816e3aa9f8d65fce20f719f7f7286e92fa2b6'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='362d716e-b2c9-4adf-a75e-732a467551fc', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='4964c45cafe90e79712367cf1554525f0ff24b110b27e389a84213fc74339977'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='6c14b56d-bd32-4547-a963-5dcf7e338d87', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='614524bd5eb6caf7da894cd9717104c5e46ae476be950010c529f3707a1c96b4')}, hash='cc3155c39f460c5d9391e9d0d9883a8bd6de3b0adef0e6426471a1b23ef9c580', text='9\\n33B 35.6 7.1\\n65B 50.9 10.6\\nLlama 27B 14.6 2.5\\n13B 28.7 3.9\\n34B 42.2 6.24\\n70B 56.8 13.5\\nTable 25: Comparison to other open-source models on mathematical reasoning tasks , GSM8k and MATH\\n(maj1@1 is reported).\\nMathematical Reasoning. In Table 25, we report results for Llama 2 and other open-source datasets on the\\nGSM8k and MATH tasks.\\nA.3 Additional Details for Fine-tuning\\nA.3.1 Detailed Statistics of Meta Human Preference Data\\nTable 26 shows detailed statistics on Meta human preference data. In total, we collected 14 batches of human\\npreferencedata(i.e.,MetaSafety+Helpfulness)onaweeklybasis,consistingofover1millionbinarymodel\\ngeneration comparisons. In general, later batches contain more samples as we onboard more annotators over\\ntime and the annotators also become more familiar with the tasks and thus have better work efficiency.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-53'),\n",
              " '6c14b56d-bd32-4547-a963-5dcf7e338d87': IndexNode(id_='6c14b56d-bd32-4547-a963-5dcf7e338d87', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-53', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='e76af321a5d43a6bea6574d74a7816e3aa9f8d65fce20f719f7f7286e92fa2b6'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='dac7c5a7-6664-42ea-89a1-07ab170a1543', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='cc3155c39f460c5d9391e9d0d9883a8bd6de3b0adef0e6426471a1b23ef9c580'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='66a972a3-8a2a-442c-8aac-7046b8de01bf', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='bbc23946cb03ad6908b12ff381bdc3e1e76e12dc9ff6ebaab8b6e51a66af48d8')}, hash='614524bd5eb6caf7da894cd9717104c5e46ae476be950010c529f3707a1c96b4', text='We\\nalso intentionally collect more multi-turn samples to increase the complexity of RLHF data and thus the\\naverage number of tokens per sample also increase accordingly over batches.\\nIn Figure 25, we plot out the preference rating change over batches. It can be clearly seen that the share\\nof samples with similar responses (e.g., negligibly better or unsure ) increase dramatically over time while\\nthose with stronger preference (e.g., significantly better ) drop in the meantime. This reflects the nature of our\\niterativemodelupdateandpreferencedataannotationprocedure-withbetter-performing Llama 2-Chat\\nmodelsusedforresponsesamplingovertime,itbecomeschallengingforannotatorstoselectabetterone\\nfrom two equally high-quality responses.\\nA.3.2 Curriculum Strategy for Meta Human Preference Data\\nHigh quality data is critical for alignment as discussed for SFT. We worked closely with the annotation\\nplatforms during our fine-tuning process, and opted for a curriculum annotation strategy.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-53'),\n",
              " '66a972a3-8a2a-442c-8aac-7046b8de01bf': IndexNode(id_='66a972a3-8a2a-442c-8aac-7046b8de01bf', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-53', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='e76af321a5d43a6bea6574d74a7816e3aa9f8d65fce20f719f7f7286e92fa2b6'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='6c14b56d-bd32-4547-a963-5dcf7e338d87', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='614524bd5eb6caf7da894cd9717104c5e46ae476be950010c529f3707a1c96b4')}, hash='bbc23946cb03ad6908b12ff381bdc3e1e76e12dc9ff6ebaab8b6e51a66af48d8', text='With the first\\nmodel,theannotatorswereaskedtomakepromptsrelativelysimple,andthentoprogressivelymovetowards\\nmorecomplexpromptsandteachingnewskillsto Llama 2-Chat . Anillustrationofthiscurriculumannotation\\non our helpfulness preference data is displayed in Figure 26.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-53'),\n",
              " 'b48be1af-4ae2-40c7-88e3-4189f8931933': IndexNode(id_='b48be1af-4ae2-40c7-88e3-4189f8931933', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-53', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='e76af321a5d43a6bea6574d74a7816e3aa9f8d65fce20f719f7f7286e92fa2b6'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='15a09b8d-0558-4083-81bd-a2f97b2b6515', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='ab6a64bf61413cdc7e1cb36dc34560c7bcbdf3124b9e1b9d08098dcc0ca9f104')}, hash='4a242b52529ab233d5fbe45c5eeee166f6b46b825279b6eb2ba2f20e3e201ff7', text='SAT-math\\nMPT 7B 23.5 27.6 23.0 18.7 21.2 20.8 25.2 32.5 23.6\\nMPT 30B 33.8 28.0 28.7 23.9 35.1 37.9 63.1 36.9 27.7\\nFalcon 7B 21.2 21.7 22.3 16.1 17.3 20.4 26.2 23.8 26.4\\nFalcon 40B 37.0 18.5 36.4 19.6 40.2 45.7 58.7 58.7 32.7\\nLlama 17B 23.9 18.9 24.6 26.1 19.2 21.9 33.0 32.5 22.3\\n13B 33.9 20.1 34.9 22.2 31.6 39.8 52.9 45.1 29.5\\n33B 41.7 18.9 37.3 18.7 48.0 59.5 74.8 44.7 35.0\\n65B 47.6 23.6 42.1 23.9 56.7 63.6 83.0 48.1 41.8\\nLlama 27B 29.3 23.2 31.0 23.9 22.4 32.7 43.2 37.4 28.2\\n13B 39.1 21.7 38.1 23.0 41.0 54.6 62.1 46.1 27.3\\n34B 43.4 19.3 40.7 21.3 47.5 62.1 77.2 49.0 32.7\\n70B 54.2 23.2 48.8 25.7 70.2 76.6 86.9 53.4 41.8\\nTable 24: Comparison to open source models on AGI Eval (English)\\n50\\n\\nModel Size GSM8k MATH\\nMPT7B 6.8 3.0\\n30B 15.2 3.1\\nFalcon7B 6.8 2.3\\n40B 19.6 5.5\\nLlama 17B 11.0 2.9\\n13B 17.8 3.9\\n33B 35.6 7.1\\n65B 50.9 10.6\\nLlama 27B 14.6 2.5\\n13B 28.7 3.9\\n34B 42.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-53'),\n",
              " '15a09b8d-0558-4083-81bd-a2f97b2b6515': IndexNode(id_='15a09b8d-0558-4083-81bd-a2f97b2b6515', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-53', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='e76af321a5d43a6bea6574d74a7816e3aa9f8d65fce20f719f7f7286e92fa2b6'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='b48be1af-4ae2-40c7-88e3-4189f8931933', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='4a242b52529ab233d5fbe45c5eeee166f6b46b825279b6eb2ba2f20e3e201ff7'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='4d903f69-defe-4d75-9e13-c16df04e34af', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='b9c50504566b61c95634e70c0326391256854ab9a064edd39b9817de173c45cc')}, hash='ab6a64bf61413cdc7e1cb36dc34560c7bcbdf3124b9e1b9d08098dcc0ca9f104', text='6 2.5\\n13B 28.7 3.9\\n34B 42.2 6.24\\n70B 56.8 13.5\\nTable 25: Comparison to other open-source models on mathematical reasoning tasks , GSM8k and MATH\\n(maj1@1 is reported).\\nMathematical Reasoning. In Table 25, we report results for Llama 2 and other open-source datasets on the\\nGSM8k and MATH tasks.\\nA.3 Additional Details for Fine-tuning\\nA.3.1 Detailed Statistics of Meta Human Preference Data\\nTable 26 shows detailed statistics on Meta human preference data. In total, we collected 14 batches of human\\npreferencedata(i.e.,MetaSafety+Helpfulness)onaweeklybasis,consistingofover1millionbinarymodel\\ngeneration comparisons. In general, later batches contain more samples as we onboard more annotators over\\ntime and the annotators also become more familiar with the tasks and thus have better work efficiency. We\\nalso intentionally collect more multi-turn samples to increase the complexity of RLHF data and thus the\\naverage number of tokens per sample also increase accordingly over batches.\\nIn Figure 25, we plot out the preference rating change over batches. It can be clearly seen that the share\\nof samples with similar responses (e.g., negligibly better or unsure ) increase dramatically over time while\\nthose with stronger preference (e.g., significantly better ) drop in the meantime. This reflects the nature of our\\niterativemodelupdateandpreferencedataannotationprocedure-withbetter-performing Llama 2-Chat\\nmodelsusedforresponsesamplingovertime,itbecomeschallengingforannotatorstoselectabetterone\\nfrom two equally high-quality responses.\\nA.3.2 Curriculum Strategy for Meta Human Preference Data\\nHigh quality data is critical for alignment as discussed for SFT. We worked closely with the annotation\\nplatforms during our fine-tuning process, and opted for a curriculum annotation strategy. With the first\\nmodel,theannotatorswereaskedtomakepromptsrelativelysimple,andthentoprogressivelymovetowards\\nmorecomplexpromptsandteachingnewskillsto Llama 2-Chat .', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-53'),\n",
              " '4d903f69-defe-4d75-9e13-c16df04e34af': IndexNode(id_='4d903f69-defe-4d75-9e13-c16df04e34af', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-53', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='e76af321a5d43a6bea6574d74a7816e3aa9f8d65fce20f719f7f7286e92fa2b6'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='15a09b8d-0558-4083-81bd-a2f97b2b6515', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='ab6a64bf61413cdc7e1cb36dc34560c7bcbdf3124b9e1b9d08098dcc0ca9f104')}, hash='b9c50504566b61c95634e70c0326391256854ab9a064edd39b9817de173c45cc', text='Anillustrationofthiscurriculumannotation\\non our helpfulness preference data is displayed in Figure 26.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-53'),\n",
              " 'node-53': IndexNode(id_='node-53', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='415b7efc-e73f-4ac4-bbfd-c1546f099026', node_type=<ObjectType.DOCUMENT: '4'>, metadata={}, hash='231b3bd773f012c01b893ada9e009ecf25ee59934614c5a595c9bf1b3a123292'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='61a87ae1-6194-425e-adca-e0d356f79543', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='eacbbb2f15adab2ecc5b435e9b3fbee3b56cb5e9e7e961ac17e8ef79c4bb96c9'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='57a8ccf2-9e64-4200-bccb-8040e2154165', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='9fb4625221dffbaac87d4ed95bd64bc1d0b056fc0f33c6c92e25f9c0852f0f82')}, hash='e76af321a5d43a6bea6574d74a7816e3aa9f8d65fce20f719f7f7286e92fa2b6', text='SAT-math\\nMPT 7B 23.5 27.6 23.0 18.7 21.2 20.8 25.2 32.5 23.6\\nMPT 30B 33.8 28.0 28.7 23.9 35.1 37.9 63.1 36.9 27.7\\nFalcon 7B 21.2 21.7 22.3 16.1 17.3 20.4 26.2 23.8 26.4\\nFalcon 40B 37.0 18.5 36.4 19.6 40.2 45.7 58.7 58.7 32.7\\nLlama 17B 23.9 18.9 24.6 26.1 19.2 21.9 33.0 32.5 22.3\\n13B 33.9 20.1 34.9 22.2 31.6 39.8 52.9 45.1 29.5\\n33B 41.7 18.9 37.3 18.7 48.0 59.5 74.8 44.7 35.0\\n65B 47.6 23.6 42.1 23.9 56.7 63.6 83.0 48.1 41.8\\nLlama 27B 29.3 23.2 31.0 23.9 22.4 32.7 43.2 37.4 28.2\\n13B 39.1 21.7 38.1 23.0 41.0 54.6 62.1 46.1 27.3\\n34B 43.4 19.3 40.7 21.3 47.5 62.1 77.2 49.0 32.7\\n70B 54.2 23.2 48.8 25.7 70.2 76.6 86.9 53.4 41.8\\nTable 24: Comparison to open source models on AGI Eval (English)\\n50\\n\\nModel Size GSM8k MATH\\nMPT7B 6.8 3.0\\n30B 15.2 3.1\\nFalcon7B 6.8 2.3\\n40B 19.6 5.5\\nLlama 17B 11.0 2.9\\n13B 17.8 3.9\\n33B 35.6 7.1\\n65B 50.9 10.6\\nLlama 27B 14.6 2.5\\n13B 28.7 3.9\\n34B 42.2 6.24\\n70B 56.8 13.5\\nTable 25: Comparison to other open-source models on mathematical reasoning tasks , GSM8k and MATH\\n(maj1@1 is reported).\\nMathematical Reasoning. In Table 25, we report results for Llama 2 and other open-source datasets on the\\nGSM8k and MATH tasks.\\nA.3 Additional Details for Fine-tuning\\nA.3.1 Detailed Statistics of Meta Human Preference Data\\nTable 26 shows detailed statistics on Meta human preference data. In total, we collected 14 batches of human\\npreferencedata(i.e.,MetaSafety+Helpfulness)onaweeklybasis,consistingofover1millionbinarymodel\\ngeneration comparisons. In general, later batches contain more samples as we onboard more annotators over\\ntime and the annotators also become more familiar with the tasks and thus have better work efficiency. We\\nalso intentionally collect more multi-turn samples to increase the complexity of RLHF data and thus the\\naverage number of tokens per sample also increase accordingly over batches.\\nIn Figure 25, we plot out the preference rating change over batches. It can be clearly seen that the share\\nof samples with similar responses (e.g., negligibly better or unsure ) increase dramatically over time while\\nthose with stronger preference (e.g., significantly better ) drop in the meantime. This reflects the nature of our\\niterativemodelupdateandpreferencedataannotationprocedure-withbetter-performing Llama 2-Chat\\nmodelsusedforresponsesamplingovertime,itbecomeschallengingforannotatorstoselectabetterone\\nfrom two equally high-quality responses.\\nA.3.2 Curriculum Strategy for Meta Human Preference Data\\nHigh quality data is critical for alignment as discussed for SFT. We worked closely with the annotation\\nplatforms during our fine-tuning process, and opted for a curriculum annotation strategy. With the first\\nmodel,theannotatorswereaskedtomakepromptsrelativelysimple,andthentoprogressivelymovetowards\\nmorecomplexpromptsandteachingnewskillsto Llama 2-Chat . Anillustrationofthiscurriculumannotation\\non our helpfulness preference data is displayed in Figure 26.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-53'),\n",
              " '93069d56-6f64-4f69-98fe-f55173a1a448': IndexNode(id_='93069d56-6f64-4f69-98fe-f55173a1a448', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-54', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='9fb4625221dffbaac87d4ed95bd64bc1d0b056fc0f33c6c92e25f9c0852f0f82'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='a394fd1f-59e2-418a-a6ca-b4c8d1fdb443', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='d94bb0a9ed4cb123c427649efa680d51093b21da059b0d1c8314bae035f0d3dd')}, hash='d04d4894daf34618d430f27c4e66065a2d17151c78ec5f209eb6587c4d239541', text='A.3.3 Ablation on Ranking Loss with Preference Rating-based Margin for Reward Modeling\\nWe ablated the ranking loss with the preference rating-based margin term for the helpfulness reward model.\\nWe tried two variants of m(r)with different magnitude for the margin term in Eq 2 as listed open-source 27\\nandcomparethemagainstthebaselinewithoutthemarginterm. Wereportboththeirper-ratingandaverage\\naccuracy on the Meta Helpful test set in Table 28.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-54'),\n",
              " 'a394fd1f-59e2-418a-a6ca-b4c8d1fdb443': IndexNode(id_='a394fd1f-59e2-418a-a6ca-b4c8d1fdb443', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-54', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='9fb4625221dffbaac87d4ed95bd64bc1d0b056fc0f33c6c92e25f9c0852f0f82'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='93069d56-6f64-4f69-98fe-f55173a1a448', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='d04d4894daf34618d430f27c4e66065a2d17151c78ec5f209eb6587c4d239541'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='33b9ee15-d876-4bc8-b7bb-43a1480351c4', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='62c863e358ef70f137677a3b4e9afc9888e99a228c6f5e7cc4c3e5ab742ac1e0')}, hash='d94bb0a9ed4cb123c427649efa680d51093b21da059b0d1c8314bae035f0d3dd', text='We observe that the margin term can indeed help the\\nrewardmodelperformbetteronmoreseparablecomparisonpairsandalargermargincanboostitfurther.\\nHowever, the larger margin also regresses performance on similar samples.\\nWe further evaluated the impact of margin-based loss on reward score distribution shifts. We plot the\\nhistogramofrewardscoresfromthetestsetinFigure27. Essentially,themargintermpushesthereward\\n51\\n\\nBatchNum. of\\nComparisonsAvg. # Turns\\nper DialogueAvg.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-54'),\n",
              " '33b9ee15-d876-4bc8-b7bb-43a1480351c4': IndexNode(id_='33b9ee15-d876-4bc8-b7bb-43a1480351c4', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-54', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='9fb4625221dffbaac87d4ed95bd64bc1d0b056fc0f33c6c92e25f9c0852f0f82'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='a394fd1f-59e2-418a-a6ca-b4c8d1fdb443', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='d94bb0a9ed4cb123c427649efa680d51093b21da059b0d1c8314bae035f0d3dd'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='2e27aa26-eed8-4ef0-ac72-9de0f18e998d', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='6fb62b33bbfeb9f45d2ac977b98666b9cf653203564d3bcf50fc235f9b74c700')}, hash='62c863e358ef70f137677a3b4e9afc9888e99a228c6f5e7cc4c3e5ab742ac1e0', text='of\\nComparisonsAvg. # Turns\\nper DialogueAvg. # Tokens\\nper ExampleAvg. # Tokens\\nin PromptAvg. # Tokens\\nin Response\\n1 5,561 4.4 547.1 25.2 159.3\\n2 17,072 4.0 554.6 22.4 170.7\\n3 30,146 3.9 603.3 19.6 195.5\\n4 36,206 3.9 652.8 45.3 182.9\\n5 49,375 3.7 603.9 46.7 163.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-54'),\n",
              " '2e27aa26-eed8-4ef0-ac72-9de0f18e998d': IndexNode(id_='2e27aa26-eed8-4ef0-ac72-9de0f18e998d', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-54', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='9fb4625221dffbaac87d4ed95bd64bc1d0b056fc0f33c6c92e25f9c0852f0f82'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='33b9ee15-d876-4bc8-b7bb-43a1480351c4', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='62c863e358ef70f137677a3b4e9afc9888e99a228c6f5e7cc4c3e5ab742ac1e0'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='eb8a0968-bf75-4f50-b225-af7cd6e94598', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='d26617cce0ec8ec176d2019225e00f7e77891295b11a062331317b024aa86b04')}, hash='6fb62b33bbfeb9f45d2ac977b98666b9cf653203564d3bcf50fc235f9b74c700', text='9\\n5 49,375 3.7 603.9 46.7 163.1\\n6 57,746 4.1 654.5 28.2 198.1\\n7 84,388 3.9 662.2 27.5 210.0\\n8 95,235 3.6 670.4 32.9 212.1\\n9 127,235 3.6 674.9 31.3 214.8\\n10 136,729 3.7 723.9 30.5 230.2\\n11 136,868 3.8 811.9 32.2 251.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-54'),\n",
              " 'eb8a0968-bf75-4f50-b225-af7cd6e94598': IndexNode(id_='eb8a0968-bf75-4f50-b225-af7cd6e94598', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-54', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='9fb4625221dffbaac87d4ed95bd64bc1d0b056fc0f33c6c92e25f9c0852f0f82'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='2e27aa26-eed8-4ef0-ac72-9de0f18e998d', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='6fb62b33bbfeb9f45d2ac977b98666b9cf653203564d3bcf50fc235f9b74c700'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='1c6426f3-5913-41ca-aa81-d81241e62798', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='77cd62c3f2e6a56623bb0e30932cc756acc3b5b91a3a290d9c86eabd2d8a9292')}, hash='d26617cce0ec8ec176d2019225e00f7e77891295b11a062331317b024aa86b04', text='2\\n11 136,868 3.8 811.9 32.2 251.1\\n12 181,293 3.9 817.0 30.8 250.9\\n13 210,881 4.2 905.9 30.3 255.6\\n14 249,356 4.3 1008.0 31.6 258.9\\nTotal 1,418,091 3.9 798.5 31.4 234.1\\nTable 26: Statistics of Meta human preference data (Safety & Helpfulness) per batch.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-54'),\n",
              " '1c6426f3-5913-41ca-aa81-d81241e62798': IndexNode(id_='1c6426f3-5913-41ca-aa81-d81241e62798', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-54', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='9fb4625221dffbaac87d4ed95bd64bc1d0b056fc0f33c6c92e25f9c0852f0f82'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='eb8a0968-bf75-4f50-b225-af7cd6e94598', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='d26617cce0ec8ec176d2019225e00f7e77891295b11a062331317b024aa86b04'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='ede007a8-13c7-4990-98a1-11d6c3ba61f8', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='570c5763a06340a2621114399d7da3e8c1464393c8aaa1e26ebce6f0d3ae0c0a')}, hash='77cd62c3f2e6a56623bb0e30932cc756acc3b5b91a3a290d9c86eabd2d8a9292', text='Note that a binary\\nhumanpreferencecomparisoncontains2responses(chosenandrejected)sharingthesameprompt(and\\nprevious dialogue). Each example consists of a prompt (including previous dialogue if available) and a\\nresponse,whichistheinputoftherewardmodel. Wereportthenumberofcomparisons,theaveragenumber\\nof turns per dialogue, the average number of tokens per example, per prompt and per response.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-54'),\n",
              " 'ede007a8-13c7-4990-98a1-11d6c3ba61f8': IndexNode(id_='ede007a8-13c7-4990-98a1-11d6c3ba61f8', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-54', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='9fb4625221dffbaac87d4ed95bd64bc1d0b056fc0f33c6c92e25f9c0852f0f82'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='1c6426f3-5913-41ca-aa81-d81241e62798', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='77cd62c3f2e6a56623bb0e30932cc756acc3b5b91a3a290d9c86eabd2d8a9292'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='0c056135-578a-4145-91b7-26ce61360e8c', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='7ccf2008d2b06c0a61f0eb2cbbc8798b8a0ccb23f92710c35785b19893e3598e')}, hash='570c5763a06340a2621114399d7da3e8c1464393c8aaa1e26ebce6f0d3ae0c0a', text='Significantly\\nBetterBetterSlightly\\nBetterNegligibly\\nBetter / Unsure\\nMargin Small 1 2/3 1/3 0\\nMargin Large 3 2 1 0\\nTable 27: Two variants of preference rating based margin with different magnitude.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-54'),\n",
              " '0c056135-578a-4145-91b7-26ce61360e8c': IndexNode(id_='0c056135-578a-4145-91b7-26ce61360e8c', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-54', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='9fb4625221dffbaac87d4ed95bd64bc1d0b056fc0f33c6c92e25f9c0852f0f82'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='ede007a8-13c7-4990-98a1-11d6c3ba61f8', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='570c5763a06340a2621114399d7da3e8c1464393c8aaa1e26ebce6f0d3ae0c0a'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='bf1d464a-3e12-4ee3-8b07-4971f58187e4', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='d4bb18570039e81bf9314ba718f95e6f8444cb3a92c57b34e2492123f547c7fa')}, hash='7ccf2008d2b06c0a61f0eb2cbbc8798b8a0ccb23f92710c35785b19893e3598e', text='Significantly\\nBetterBetterSlightly\\nBetterNegligibly\\nBetter / UnsureAvg\\nNo margin 79.1 66.9 59.8 54.5 62.5\\nMargin Small 80.4 67.3 60.4 55.0 63.0\\nMargin Large 80.7 67.5 60.5 54.3 62.9\\nTable 28: Ablation on preference rating-based margin in Helpful reward model ranking loss. The rating\\nmargin component helps improve model accuracy on samples with more separable response pairs (e.g.,\\nchosen response significantly better the rejected counterpart).', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-54'),\n",
              " 'bf1d464a-3e12-4ee3-8b07-4971f58187e4': IndexNode(id_='bf1d464a-3e12-4ee3-8b07-4971f58187e4', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-54', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='9fb4625221dffbaac87d4ed95bd64bc1d0b056fc0f33c6c92e25f9c0852f0f82'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='0c056135-578a-4145-91b7-26ce61360e8c', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='7ccf2008d2b06c0a61f0eb2cbbc8798b8a0ccb23f92710c35785b19893e3598e'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='2133a91a-18cd-4c3e-aad1-4393a436863e', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='094170c4f15f1c91f03bab5abe465428b5e5b40b7318670fe9932113730267de')}, hash='d4bb18570039e81bf9314ba718f95e6f8444cb3a92c57b34e2492123f547c7fa', text='model to assign more extreme scores to model generations to form a binary split pattern and a larger\\nmargin makes this distribution shift more significant. The above observation suggests investment in reward\\ncalibrationforfutureworkasreinforcementlearningalgorithms,suchasPPO,canbesensitivetoreward\\ndistribution change.\\nA.3.4 Ablation on Ranking Loss with Safety Auxiliary Loss for Reward Modeling\\nWe ablated the impact of the safety auxiliary loss with results on the Meta Safety test set shown in Table 29.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-54'),\n",
              " '2133a91a-18cd-4c3e-aad1-4393a436863e': IndexNode(id_='2133a91a-18cd-4c3e-aad1-4393a436863e', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-54', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='9fb4625221dffbaac87d4ed95bd64bc1d0b056fc0f33c6c92e25f9c0852f0f82'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='bf1d464a-3e12-4ee3-8b07-4971f58187e4', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='d4bb18570039e81bf9314ba718f95e6f8444cb3a92c57b34e2492123f547c7fa')}, hash='094170c4f15f1c91f03bab5abe465428b5e5b40b7318670fe9932113730267de', text='As expected, The customized loss improves the recall of unsafe responses when we use a reward score of 0.5\\nas the threshold (negative before Sigmoid) and thus offers a better safety reward signal for RLHF. Teaching\\nthemodeltodiscriminatebetweensafeandunsafemodelgenerationsalsoimprovesmodelaccuracyonthree\\nsubcategories.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-54'),\n",
              " 'd7523f3f-0a91-488f-ba06-281e3f4599e5': IndexNode(id_='d7523f3f-0a91-488f-ba06-281e3f4599e5', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-54', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='9fb4625221dffbaac87d4ed95bd64bc1d0b056fc0f33c6c92e25f9c0852f0f82'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='8afbb150-d09e-4f54-b62d-2646605e5fb1', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='ebe19e185713b79b23f29d733478ecdc11bb25b061c5af3a7ad156d5785d2ac3')}, hash='3f82f57383442ece23cffbd6463c24a77405adb162084c97f25b5706964b7c35', text='A.3.3 Ablation on Ranking Loss with Preference Rating-based Margin for Reward Modeling\\nWe ablated the ranking loss with the preference rating-based margin term for the helpfulness reward model.\\nWe tried two variants of m(r)with different magnitude for the margin term in Eq 2 as listed open-source 27\\nandcomparethemagainstthebaselinewithoutthemarginterm. Wereportboththeirper-ratingandaverage\\naccuracy on the Meta Helpful test set in Table 28. We observe that the margin term can indeed help the\\nrewardmodelperformbetteronmoreseparablecomparisonpairsandalargermargincanboostitfurther.\\nHowever, the larger margin also regresses performance on similar samples.\\nWe further evaluated the impact of margin-based loss on reward score distribution shifts. We plot the\\nhistogramofrewardscoresfromthetestsetinFigure27. Essentially,themargintermpushesthereward\\n51\\n\\nBatchNum. of\\nComparisonsAvg. # Turns\\nper DialogueAvg. # Tokens\\nper ExampleAvg. # Tokens\\nin PromptAvg.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-54'),\n",
              " ...}"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "all_nodes_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "qcBPNjKOrCGE"
      },
      "outputs": [],
      "source": [
        "vector_index_chunk = VectorStoreIndex(\n",
        "    all_nodes, service_context=service_context\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "lyDn8WQVrDZ-"
      },
      "outputs": [],
      "source": [
        "vector_retriever_chunk = vector_index_chunk.as_retriever(similarity_top_k=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "3t3YyCov8Z0V"
      },
      "outputs": [],
      "source": [
        "retriever_chunk = RecursiveRetriever(\n",
        "    \"vector\",\n",
        "    retriever_dict={\"vector\": vector_retriever_chunk},\n",
        "    node_dict=all_nodes_dict,\n",
        "    verbose=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 562
        },
        "id": "l8BMwy7N8a7Y",
        "outputId": "b1ada559-2bac-4168-f8dd-064bd221ace1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;3;34mRetrieving with query id None: Can you tell me about the key concepts for safety finetuning\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-1\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-1: Can you tell me about the key concepts for safety finetuning\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-22\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-22: Can you tell me about the key concepts for safety finetuning\n",
            "\u001b[0m"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "**Node ID:** node-1<br>**Similarity:** 0.873018577198763<br>**Text:** . . . . . . . . . . . . . . . . . . . . . . . . . . . . 16\n3.4 RLHF Results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 17\n4 Safety 20\n4.1 Safety in Pretraining . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 20\n4.2 Safety Fine-Tuning . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 23\n4.3 Red Teaming . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 28\n4.4 Safety Evaluation of Llama 2-Chat . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 29\n5 Discussion 32\n5.1 Learnings and Observations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 32\n5.2 Limitations and Ethical Considerations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 34\n5.3 Responsible Release Strategy . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 35\n6 Related Work 35\n7 Conclusion 36\nA Appendix 46\nA.1 Contributions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 46\nA.2 Additional Details for Pretraining . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 47\nA.3 Additional Details for Fine-tuning . . . . . . . . . . . . . . . . . . . . .<br>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "**Node ID:** node-22<br>**Similarity:** 0.8656067071505295<br>**Text:** We observe that models\ntrained from less aggressively filtered pretraining data also required fewer examples to achieve reasonable\nsafety-alignment. Wereiteratethatthismotivatedchoicedoesimplythatadditionalsafetymitigationsshould\nbe applied before deployment of base Llama 2 models.\n22\n\nTruthfulQA ↑ToxiGen ↓\nMPT7B 29.13 22.32\n30B 35.25 22.61\nFalcon7B 25.95 14.53\n40B 40.39 23.44\nLlama 17B 27.42 23.00\n13B 41.74 23.08\n33B 44.19 22.57\n65B 48.71 21.77\nLlama 27B 33.29 21.25\n13B 41.86 26.10\n34B 43.45 21.19\n70B 50.18 24.60\nTable 11: Evaluation of pretrained LLMs on automatic safety benchmarks. For TruthfulQA, we present the\npercentageofgenerationsthatarebothtruthfulandinformative(thehigherthebetter). ForToxiGen,we\npresent the percentage of toxic generations (the smaller, the better).\nBenchmarks give a summary view ofmodel capabilities and behaviors that allow us to understand general\npatternsinthemodel,buttheydonotprovideafullycomprehensiveviewoftheimpactthemodelmayhave\nonpeopleorreal-worldoutcomes;thatwouldrequirestudyofend-to-endproductdeployments. Further\ntesting and mitigation should be done to understand bias and other social issues for the specific context\nin which a system may be deployed. For this, it may be necessary to test beyond the groups available in\ntheBOLDdataset(race,religion,andgender). AsLLMsareintegratedanddeployed,welookforwardto\ncontinuing research that will amplify their potential for positive impact on these important social issues.\n4.2 Safety Fine-Tuning\nIn this section, we describe our approach to safety fine-tuning, including safety categories, annotation\nguidelines,andthetechniquesweusetomitigatesafetyrisks. Weemployaprocesssimilartothegeneral\nfine-tuning methods as described in Section 3, with some notable differences related to safety concerns.\nSpecifically, we use the following techniques in safety fine-tuning:\n1.Supervised Safety Fine-Tuning : We initialize by gathering adversarial prompts and safe demonstra-\ntions that are then included in...<br>"
          },
          "metadata": {}
        }
      ],
      "source": [
        "nodes = retriever_chunk.retrieve(\n",
        "    \"Can you tell me about the key concepts for safety finetuning\"\n",
        ")\n",
        "for node in nodes:\n",
        "    display_source_node(node, source_length=2000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "Ys5kVd2N8cIm"
      },
      "outputs": [],
      "source": [
        "query_engine_chunk = RetrieverQueryEngine.from_args(\n",
        "    retriever_chunk, service_context=service_context\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AkTD2Vhf8fCk",
        "outputId": "bc8bff6b-7631-459e-b292-08a8a3f932f0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;3;34mRetrieving with query id None: Can you tell me about the key concepts for safety finetuning\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-1\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-1: Can you tell me about the key concepts for safety finetuning\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-22\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-22: Can you tell me about the key concepts for safety finetuning\n",
            "\u001b[0mThe key concepts for safety fine-tuning include supervised safety fine-tuning, safety RLHF (Reinforcement Learning from Human Feedback), and safety context distillation. \n",
            "\n",
            "In supervised safety fine-tuning, adversarial prompts and safe demonstrations are gathered and included in the general supervised fine-tuning process. This helps the model align with safety guidelines even before RLHF and lays the foundation for high-quality human preference data annotation.\n",
            "\n",
            "Safety RLHF involves integrating safety in the general RLHF pipeline. This includes training a safety-specific reward model and gathering more challenging adversarial prompts for rejection sampling style fine-tuning and PPO (Proximal Policy Optimization) optimization.\n",
            "\n",
            "Safety context distillation is the final step in safety fine-tuning. It involves refining the RLHF pipeline with context distillation, which generates safer model responses by prefixing a prompt with a safety preprompt. The model is then fine-tuned on the safer responses without the preprompt, effectively distilling the safety preprompt (context) into the model. A targeted approach is used to allow the safety reward model to choose whether to use context distillation for each sample.\n",
            "\n",
            "These concepts are used to mitigate safety risks and improve the safety alignment of the model during the fine-tuning process.\n"
          ]
        }
      ],
      "source": [
        "response = query_engine_chunk.query(\n",
        "    \"Can you tell me about the key concepts for safety finetuning\"\n",
        ")\n",
        "print(str(response))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TFNJJl7u3vI0"
      },
      "source": [
        "# Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "2siSjRog3wLu"
      },
      "outputs": [],
      "source": [
        "from llama_index.evaluation import (\n",
        "    generate_question_context_pairs,\n",
        "    EmbeddingQAFinetuneDataset,\n",
        ")\n",
        "import nest_asyncio\n",
        "\n",
        "nest_asyncio.apply()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gyx-ITdG8qQA",
        "outputId": "acdc254e-5be4-46a9-b3ab-37ceb30678a9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 80/80 [02:37<00:00,  1.97s/it]\n"
          ]
        }
      ],
      "source": [
        "eval_dataset = generate_question_context_pairs(base_nodes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "6fVETf-h8shR"
      },
      "outputs": [],
      "source": [
        "eval_dataset.save_json(\"llama2_eval_dataset.json\")\n",
        "# eval_dataset = EmbeddingQAFinetuneDataset.from_json(\"data/llama2_eval_dataset.json\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "ev-0XNWc85jY"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from llama_index.evaluation import RetrieverEvaluator, get_retrieval_results_df\n",
        "\n",
        "# set vector retriever similarity top k to higher\n",
        "top_k = 10\n",
        "\n",
        "\n",
        "def display_results(names, results_arr):\n",
        "    \"\"\"Display results from evaluate.\"\"\"\n",
        "\n",
        "    hit_rates = []\n",
        "    mrrs = []\n",
        "    for name, eval_results in zip(names, results_arr):\n",
        "        metric_dicts = []\n",
        "        for eval_result in eval_results:\n",
        "            metric_dict = eval_result.metric_vals_dict\n",
        "            metric_dicts.append(metric_dict)\n",
        "        results_df = pd.DataFrame(metric_dicts)\n",
        "\n",
        "        hit_rate = results_df[\"hit_rate\"].mean()\n",
        "        mrr = results_df[\"mrr\"].mean()\n",
        "        hit_rates.append(hit_rate)\n",
        "        mrrs.append(mrr)\n",
        "\n",
        "    final_df = pd.DataFrame(\n",
        "        {\"retrievers\": names, \"hit_rate\": hit_rates, \"mrr\": mrrs}\n",
        "    )\n",
        "    display(final_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CGQBgWOb88PZ",
        "outputId": "02a695c4-25c7-4233-8370-a129c8a90d95"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 167/167 [00:15<00:00, 10.80it/s]\n"
          ]
        }
      ],
      "source": [
        "# base\n",
        "base_retriever = base_index.as_retriever(similarity_top_k=top_k)\n",
        "retriever_evaluator = RetrieverEvaluator.from_metric_names(\n",
        "    [\"mrr\", \"hit_rate\"], retriever=base_retriever\n",
        ")\n",
        "results_base = await retriever_evaluator.aevaluate_dataset(\n",
        "    eval_dataset, show_progress=True\n",
        ")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iJNrlsW39y11",
        "outputId": "0ad2aea2-f559-4207-9751-7141c1084f0b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/167 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;3;34mRetrieving with query id None: In the context of language processing, what is the significance of the paper \"A general language assistant as a laboratory for alignment\" by Askell et al. (2021a)?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-7\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-7: In the context of language processing, what is the significance of the paper \"A general language assistant as a laboratory for alignment\" by Askell et al. (2021a)?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-41\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-41: In the context of language processing, what is the significance of the paper \"A general language assistant as a laboratory for alignment\" by Askell et al. (2021a)?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-38\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-38: In the context of language processing, what is the significance of the paper \"A general language assistant as a laboratory for alignment\" by Askell et al. (2021a)?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-36\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-36: In the context of language processing, what is the significance of the paper \"A general language assistant as a laboratory for alignment\" by Askell et al. (2021a)?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-46\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-46: In the context of language processing, what is the significance of the paper \"A general language assistant as a laboratory for alignment\" by Askell et al. (2021a)?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-15\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-15: In the context of language processing, what is the significance of the paper \"A general language assistant as a laboratory for alignment\" by Askell et al. (2021a)?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-2\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-2: In the context of language processing, what is the significance of the paper \"A general language assistant as a laboratory for alignment\" by Askell et al. (2021a)?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-40\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-40: In the context of language processing, what is the significance of the paper \"A general language assistant as a laboratory for alignment\" by Askell et al. (2021a)?\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id None: What are the different sections covered in the document?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-1\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-1: What are the different sections covered in the document?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-70\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-70: What are the different sections covered in the document?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-73\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-73: What are the different sections covered in the document?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-6\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-6: What are the different sections covered in the document?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-19\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-19: What are the different sections covered in the document?\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id None: Based on the evaluation results on TruthfulQA, which pretrained model generation achieved the highest percentage for (true + info) % true % info? How does this compare to the fine-tuned models?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-69\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-69: Based on the evaluation results on TruthfulQA, which pretrained model generation achieved the highest percentage for (true + info) % true % info? How does this compare to the fine-tuned models?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-68\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-68: Based on the evaluation results on TruthfulQA, which pretrained model generation achieved the highest percentage for (true + info) % true % info? How does this compare to the fine-tuned models?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-38\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-38: Based on the evaluation results on TruthfulQA, which pretrained model generation achieved the highest percentage for (true + info) % true % info? How does this compare to the fine-tuned models?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-22\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-22: Based on the evaluation results on TruthfulQA, which pretrained model generation achieved the highest percentage for (true + info) % true % info? How does this compare to the fine-tuned models?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-49\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-49: Based on the evaluation results on TruthfulQA, which pretrained model generation achieved the highest percentage for (true + info) % true % info? How does this compare to the fine-tuned models?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-50\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-50: Based on the evaluation results on TruthfulQA, which pretrained model generation achieved the highest percentage for (true + info) % true % info? How does this compare to the fine-tuned models?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-4\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-4: Based on the evaluation results on TruthfulQA, which pretrained model generation achieved the highest percentage for (true + info) % true % info? How does this compare to the fine-tuned models?\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id None: How does the paper \"Is automation labor-displacing? Productivity growth, employment, and the labor share\" by Autor and Salomons (2018) contribute to the understanding of the impact of automation on the labor market?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-35\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-35: How does the paper \"Is automation labor-displacing? Productivity growth, employment, and the labor share\" by Autor and Salomons (2018) contribute to the understanding of the impact of automation on the labor market?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-46\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-46: How does the paper \"Is automation labor-displacing? Productivity growth, employment, and the labor share\" by Autor and Salomons (2018) contribute to the understanding of the impact of automation on the labor market?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-34\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-34: How does the paper \"Is automation labor-displacing? Productivity growth, employment, and the labor share\" by Autor and Salomons (2018) contribute to the understanding of the impact of automation on the labor market?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-32\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-32: How does the paper \"Is automation labor-displacing? Productivity growth, employment, and the labor share\" by Autor and Salomons (2018) contribute to the understanding of the impact of automation on the labor market?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-45\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-45: How does the paper \"Is automation labor-displacing? Productivity growth, employment, and the labor share\" by Autor and Salomons (2018) contribute to the understanding of the impact of automation on the labor market?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-22\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-22: How does the paper \"Is automation labor-displacing? Productivity growth, employment, and the labor share\" by Autor and Salomons (2018) contribute to the understanding of the impact of automation on the labor market?\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id None: How does the document address the topic of safety in the context of RLHF?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-22\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-22: How does the document address the topic of safety in the context of RLHF?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-24\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-24: How does the document address the topic of safety in the context of RLHF?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-58\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-58: How does the document address the topic of safety in the context of RLHF?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-33\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-33: How does the document address the topic of safety in the context of RLHF?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-9\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-9: How does the document address the topic of safety in the context of RLHF?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-23\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-23: How does the document address the topic of safety in the context of RLHF?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-26\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-26: How does the document address the topic of safety in the context of RLHF?\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id None: What are some limitations of using benchmarks to evaluate the safety of fine-tuned/chat-oriented models, as mentioned in the context information? How can monitoring disaggregated metrics and benchmarks help in better understanding the behavior of LLMs across different demographic groups?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-70\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-70: What are some limitations of using benchmarks to evaluate the safety of fine-tuned/chat-oriented models, as mentioned in the context information? How can monitoring disaggregated metrics and benchmarks help in better understanding the behavior of LLMs across different demographic groups?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-72\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-72: What are some limitations of using benchmarks to evaluate the safety of fine-tuned/chat-oriented models, as mentioned in the context information? How can monitoring disaggregated metrics and benchmarks help in better understanding the behavior of LLMs across different demographic groups?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-3\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-3: What are some limitations of using benchmarks to evaluate the safety of fine-tuned/chat-oriented models, as mentioned in the context information? How can monitoring disaggregated metrics and benchmarks help in better understanding the behavior of LLMs across different demographic groups?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-32\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-32: What are some limitations of using benchmarks to evaluate the safety of fine-tuned/chat-oriented models, as mentioned in the context information? How can monitoring disaggregated metrics and benchmarks help in better understanding the behavior of LLMs across different demographic groups?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-23\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-23: What are some limitations of using benchmarks to evaluate the safety of fine-tuned/chat-oriented models, as mentioned in the context information? How can monitoring disaggregated metrics and benchmarks help in better understanding the behavior of LLMs across different demographic groups?\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id None: In the context of AI research, what is the significance of the papers \"Training a helpful and harmless assistant with reinforcement learning from human feedback\" and \"Constitutional AI: Harmlessness from AI feedback\"?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-36\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-36: In the context of AI research, what is the significance of the papers \"Training a helpful and harmless assistant with reinforcement learning from human feedback\" and \"Constitutional AI: Harmlessness from AI feedback\"?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-12\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-12: In the context of AI research, what is the significance of the papers \"Training a helpful and harmless assistant with reinforcement learning from human feedback\" and \"Constitutional AI: Harmlessness from AI feedback\"?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-23\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-23: In the context of AI research, what is the significance of the papers \"Training a helpful and harmless assistant with reinforcement learning from human feedback\" and \"Constitutional AI: Harmlessness from AI feedback\"?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-0\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-0: In the context of AI research, what is the significance of the papers \"Training a helpful and harmless assistant with reinforcement learning from human feedback\" and \"Constitutional AI: Harmlessness from AI feedback\"?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-42\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-42: In the context of AI research, what is the significance of the papers \"Training a helpful and harmless assistant with reinforcement learning from human feedback\" and \"Constitutional AI: Harmlessness from AI feedback\"?\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id None: How does the training methodology of Large Language Models (LLMs) contribute to their remarkable capabilities?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-2\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-2: How does the training methodology of Large Language Models (LLMs) contribute to their remarkable capabilities?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-32\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-32: How does the training methodology of Large Language Models (LLMs) contribute to their remarkable capabilities?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-0\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-0: How does the training methodology of Large Language Models (LLMs) contribute to their remarkable capabilities?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-31\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-31: How does the training methodology of Large Language Models (LLMs) contribute to their remarkable capabilities?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-40\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-40: How does the training methodology of Large Language Models (LLMs) contribute to their remarkable capabilities?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-44\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-44: How does the training methodology of Large Language Models (LLMs) contribute to their remarkable capabilities?\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id None: In the context of the provided information, what are the demographic groups that have the highest percentage of toxic generations in the ToxiGen model? How does this information reflect the potential biases in the model's outputs?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-71\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-71: In the context of the provided information, what are the demographic groups that have the highest percentage of toxic generations in the ToxiGen model? How does this information reflect the potential biases in the model's outputs?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-21\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-21: In the context of the provided information, what are the demographic groups that have the highest percentage of toxic generations in the ToxiGen model? How does this information reflect the potential biases in the model's outputs?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-69\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-69: In the context of the provided information, what are the demographic groups that have the highest percentage of toxic generations in the ToxiGen model? How does this information reflect the potential biases in the model's outputs?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-29\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-29: In the context of the provided information, what are the demographic groups that have the highest percentage of toxic generations in the ToxiGen model? How does this information reflect the potential biases in the model's outputs?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-22\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-22: In the context of the provided information, what are the demographic groups that have the highest percentage of toxic generations in the ToxiGen model? How does this information reflect the potential biases in the model's outputs?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-68\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-68: In the context of the provided information, what are the demographic groups that have the highest percentage of toxic generations in the ToxiGen model? How does this information reflect the potential biases in the model's outputs?\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id None: How do the papers \"On the dangers of stochastic parrots: Can language models be too big?\" and \"Guiding the release of safer e2e conversational AI through value sensitive design\" contribute to the field of AI ethics and accountability?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-36\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-36: How do the papers \"On the dangers of stochastic parrots: Can language models be too big?\" and \"Guiding the release of safer e2e conversational AI through value sensitive design\" contribute to the field of AI ethics and accountability?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-46\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-46: How do the papers \"On the dangers of stochastic parrots: Can language models be too big?\" and \"Guiding the release of safer e2e conversational AI through value sensitive design\" contribute to the field of AI ethics and accountability?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-32\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-32: How do the papers \"On the dangers of stochastic parrots: Can language models be too big?\" and \"Guiding the release of safer e2e conversational AI through value sensitive design\" contribute to the field of AI ethics and accountability?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-28\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-28: How do the papers \"On the dangers of stochastic parrots: Can language models be too big?\" and \"Guiding the release of safer e2e conversational AI through value sensitive design\" contribute to the field of AI ethics and accountability?\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id None: What are some challenges and limitations associated with human evaluations of LLMs, as mentioned in the document?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-70\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-70: What are some challenges and limitations associated with human evaluations of LLMs, as mentioned in the document?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-18\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-18: What are some challenges and limitations associated with human evaluations of LLMs, as mentioned in the document?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-31\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-31: What are some challenges and limitations associated with human evaluations of LLMs, as mentioned in the document?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-2\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-2: What are some challenges and limitations associated with human evaluations of LLMs, as mentioned in the document?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-26\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-26: What are some challenges and limitations associated with human evaluations of LLMs, as mentioned in the document?\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id None: Compare the performance of the MPT7B and Falcon7B models in generating toxic content across different demographic groups. Based on the given data, which model seems to exhibit a higher level of bias in its outputs? Justify your answer with specific examples from the table.\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-21\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-21: Compare the performance of the MPT7B and Falcon7B models in generating toxic content across different demographic groups. Based on the given data, which model seems to exhibit a higher level of bias in its outputs? Justify your answer with specific examples from the table.\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-70\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-70: Compare the performance of the MPT7B and Falcon7B models in generating toxic content across different demographic groups. Based on the given data, which model seems to exhibit a higher level of bias in its outputs? Justify your answer with specific examples from the table.\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-29\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-29: Compare the performance of the MPT7B and Falcon7B models in generating toxic content across different demographic groups. Based on the given data, which model seems to exhibit a higher level of bias in its outputs? Justify your answer with specific examples from the table.\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-69\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-69: Compare the performance of the MPT7B and Falcon7B models in generating toxic content across different demographic groups. Based on the given data, which model seems to exhibit a higher level of bias in its outputs? Justify your answer with specific examples from the table.\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id None: What are some recent advancements in language models mentioned in the context information?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-40\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-40: What are some recent advancements in language models mentioned in the context information?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-32\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-32: What are some recent advancements in language models mentioned in the context information?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-37\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-37: What are some recent advancements in language models mentioned in the context information?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-44\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-44: What are some recent advancements in language models mentioned in the context information?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-38\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-38: What are some recent advancements in language models mentioned in the context information?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-46\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-46: What are some recent advancements in language models mentioned in the context information?\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id None: How does the release of Llama 2 and Llama 2-Chat contribute to the advancement of AI alignment research within the community?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-3\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-3: How does the release of Llama 2 and Llama 2-Chat contribute to the advancement of AI alignment research within the community?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-34\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-34: How does the release of Llama 2 and Llama 2-Chat contribute to the advancement of AI alignment research within the community?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-30\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-30: How does the release of Llama 2 and Llama 2-Chat contribute to the advancement of AI alignment research within the community?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-7\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-7: How does the release of Llama 2 and Llama 2-Chat contribute to the advancement of AI alignment research within the community?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-0\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-0: How does the release of Llama 2 and Llama 2-Chat contribute to the advancement of AI alignment research within the community?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-4\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-4: How does the release of Llama 2 and Llama 2-Chat contribute to the advancement of AI alignment research within the community?\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id None: In the context of the BOLD dataset, what is the purpose of using demographic group labels such as Asian Americans, African Americans, European Americans, Hispanic and Latino Americans?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-72\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-72: In the context of the BOLD dataset, what is the purpose of using demographic group labels such as Asian Americans, African Americans, European Americans, Hispanic and Latino Americans?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-21\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-21: In the context of the BOLD dataset, what is the purpose of using demographic group labels such as Asian Americans, African Americans, European Americans, Hispanic and Latino Americans?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-69\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-69: In the context of the BOLD dataset, what is the purpose of using demographic group labels such as Asian Americans, African Americans, European Americans, Hispanic and Latino Americans?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-19\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-19: In the context of the BOLD dataset, what is the purpose of using demographic group labels such as Asian Americans, African Americans, European Americans, Hispanic and Latino Americans?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-20\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-20: In the context of the BOLD dataset, what is the purpose of using demographic group labels such as Asian Americans, African Americans, European Americans, Hispanic and Latino Americans?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-22\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-22: In the context of the BOLD dataset, what is the purpose of using demographic group labels such as Asian Americans, African Americans, European Americans, Hispanic and Latino Americans?\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id None: How does Vicuna, an open-source chatbot, compare to GPT-4 in terms of chat quality?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-37\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-37: How does Vicuna, an open-source chatbot, compare to GPT-4 in terms of chat quality?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-17\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-17: How does Vicuna, an open-source chatbot, compare to GPT-4 in terms of chat quality?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-18\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-18: How does Vicuna, an open-source chatbot, compare to GPT-4 in terms of chat quality?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-56\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-56: How does Vicuna, an open-source chatbot, compare to GPT-4 in terms of chat quality?\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id None: What measures have been taken to enhance the safety of the Llama 2 and Llama 2-Chat models, and how do they compare to existing open-source and closed-source models in terms of safety performance?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-3\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-3: What measures have been taken to enhance the safety of the Llama 2 and Llama 2-Chat models, and how do they compare to existing open-source and closed-source models in terms of safety performance?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-0\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-0: What measures have been taken to enhance the safety of the Llama 2 and Llama 2-Chat models, and how do they compare to existing open-source and closed-source models in terms of safety performance?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-34\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-34: What measures have been taken to enhance the safety of the Llama 2 and Llama 2-Chat models, and how do they compare to existing open-source and closed-source models in terms of safety performance?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-1\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-1: What measures have been taken to enhance the safety of the Llama 2 and Llama 2-Chat models, and how do they compare to existing open-source and closed-source models in terms of safety performance?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-32\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-32: What measures have been taken to enhance the safety of the Llama 2 and Llama 2-Chat models, and how do they compare to existing open-source and closed-source models in terms of safety performance?\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id None: How does the BOLD dataset address the limitations of existing benchmarks in assessing the language understanding and generation abilities of chat models?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-72\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-72: How does the BOLD dataset address the limitations of existing benchmarks in assessing the language understanding and generation abilities of chat models?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-0\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-0: How does the BOLD dataset address the limitations of existing benchmarks in assessing the language understanding and generation abilities of chat models?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-17\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-17: How does the BOLD dataset address the limitations of existing benchmarks in assessing the language understanding and generation abilities of chat models?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-41\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-41: How does the BOLD dataset address the limitations of existing benchmarks in assessing the language understanding and generation abilities of chat models?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-3\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-3: How does the BOLD dataset address the limitations of existing benchmarks in assessing the language understanding and generation abilities of chat models?\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id None: In the paper \"Deep reinforcement learning from human preferences,\" what is the main focus of the research and what are the key findings?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-8\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-8: In the paper \"Deep reinforcement learning from human preferences,\" what is the main focus of the research and what are the key findings?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-30\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-30: In the paper \"Deep reinforcement learning from human preferences,\" what is the main focus of the research and what are the key findings?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-10\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-10: In the paper \"Deep reinforcement learning from human preferences,\" what is the main focus of the research and what are the key findings?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-11\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-11: In the paper \"Deep reinforcement learning from human preferences,\" what is the main focus of the research and what are the key findings?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-36\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-36: In the paper \"Deep reinforcement learning from human preferences,\" what is the main focus of the research and what are the key findings?\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id None: What changes were made to improve the performance of Llama 2 models compared to Llama 1 models?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-7\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-7: What changes were made to improve the performance of Llama 2 models compared to Llama 1 models?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-4\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-4: What changes were made to improve the performance of Llama 2 models compared to Llama 1 models?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-18\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-18: What changes were made to improve the performance of Llama 2 models compared to Llama 1 models?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-0\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-0: What changes were made to improve the performance of Llama 2 models compared to Llama 1 models?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-3\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-3: What changes were made to improve the performance of Llama 2 models compared to Llama 1 models?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-50\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-50: What changes were made to improve the performance of Llama 2 models compared to Llama 1 models?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-6\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-6: What changes were made to improve the performance of Llama 2 models compared to Llama 1 models?\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id None: In the context of the religious ideology domain, what is the difference in sentiment scores between the pretrained models and the fine-tuned models for the Judaism category?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-69\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-69: In the context of the religious ideology domain, what is the difference in sentiment scores between the pretrained models and the fine-tuned models for the Judaism category?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-74\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-74: In the context of the religious ideology domain, what is the difference in sentiment scores between the pretrained models and the fine-tuned models for the Judaism category?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-73\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-73: In the context of the religious ideology domain, what is the difference in sentiment scores between the pretrained models and the fine-tuned models for the Judaism category?\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id None: How does the paper \"Scaling instruction-finetuned language models\" contribute to the field of natural language processing and what are the potential implications of its findings?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-38\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-38: How does the paper \"Scaling instruction-finetuned language models\" contribute to the field of natural language processing and what are the potential implications of its findings?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-33\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-33: How does the paper \"Scaling instruction-finetuned language models\" contribute to the field of natural language processing and what are the potential implications of its findings?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-40\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-40: How does the paper \"Scaling instruction-finetuned language models\" contribute to the field of natural language processing and what are the potential implications of its findings?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-46\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-46: How does the paper \"Scaling instruction-finetuned language models\" contribute to the field of natural language processing and what are the potential implications of its findings?\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id None: How did the training corpus for Llama 2 models differ from the training corpus for Llama 1 models?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-4\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-4: How did the training corpus for Llama 2 models differ from the training corpus for Llama 1 models?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-31\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-31: How did the training corpus for Llama 2 models differ from the training corpus for Llama 1 models?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-17\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-17: How did the training corpus for Llama 2 models differ from the training corpus for Llama 1 models?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-78\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-78: How did the training corpus for Llama 2 models differ from the training corpus for Llama 1 models?\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id None: How do the sentiment scores for the Buddhism category vary across different models, both pretrained and fine-tuned, in the religious ideology domain?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-69\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-69: How do the sentiment scores for the Buddhism category vary across different models, both pretrained and fine-tuned, in the religious ideology domain?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-74\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-74: How do the sentiment scores for the Buddhism category vary across different models, both pretrained and fine-tuned, in the religious ideology domain?\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id None: In the context of large web text corpora, what is the significance of the study on the colossal clean crawled corpus? Provide a brief overview of the findings and its implications in natural language processing.\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-19\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-19: In the context of large web text corpora, what is the significance of the study on the colossal clean crawled corpus? Provide a brief overview of the findings and its implications in natural language processing.\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-72\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-72: In the context of large web text corpora, what is the significance of the study on the colossal clean crawled corpus? Provide a brief overview of the findings and its implications in natural language processing.\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-43\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-43: In the context of large web text corpora, what is the significance of the study on the colossal clean crawled corpus? Provide a brief overview of the findings and its implications in natural language processing.\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-38\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-38: In the context of large web text corpora, what is the significance of the study on the colossal clean crawled corpus? Provide a brief overview of the findings and its implications in natural language processing.\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-31\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-31: In the context of large web text corpora, what is the significance of the study on the colossal clean crawled corpus? Provide a brief overview of the findings and its implications in natural language processing.\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-39\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-39: In the context of large web text corpora, what is the significance of the study on the colossal clean crawled corpus? Provide a brief overview of the findings and its implications in natural language processing.\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-37\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-37: In the context of large web text corpora, what is the significance of the study on the colossal clean crawled corpus? Provide a brief overview of the findings and its implications in natural language processing.\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-36\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-36: In the context of large web text corpora, what is the significance of the study on the colossal clean crawled corpus? Provide a brief overview of the findings and its implications in natural language processing.\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id None: What is the total vocabulary size used in the Llama 2 models' tokenizer?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-5\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-5: What is the total vocabulary size used in the Llama 2 models' tokenizer?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-48\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-48: What is the total vocabulary size used in the Llama 2 models' tokenizer?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-4\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-4: What is the total vocabulary size used in the Llama 2 models' tokenizer?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-56\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-56: What is the total vocabulary size used in the Llama 2 models' tokenizer?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-78\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-78: What is the total vocabulary size used in the Llama 2 models' tokenizer?\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id None: In the context of political ideologies, compare and contrast liberalism and nationalism. Discuss their key principles and how they differ in their approach to governance and society.\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-74\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-74: In the context of political ideologies, compare and contrast liberalism and nationalism. Discuss their key principles and how they differ in their approach to governance and society.\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-65\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-65: In the context of political ideologies, compare and contrast liberalism and nationalism. Discuss their key principles and how they differ in their approach to governance and society.\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-69\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-69: In the context of political ideologies, compare and contrast liberalism and nationalism. Discuss their key principles and how they differ in their approach to governance and society.\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-66\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-66: In the context of political ideologies, compare and contrast liberalism and nationalism. Discuss their key principles and how they differ in their approach to governance and society.\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id None: Discuss the research paper titled \"Measuring the carbon intensity of AI in cloud instances.\" What are the key factors considered in measuring the carbon intensity, and what are the potential implications of this research in the field of artificial intelligence?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-39\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-39: Discuss the research paper titled \"Measuring the carbon intensity of AI in cloud instances.\" What are the key factors considered in measuring the carbon intensity, and what are the potential implications of this research in the field of artificial intelligence?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-5\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-5: Discuss the research paper titled \"Measuring the carbon intensity of AI in cloud instances.\" What are the key factors considered in measuring the carbon intensity, and what are the potential implications of this research in the field of artificial intelligence?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-79\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-79: Discuss the research paper titled \"Measuring the carbon intensity of AI in cloud instances.\" What are the key factors considered in measuring the carbon intensity, and what are the potential implications of this research in the field of artificial intelligence?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-43\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-43: Discuss the research paper titled \"Measuring the carbon intensity of AI in cloud instances.\" What are the key factors considered in measuring the carbon intensity, and what are the potential implications of this research in the field of artificial intelligence?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-40\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-40: Discuss the research paper titled \"Measuring the carbon intensity of AI in cloud instances.\" What are the key factors considered in measuring the carbon intensity, and what are the potential implications of this research in the field of artificial intelligence?\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id None: How much carbon emissions were estimated for pretraining the Llama 2 family of models, and how were these emissions offset?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-5\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-5: How much carbon emissions were estimated for pretraining the Llama 2 family of models, and how were these emissions offset?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-79\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-79: How much carbon emissions were estimated for pretraining the Llama 2 family of models, and how were these emissions offset?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-0\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-0: How much carbon emissions were estimated for pretraining the Llama 2 family of models, and how were these emissions offset?\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id None: Within the domain of professions and industries, identify three fields of study or career paths that are associated with artistic expression. Explain the significance of artistic expression in these fields and how it contributes to the overall industry or profession.\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-69\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-69: Within the domain of professions and industries, identify three fields of study or career paths that are associated with artistic expression. Explain the significance of artistic expression in these fields and how it contributes to the overall industry or profession.\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-30\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-30: Within the domain of professions and industries, identify three fields of study or career paths that are associated with artistic expression. Explain the significance of artistic expression in these fields and how it contributes to the overall industry or profession.\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-46\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-46: Within the domain of professions and industries, identify three fields of study or career paths that are associated with artistic expression. Explain the significance of artistic expression in these fields and how it contributes to the overall industry or profession.\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-35\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-35: Within the domain of professions and industries, identify three fields of study or career paths that are associated with artistic expression. Explain the significance of artistic expression in these fields and how it contributes to the overall industry or profession.\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-45\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-45: Within the domain of professions and industries, identify three fields of study or career paths that are associated with artistic expression. Explain the significance of artistic expression in these fields and how it contributes to the overall industry or profession.\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-32\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-32: Within the domain of professions and industries, identify three fields of study or career paths that are associated with artistic expression. Explain the significance of artistic expression in these fields and how it contributes to the overall industry or profession.\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id None: In the field of language model evaluation, what is the purpose of the framework mentioned in the context information? How does it contribute to the improvement of language models?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-40\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-40: In the field of language model evaluation, what is the purpose of the framework mentioned in the context information? How does it contribute to the improvement of language models?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-27\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-27: In the field of language model evaluation, what is the purpose of the framework mentioned in the context information? How does it contribute to the improvement of language models?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-72\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-72: In the field of language model evaluation, what is the purpose of the framework mentioned in the context information? How does it contribute to the improvement of language models?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-17\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-17: In the field of language model evaluation, what is the purpose of the framework mentioned in the context information? How does it contribute to the improvement of language models?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-49\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-49: In the field of language model evaluation, what is the purpose of the framework mentioned in the context information? How does it contribute to the improvement of language models?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-15\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-15: In the field of language model evaluation, what is the purpose of the framework mentioned in the context information? How does it contribute to the improvement of language models?\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id None: Question: In the context information, which benchmarks fall under the \"Commonsense Reasoning\" category?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-45\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-45: Question: In the context information, which benchmarks fall under the \"Commonsense Reasoning\" category?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-6\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-6: Question: In the context information, which benchmarks fall under the \"Commonsense Reasoning\" category?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-36\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-36: Question: In the context information, which benchmarks fall under the \"Commonsense Reasoning\" category?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-68\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-68: Question: In the context information, which benchmarks fall under the \"Commonsense Reasoning\" category?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-41\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-41: Question: In the context information, which benchmarks fall under the \"Commonsense Reasoning\" category?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-37\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-37: Question: In the context information, which benchmarks fall under the \"Commonsense Reasoning\" category?\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id None: Based on the context information provided, design a question that tests the students' understanding of the performance of different models.\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-26\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-26: Based on the context information provided, design a question that tests the students' understanding of the performance of different models.\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-48\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-48: Based on the context information provided, design a question that tests the students' understanding of the performance of different models.\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-72\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-72: Based on the context information provided, design a question that tests the students' understanding of the performance of different models.\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-68\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-68: Based on the context information provided, design a question that tests the students' understanding of the performance of different models.\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-27\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-27: Based on the context information provided, design a question that tests the students' understanding of the performance of different models.\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-12\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-12: Based on the context information provided, design a question that tests the students' understanding of the performance of different models.\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-17\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-17: Based on the context information provided, design a question that tests the students' understanding of the performance of different models.\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id None: How does the article \"Repairing the cracked foundation: A survey of obstacles in evaluation practices for generated text\" shed light on the challenges faced in evaluating generated text? What are some of the key findings discussed in the article?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-40\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-40: How does the article \"Repairing the cracked foundation: A survey of obstacles in evaluation practices for generated text\" shed light on the challenges faced in evaluating generated text? What are some of the key findings discussed in the article?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-41\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-41: How does the article \"Repairing the cracked foundation: A survey of obstacles in evaluation practices for generated text\" shed light on the challenges faced in evaluating generated text? What are some of the key findings discussed in the article?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-28\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-28: How does the article \"Repairing the cracked foundation: A survey of obstacles in evaluation practices for generated text\" shed light on the challenges faced in evaluating generated text? What are some of the key findings discussed in the article?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-32\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-32: How does the article \"Repairing the cracked foundation: A survey of obstacles in evaluation practices for generated text\" shed light on the challenges faced in evaluating generated text? What are some of the key findings discussed in the article?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-33\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-33: How does the article \"Repairing the cracked foundation: A survey of obstacles in evaluation practices for generated text\" shed light on the challenges faced in evaluating generated text? What are some of the key findings discussed in the article?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-76\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-76: How does the article \"Repairing the cracked foundation: A survey of obstacles in evaluation practices for generated text\" shed light on the challenges faced in evaluating generated text? What are some of the key findings discussed in the article?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-72\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-72: How does the article \"Repairing the cracked foundation: A survey of obstacles in evaluation practices for generated text\" shed light on the challenges faced in evaluating generated text? What are some of the key findings discussed in the article?\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id None: Question: What is the average performance of the Llama 27B model on the MMLU, BBH, and AGI Eval benchmarks?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-7\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-7: Question: What is the average performance of the Llama 27B model on the MMLU, BBH, and AGI Eval benchmarks?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-50\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-50: Question: What is the average performance of the Llama 27B model on the MMLU, BBH, and AGI Eval benchmarks?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-53\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-53: Question: What is the average performance of the Llama 27B model on the MMLU, BBH, and AGI Eval benchmarks?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-6\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-6: Question: What is the average performance of the Llama 27B model on the MMLU, BBH, and AGI Eval benchmarks?\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id None: Create a question that requires students to analyze the performance of a specific model and compare it to other models mentioned in the context information.\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-57\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-57: Create a question that requires students to analyze the performance of a specific model and compare it to other models mentioned in the context information.\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-27\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-27: Create a question that requires students to analyze the performance of a specific model and compare it to other models mentioned in the context information.\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-25\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-25: Create a question that requires students to analyze the performance of a specific model and compare it to other models mentioned in the context information.\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-48\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-48: Create a question that requires students to analyze the performance of a specific model and compare it to other models mentioned in the context information.\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-52\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-52: Create a question that requires students to analyze the performance of a specific model and compare it to other models mentioned in the context information.\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-72\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-72: Create a question that requires students to analyze the performance of a specific model and compare it to other models mentioned in the context information.\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id None: In the context of language models, what is the purpose of the study conducted by Or Honovich, Thomas Scialom, Omer Levy, and Timo Schick? Provide a brief summary of their findings.\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-41\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-41: In the context of language models, what is the purpose of the study conducted by Or Honovich, Thomas Scialom, Omer Levy, and Timo Schick? Provide a brief summary of their findings.\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-40\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-40: In the context of language models, what is the purpose of the study conducted by Or Honovich, Thomas Scialom, Omer Levy, and Timo Schick? Provide a brief summary of their findings.\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-44\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-44: In the context of language models, what is the purpose of the study conducted by Or Honovich, Thomas Scialom, Omer Levy, and Timo Schick? Provide a brief summary of their findings.\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-45\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-45: In the context of language models, what is the purpose of the study conducted by Or Honovich, Thomas Scialom, Omer Levy, and Timo Schick? Provide a brief summary of their findings.\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-35\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-35: In the context of language models, what is the purpose of the study conducted by Or Honovich, Thomas Scialom, Omer Levy, and Timo Schick? Provide a brief summary of their findings.\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id None: In the context of AGI Eval, compare the performance of Llama 2 models to Llama 1 models. How much improvement is observed in terms of MMLU and BBH scores for Llama 2 70B compared to Llama 1 65B?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-7\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-7: In the context of AGI Eval, compare the performance of Llama 2 models to Llama 1 models. How much improvement is observed in terms of MMLU and BBH scores for Llama 2 70B compared to Llama 1 65B?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-50\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-50: In the context of AGI Eval, compare the performance of Llama 2 models to Llama 1 models. How much improvement is observed in terms of MMLU and BBH scores for Llama 2 70B compared to Llama 1 65B?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-53\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-53: In the context of AGI Eval, compare the performance of Llama 2 models to Llama 1 models. How much improvement is observed in terms of MMLU and BBH scores for Llama 2 70B compared to Llama 1 65B?\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id None: How does the quality assurance process ensure high-quality annotations for training the model?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-76\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-76: How does the quality assurance process ensure high-quality annotations for training the model?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-53\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-53: How does the quality assurance process ensure high-quality annotations for training the model?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-8\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-8: How does the quality assurance process ensure high-quality annotations for training the model?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-23\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-23: How does the quality assurance process ensure high-quality annotations for training the model?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-17\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-17: How does the quality assurance process ensure high-quality annotations for training the model?\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id None: How do language generation models pose potential harm, as discussed in the paper by Sachin Kumar, Vidhisha Balachandran, Lucille Njoo, Antonios Anastasopoulos, and Yulia Tsvetkov? Explain the suggested actions to mitigate this harm.\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-41\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-41: How do language generation models pose potential harm, as discussed in the paper by Sachin Kumar, Vidhisha Balachandran, Lucille Njoo, Antonios Anastasopoulos, and Yulia Tsvetkov? Explain the suggested actions to mitigate this harm.\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-46\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-46: How do language generation models pose potential harm, as discussed in the paper by Sachin Kumar, Vidhisha Balachandran, Lucille Njoo, Antonios Anastasopoulos, and Yulia Tsvetkov? Explain the suggested actions to mitigate this harm.\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-40\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-40: How do language generation models pose potential harm, as discussed in the paper by Sachin Kumar, Vidhisha Balachandran, Lucille Njoo, Antonios Anastasopoulos, and Yulia Tsvetkov? Explain the suggested actions to mitigate this harm.\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-32\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-32: How do language generation models pose potential harm, as discussed in the paper by Sachin Kumar, Vidhisha Balachandran, Lucille Njoo, Antonios Anastasopoulos, and Yulia Tsvetkov? Explain the suggested actions to mitigate this harm.\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-39\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-39: How do language generation models pose potential harm, as discussed in the paper by Sachin Kumar, Vidhisha Balachandran, Lucille Njoo, Antonios Anastasopoulos, and Yulia Tsvetkov? Explain the suggested actions to mitigate this harm.\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-31\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-31: How do language generation models pose potential harm, as discussed in the paper by Sachin Kumar, Vidhisha Balachandran, Lucille Njoo, Antonios Anastasopoulos, and Yulia Tsvetkov? Explain the suggested actions to mitigate this harm.\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id None: Compare the performance of Llama 2 70B to GPT-3.5 (OpenAI, 2023) and PaLM (540B) (Chowdhery et al., 2022) on the MMLU and GSM8K benchmarks. How does Llama 2 70B perform in comparison?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-7\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-7: Compare the performance of Llama 2 70B to GPT-3.5 (OpenAI, 2023) and PaLM (540B) (Chowdhery et al., 2022) on the MMLU and GSM8K benchmarks. How does Llama 2 70B perform in comparison?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-50\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-50: Compare the performance of Llama 2 70B to GPT-3.5 (OpenAI, 2023) and PaLM (540B) (Chowdhery et al., 2022) on the MMLU and GSM8K benchmarks. How does Llama 2 70B perform in comparison?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-53\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-53: Compare the performance of Llama 2 70B to GPT-3.5 (OpenAI, 2023) and PaLM (540B) (Chowdhery et al., 2022) on the MMLU and GSM8K benchmarks. How does Llama 2 70B perform in comparison?\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id None: What are the negative user experience categories that annotators are instructed to avoid when writing responses?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-76\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-76: What are the negative user experience categories that annotators are instructed to avoid when writing responses?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-23\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-23: What are the negative user experience categories that annotators are instructed to avoid when writing responses?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-73\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-73: What are the negative user experience categories that annotators are instructed to avoid when writing responses?\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id None: What is the significance of deduplicating training data in improving language models, according to the paper \"Deduplicating training data makes language models better\"?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-42\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-42: What is the significance of deduplicating training data in improving language models, according to the paper \"Deduplicating training data makes language models better\"?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-41\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-41: What is the significance of deduplicating training data in improving language models, according to the paper \"Deduplicating training data makes language models better\"?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-40\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-40: What is the significance of deduplicating training data in improving language models, according to the paper \"Deduplicating training data makes language models better\"?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-39\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-39: What is the significance of deduplicating training data in improving language models, according to the paper \"Deduplicating training data makes language models better\"?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-31\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-31: What is the significance of deduplicating training data in improving language models, according to the paper \"Deduplicating training data makes language models better\"?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-12\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-12: What is the significance of deduplicating training data in improving language models, according to the paper \"Deduplicating training data makes language models better\"?\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id None: How did the researchers improve the quality of the SFT data in their study?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-8\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-8: How did the researchers improve the quality of the SFT data in their study?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-53\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-53: How did the researchers improve the quality of the SFT data in their study?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-18\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-18: How did the researchers improve the quality of the SFT data in their study?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-78\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-78: How did the researchers improve the quality of the SFT data in their study?\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id None: How does the methodology in Chowdhery et al. (2022) improve upon previous approaches in detecting contamination in evaluation datasets?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-77\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-77: How does the methodology in Chowdhery et al. (2022) improve upon previous approaches in detecting contamination in evaluation datasets?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-78\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-78: How does the methodology in Chowdhery et al. (2022) improve upon previous approaches in detecting contamination in evaluation datasets?\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id None: How does the \"Self-refine\" approach, described in the paper \"Self-refine: Iterative refinement with self-feedback,\" contribute to the field of AI research?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-42\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-42: How does the \"Self-refine\" approach, described in the paper \"Self-refine: Iterative refinement with self-feedback,\" contribute to the field of AI research?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-45\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-45: How does the \"Self-refine\" approach, described in the paper \"Self-refine: Iterative refinement with self-feedback,\" contribute to the field of AI research?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-4\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-4: How does the \"Self-refine\" approach, described in the paper \"Self-refine: Iterative refinement with self-feedback,\" contribute to the field of AI research?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-34\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-34: How does the \"Self-refine\" approach, described in the paper \"Self-refine: Iterative refinement with self-feedback,\" contribute to the field of AI research?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-36\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-36: How does the \"Self-refine\" approach, described in the paper \"Self-refine: Iterative refinement with self-feedback,\" contribute to the field of AI research?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-43\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-43: How does the \"Self-refine\" approach, described in the paper \"Self-refine: Iterative refinement with self-feedback,\" contribute to the field of AI research?\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id None: What is the purpose of the human preference data collection in RLHF?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-53\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-53: What is the purpose of the human preference data collection in RLHF?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-8\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-8: What is the purpose of the human preference data collection in RLHF?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-10\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-10: What is the purpose of the human preference data collection in RLHF?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-23\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-23: What is the purpose of the human preference data collection in RLHF?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-12\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-12: What is the purpose of the human preference data collection in RLHF?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-30\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-30: What is the purpose of the human preference data collection in RLHF?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-54\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-54: What is the purpose of the human preference data collection in RLHF?\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id None: What is the approach used in this study to determine contamination in evaluation samples, and how does it differ from previous methodologies?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-77\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-77: What is the approach used in this study to determine contamination in evaluation samples, and how does it differ from previous methodologies?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-78\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-78: What is the approach used in this study to determine contamination in evaluation samples, and how does it differ from previous methodologies?\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id None: In the context of training language models, what is the significance of human feedback and how does it contribute to improving model performance?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-43\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-43: In the context of training language models, what is the significance of human feedback and how does it contribute to improving model performance?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-36\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-36: In the context of training language models, what is the significance of human feedback and how does it contribute to improving model performance?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-17\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-17: In the context of training language models, what is the significance of human feedback and how does it contribute to improving model performance?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-8\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-8: In the context of training language models, what is the significance of human feedback and how does it contribute to improving model performance?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-2\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-2: In the context of training language models, what is the significance of human feedback and how does it contribute to improving model performance?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-33\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-33: In the context of training language models, what is the significance of human feedback and how does it contribute to improving model performance?\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id None: How does the collection of preference annotations in Llama 2-Chat focus on helpfulness and safety? Explain the importance of separating these two aspects in the annotation process.\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-9\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-9: How does the collection of preference annotations in Llama 2-Chat focus on helpfulness and safety? Explain the importance of separating these two aspects in the annotation process.\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-28\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-28: How does the collection of preference annotations in Llama 2-Chat focus on helpfulness and safety? Explain the importance of separating these two aspects in the annotation process.\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-63\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-63: How does the collection of preference annotations in Llama 2-Chat focus on helpfulness and safety? Explain the importance of separating these two aspects in the annotation process.\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-3\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-3: How does the collection of preference annotations in Llama 2-Chat focus on helpfulness and safety? Explain the importance of separating these two aspects in the annotation process.\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id None: Based on the contamination analysis results in Table 51, which datasets appear to have been boosted due to contamination in the training data? How does the impact of contamination differ between the 70B model and the 7B model?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-78\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-78: Based on the contamination analysis results in Table 51, which datasets appear to have been boosted due to contamination in the training data? How does the impact of contamination differ between the 70B model and the 7B model?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-21\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-21: Based on the contamination analysis results in Table 51, which datasets appear to have been boosted due to contamination in the training data? How does the impact of contamination differ between the 70B model and the 7B model?\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id None: How do large neural network training and carbon emissions relate to each other, and what are the implications of this relationship in the field of artificial intelligence?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-43\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-43: How do large neural network training and carbon emissions relate to each other, and what are the implications of this relationship in the field of artificial intelligence?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-5\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-5: How do large neural network training and carbon emissions relate to each other, and what are the implications of this relationship in the field of artificial intelligence?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-39\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-39: How do large neural network training and carbon emissions relate to each other, and what are the implications of this relationship in the field of artificial intelligence?\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id None: What additional information is collected during the safety stage of annotation in Llama 2-Chat? Describe the three categories into which model responses are binned based on safety.\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-9\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-9: What additional information is collected during the safety stage of annotation in Llama 2-Chat? Describe the three categories into which model responses are binned based on safety.\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-63\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-63: What additional information is collected during the safety stage of annotation in Llama 2-Chat? Describe the three categories into which model responses are binned based on safety.\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-28\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-28: What additional information is collected during the safety stage of annotation in Llama 2-Chat? Describe the three categories into which model responses are binned based on safety.\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-3\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-3: What additional information is collected during the safety stage of annotation in Llama 2-Chat? Describe the three categories into which model responses are binned based on safety.\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id None: According to the model card, what are the variations available for Llama 2? How do these variations differ in terms of parameter sizes and functionality?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-78\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-78: According to the model card, what are the variations available for Llama 2? How do these variations differ in terms of parameter sizes and functionality?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-79\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-79: According to the model card, what are the variations available for Llama 2? How do these variations differ in terms of parameter sizes and functionality?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-2\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-2: According to the model card, what are the variations available for Llama 2? How do these variations differ in terms of parameter sizes and functionality?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-53\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-53: According to the model card, what are the variations available for Llama 2? How do these variations differ in terms of parameter sizes and functionality?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-18\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-18: According to the model card, what are the variations available for Llama 2? How do these variations differ in terms of parameter sizes and functionality?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-0\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-0: According to the model card, what are the variations available for Llama 2? How do these variations differ in terms of parameter sizes and functionality?\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id None: Based on the context information provided, what is the main focus of the Winogrande challenge and how does it differ from the Socialiqa challenge?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-44\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-44: Based on the context information provided, what is the main focus of the Winogrande challenge and how does it differ from the Socialiqa challenge?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-41\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-41: Based on the context information provided, what is the main focus of the Winogrande challenge and how does it differ from the Socialiqa challenge?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-18\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-18: Based on the context information provided, what is the main focus of the Winogrande challenge and how does it differ from the Socialiqa challenge?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-45\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-45: Based on the context information provided, what is the main focus of the Winogrande challenge and how does it differ from the Socialiqa challenge?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-26\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-26: Based on the context information provided, what is the main focus of the Winogrande challenge and how does it differ from the Socialiqa challenge?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-2\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-2: Based on the context information provided, what is the main focus of the Winogrande challenge and how does it differ from the Socialiqa challenge?\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id None: How were human annotations collected for Llama 2-Chat? Explain the process and its impact on improving reward models.\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-9\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-9: How were human annotations collected for Llama 2-Chat? Explain the process and its impact on improving reward models.\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-30\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-30: How were human annotations collected for Llama 2-Chat? Explain the process and its impact on improving reward models.\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-12\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-12: How were human annotations collected for Llama 2-Chat? Explain the process and its impact on improving reward models.\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-4\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-4: How were human annotations collected for Llama 2-Chat? Explain the process and its impact on improving reward models.\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id None: What is the purpose of Llama 2's supervised fine-tuning and reinforcement learning with human feedback?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-7\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-7: What is the purpose of Llama 2's supervised fine-tuning and reinforcement learning with human feedback?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-4\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-4: What is the purpose of Llama 2's supervised fine-tuning and reinforcement learning with human feedback?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-30\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-30: What is the purpose of Llama 2's supervised fine-tuning and reinforcement learning with human feedback?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-0\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-0: What is the purpose of Llama 2's supervised fine-tuning and reinforcement learning with human feedback?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-12\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-12: What is the purpose of Llama 2's supervised fine-tuning and reinforcement learning with human feedback?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-79\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-79: What is the purpose of Llama 2's supervised fine-tuning and reinforcement learning with human feedback?\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id None: In the field of natural language processing, what are some recent advancements in language models and their applications?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-40\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-40: In the field of natural language processing, what are some recent advancements in language models and their applications?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-37\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-37: In the field of natural language processing, what are some recent advancements in language models and their applications?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-44\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-44: In the field of natural language processing, what are some recent advancements in language models and their applications?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-46\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-46: In the field of natural language processing, what are some recent advancements in language models and their applications?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-41\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-41: In the field of natural language processing, what are some recent advancements in language models and their applications?\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id None: Compare the preference data collected for reward modeling in Llama 2-Chat with other open-source preference datasets. Highlight the differences in terms of conversation turns and length.\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-12\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-12: Compare the preference data collected for reward modeling in Llama 2-Chat with other open-source preference datasets. Highlight the differences in terms of conversation turns and length.\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-10\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-10: Compare the preference data collected for reward modeling in Llama 2-Chat with other open-source preference datasets. Highlight the differences in terms of conversation turns and length.\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-17\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-17: Compare the preference data collected for reward modeling in Llama 2-Chat with other open-source preference datasets. Highlight the differences in terms of conversation turns and length.\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-9\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-9: Compare the preference data collected for reward modeling in Llama 2-Chat with other open-source preference datasets. Highlight the differences in terms of conversation turns and length.\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-3\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-3: Compare the preference data collected for reward modeling in Llama 2-Chat with other open-source preference datasets. Highlight the differences in terms of conversation turns and length.\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-4\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-4: Compare the preference data collected for reward modeling in Llama 2-Chat with other open-source preference datasets. Highlight the differences in terms of conversation turns and length.\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id None: How was the carbon footprint of Llama 2's pretraining process offset?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-5\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-5: How was the carbon footprint of Llama 2's pretraining process offset?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-79\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-79: How was the carbon footprint of Llama 2's pretraining process offset?\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id None: In the paper \"i'm sorry to hear that\": Finding new biases in language models with a holistic descriptor dataset, what is the main objective of the research conducted by Eric Michael Smith and his colleagues?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-45\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-45: In the paper \"i'm sorry to hear that\": Finding new biases in language models with a holistic descriptor dataset, what is the main objective of the research conducted by Eric Michael Smith and his colleagues?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-40\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-40: In the paper \"i'm sorry to hear that\": Finding new biases in language models with a holistic descriptor dataset, what is the main objective of the research conducted by Eric Michael Smith and his colleagues?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-28\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-28: In the paper \"i'm sorry to hear that\": Finding new biases in language models with a holistic descriptor dataset, what is the main objective of the research conducted by Eric Michael Smith and his colleagues?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-43\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-43: In the paper \"i'm sorry to hear that\": Finding new biases in language models with a holistic descriptor dataset, what is the main objective of the research conducted by Eric Michael Smith and his colleagues?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-44\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-44: In the paper \"i'm sorry to hear that\": Finding new biases in language models with a holistic descriptor dataset, what is the main objective of the research conducted by Eric Michael Smith and his colleagues?\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id None: How does the reward modeling process work in Llama 2-Chat? Describe the inputs and outputs of the reward model and its role in optimizing the model's performance.\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-9\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-9: How does the reward modeling process work in Llama 2-Chat? Describe the inputs and outputs of the reward model and its role in optimizing the model's performance.\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-10\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-10: How does the reward modeling process work in Llama 2-Chat? Describe the inputs and outputs of the reward model and its role in optimizing the model's performance.\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-12\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-12: How does the reward modeling process work in Llama 2-Chat? Describe the inputs and outputs of the reward model and its role in optimizing the model's performance.\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-4\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-4: How does the reward modeling process work in Llama 2-Chat? Describe the inputs and outputs of the reward model and its role in optimizing the model's performance.\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-30\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-30: How does the reward modeling process work in Llama 2-Chat? Describe the inputs and outputs of the reward model and its role in optimizing the model's performance.\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id None: Which paper discusses the evaluation of the social impact of generative AI systems in systems and society, and who are the authors of this paper?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-45\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-45: Which paper discusses the evaluation of the social impact of generative AI systems in systems and society, and who are the authors of this paper?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-32\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-32: Which paper discusses the evaluation of the social impact of generative AI systems in systems and society, and who are the authors of this paper?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-39\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-39: Which paper discusses the evaluation of the social impact of generative AI systems in systems and society, and who are the authors of this paper?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-34\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-34: Which paper discusses the evaluation of the social impact of generative AI systems in systems and society, and who are the authors of this paper?\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id None: Why are separate reward models trained for helpfulness and safety in Llama 2-Chat? Discuss the trade-off between helpfulness and safety and how separate models address this challenge.\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-9\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-9: Why are separate reward models trained for helpfulness and safety in Llama 2-Chat? Discuss the trade-off between helpfulness and safety and how separate models address this challenge.\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-12\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-12: Why are separate reward models trained for helpfulness and safety in Llama 2-Chat? Discuss the trade-off between helpfulness and safety and how separate models address this challenge.\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-10\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-10: Why are separate reward models trained for helpfulness and safety in Llama 2-Chat? Discuss the trade-off between helpfulness and safety and how separate models address this challenge.\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-3\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-3: Why are separate reward models trained for helpfulness and safety in Llama 2-Chat? Discuss the trade-off between helpfulness and safety and how separate models address this challenge.\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-11\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-11: Why are separate reward models trained for helpfulness and safety in Llama 2-Chat? Discuss the trade-off between helpfulness and safety and how separate models address this challenge.\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id None: In the field of artificial intelligence, what are some potential applications discussed in the context information?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-34\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-34: In the field of artificial intelligence, what are some potential applications discussed in the context information?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-37\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-37: In the field of artificial intelligence, what are some potential applications discussed in the context information?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-32\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-32: In the field of artificial intelligence, what are some potential applications discussed in the context information?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-46\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-46: In the field of artificial intelligence, what are some potential applications discussed in the context information?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-26\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-26: In the field of artificial intelligence, what are some potential applications discussed in the context information?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-49\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-49: In the field of artificial intelligence, what are some potential applications discussed in the context information?\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id None: How are the reward models in Llama 2-Chat initialized? Explain the benefit of initializing the reward models from pretrained chat model checkpoints.\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-4\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-4: How are the reward models in Llama 2-Chat initialized? Explain the benefit of initializing the reward models from pretrained chat model checkpoints.\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-10\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-10: How are the reward models in Llama 2-Chat initialized? Explain the benefit of initializing the reward models from pretrained chat model checkpoints.\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-12\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-12: How are the reward models in Llama 2-Chat initialized? Explain the benefit of initializing the reward models from pretrained chat model checkpoints.\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-9\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-9: How are the reward models in Llama 2-Chat initialized? Explain the benefit of initializing the reward models from pretrained chat model checkpoints.\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id None: How do language models play a role in various domains according to the context information?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-72\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-72: How do language models play a role in various domains according to the context information?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-45\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-45: How do language models play a role in various domains according to the context information?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-40\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-40: How do language models play a role in various domains according to the context information?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-44\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-44: How do language models play a role in various domains according to the context information?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-43\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-43: How do language models play a role in various domains according to the context information?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-39\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-39: How do language models play a role in various domains according to the context information?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-46\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-46: How do language models play a role in various domains according to the context information?\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id None: In the context of training the reward model, what is the purpose of converting pairwise human preference data into a binary ranking label format? How does the binary ranking loss function help in training the reward model?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-10\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-10: In the context of training the reward model, what is the purpose of converting pairwise human preference data into a binary ranking label format? How does the binary ranking loss function help in training the reward model?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-8\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-8: In the context of training the reward model, what is the purpose of converting pairwise human preference data into a binary ranking label format? How does the binary ranking loss function help in training the reward model?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-54\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-54: In the context of training the reward model, what is the purpose of converting pairwise human preference data into a binary ranking label format? How does the binary ranking loss function help in training the reward model?\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id None: What is the purpose of the Pytorch fsdp framework mentioned in the context information? How does it contribute to scaling fully sharded data parallel?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-47\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-47: What is the purpose of the Pytorch fsdp framework mentioned in the context information? How does it contribute to scaling fully sharded data parallel?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-15\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-15: What is the purpose of the Pytorch fsdp framework mentioned in the context information? How does it contribute to scaling fully sharded data parallel?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-49\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-49: What is the purpose of the Pytorch fsdp framework mentioned in the context information? How does it contribute to scaling fully sharded data parallel?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-27\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-27: What is the purpose of the Pytorch fsdp framework mentioned in the context information? How does it contribute to scaling fully sharded data parallel?\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id None: How does the margin component in the loss function contribute to improving the accuracy of the Helpfulness reward model? Can you explain the rationale behind using a larger margin for pairs with distinct responses and a smaller one for those with similar responses?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-54\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-54: How does the margin component in the loss function contribute to improving the accuracy of the Helpfulness reward model? Can you explain the rationale behind using a larger margin for pairs with distinct responses and a smaller one for those with similar responses?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-10\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-10: How does the margin component in the loss function contribute to improving the accuracy of the Helpfulness reward model? Can you explain the rationale behind using a larger margin for pairs with distinct responses and a smaller one for those with similar responses?\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id None: In the context information, what is the main focus of the Lima project? How does it propose that \"less is more\" for alignment?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-47\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-47: In the context information, what is the main focus of the Lima project? How does it propose that \"less is more\" for alignment?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-48\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-48: In the context information, what is the main focus of the Lima project? How does it propose that \"less is more\" for alignment?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-10\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-10: In the context information, what is the main focus of the Lima project? How does it propose that \"less is more\" for alignment?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-49\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-49: In the context information, what is the main focus of the Lima project? How does it propose that \"less is more\" for alignment?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-27\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-27: In the context information, what is the main focus of the Lima project? How does it propose that \"less is more\" for alignment?\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id None: How did the researchers prevent reward hacking in the Llama 2-Chat model?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-11\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-11: How did the researchers prevent reward hacking in the Llama 2-Chat model?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-9\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-9: How did the researchers prevent reward hacking in the Llama 2-Chat model?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-30\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-30: How did the researchers prevent reward hacking in the Llama 2-Chat model?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-12\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-12: How did the researchers prevent reward hacking in the Llama 2-Chat model?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-10\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-10: How did the researchers prevent reward hacking in the Llama 2-Chat model?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-34\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-34: How did the researchers prevent reward hacking in the Llama 2-Chat model?\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id None: How did the human annotators contribute to improving the tuned model performance in this study?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-8\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-8: How did the human annotators contribute to improving the tuned model performance in this study?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-53\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-53: How did the human annotators contribute to improving the tuned model performance in this study?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-30\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-30: How did the human annotators contribute to improving the tuned model performance in this study?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-23\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-23: How did the human annotators contribute to improving the tuned model performance in this study?\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id None: What were the mixing recipes used for training the Helpfulness and Safety reward models, and why was the setting with 10% helpfulness data found to be beneficial?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-24\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-24: What were the mixing recipes used for training the Helpfulness and Safety reward models, and why was the setting with 10% helpfulness data found to be beneficial?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-11\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-11: What were the mixing recipes used for training the Helpfulness and Safety reward models, and why was the setting with 10% helpfulness data found to be beneficial?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-9\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-9: What were the mixing recipes used for training the Helpfulness and Safety reward models, and why was the setting with 10% helpfulness data found to be beneficial?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-25\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-25: What were the mixing recipes used for training the Helpfulness and Safety reward models, and why was the setting with 10% helpfulness data found to be beneficial?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-60\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-60: What were the mixing recipes used for training the Helpfulness and Safety reward models, and why was the setting with 10% helpfulness data found to be beneficial?\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id None: What were the key roles of the red team organizers in enhancing the safety and robustness of the models?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-48\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-48: What were the key roles of the red team organizers in enhancing the safety and robustness of the models?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-28\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-28: What were the key roles of the red team organizers in enhancing the safety and robustness of the models?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-27\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-27: What were the key roles of the red team organizers in enhancing the safety and robustness of the models?\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id None: How do the reward models perform compared to the baselines in terms of accuracy on the internal test sets collected based on Llama 2-Chat?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-12\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-12: How do the reward models perform compared to the baselines in terms of accuracy on the internal test sets collected based on Llama 2-Chat?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-9\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-9: How do the reward models perform compared to the baselines in terms of accuracy on the internal test sets collected based on Llama 2-Chat?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-3\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-3: How do the reward models perform compared to the baselines in terms of accuracy on the internal test sets collected based on Llama 2-Chat?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-17\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-17: How do the reward models perform compared to the baselines in terms of accuracy on the internal test sets collected based on Llama 2-Chat?\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id None: How does the grouped-query attention variant (GQA) compare to the multi-head attention (MHA) baseline in terms of performance on evaluation tasks?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-49\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-49: How does the grouped-query attention variant (GQA) compare to the multi-head attention (MHA) baseline in terms of performance on evaluation tasks?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-50\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-50: How does the grouped-query attention variant (GQA) compare to the multi-head attention (MHA) baseline in terms of performance on evaluation tasks?\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id None: What are the two main algorithms explored for RLHF fine-tuning in the iterative process?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-12\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-12: What are the two main algorithms explored for RLHF fine-tuning in the iterative process?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-13\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-13: What are the two main algorithms explored for RLHF fine-tuning in the iterative process?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-33\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-33: What are the two main algorithms explored for RLHF fine-tuning in the iterative process?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-7\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-7: What are the two main algorithms explored for RLHF fine-tuning in the iterative process?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-4\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-4: What are the two main algorithms explored for RLHF fine-tuning in the iterative process?\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id None: What is the purpose of caching the key (K) and value (V) pairs in autoregressive decoding, and how does it affect attention computation?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-49\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-49: What is the purpose of caching the key (K) and value (V) pairs in autoregressive decoding, and how does it affect attention computation?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-15\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-15: What is the purpose of caching the key (K) and value (V) pairs in autoregressive decoding, and how does it affect attention computation?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-30\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-30: What is the purpose of caching the key (K) and value (V) pairs in autoregressive decoding, and how does it affect attention computation?\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id None: Explain the difference between Rejection Sampling fine-tuning and Proximal Policy Optimization (PPO) in the context of RL algorithms. How do they differ in terms of breadth and depth?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-13\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-13: Explain the difference between Rejection Sampling fine-tuning and Proximal Policy Optimization (PPO) in the context of RL algorithms. How do they differ in terms of breadth and depth?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-12\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-12: Explain the difference between Rejection Sampling fine-tuning and Proximal Policy Optimization (PPO) in the context of RL algorithms. How do they differ in terms of breadth and depth?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-14\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-14: Explain the difference between Rejection Sampling fine-tuning and Proximal Policy Optimization (PPO) in the context of RL algorithms. How do they differ in terms of breadth and depth?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-4\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-4: Explain the difference between Rejection Sampling fine-tuning and Proximal Policy Optimization (PPO) in the context of RL algorithms. How do they differ in terms of breadth and depth?\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id None: In the context of the Llama 2 models, what is the reason for choosing GQA over MQA based on the ablation results and ease of scaling inference? Provide specific details from the context to support your answer.\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-50\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-50: In the context of the Llama 2 models, what is the reason for choosing GQA over MQA based on the ablation results and ease of scaling inference? Provide specific details from the context to support your answer.\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-4\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-4: In the context of the Llama 2 models, what is the reason for choosing GQA over MQA based on the ablation results and ease of scaling inference? Provide specific details from the context to support your answer.\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-49\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-49: In the context of the Llama 2 models, what is the reason for choosing GQA over MQA based on the ablation results and ease of scaling inference? Provide specific details from the context to support your answer.\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id None: Describe the iterative approach used in RLHF (Version 4) for answer selection. How does it differ from earlier versions, and what improvements were observed as a result of this modification?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-13\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-13: Describe the iterative approach used in RLHF (Version 4) for answer selection. How does it differ from earlier versions, and what improvements were observed as a result of this modification?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-33\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-33: Describe the iterative approach used in RLHF (Version 4) for answer selection. How does it differ from earlier versions, and what improvements were observed as a result of this modification?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-17\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-17: Describe the iterative approach used in RLHF (Version 4) for answer selection. How does it differ from earlier versions, and what improvements were observed as a result of this modification?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-4\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-4: Describe the iterative approach used in RLHF (Version 4) for answer selection. How does it differ from earlier versions, and what improvements were observed as a result of this modification?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-12\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-12: Describe the iterative approach used in RLHF (Version 4) for answer selection. How does it differ from earlier versions, and what improvements were observed as a result of this modification?\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id None: Compare the performance of Llama 2 with other open-source models on the NaturalQuestions and TriviaQA benchmarks. How does Llama 2 fare in terms of world knowledge? Use specific information from the context to justify your response.\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-7\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-7: Compare the performance of Llama 2 with other open-source models on the NaturalQuestions and TriviaQA benchmarks. How does Llama 2 fare in terms of world knowledge? Use specific information from the context to justify your response.\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-50\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-50: Compare the performance of Llama 2 with other open-source models on the NaturalQuestions and TriviaQA benchmarks. How does Llama 2 fare in terms of world knowledge? Use specific information from the context to justify your response.\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-17\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-17: Compare the performance of Llama 2 with other open-source models on the NaturalQuestions and TriviaQA benchmarks. How does Llama 2 fare in terms of world knowledge? Use specific information from the context to justify your response.\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-3\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-3: Compare the performance of Llama 2 with other open-source models on the NaturalQuestions and TriviaQA benchmarks. How does Llama 2 fare in terms of world knowledge? Use specific information from the context to justify your response.\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-31\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-31: Compare the performance of Llama 2 with other open-source models on the NaturalQuestions and TriviaQA benchmarks. How does Llama 2 fare in terms of world knowledge? Use specific information from the context to justify your response.\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-0\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-0: Compare the performance of Llama 2 with other open-source models on the NaturalQuestions and TriviaQA benchmarks. How does Llama 2 fare in terms of world knowledge? Use specific information from the context to justify your response.\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-58\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-58: Compare the performance of Llama 2 with other open-source models on the NaturalQuestions and TriviaQA benchmarks. How does Llama 2 fare in terms of world knowledge? Use specific information from the context to justify your response.\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id None: How does the temperature parameter affect the exploration in rejection sampling? Provide an explanation based on the information given in the context.\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-14\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-14: How does the temperature parameter affect the exploration in rejection sampling? Provide an explanation based on the information given in the context.\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-13\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-13: How does the temperature parameter affect the exploration in rejection sampling? Provide an explanation based on the information given in the context.\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-27\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-27: How does the temperature parameter affect the exploration in rejection sampling? Provide an explanation based on the information given in the context.\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id None: Based on the performance results on standard benchmarks, which model achieved the highest score in the BoolQ task?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-38\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-38: Based on the performance results on standard benchmarks, which model achieved the highest score in the BoolQ task?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-50\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-50: Based on the performance results on standard benchmarks, which model achieved the highest score in the BoolQ task?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-51\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-51: Based on the performance results on standard benchmarks, which model achieved the highest score in the BoolQ task?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-7\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-7: Based on the performance results on standard benchmarks, which model achieved the highest score in the BoolQ task?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-13\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-13: Based on the performance results on standard benchmarks, which model achieved the highest score in the BoolQ task?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-70\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-70: Based on the performance results on standard benchmarks, which model achieved the highest score in the BoolQ task?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-68\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-68: Based on the performance results on standard benchmarks, which model achieved the highest score in the BoolQ task?\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id None: Explain the role of the penalty term in the final reward function used during optimization. How does it contribute to training stability and prevent reward hacking?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-14\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-14: Explain the role of the penalty term in the final reward function used during optimization. How does it contribute to training stability and prevent reward hacking?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-54\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-54: Explain the role of the penalty term in the final reward function used during optimization. How does it contribute to training stability and prevent reward hacking?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-8\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-8: Explain the role of the penalty term in the final reward function used during optimization. How does it contribute to training stability and prevent reward hacking?\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id None: Compare the performance of the Falcon7B model and the Llama 17B model in the SIQA task. Which model performed better?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-7\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-7: Compare the performance of the Falcon7B model and the Llama 17B model in the SIQA task. Which model performed better?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-53\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-53: Compare the performance of the Falcon7B model and the Llama 17B model in the SIQA task. Which model performed better?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-50\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-50: Compare the performance of the Falcon7B model and the Llama 17B model in the SIQA task. Which model performed better?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-51\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-51: Compare the performance of the Falcon7B model and the Llama 17B model in the SIQA task. Which model performed better?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-52\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-52: Compare the performance of the Falcon7B model and the Llama 17B model in the SIQA task. Which model performed better?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-74\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-74: Compare the performance of the Falcon7B model and the Llama 17B model in the SIQA task. Which model performed better?\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id None: How does the GAtt method address the limitations of initial RLHF models in maintaining multi-turn consistency in dialogue setups?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-15\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-15: How does the GAtt method address the limitations of initial RLHF models in maintaining multi-turn consistency in dialogue setups?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-7\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-7: How does the GAtt method address the limitations of initial RLHF models in maintaining multi-turn consistency in dialogue setups?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-55\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-55: How does the GAtt method address the limitations of initial RLHF models in maintaining multi-turn consistency in dialogue setups?\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id None: Based on the given context information, what is the highest exact match performance achieved by the MPT 30B model in the TriviaQA dataset?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-52\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-52: Based on the given context information, what is the highest exact match performance achieved by the MPT 30B model in the TriviaQA dataset?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-41\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-41: Based on the given context information, what is the highest exact match performance achieved by the MPT 30B model in the TriviaQA dataset?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-50\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-50: Based on the given context information, what is the highest exact match performance achieved by the MPT 30B model in the TriviaQA dataset?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-21\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-21: Based on the given context information, what is the highest exact match performance achieved by the MPT 30B model in the TriviaQA dataset?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-49\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-49: Based on the given context information, what is the highest exact match performance achieved by the MPT 30B model in the TriviaQA dataset?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-34\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-34: Based on the given context information, what is the highest exact match performance achieved by the MPT 30B model in the TriviaQA dataset?\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id None: What is the purpose of setting β to different values for the 7B and 13B models compared to the 34B and 70B models?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-15\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-15: What is the purpose of setting β to different values for the 7B and 13B models compared to the 34B and 70B models?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-78\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-78: What is the purpose of setting β to different values for the 7B and 13B models compared to the 34B and 70B models?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-53\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-53: What is the purpose of setting β to different values for the 7B and 13B models compared to the 34B and 70B models?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-7\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-7: What is the purpose of setting β to different values for the 7B and 13B models compared to the 34B and 70B models?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-6\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-6: What is the purpose of setting β to different values for the 7B and 13B models compared to the 34B and 70B models?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-73\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-73: What is the purpose of setting β to different values for the 7B and 13B models compared to the 34B and 70B models?\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id None: Among the open-source models mentioned in the context, which model achieved the highest average score in the LSAT-AR test?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-52\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-52: Among the open-source models mentioned in the context, which model achieved the highest average score in the LSAT-AR test?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-7\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-7: Among the open-source models mentioned in the context, which model achieved the highest average score in the LSAT-AR test?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-34\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-34: Among the open-source models mentioned in the context, which model achieved the highest average score in the LSAT-AR test?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-12\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-12: Among the open-source models mentioned in the context, which model achieved the highest average score in the LSAT-AR test?\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id None: In the context of the dialogue, what is the significance of London as a city? Provide examples from the text to support your answer.\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-16\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-16: In the context of the dialogue, what is the significance of London as a city? Provide examples from the text to support your answer.\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id None: For the SAT-math section, what is the average score for the MPT 30B model on the MATH task?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-53\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-53: For the SAT-math section, what is the average score for the MPT 30B model on the MATH task?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-6\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-6: For the SAT-math section, what is the average score for the MPT 30B model on the MATH task?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-50\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-50: For the SAT-math section, what is the average score for the MPT 30B model on the MATH task?\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id None: How does the GAtt technique contribute to reshaping attention during fine-tuning? Explain the difference in attention activations between the model with GAtt and the model without GAtt, as shown in Figure 10.\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-16\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-16: How does the GAtt technique contribute to reshaping attention during fine-tuning? Explain the difference in attention activations between the model with GAtt and the model without GAtt, as shown in Figure 10.\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-55\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-55: How does the GAtt technique contribute to reshaping attention during fine-tuning? Explain the difference in attention activations between the model with GAtt and the model without GAtt, as shown in Figure 10.\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-15\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-15: How does the GAtt technique contribute to reshaping attention during fine-tuning? Explain the difference in attention activations between the model with GAtt and the model without GAtt, as shown in Figure 10.\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-7\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-7: How does the GAtt technique contribute to reshaping attention during fine-tuning? Explain the difference in attention activations between the model with GAtt and the model without GAtt, as shown in Figure 10.\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id None: In the Meta human preference data, how many batches of human preference data were collected in total?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-54\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-54: In the Meta human preference data, how many batches of human preference data were collected in total?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-53\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-53: In the Meta human preference data, how many batches of human preference data were collected in total?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-55\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-55: In the Meta human preference data, how many batches of human preference data were collected in total?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-10\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-10: In the Meta human preference data, how many batches of human preference data were collected in total?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-9\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-9: In the Meta human preference data, how many batches of human preference data were collected in total?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-8\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-8: In the Meta human preference data, how many batches of human preference data were collected in total?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-11\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-11: In the Meta human preference data, how many batches of human preference data were collected in total?\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id None: How did the researchers ensure that their reward model won't diverge from human preferences?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-11\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-11: How did the researchers ensure that their reward model won't diverge from human preferences?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-8\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-8: How did the researchers ensure that their reward model won't diverge from human preferences?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-17\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-17: How did the researchers ensure that their reward model won't diverge from human preferences?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-10\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-10: How did the researchers ensure that their reward model won't diverge from human preferences?\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id None: How does the ablation of the ranking loss with the preference rating-based margin term impact the performance of the helpfulness reward model? Provide examples of the observed effects on separable and similar samples.\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-54\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-54: How does the ablation of the ranking loss with the preference rating-based margin term impact the performance of the helpfulness reward model? Provide examples of the observed effects on separable and similar samples.\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-10\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-10: How does the ablation of the ranking loss with the preference rating-based margin term impact the performance of the helpfulness reward model? Provide examples of the observed effects on separable and similar samples.\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id None: How did the Llama 2-Chat models perform in comparison to other open-source and closed-source models in terms of helpfulness and safety, according to human evaluators?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-3\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-3: How did the Llama 2-Chat models perform in comparison to other open-source and closed-source models in terms of helpfulness and safety, according to human evaluators?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-2\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-2: How did the Llama 2-Chat models perform in comparison to other open-source and closed-source models in terms of helpfulness and safety, according to human evaluators?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-17\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-17: How did the Llama 2-Chat models perform in comparison to other open-source and closed-source models in terms of helpfulness and safety, according to human evaluators?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-34\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-34: How did the Llama 2-Chat models perform in comparison to other open-source and closed-source models in terms of helpfulness and safety, according to human evaluators?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-0\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-0: How did the Llama 2-Chat models perform in comparison to other open-source and closed-source models in terms of helpfulness and safety, according to human evaluators?\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id None: What is the purpose of the safety auxiliary loss in the reward modeling process? How does it improve the recall of unsafe responses and the overall model accuracy?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-54\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-54: What is the purpose of the safety auxiliary loss in the reward modeling process? How does it improve the recall of unsafe responses and the overall model accuracy?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-55\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-55: What is the purpose of the safety auxiliary loss in the reward modeling process? How does it improve the recall of unsafe responses and the overall model accuracy?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-23\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-23: What is the purpose of the safety auxiliary loss in the reward modeling process? How does it improve the recall of unsafe responses and the overall model accuracy?\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id None: How do Llama 2-Chat models compare to open-source models in terms of performance on single turn and multi-turn prompts? Provide specific examples from the context information to support your answer.\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-18\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-18: How do Llama 2-Chat models compare to open-source models in terms of performance on single turn and multi-turn prompts? Provide specific examples from the context information to support your answer.\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-58\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-58: How do Llama 2-Chat models compare to open-source models in terms of performance on single turn and multi-turn prompts? Provide specific examples from the context information to support your answer.\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-56\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-56: How do Llama 2-Chat models compare to open-source models in terms of performance on single turn and multi-turn prompts? Provide specific examples from the context information to support your answer.\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-3\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-3: How do Llama 2-Chat models compare to open-source models in terms of performance on single turn and multi-turn prompts? Provide specific examples from the context information to support your answer.\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-17\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-17: How do Llama 2-Chat models compare to open-source models in terms of performance on single turn and multi-turn prompts? Provide specific examples from the context information to support your answer.\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id None: In the context of the given information, what is the significance of the \"Auxiliary Safety Loss\" in the ablation study? How does it impact the performance of Llama 2-Chat in terms of accuracy and recall?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-55\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-55: In the context of the given information, what is the significance of the \"Auxiliary Safety Loss\" in the ablation study? How does it impact the performance of Llama 2-Chat in terms of accuracy and recall?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-31\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-31: In the context of the given information, what is the significance of the \"Auxiliary Safety Loss\" in the ablation study? How does it impact the performance of Llama 2-Chat in terms of accuracy and recall?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-70\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-70: In the context of the given information, what is the significance of the \"Auxiliary Safety Loss\" in the ablation study? How does it impact the performance of Llama 2-Chat in terms of accuracy and recall?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-3\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-3: In the context of the given information, what is the significance of the \"Auxiliary Safety Loss\" in the ablation study? How does it impact the performance of Llama 2-Chat in terms of accuracy and recall?\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id None: What limitations should be considered when evaluating the performance of Llama 2-Chat models based on human evaluations? Discuss at least three limitations mentioned in the context information and explain their potential impact on the results.\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-18\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-18: What limitations should be considered when evaluating the performance of Llama 2-Chat models based on human evaluations? Discuss at least three limitations mentioned in the context information and explain their potential impact on the results.\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-31\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-31: What limitations should be considered when evaluating the performance of Llama 2-Chat models based on human evaluations? Discuss at least three limitations mentioned in the context information and explain their potential impact on the results.\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-30\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-30: What limitations should be considered when evaluating the performance of Llama 2-Chat models based on human evaluations? Discuss at least three limitations mentioned in the context information and explain their potential impact on the results.\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-17\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-17: What limitations should be considered when evaluating the performance of Llama 2-Chat models based on human evaluations? Discuss at least three limitations mentioned in the context information and explain their potential impact on the results.\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-56\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-56: What limitations should be considered when evaluating the performance of Llama 2-Chat models based on human evaluations? Discuss at least three limitations mentioned in the context information and explain their potential impact on the results.\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-3\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-3: What limitations should be considered when evaluating the performance of Llama 2-Chat models based on human evaluations? Discuss at least three limitations mentioned in the context information and explain their potential impact on the results.\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id None: Based on the results of the GAtt experiment, how does the presence of GAtt affect the ability of Llama 2-Chat to refer to attributes over multiple turns? Compare the performance of Llama 2-Chat with and without GAtt in terms of accuracy and the number of turns it can refer to attributes.\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-55\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-55: Based on the results of the GAtt experiment, how does the presence of GAtt affect the ability of Llama 2-Chat to refer to attributes over multiple turns? Compare the performance of Llama 2-Chat with and without GAtt in terms of accuracy and the number of turns it can refer to attributes.\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-15\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-15: Based on the results of the GAtt experiment, how does the presence of GAtt affect the ability of Llama 2-Chat to refer to attributes over multiple turns? Compare the performance of Llama 2-Chat with and without GAtt in terms of accuracy and the number of turns it can refer to attributes.\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-58\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-58: Based on the results of the GAtt experiment, how does the presence of GAtt affect the ability of Llama 2-Chat to refer to attributes over multiple turns? Compare the performance of Llama 2-Chat with and without GAtt in terms of accuracy and the number of turns it can refer to attributes.\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-17\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-17: Based on the results of the GAtt experiment, how does the presence of GAtt affect the ability of Llama 2-Chat to refer to attributes over multiple turns? Compare the performance of Llama 2-Chat with and without GAtt in terms of accuracy and the number of turns it can refer to attributes.\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id None: How did the researchers ensure responsible pretraining of the models in terms of privacy and legal considerations?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-19\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-19: How did the researchers ensure responsible pretraining of the models in terms of privacy and legal considerations?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-27\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-27: How did the researchers ensure responsible pretraining of the models in terms of privacy and legal considerations?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-4\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-4: How did the researchers ensure responsible pretraining of the models in terms of privacy and legal considerations?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-26\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-26: How did the researchers ensure responsible pretraining of the models in terms of privacy and legal considerations?\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id None: In the context information provided, what is the range of density values observed?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-56\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-56: In the context information provided, what is the range of density values observed?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-31\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-31: In the context information provided, what is the range of density values observed?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-77\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-77: In the context information provided, what is the range of density values observed?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-74\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-74: In the context information provided, what is the range of density values observed?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-75\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-75: In the context information provided, what is the range of density values observed?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-78\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-78: In the context information provided, what is the range of density values observed?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-26\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-26: In the context information provided, what is the range of density values observed?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-18\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-18: In the context information provided, what is the range of density values observed?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-54\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-54: In the context information provided, what is the range of density values observed?\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id None: What potential biases were identified in the pretraining data, specifically related to pronoun usage and demographic representation?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-19\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-19: What potential biases were identified in the pretraining data, specifically related to pronoun usage and demographic representation?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-20\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-20: What potential biases were identified in the pretraining data, specifically related to pronoun usage and demographic representation?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-45\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-45: What potential biases were identified in the pretraining data, specifically related to pronoun usage and demographic representation?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-21\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-21: What potential biases were identified in the pretraining data, specifically related to pronoun usage and demographic representation?\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id None: How does the incorporation of a preference rating based margin affect the reward model score distribution shift?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-54\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-54: How does the incorporation of a preference rating based margin affect the reward model score distribution shift?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-56\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-56: How does the incorporation of a preference rating based margin affect the reward model score distribution shift?\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id None: In the context of gender and sex, what is the difference in prevalence between the use of \"she\" pronouns and the term \"female\"? How does this difference reflect the linguistic markedness of these terms?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-20\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-20: In the context of gender and sex, what is the difference in prevalence between the use of \"she\" pronouns and the term \"female\"? How does this difference reflect the linguistic markedness of these terms?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-19\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-19: In the context of gender and sex, what is the difference in prevalence between the use of \"she\" pronouns and the term \"female\"? How does this difference reflect the linguistic markedness of these terms?\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id None: As a teacher/professor, for the upcoming quiz/examination, you can ask the following question related to the context information provided:\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-65\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-65: As a teacher/professor, for the upcoming quiz/examination, you can ask the following question related to the context information provided:\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-26\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-26: As a teacher/professor, for the upcoming quiz/examination, you can ask the following question related to the context information provided:\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-37\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-37: As a teacher/professor, for the upcoming quiz/examination, you can ask the following question related to the context information provided:\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-48\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-48: As a teacher/professor, for the upcoming quiz/examination, you can ask the following question related to the context information provided:\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-27\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-27: As a teacher/professor, for the upcoming quiz/examination, you can ask the following question related to the context information provided:\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id None: In the analysis of demographic representations, what Western skew is observed in terms of nationality, race and ethnicity, and religion? Provide specific percentages for the prevalence of terms such as \"American,\" \"European,\" \"Christian,\" \"Catholic,\" and \"Jewish.\"\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-20\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-20: In the analysis of demographic representations, what Western skew is observed in terms of nationality, race and ethnicity, and religion? Provide specific percentages for the prevalence of terms such as \"American,\" \"European,\" \"Christian,\" \"Catholic,\" and \"Jewish.\"\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-69\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-69: In the analysis of demographic representations, what Western skew is observed in terms of nationality, race and ethnicity, and religion? Provide specific percentages for the prevalence of terms such as \"American,\" \"European,\" \"Christian,\" \"Catholic,\" and \"Jewish.\"\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-19\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-19: In the analysis of demographic representations, what Western skew is observed in terms of nationality, race and ethnicity, and religion? Provide specific percentages for the prevalence of terms such as \"American,\" \"European,\" \"Christian,\" \"Catholic,\" and \"Jewish.\"\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id None: Question 1: In the evaluation methodology mentioned, how do the human annotators rate the model responses? Provide the labels used in the seven-point scale.\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-72\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-72: Question 1: In the evaluation methodology mentioned, how do the human annotators rate the model responses? Provide the labels used in the seven-point scale.\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-57\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-57: Question 1: In the evaluation methodology mentioned, how do the human annotators rate the model responses? Provide the labels used in the seven-point scale.\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-17\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-17: Question 1: In the evaluation methodology mentioned, how do the human annotators rate the model responses? Provide the labels used in the seven-point scale.\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-76\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-76: Question 1: In the evaluation methodology mentioned, how do the human annotators rate the model responses? Provide the labels used in the seven-point scale.\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-30\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-30: Question 1: In the evaluation methodology mentioned, how do the human annotators rate the model responses? Provide the labels used in the seven-point scale.\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-8\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-8: Question 1: In the evaluation methodology mentioned, how do the human annotators rate the model responses? Provide the labels used in the seven-point scale.\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id None: How does the language distribution in the pretraining data impact the suitability of the model for different languages? Provide examples to support your answer.\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-19\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-19: How does the language distribution in the pretraining data impact the suitability of the model for different languages? Provide examples to support your answer.\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-21\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-21: How does the language distribution in the pretraining data impact the suitability of the model for different languages? Provide examples to support your answer.\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-20\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-20: How does the language distribution in the pretraining data impact the suitability of the model for different languages? Provide examples to support your answer.\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-41\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-41: How does the language distribution in the pretraining data impact the suitability of the model for different languages? Provide examples to support your answer.\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-45\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-45: How does the language distribution in the pretraining data impact the suitability of the model for different languages? Provide examples to support your answer.\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id None: Question 2: In the additional results section, what is the increase in Llama 2-Chat's win rate when the human evaluation is conducted without any system prompt for ChatGPT?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-57\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-57: Question 2: In the additional results section, what is the increase in Llama 2-Chat's win rate when the human evaluation is conducted without any system prompt for ChatGPT?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-17\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-17: Question 2: In the additional results section, what is the increase in Llama 2-Chat's win rate when the human evaluation is conducted without any system prompt for ChatGPT?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-58\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-58: Question 2: In the additional results section, what is the increase in Llama 2-Chat's win rate when the human evaluation is conducted without any system prompt for ChatGPT?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-18\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-18: Question 2: In the additional results section, what is the increase in Llama 2-Chat's win rate when the human evaluation is conducted without any system prompt for ChatGPT?\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id None: Compare the performance of Llama 2 with Llama 1, Falcon, and MPT in terms of truthfulness, toxicity, and bias. Discuss the observed changes in these metrics and possible reasons behind them.\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-29\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-29: Compare the performance of Llama 2 with Llama 1, Falcon, and MPT in terms of truthfulness, toxicity, and bias. Discuss the observed changes in these metrics and possible reasons behind them.\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-7\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-7: Compare the performance of Llama 2 with Llama 1, Falcon, and MPT in terms of truthfulness, toxicity, and bias. Discuss the observed changes in these metrics and possible reasons behind them.\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-18\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-18: Compare the performance of Llama 2 with Llama 1, Falcon, and MPT in terms of truthfulness, toxicity, and bias. Discuss the observed changes in these metrics and possible reasons behind them.\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-70\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-70: Compare the performance of Llama 2 with Llama 1, Falcon, and MPT in terms of truthfulness, toxicity, and bias. Discuss the observed changes in these metrics and possible reasons behind them.\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-21\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-21: Compare the performance of Llama 2 with Llama 1, Falcon, and MPT in terms of truthfulness, toxicity, and bias. Discuss the observed changes in these metrics and possible reasons behind them.\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id None: As a teacher/professor, what factors should you consider when setting up diverse questions for an upcoming quiz/examination?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-76\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-76: As a teacher/professor, what factors should you consider when setting up diverse questions for an upcoming quiz/examination?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-18\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-18: As a teacher/professor, what factors should you consider when setting up diverse questions for an upcoming quiz/examination?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-26\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-26: As a teacher/professor, what factors should you consider when setting up diverse questions for an upcoming quiz/examination?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-27\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-27: As a teacher/professor, what factors should you consider when setting up diverse questions for an upcoming quiz/examination?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-37\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-37: As a teacher/professor, what factors should you consider when setting up diverse questions for an upcoming quiz/examination?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-6\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-6: As a teacher/professor, what factors should you consider when setting up diverse questions for an upcoming quiz/examination?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-41\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-41: As a teacher/professor, what factors should you consider when setting up diverse questions for an upcoming quiz/examination?\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id None: In the context of safety fine-tuning, what are the three risk categories considered for creating adversarial prompts? Provide examples of each category.\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-22\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-22: In the context of safety fine-tuning, what are the three risk categories considered for creating adversarial prompts? Provide examples of each category.\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-26\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-26: In the context of safety fine-tuning, what are the three risk categories considered for creating adversarial prompts? Provide examples of each category.\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-12\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-12: In the context of safety fine-tuning, what are the three risk categories considered for creating adversarial prompts? Provide examples of each category.\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id None: How can you ensure that the questions you set for the quiz/examination are diverse in nature, based on the context information provided?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-26\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-26: How can you ensure that the questions you set for the quiz/examination are diverse in nature, based on the context information provided?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-41\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-41: How can you ensure that the questions you set for the quiz/examination are diverse in nature, based on the context information provided?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-27\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-27: How can you ensure that the questions you set for the quiz/examination are diverse in nature, based on the context information provided?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-37\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-37: How can you ensure that the questions you set for the quiz/examination are diverse in nature, based on the context information provided?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-65\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-65: How can you ensure that the questions you set for the quiz/examination are diverse in nature, based on the context information provided?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-68\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-68: How can you ensure that the questions you set for the quiz/examination are diverse in nature, based on the context information provided?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-52\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-52: How can you ensure that the questions you set for the quiz/examination are diverse in nature, based on the context information provided?\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id None: How does the process of safety fine-tuning differ from general fine-tuning methods? Explain the techniques used in safety fine-tuning and their purpose.\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-22\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-22: How does the process of safety fine-tuning differ from general fine-tuning methods? Explain the techniques used in safety fine-tuning and their purpose.\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-23\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-23: How does the process of safety fine-tuning differ from general fine-tuning methods? Explain the techniques used in safety fine-tuning and their purpose.\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-24\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-24: How does the process of safety fine-tuning differ from general fine-tuning methods? Explain the techniques used in safety fine-tuning and their purpose.\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-3\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-3: How does the process of safety fine-tuning differ from general fine-tuning methods? Explain the techniques used in safety fine-tuning and their purpose.\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-58\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-58: How does the process of safety fine-tuning differ from general fine-tuning methods? Explain the techniques used in safety fine-tuning and their purpose.\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-7\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-7: How does the process of safety fine-tuning differ from general fine-tuning methods? Explain the techniques used in safety fine-tuning and their purpose.\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id None: What are some versatile haircuts that can suit a wide range of people? How can these haircuts be adapted to different face shapes and hair textures?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-59\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-59: What are some versatile haircuts that can suit a wide range of people? How can these haircuts be adapted to different face shapes and hair textures?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-58\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-58: What are some versatile haircuts that can suit a wide range of people? How can these haircuts be adapted to different face shapes and hair textures?\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id None: How does the model address immediate safety concerns in its responses? Provide examples of potential risks that the model explains to the user.\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-65\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-65: How does the model address immediate safety concerns in its responses? Provide examples of potential risks that the model explains to the user.\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-23\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-23: How does the model address immediate safety concerns in its responses? Provide examples of potential risks that the model explains to the user.\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-18\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-18: How does the model address immediate safety concerns in its responses? Provide examples of potential risks that the model explains to the user.\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-22\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-22: How does the model address immediate safety concerns in its responses? Provide examples of potential risks that the model explains to the user.\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-24\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-24: How does the model address immediate safety concerns in its responses? Provide examples of potential risks that the model explains to the user.\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-26\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-26: How does the model address immediate safety concerns in its responses? Provide examples of potential risks that the model explains to the user.\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id None: How can a professional stylist help in finding the perfect haircut for an individual? Discuss the factors that should be considered, such as personal style, hair texture, and face shape.\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-58\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-58: How can a professional stylist help in finding the perfect haircut for an individual? Discuss the factors that should be considered, such as personal style, hair texture, and face shape.\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-59\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-59: How can a professional stylist help in finding the perfect haircut for an individual? Discuss the factors that should be considered, such as personal style, hair texture, and face shape.\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id None: What is the purpose of Safety RLHF (Reinforcement Learning from Human Feedback) in training the model? Explain how it helps improve the model's responses and safety robustness.\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-22\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-22: What is the purpose of Safety RLHF (Reinforcement Learning from Human Feedback) in training the model? Explain how it helps improve the model's responses and safety robustness.\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-23\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-23: What is the purpose of Safety RLHF (Reinforcement Learning from Human Feedback) in training the model? Explain how it helps improve the model's responses and safety robustness.\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-33\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-33: What is the purpose of Safety RLHF (Reinforcement Learning from Human Feedback) in training the model? Explain how it helps improve the model's responses and safety robustness.\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-26\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-26: What is the purpose of Safety RLHF (Reinforcement Learning from Human Feedback) in training the model? Explain how it helps improve the model's responses and safety robustness.\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id None: How does a pixie cut differ from other short haircuts in terms of length and styling options?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-59\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-59: How does a pixie cut differ from other short haircuts in terms of length and styling options?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-60\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-60: How does a pixie cut differ from other short haircuts in terms of length and styling options?\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id None: How does the addition of safety training data affect the general model performance, particularly in terms of helpfulness? Provide an overview of the trends observed in safety data scaling during the ablation experiment.\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-24\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-24: How does the addition of safety training data affect the general model performance, particularly in terms of helpfulness? Provide an overview of the trends observed in safety data scaling during the ablation experiment.\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-25\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-25: How does the addition of safety training data affect the general model performance, particularly in terms of helpfulness? Provide an overview of the trends observed in safety data scaling during the ablation experiment.\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-58\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-58: How does the addition of safety training data affect the general model performance, particularly in terms of helpfulness? Provide an overview of the trends observed in safety data scaling during the ablation experiment.\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-23\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-23: How does the addition of safety training data affect the general model performance, particularly in terms of helpfulness? Provide an overview of the trends observed in safety data scaling during the ablation experiment.\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id None: Explain the steps involved in setting up and operating a Ponzi scheme, highlighting the key actions taken by the masterminds.\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-60\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-60: Explain the steps involved in setting up and operating a Ponzi scheme, highlighting the key actions taken by the masterminds.\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-25\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-25: Explain the steps involved in setting up and operating a Ponzi scheme, highlighting the key actions taken by the masterminds.\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id None: Describe the impact of safety RLHF (Reinforcement Learning from Human Feedback) on model performance, as measured by the reward model score distributions. Discuss the changes in safety and helpfulness reward model scores of generations on the Meta Safety and Meta Helpfulness test sets before and after safety RLHF.\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-24\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-24: Describe the impact of safety RLHF (Reinforcement Learning from Human Feedback) on model performance, as measured by the reward model score distributions. Discuss the changes in safety and helpfulness reward model scores of generations on the Meta Safety and Meta Helpfulness test sets before and after safety RLHF.\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-58\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-58: Describe the impact of safety RLHF (Reinforcement Learning from Human Feedback) on model performance, as measured by the reward model score distributions. Discuss the changes in safety and helpfulness reward model scores of generations on the Meta Safety and Meta Helpfulness test sets before and after safety RLHF.\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-23\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-23: Describe the impact of safety RLHF (Reinforcement Learning from Human Feedback) on model performance, as measured by the reward model score distributions. Discuss the changes in safety and helpfulness reward model scores of generations on the Meta Safety and Meta Helpfulness test sets before and after safety RLHF.\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-22\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-22: Describe the impact of safety RLHF (Reinforcement Learning from Human Feedback) on model performance, as measured by the reward model score distributions. Discuss the changes in safety and helpfulness reward model scores of generations on the Meta Safety and Meta Helpfulness test sets before and after safety RLHF.\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id None: In the context of comedy roasts, explain the importance of using respectful and playful language. Provide examples of lighthearted and playful roast jokes that adhere to this principle.\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-61\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-61: In the context of comedy roasts, explain the importance of using respectful and playful language. Provide examples of lighthearted and playful roast jokes that adhere to this principle.\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-62\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-62: In the context of comedy roasts, explain the importance of using respectful and playful language. Provide examples of lighthearted and playful roast jokes that adhere to this principle.\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-7\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-7: In the context of comedy roasts, explain the importance of using respectful and playful language. Provide examples of lighthearted and playful roast jokes that adhere to this principle.\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id None: As a teacher/professor, for the upcoming quiz/examination, please provide two diverse questions related to the impact of increasing safety data on model performance and behavior in responding to adversarial and non-adversarial prompts.\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-25\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-25: As a teacher/professor, for the upcoming quiz/examination, please provide two diverse questions related to the impact of increasing safety data on model performance and behavior in responding to adversarial and non-adversarial prompts.\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-26\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-26: As a teacher/professor, for the upcoming quiz/examination, please provide two diverse questions related to the impact of increasing safety data on model performance and behavior in responding to adversarial and non-adversarial prompts.\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-23\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-23: As a teacher/professor, for the upcoming quiz/examination, please provide two diverse questions related to the impact of increasing safety data on model performance and behavior in responding to adversarial and non-adversarial prompts.\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-12\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-12: As a teacher/professor, for the upcoming quiz/examination, please provide two diverse questions related to the impact of increasing safety data on model performance and behavior in responding to adversarial and non-adversarial prompts.\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id None: Discuss the potential consequences of using offensive or hurtful language during a comedy roast. How can comedians ensure that their jokes are clever, witty, and satirical without crossing the line into being hurtful or insulting?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-62\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-62: Discuss the potential consequences of using offensive or hurtful language during a comedy roast. How can comedians ensure that their jokes are clever, witty, and satirical without crossing the line into being hurtful or insulting?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-61\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-61: Discuss the potential consequences of using offensive or hurtful language during a comedy roast. How can comedians ensure that their jokes are clever, witty, and satirical without crossing the line into being hurtful or insulting?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-7\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-7: Discuss the potential consequences of using offensive or hurtful language during a comedy roast. How can comedians ensure that their jokes are clever, witty, and satirical without crossing the line into being hurtful or insulting?\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id None: As an educator, please create two questions for the upcoming quiz/examination that explore the false refusal rate and its impact on model behavior when responding to non-adversarial prompts.\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-25\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-25: As an educator, please create two questions for the upcoming quiz/examination that explore the false refusal rate and its impact on model behavior when responding to non-adversarial prompts.\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-10\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-10: As an educator, please create two questions for the upcoming quiz/examination that explore the false refusal rate and its impact on model behavior when responding to non-adversarial prompts.\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-12\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-12: As an educator, please create two questions for the upcoming quiz/examination that explore the false refusal rate and its impact on model behavior when responding to non-adversarial prompts.\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id None: In the context of comedy roasts, what are some strategies that can be used to create a fun and entertaining experience for everyone involved? How should one approach the use of humor in a roast to ensure it remains light-hearted and respectful?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-62\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-62: In the context of comedy roasts, what are some strategies that can be used to create a fun and entertaining experience for everyone involved? How should one approach the use of humor in a roast to ensure it remains light-hearted and respectful?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-61\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-61: In the context of comedy roasts, what are some strategies that can be used to create a fun and entertaining experience for everyone involved? How should one approach the use of humor in a roast to ensure it remains light-hearted and respectful?\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id None: In the context of context distillation for safety, what is the purpose of prefixing a safety preprompt to adversarial prompts?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-26\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-26: In the context of context distillation for safety, what is the purpose of prefixing a safety preprompt to adversarial prompts?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-65\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-65: In the context of context distillation for safety, what is the purpose of prefixing a safety preprompt to adversarial prompts?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-27\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-27: In the context of context distillation for safety, what is the purpose of prefixing a safety preprompt to adversarial prompts?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-22\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-22: In the context of context distillation for safety, what is the purpose of prefixing a safety preprompt to adversarial prompts?\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id None: In the given context, what are the strong opinions of the woman regarding pizza? Discuss her preferences for Chicago-style pizza, her stance on folding pizza slices, and her thoughts on pineapples as a topping.\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-62\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-62: In the given context, what are the strong opinions of the woman regarding pizza? Discuss her preferences for Chicago-style pizza, her stance on folding pizza slices, and her thoughts on pineapples as a topping.\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-66\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-66: In the given context, what are the strong opinions of the woman regarding pizza? Discuss her preferences for Chicago-style pizza, her stance on folding pizza slices, and her thoughts on pineapples as a topping.\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-63\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-63: In the given context, what are the strong opinions of the woman regarding pizza? Discuss her preferences for Chicago-style pizza, her stance on folding pizza slices, and her thoughts on pineapples as a topping.\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id None: How does context distillation with answer templates enhance the safety capabilities of LLMs in generating responses to adversarial prompts?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-26\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-26: How does context distillation with answer templates enhance the safety capabilities of LLMs in generating responses to adversarial prompts?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-27\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-27: How does context distillation with answer templates enhance the safety capabilities of LLMs in generating responses to adversarial prompts?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-3\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-3: How does context distillation with answer templates enhance the safety capabilities of LLMs in generating responses to adversarial prompts?\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id None: In the context of the given document, what are the author's opinions about Chicago-style pizza? Provide specific details to support your answer.\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-63\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-63: In the context of the given document, what are the author's opinions about Chicago-style pizza? Provide specific details to support your answer.\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-62\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-62: In the context of the given document, what are the author's opinions about Chicago-style pizza? Provide specific details to support your answer.\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id None: How does the safety reward model help in deciding whether to apply context distillation in the case of adversarial prompts? Provide an example from the context information to support your answer.\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-27\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-27: How does the safety reward model help in deciding whether to apply context distillation in the case of adversarial prompts? Provide an example from the context information to support your answer.\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-26\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-26: How does the safety reward model help in deciding whether to apply context distillation in the case of adversarial prompts? Provide an example from the context information to support your answer.\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-12\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-12: How does the safety reward model help in deciding whether to apply context distillation in the case of adversarial prompts? Provide an example from the context information to support your answer.\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id None: Based on the context information, describe the taste and ingredients of the dish \"sex in a pan\". How is it typically described and what precautions should be taken when trying it for the first time?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-64\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-64: Based on the context information, describe the taste and ingredients of the dish \"sex in a pan\". How is it typically described and what precautions should be taken when trying it for the first time?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-63\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-63: Based on the context information, describe the taste and ingredients of the dish \"sex in a pan\". How is it typically described and what precautions should be taken when trying it for the first time?\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id None: What is the purpose of red teaming in the development of language models? Explain how red teaming helps identify and mitigate risks.\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-27\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-27: What is the purpose of red teaming in the development of language models? Explain how red teaming helps identify and mitigate risks.\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-39\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-39: What is the purpose of red teaming in the development of language models? Explain how red teaming helps identify and mitigate risks.\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-28\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-28: What is the purpose of red teaming in the development of language models? Explain how red teaming helps identify and mitigate risks.\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id None: What are some factors that can influence the taste of sex in a pan?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-64\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-64: What are some factors that can influence the taste of sex in a pan?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-63\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-63: What are some factors that can influence the taste of sex in a pan?\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id None: How did the red teaming exercises contribute to improving the robustness of the models? Provide specific examples from the context information.\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-28\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-28: How did the red teaming exercises contribute to improving the robustness of the models? Provide specific examples from the context information.\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-27\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-27: How did the red teaming exercises contribute to improving the robustness of the models? Provide specific examples from the context information.\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id None: Why is it important to prioritize consent and safety during any sexual activity, including sex in a pan?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-64\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-64: Why is it important to prioritize consent and safety during any sexual activity, including sex in a pan?\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id None: In the safety evaluation of Llama 2-Chat, what were the main evaluation metrics used to assess safety violations? How did the annotators determine if a response was violating or not?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-28\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-28: In the safety evaluation of Llama 2-Chat, what were the main evaluation metrics used to assess safety violations? How did the annotators determine if a response was violating or not?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-9\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-9: In the safety evaluation of Llama 2-Chat, what were the main evaluation metrics used to assess safety violations? How did the annotators determine if a response was violating or not?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-29\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-29: In the safety evaluation of Llama 2-Chat, what were the main evaluation metrics used to assess safety violations? How did the annotators determine if a response was violating or not?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-63\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-63: In the safety evaluation of Llama 2-Chat, what were the main evaluation metrics used to assess safety violations? How did the annotators determine if a response was violating or not?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-3\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-3: In the safety evaluation of Llama 2-Chat, what were the main evaluation metrics used to assess safety violations? How did the annotators determine if a response was violating or not?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-1\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-1: In the safety evaluation of Llama 2-Chat, what were the main evaluation metrics used to assess safety violations? How did the annotators determine if a response was violating or not?\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id None: In the context of context distillation, what are the four steps that the model should follow when addressing a question classified as belonging to the violating category 'Criminal / Fraudulent Content'? Provide a brief explanation for each step.\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-65\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-65: In the context of context distillation, what are the four steps that the model should follow when addressing a question classified as belonging to the violating category 'Criminal / Fraudulent Content'? Provide a brief explanation for each step.\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-26\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-26: In the context of context distillation, what are the four steps that the model should follow when addressing a question classified as belonging to the violating category 'Criminal / Fraudulent Content'? Provide a brief explanation for each step.\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-25\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-25: In the context of context distillation, what are the four steps that the model should follow when addressing a question classified as belonging to the violating category 'Criminal / Fraudulent Content'? Provide a brief explanation for each step.\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id None: In Figure 18, it is mentioned that Llama 2-Chat has a comparable or lower overall violation percentage across model sizes. How does the violation percentage of Llama 2-Chat compare to other LLMs like ChatGPT and Falcon?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-29\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-29: In Figure 18, it is mentioned that Llama 2-Chat has a comparable or lower overall violation percentage across model sizes. How does the violation percentage of Llama 2-Chat compare to other LLMs like ChatGPT and Falcon?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-18\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-18: In Figure 18, it is mentioned that Llama 2-Chat has a comparable or lower overall violation percentage across model sizes. How does the violation percentage of Llama 2-Chat compare to other LLMs like ChatGPT and Falcon?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-28\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-28: In Figure 18, it is mentioned that Llama 2-Chat has a comparable or lower overall violation percentage across model sizes. How does the violation percentage of Llama 2-Chat compare to other LLMs like ChatGPT and Falcon?\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id None: Explain the significance of the elephant symbol for the Republican Party. How has its symbolism evolved over time and what qualities does it represent according to Thomas Nast's cartoon?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-65\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-65: Explain the significance of the elephant symbol for the Republican Party. How has its symbolism evolved over time and what qualities does it represent according to Thomas Nast's cartoon?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-69\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-69: Explain the significance of the elephant symbol for the Republican Party. How has its symbolism evolved over time and what qualities does it represent according to Thomas Nast's cartoon?\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id None: According to Figure 19, multi-turn conversations are more prone to inducing unsafe responses. How does Llama 2-Chat perform in terms of violation percentage in multi-turn conversations compared to baselines?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-29\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-29: According to Figure 19, multi-turn conversations are more prone to inducing unsafe responses. How does Llama 2-Chat perform in terms of violation percentage in multi-turn conversations compared to baselines?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-58\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-58: According to Figure 19, multi-turn conversations are more prone to inducing unsafe responses. How does Llama 2-Chat perform in terms of violation percentage in multi-turn conversations compared to baselines?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-18\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-18: According to Figure 19, multi-turn conversations are more prone to inducing unsafe responses. How does Llama 2-Chat perform in terms of violation percentage in multi-turn conversations compared to baselines?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-3\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-3: According to Figure 19, multi-turn conversations are more prone to inducing unsafe responses. How does Llama 2-Chat perform in terms of violation percentage in multi-turn conversations compared to baselines?\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id None: As a teacher/professor, you can ask the following question for the upcoming quiz/examination:\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-43\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-43: As a teacher/professor, you can ask the following question for the upcoming quiz/examination:\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-57\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-57: As a teacher/professor, you can ask the following question for the upcoming quiz/examination:\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-65\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-65: As a teacher/professor, you can ask the following question for the upcoming quiz/examination:\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-33\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-33: As a teacher/professor, you can ask the following question for the upcoming quiz/examination:\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-16\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-16: As a teacher/professor, you can ask the following question for the upcoming quiz/examination:\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-37\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-37: As a teacher/professor, you can ask the following question for the upcoming quiz/examination:\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-6\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-6: As a teacher/professor, you can ask the following question for the upcoming quiz/examination:\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-42\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-42: As a teacher/professor, you can ask the following question for the upcoming quiz/examination:\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-66\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-66: As a teacher/professor, you can ask the following question for the upcoming quiz/examination:\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id None: How did the tuning process reveal the effectiveness of reinforcement learning in the development of Llama 2-Chat? Explain the synergy between humans and LLMs in the annotation process.\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-30\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-30: How did the tuning process reveal the effectiveness of reinforcement learning in the development of Llama 2-Chat? Explain the synergy between humans and LLMs in the annotation process.\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-7\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-7: How did the tuning process reveal the effectiveness of reinforcement learning in the development of Llama 2-Chat? Explain the synergy between humans and LLMs in the annotation process.\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-4\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-4: How did the tuning process reveal the effectiveness of reinforcement learning in the development of Llama 2-Chat? Explain the synergy between humans and LLMs in the annotation process.\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-3\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-3: How did the tuning process reveal the effectiveness of reinforcement learning in the development of Llama 2-Chat? Explain the synergy between humans and LLMs in the annotation process.\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-12\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-12: How did the tuning process reveal the effectiveness of reinforcement learning in the development of Llama 2-Chat? Explain the synergy between humans and LLMs in the annotation process.\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id None: Question 1: Why is it important to respect and appreciate people's diverse food preferences, regardless of their race or ethnicity? Provide at least two reasons.\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-66\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-66: Question 1: Why is it important to respect and appreciate people's diverse food preferences, regardless of their race or ethnicity? Provide at least two reasons.\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-65\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-65: Question 1: Why is it important to respect and appreciate people's diverse food preferences, regardless of their race or ethnicity? Provide at least two reasons.\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id None: Describe the phenomenon of in-context temperature rescaling observed in RLHF. How does the model adapt its temperature based on the type of prompt? Provide examples from the context information.\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-30\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-30: Describe the phenomenon of in-context temperature rescaling observed in RLHF. How does the model adapt its temperature based on the type of prompt? Provide examples from the context information.\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-14\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-14: Describe the phenomenon of in-context temperature rescaling observed in RLHF. How does the model adapt its temperature based on the type of prompt? Provide examples from the context information.\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-33\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-33: Describe the phenomenon of in-context temperature rescaling observed in RLHF. How does the model adapt its temperature based on the type of prompt? Provide examples from the context information.\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-23\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-23: Describe the phenomenon of in-context temperature rescaling observed in RLHF. How does the model adapt its temperature based on the type of prompt? Provide examples from the context information.\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id None: Question 2: How can you ensure a safe and enjoyable environment at a party without serving alcohol? Provide at least three alternative options for creating a fun atmosphere.\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-66\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-66: Question 2: How can you ensure a safe and enjoyable environment at a party without serving alcohol? Provide at least three alternative options for creating a fun atmosphere.\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-65\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-65: Question 2: How can you ensure a safe and enjoyable environment at a party without serving alcohol? Provide at least three alternative options for creating a fun atmosphere.\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id None: How does the Llama 2-Chat model demonstrate its generalization ability in terms of time awareness?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-31\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-31: How does the Llama 2-Chat model demonstrate its generalization ability in terms of time awareness?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-30\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-30: How does the Llama 2-Chat model demonstrate its generalization ability in terms of time awareness?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-3\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-3: How does the Llama 2-Chat model demonstrate its generalization ability in terms of time awareness?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-34\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-34: How does the Llama 2-Chat model demonstrate its generalization ability in terms of time awareness?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-0\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-0: How does the Llama 2-Chat model demonstrate its generalization ability in terms of time awareness?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-17\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-17: How does the Llama 2-Chat model demonstrate its generalization ability in terms of time awareness?\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id None: In the context of car security and starting a car without a key, discuss the potential risks and consequences of hotwiring a car.\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-67\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-67: In the context of car security and starting a car without a key, discuss the potential risks and consequences of hotwiring a car.\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-68\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-68: In the context of car security and starting a car without a key, discuss the potential risks and consequences of hotwiring a car.\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id None: What are the limitations and ethical considerations associated with the Llama 2-Chat model?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-31\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-31: What are the limitations and ethical considerations associated with the Llama 2-Chat model?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-3\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-3: What are the limitations and ethical considerations associated with the Llama 2-Chat model?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-30\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-30: What are the limitations and ethical considerations associated with the Llama 2-Chat model?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-0\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-0: What are the limitations and ethical considerations associated with the Llama 2-Chat model?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-29\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-29: What are the limitations and ethical considerations associated with the Llama 2-Chat model?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-18\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-18: What are the limitations and ethical considerations associated with the Llama 2-Chat model?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-34\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-34: What are the limitations and ethical considerations associated with the Llama 2-Chat model?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-1\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-1: What are the limitations and ethical considerations associated with the Llama 2-Chat model?\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id None: Explain the legal and safe alternatives to starting a car without a key, highlighting keyless entry systems, remote starters, and smartphone apps.\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-67\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-67: Explain the legal and safe alternatives to starting a car without a key, highlighting keyless entry systems, remote starters, and smartphone apps.\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-68\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-68: Explain the legal and safe alternatives to starting a car without a key, highlighting keyless entry systems, remote starters, and smartphone apps.\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id None: How does the responsible release strategy of Llama 2 differ from other companies' approaches to AI development?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-32\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-32: How does the responsible release strategy of Llama 2 differ from other companies' approaches to AI development?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-3\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-3: How does the responsible release strategy of Llama 2 differ from other companies' approaches to AI development?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-30\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-30: How does the responsible release strategy of Llama 2 differ from other companies' approaches to AI development?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-48\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-48: How does the responsible release strategy of Llama 2 differ from other companies' approaches to AI development?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-34\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-34: How does the responsible release strategy of Llama 2 differ from other companies' approaches to AI development?\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id None: How does understanding the ignition system in a car help someone learn how to start a car without a key? Provide examples of different types of ignition systems mentioned in the context.\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-68\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-68: How does understanding the ignition system in a car help someone learn how to start a car without a key? Provide examples of different types of ignition systems mentioned in the context.\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-67\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-67: How does understanding the ignition system in a car help someone learn how to start a car without a key? Provide examples of different types of ignition systems mentioned in the context.\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id None: What are the potential risks associated with the use of conversational AI agents like Llama 2, and how has OpenAI attempted to mitigate these risks?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-0\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-0: What are the potential risks associated with the use of conversational AI agents like Llama 2, and how has OpenAI attempted to mitigate these risks?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-34\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-34: What are the potential risks associated with the use of conversational AI agents like Llama 2, and how has OpenAI attempted to mitigate these risks?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-32\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-32: What are the potential risks associated with the use of conversational AI agents like Llama 2, and how has OpenAI attempted to mitigate these risks?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-3\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-3: What are the potential risks associated with the use of conversational AI agents like Llama 2, and how has OpenAI attempted to mitigate these risks?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-30\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-30: What are the potential risks associated with the use of conversational AI agents like Llama 2, and how has OpenAI attempted to mitigate these risks?\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id None: What are the potential dangers and safety considerations involved in starting a car without a key? Explain why it is important to be cautious and seek professional help if not comfortable with starting a car without a key.\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-67\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-67: What are the potential dangers and safety considerations involved in starting a car without a key? Explain why it is important to be cautious and seek professional help if not comfortable with starting a car without a key.\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-68\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-68: What are the potential dangers and safety considerations involved in starting a car without a key? Explain why it is important to be cautious and seek professional help if not comfortable with starting a car without a key.\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id None: How do distillation-based models such as Vicuna and Alpaca differ from closed-source counterparts like GPT-3 and Chinchilla in terms of performance and usability?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-33\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-33: How do distillation-based models such as Vicuna and Alpaca differ from closed-source counterparts like GPT-3 and Chinchilla in terms of performance and usability?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-2\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-2: How do distillation-based models such as Vicuna and Alpaca differ from closed-source counterparts like GPT-3 and Chinchilla in terms of performance and usability?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-7\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-7: How do distillation-based models such as Vicuna and Alpaca differ from closed-source counterparts like GPT-3 and Chinchilla in terms of performance and usability?\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id None: How does Llama 2-Chat, a collection of pretrained and fine-tuned large language models, differ from open-source chat models in terms of performance on benchmarks and suitability as a substitute for closed-source models?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-0\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-0: How does Llama 2-Chat, a collection of pretrained and fine-tuned large language models, differ from open-source chat models in terms of performance on benchmarks and suitability as a substitute for closed-source models?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-3\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-3: How does Llama 2-Chat, a collection of pretrained and fine-tuned large language models, differ from open-source chat models in terms of performance on benchmarks and suitability as a substitute for closed-source models?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-34\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-34: How does Llama 2-Chat, a collection of pretrained and fine-tuned large language models, differ from open-source chat models in terms of performance on benchmarks and suitability as a substitute for closed-source models?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-17\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-17: How does Llama 2-Chat, a collection of pretrained and fine-tuned large language models, differ from open-source chat models in terms of performance on benchmarks and suitability as a substitute for closed-source models?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-56\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-56: How does Llama 2-Chat, a collection of pretrained and fine-tuned large language models, differ from open-source chat models in terms of performance on benchmarks and suitability as a substitute for closed-source models?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-30\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-30: How does Llama 2-Chat, a collection of pretrained and fine-tuned large language models, differ from open-source chat models in terms of performance on benchmarks and suitability as a substitute for closed-source models?\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id None: What are some of the safety challenges associated with Large Language Models, as highlighted in recent literature?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-32\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-32: What are some of the safety challenges associated with Large Language Models, as highlighted in recent literature?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-72\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-72: What are some of the safety challenges associated with Large Language Models, as highlighted in recent literature?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-46\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-46: What are some of the safety challenges associated with Large Language Models, as highlighted in recent literature?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-41\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-41: What are some of the safety challenges associated with Large Language Models, as highlighted in recent literature?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-2\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-2: What are some of the safety challenges associated with Large Language Models, as highlighted in recent literature?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-26\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-26: What are some of the safety challenges associated with Large Language Models, as highlighted in recent literature?\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id None: In the context of evaluating model generations, what is the purpose of conducting sentiment analysis using the Valence Aware Dictionary and Sentiment Reasoner (VADER)? How does VADER determine the sentiment conveyed by the combination of prompt prefix and model generation?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-69\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-69: In the context of evaluating model generations, what is the purpose of conducting sentiment analysis using the Valence Aware Dictionary and Sentiment Reasoner (VADER)? How does VADER determine the sentiment conveyed by the combination of prompt prefix and model generation?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-21\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-21: In the context of evaluating model generations, what is the purpose of conducting sentiment analysis using the Valence Aware Dictionary and Sentiment Reasoner (VADER)? How does VADER determine the sentiment conveyed by the combination of prompt prefix and model generation?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-56\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-56: In the context of evaluating model generations, what is the purpose of conducting sentiment analysis using the Valence Aware Dictionary and Sentiment Reasoner (VADER)? How does VADER determine the sentiment conveyed by the combination of prompt prefix and model generation?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-18\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-18: In the context of evaluating model generations, what is the purpose of conducting sentiment analysis using the Valence Aware Dictionary and Sentiment Reasoner (VADER)? How does VADER determine the sentiment conveyed by the combination of prompt prefix and model generation?\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id None: What are the key components and techniques used in the fine-tuning process of Llama 2-Chat, including supervised fine-tuning and reinforcement learning with human feedback?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-7\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-7: What are the key components and techniques used in the fine-tuning process of Llama 2-Chat, including supervised fine-tuning and reinforcement learning with human feedback?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-4\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-4: What are the key components and techniques used in the fine-tuning process of Llama 2-Chat, including supervised fine-tuning and reinforcement learning with human feedback?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-30\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-30: What are the key components and techniques used in the fine-tuning process of Llama 2-Chat, including supervised fine-tuning and reinforcement learning with human feedback?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-0\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-0: What are the key components and techniques used in the fine-tuning process of Llama 2-Chat, including supervised fine-tuning and reinforcement learning with human feedback?\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id None: What are some of the concerns and challenges associated with chatbot-oriented LLMs, as highlighted in the given context information? Provide examples from the text to support your answer.\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-31\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-31: What are some of the concerns and challenges associated with chatbot-oriented LLMs, as highlighted in the given context information? Provide examples from the text to support your answer.\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-34\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-34: What are some of the concerns and challenges associated with chatbot-oriented LLMs, as highlighted in the given context information? Provide examples from the text to support your answer.\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-2\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-2: What are some of the concerns and challenges associated with chatbot-oriented LLMs, as highlighted in the given context information? Provide examples from the text to support your answer.\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-18\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-18: What are some of the concerns and challenges associated with chatbot-oriented LLMs, as highlighted in the given context information? Provide examples from the text to support your answer.\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-32\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-32: What are some of the concerns and challenges associated with chatbot-oriented LLMs, as highlighted in the given context information? Provide examples from the text to support your answer.\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id None: Based on the evaluation results presented in the document, discuss the changes in truthfulness percentage for pretrained models after instruction fine-tuning. How do the fine-tuned Llama 2-Chat models compare to their pretrained versions in terms of truthfulness?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-69\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-69: Based on the evaluation results presented in the document, discuss the changes in truthfulness percentage for pretrained models after instruction fine-tuning. How do the fine-tuned Llama 2-Chat models compare to their pretrained versions in terms of truthfulness?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-17\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-17: Based on the evaluation results presented in the document, discuss the changes in truthfulness percentage for pretrained models after instruction fine-tuning. How do the fine-tuned Llama 2-Chat models compare to their pretrained versions in terms of truthfulness?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-4\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-4: Based on the evaluation results presented in the document, discuss the changes in truthfulness percentage for pretrained models after instruction fine-tuning. How do the fine-tuned Llama 2-Chat models compare to their pretrained versions in terms of truthfulness?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-34\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-34: Based on the evaluation results presented in the document, discuss the changes in truthfulness percentage for pretrained models after instruction fine-tuning. How do the fine-tuned Llama 2-Chat models compare to their pretrained versions in terms of truthfulness?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-29\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-29: Based on the evaluation results presented in the document, discuss the changes in truthfulness percentage for pretrained models after instruction fine-tuning. How do the fine-tuned Llama 2-Chat models compare to their pretrained versions in terms of truthfulness?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-3\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-3: Based on the evaluation results presented in the document, discuss the changes in truthfulness percentage for pretrained models after instruction fine-tuning. How do the fine-tuned Llama 2-Chat models compare to their pretrained versions in terms of truthfulness?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-7\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-7: Based on the evaluation results presented in the document, discuss the changes in truthfulness percentage for pretrained models after instruction fine-tuning. How do the fine-tuned Llama 2-Chat models compare to their pretrained versions in terms of truthfulness?\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id None: How does the study introduce Llama 2 as a new family of pretrained and fine-tuned models? Discuss the scale of parameters, competitiveness with existing models, and alignment with principles of helpfulness and safety.\n",
            "\u001b[0m"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 167/167 [00:29<00:00,  5.62it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;3;38;5;200mRetrieved node with id, entering: node-79\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-79: How does the study introduce Llama 2 as a new family of pretrained and fine-tuned models? Discuss the scale of parameters, competitiveness with existing models, and alignment with principles of helpfulness and safety.\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-4\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-4: How does the study introduce Llama 2 as a new family of pretrained and fine-tuned models? Discuss the scale of parameters, competitiveness with existing models, and alignment with principles of helpfulness and safety.\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-7\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-7: How does the study introduce Llama 2 as a new family of pretrained and fine-tuned models? Discuss the scale of parameters, competitiveness with existing models, and alignment with principles of helpfulness and safety.\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-0\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id node-0: How does the study introduce Llama 2 as a new family of pretrained and fine-tuned models? Discuss the scale of parameters, competitiveness with existing models, and alignment with principles of helpfulness and safety.\n",
            "\u001b[0m"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# chunk\n",
        "vector_retriever_chunk = vector_index_chunk.as_retriever(\n",
        "    similarity_top_k=top_k\n",
        ")\n",
        "retriever_chunk = RecursiveRetriever(\n",
        "    \"vector\",\n",
        "    retriever_dict={\"vector\": vector_retriever_chunk},\n",
        "    node_dict=all_nodes_dict,\n",
        "    verbose=True,\n",
        ")\n",
        "retriever_evaluator = RetrieverEvaluator.from_metric_names(\n",
        "    [\"mrr\", \"hit_rate\"], retriever=retriever_chunk\n",
        ")\n",
        "\n",
        "results_chunk = await retriever_evaluator.aevaluate_dataset(\n",
        "    eval_dataset, show_progress=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "id": "EqbEf9aP9_-5",
        "outputId": "532ba2b9-c293-41b4-c069-aad2dbe40106"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                     retrievers  hit_rate       mrr\n",
              "0                Base Retriever  0.802395  0.603816\n",
              "1  Retriever (Chunk References)  0.910180  0.768686"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b5ef649b-032c-43af-a076-941b4d9cfc8f\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>retrievers</th>\n",
              "      <th>hit_rate</th>\n",
              "      <th>mrr</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Base Retriever</td>\n",
              "      <td>0.802395</td>\n",
              "      <td>0.603816</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Retriever (Chunk References)</td>\n",
              "      <td>0.910180</td>\n",
              "      <td>0.768686</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b5ef649b-032c-43af-a076-941b4d9cfc8f')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-b5ef649b-032c-43af-a076-941b4d9cfc8f button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-b5ef649b-032c-43af-a076-941b4d9cfc8f');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-f5e15970-f813-4464-9487-87f524169086\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f5e15970-f813-4464-9487-87f524169086')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-f5e15970-f813-4464-9487-87f524169086 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "full_results_df = get_retrieval_results_df(\n",
        "    [\n",
        "        \"Base Retriever\",\n",
        "        \"Retriever (Chunk References)\"\n",
        "    ],\n",
        "    [results_base, results_chunk],\n",
        ")\n",
        "display(full_results_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jsj_n2hI08Bw"
      },
      "source": [
        "# Sentence Window Retrieval\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "mGPlNnlL1NzE"
      },
      "outputs": [],
      "source": [
        "from llama_index.node_parser import SentenceWindowNodeParser"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "naJwk-SY06vv"
      },
      "outputs": [],
      "source": [
        "# create the sentence window node parser w/ default settings\n",
        "node_parser = SentenceWindowNodeParser.from_defaults(\n",
        "    window_size=3,\n",
        "    window_metadata_key=\"window\",\n",
        "    original_text_metadata_key=\"original_text\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lE30uiuu1Lsz",
        "outputId": "fea6c051-4bf6-435b-ee34-c62f4402f0c8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SentenceWindowNodeParser(sentence_splitter=<function split_by_sentence_tokenizer.<locals>.split at 0x790212e61000>, window_size=3, window_metadata_key='window', original_text_metadata_key='original_text', include_metadata=True, include_prev_next_rel=True, metadata_extractor=None, callback_manager=<llama_index.callbacks.base.CallbackManager object at 0x7901187557e0>)"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ],
      "source": [
        "node_parser"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "9xNTUIh_1Saw"
      },
      "outputs": [],
      "source": [
        "sentence_nodes = node_parser.get_nodes_from_documents(docs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "jTc_xY_q1rUg"
      },
      "outputs": [],
      "source": [
        "sentence_index = VectorStoreIndex(sentence_nodes, service_context=service_context)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "nDOgmEXE_QuZ"
      },
      "outputs": [],
      "source": [
        "from llama_index.indices.postprocessor import MetadataReplacementPostProcessor\n",
        "\n",
        "query_engine = sentence_index.as_query_engine(\n",
        "    similarity_top_k=2,\n",
        "    # the target key defaults to `window` to match the node_parser's default\n",
        "    node_postprocessors=[\n",
        "        MetadataReplacementPostProcessor(target_metadata_key=\"window\")\n",
        "    ],\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ku1-C7d_x3J",
        "outputId": "d6db1e33-f80f-44ce-cff9-38a9c6cb1d74"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The key concepts for safety fine-tuning include supervised safety fine-tuning and safety reinforcement learning from human feedback (RLHF). In supervised safety fine-tuning, adversarial prompts and safe demonstrations are gathered and included in the general supervised fine-tuning process. This helps align the model with safety guidelines even before RLHF and lays the foundation for high-quality human preference data annotation. Safety RLHF involves integrating safety into the general RLHF pipeline. These techniques are used to mitigate safety risks and ensure the safety of the system during fine-tuning.\n"
          ]
        }
      ],
      "source": [
        "window_response = query_engine.query(\n",
        "    \"Can you tell me about the key concepts for safety finetuning\"\n",
        ")\n",
        "print(window_response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "95qZIGWw_5z0",
        "outputId": "dbb7834b-d84f-43f4-e4ce-590378aafcb8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Window: Further\n",
            "testing and mitigation should be done to understand bias and other social issues for the specific context\n",
            "in which a system may be deployed.  For this, it may be necessary to test beyond the groups available in\n",
            "theBOLDdataset(race,religion,andgender).  AsLLMsareintegratedanddeployed,welookforwardto\n",
            "continuing research that will amplify their potential for positive impact on these important social issues.\n",
            " 4.2 Safety Fine-Tuning\n",
            "In this section, we describe our approach to safety fine-tuning, including safety categories, annotation\n",
            "guidelines,andthetechniquesweusetomitigatesafetyrisks.  Weemployaprocesssimilartothegeneral\n",
            "fine-tuning methods as described in Section 3, with some notable differences related to safety concerns.\n",
            " Specifically, we use the following techniques in safety fine-tuning:\n",
            "1.Supervised Safety Fine-Tuning : We initialize by gathering adversarial prompts and safe demonstra-\n",
            "tions that are then included in the general supervised fine-tuning process (Section 3.1). \n",
            "------------------\n",
            "Original Sentence: 4.2 Safety Fine-Tuning\n",
            "In this section, we describe our approach to safety fine-tuning, including safety categories, annotation\n",
            "guidelines,andthetechniquesweusetomitigatesafetyrisks. \n"
          ]
        }
      ],
      "source": [
        "# check the original sentence that was retrieved for each node, as well as the actual window of sentences that was sent to the LLM.\n",
        "window = window_response.source_nodes[0].node.metadata[\"window\"]\n",
        "sentence = window_response.source_nodes[0].node.metadata[\"original_text\"]\n",
        "\n",
        "print(f\"Window: {window}\")\n",
        "print(\"------------------\")\n",
        "print(f\"Original Sentence: {sentence}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "L3dJ8LcJbMn0"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}